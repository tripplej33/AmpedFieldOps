--- FILE: backend/jest.config.js ---
module.exports = {
  preset: 'ts-jest',
  testEnvironment: 'node',
  roots: ['<rootDir>/src'],
  testMatch: ['**/__tests__/**/*.ts', '**/?(*.)+(spec|test).ts'],
  transform: {
    '^.+\\.ts$': 'ts-jest',
  },
  globals: {
    'ts-jest': {
      tsconfig: {
        types: ['node', 'jest'],
      },
    },
  },
  collectCoverageFrom: [
    'src/**/*.ts',
    '!src/**/*.d.ts',
    '!src/**/*.test.ts',
    '!src/**/*.spec.ts',
    '!src/db/migrate.ts',
    '!src/db/seed.ts',
    '!src/server.ts',
  ],
  coverageDirectory: 'coverage',
  coverageReporters: ['text', 'lcov', 'html'],
  moduleFileExtensions: ['ts', 'js', 'json'],
  testTimeout: 10000,
};
--- FILE: backend/scripts/cleanup-duplicate-activity-types.ts ---
import dotenv from 'dotenv';
import { query } from '../src/db/index';

// Suppress dotenv parsing warnings
dotenv.config({ debug: false, override: false });

/**
 * Cleanup script to remove duplicate activity types
 * Keeps only the most recent entry for each name
 */
async function cleanupDuplicateActivityTypes() {
  console.log('üßπ Cleaning up duplicate activity types...');
  
  try {
    // Find duplicates and keep only the most recent one
    const duplicateResult = await query(`
      WITH ranked_activity_types AS (
        SELECT 
          id,
          name,
          icon,
          color,
          hourly_rate,
          is_active,
          created_at,
          ROW_NUMBER() OVER (
            PARTITION BY LOWER(TRIM(name))
            ORDER BY created_at DESC, id DESC
          ) as rn
        FROM activity_types
      )
      DELETE FROM activity_types
      WHERE id IN (
        SELECT id FROM ranked_activity_types WHERE rn > 1
      )
    `);
    
    console.log(`‚úì Cleaned up duplicate activity types`);
    
    // Show remaining duplicates
    const remainingResult = await query(`
      SELECT LOWER(TRIM(name)) as name_lower, COUNT(*) as count
      FROM activity_types
      GROUP BY LOWER(TRIM(name))
      HAVING COUNT(*) > 1
    `);
    
    if (remainingResult.rows.length > 0) {
      console.warn('‚ö†Ô∏è  Still found duplicates:', remainingResult.rows);
    } else {
      console.log('‚úì No duplicates found');
    }
    
    // Show final count
    const finalCount = await query('SELECT COUNT(*) as count FROM activity_types');
    console.log(`‚úì Total activity types: ${finalCount.rows[0].count}`);
    
    process.exit(0);
  } catch (error: any) {
    console.error('‚ùå Error cleaning up duplicates:', error);
    process.exit(1);
  }
}

cleanupDuplicateActivityTypes();

--- FILE: backend/scripts/cleanup-duplicates.ts ---
import dotenv from 'dotenv';
import { query } from '../src/db/index';

// Suppress dotenv parsing warnings
dotenv.config({ debug: false, override: false });

/**
 * Cleanup script to remove duplicate settings entries
 * Keeps only the most recent entry for each (key, user_id) combination
 */
async function cleanupDuplicateSettings() {
  console.log('üßπ Cleaning up duplicate settings...');
  
  try {
    // Find duplicates and keep only the most recent one
    const duplicateResult = await query(`
      WITH ranked_settings AS (
        SELECT 
          id,
          key,
          user_id,
          value,
          created_at,
          ROW_NUMBER() OVER (
            PARTITION BY key, user_id 
            ORDER BY created_at DESC, id DESC
          ) as rn
        FROM settings
      )
      DELETE FROM settings
      WHERE id IN (
        SELECT id FROM ranked_settings WHERE rn > 1
      )
    `);
    
    console.log(`‚úì Cleaned up duplicate settings`);
    
    // Show remaining settings
    const remainingResult = await query(`
      SELECT key, user_id, COUNT(*) as count
      FROM settings
      GROUP BY key, user_id
      HAVING COUNT(*) > 1
    `);
    
    if (remainingResult.rows.length > 0) {
      console.warn('‚ö†Ô∏è  Still found duplicates:', remainingResult.rows);
    } else {
      console.log('‚úì No duplicates found');
    }
    
    process.exit(0);
  } catch (error: any) {
    console.error('‚ùå Error cleaning up duplicates:', error);
    process.exit(1);
  }
}

cleanupDuplicateSettings();

--- FILE: backend/src/config/cors.ts ---
import { query } from '../db';
import { env } from './env';

// Cache for frontend URL
let cachedFrontendUrl: string | null = null;
let cacheTimestamp: number = 0;
const CACHE_TTL = 60000; // 1 minute cache

/**
 * Extracts the frontend URL from the Xero redirect URI stored in the database.
 * Falls back to FRONTEND_URL env var, then to localhost.
 */
async function getFrontendUrlFromXeroRedirect(): Promise<string> {
  try {
    // Query database for xero_redirect_uri setting
    const result = await query(
      `SELECT value FROM settings WHERE key = 'xero_redirect_uri' AND user_id IS NULL`
    );

    if (result.rows.length > 0 && result.rows[0].value) {
      const redirectUri = result.rows[0].value as string;
      
      try {
        // Parse the redirect URI and extract the origin
        // e.g., https://admin.ampedlogix.com/api/xero/callback -> https://admin.ampedlogix.com
        const redirectUrl = new URL(redirectUri);
        const frontendUrl = redirectUrl.origin;
        
        console.log('[CORS] Using frontend URL from Xero redirect URI:', frontendUrl);
        return frontendUrl;
      } catch (e) {
        console.warn('[CORS] Could not parse redirect URI:', redirectUri, e);
      }
    }
  } catch (error) {
    console.warn('[CORS] Failed to query database for redirect URI, using fallback:', error);
  }

  // Fallback to FRONTEND_URL env var
  if (env.FRONTEND_URL) {
    console.log('[CORS] Using FRONTEND_URL from environment:', env.FRONTEND_URL);
    return env.FRONTEND_URL;
  }

  // Final fallback to localhost
  console.log('[CORS] Using default localhost fallback');
  return 'http://localhost:3000';
}

/**
 * Refreshes the cached frontend URL from the database.
 * This should be called on startup and periodically.
 */
export async function refreshFrontendUrlCache(): Promise<void> {
  try {
    const frontendUrl = await getFrontendUrlFromXeroRedirect();
    cachedFrontendUrl = frontendUrl;
    cacheTimestamp = Date.now();
    console.log('[CORS] Cache refreshed. Frontend URL:', frontendUrl);
  } catch (error) {
    console.error('[CORS] Failed to refresh cache:', error);
    // Keep using existing cache if refresh fails
  }
}

/**
 * Gets the cached frontend URL, refreshing if needed.
 * This is synchronous for use in CORS middleware.
 */
function getCachedFrontendUrl(): string {
  const now = Date.now();
  
  // If cache is expired or missing, use fallback (will be refreshed in background)
  if (!cachedFrontendUrl || (now - cacheTimestamp) > CACHE_TTL) {
    // Use fallback while cache refreshes
    return env.FRONTEND_URL || 'http://localhost:3000';
  }
  
  return cachedFrontendUrl;
}

/**
 * Creates a CORS origin function that dynamically allows requests from
 * the frontend URL extracted from the Xero redirect URI.
 * 
 * The function is synchronous and uses a cached value that's refreshed
 * periodically in the background.
 */
export function createDynamicCorsOrigin() {
  return (origin: string | undefined, callback: (err: Error | null, allow?: boolean) => void) => {
    // Allow requests with no origin (mobile apps, Postman, curl, etc.)
    if (!origin) {
      return callback(null, true);
    }

    // Always allow localhost for development
    if (origin.includes('localhost') || origin.includes('127.0.0.1')) {
      return callback(null, true);
    }

    // Get cached frontend URL
    const frontendUrl = getCachedFrontendUrl();

    // Check if origin matches the frontend URL
    if (origin === frontendUrl) {
      return callback(null, true);
    }

    // Log rejected origins in development
    if (env.NODE_ENV === 'development') {
      console.warn('[CORS] Rejected origin:', origin, 'Expected:', frontendUrl);
    }

    // Reject if no match
    return callback(null, false);
  };
}

/**
 * Initializes the CORS cache on server startup.
 * Should be called once when the server starts.
 */
export async function initializeCorsCache(): Promise<void> {
  await refreshFrontendUrlCache();
  
  // Set up periodic refresh (every minute)
  setInterval(() => {
    refreshFrontendUrlCache().catch(err => {
      console.error('[CORS] Background cache refresh failed:', err);
    });
  }, CACHE_TTL);
}
--- FILE: backend/src/config/env.ts ---
import dotenv from 'dotenv';
import { AUTH_CONSTANTS } from '../lib/constants';

// Load .env file, suppressing parsing warnings (non-critical)
// Warnings about unparseable lines are usually from comments or optional config
dotenv.config({ 
  debug: false,
  override: false 
});

interface EnvConfig {
  // Database
  DATABASE_URL: string;
  
  // Auth
  JWT_SECRET: string;
  
  // Server
  PORT: number;
  NODE_ENV: 'development' | 'production' | 'test';
  FRONTEND_URL: string;
  BACKEND_URL?: string;
  
  // Xero (optional)
  XERO_CLIENT_ID?: string;
  XERO_CLIENT_SECRET?: string;
  XERO_REDIRECT_URI?: string;
  
  // Redis (optional)
  REDIS_HOST?: string;
  REDIS_PORT?: string;
  REDIS_PASSWORD?: string;
  
  // Email/SMTP (optional)
  SMTP_HOST?: string;
  SMTP_PORT?: string;
  SMTP_USER?: string;
  SMTP_PASSWORD?: string;
  SMTP_FROM?: string;
  
  // OCR Service (optional)
  OCR_SERVICE_URL?: string;
}

function getEnvVar(key: string, required = true, defaultValue?: string): string {
  const value = process.env[key] || defaultValue;
  
  if (required && !value) {
    throw new Error(`Missing required environment variable: ${key}`);
  }
  
  return value || '';
}

function validateEnv(): EnvConfig {
  // Validate required variables
  const jwtSecret = getEnvVar('JWT_SECRET');
  if (jwtSecret.length < AUTH_CONSTANTS.MIN_JWT_SECRET_LENGTH) {
    throw new Error(`JWT_SECRET must be at least ${AUTH_CONSTANTS.MIN_JWT_SECRET_LENGTH} characters long`);
  }

  return {
    DATABASE_URL: getEnvVar('DATABASE_URL'),
    JWT_SECRET: jwtSecret,
    PORT: parseInt(getEnvVar('PORT', false, '3001'), 10),
    NODE_ENV: (getEnvVar('NODE_ENV', false, 'development') as 'development' | 'production' | 'test'),
    FRONTEND_URL: getEnvVar('FRONTEND_URL', false, 'http://localhost:5173'),
    BACKEND_URL: getEnvVar('BACKEND_URL', false),
    XERO_CLIENT_ID: getEnvVar('XERO_CLIENT_ID', false),
    XERO_CLIENT_SECRET: getEnvVar('XERO_CLIENT_SECRET', false),
    XERO_REDIRECT_URI: getEnvVar('XERO_REDIRECT_URI', false),
    REDIS_HOST: getEnvVar('REDIS_HOST', false),
    REDIS_PORT: getEnvVar('REDIS_PORT', false),
    REDIS_PASSWORD: getEnvVar('REDIS_PASSWORD', false),
    SMTP_HOST: getEnvVar('SMTP_HOST', false),
    SMTP_PORT: getEnvVar('SMTP_PORT', false),
    SMTP_USER: getEnvVar('SMTP_USER', false),
    SMTP_PASSWORD: getEnvVar('SMTP_PASSWORD', false),
    SMTP_FROM: getEnvVar('SMTP_FROM', false),
    OCR_SERVICE_URL: getEnvVar('OCR_SERVICE_URL', false, 'http://ocr-service:8000'),
  };
}

// Validate on import
export const env = validateEnv();

--- FILE: backend/src/db/ensureXeroTables.ts ---
import { query } from './index';

/**
 * Ensures all Xero-related tables exist
 * Creates them if they don't exist
 */
export async function ensureXeroTables(): Promise<void> {
  const tables = [
    'xero_invoices',
    'xero_quotes',
    'xero_purchase_orders',
    'xero_purchase_order_line_items',
    'xero_bills',
    'xero_expenses',
    'xero_payments',
    'bank_transactions',
    'xero_credit_notes'
  ];

  for (const tableName of tables) {
    try {
      // Check if table exists
      const result = await query(
        `SELECT EXISTS (
          SELECT FROM information_schema.tables 
          WHERE table_schema = 'public' 
          AND table_name = $1
        )`,
        [tableName]
      );

      if (!result.rows[0].exists) {
        console.log(`[Migration] Creating missing table: ${tableName}`);
        await createTable(tableName);
      }
    } catch (error: any) {
      console.error(`[Migration] Error checking/creating table ${tableName}:`, error.message);
    }
  }
}

async function createTable(tableName: string): Promise<void> {
  const tableDefinitions: Record<string, string | string[]> = {
    'xero_invoices': [
      `CREATE TABLE IF NOT EXISTS xero_invoices (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        xero_invoice_id VARCHAR(100) UNIQUE NOT NULL,
        invoice_number VARCHAR(50),
        client_id UUID REFERENCES clients(id) ON DELETE SET NULL,
        project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
        status VARCHAR(50),
        amount_due DECIMAL(15,2),
        amount_paid DECIMAL(15,2),
        total DECIMAL(15,2),
        currency VARCHAR(10) DEFAULT 'USD',
        issue_date DATE,
        due_date DATE,
        line_items JSONB,
        synced_at TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )`,
      `ALTER TABLE xero_invoices ADD COLUMN IF NOT EXISTS paid_date DATE`,
      `ALTER TABLE xero_invoices ADD COLUMN IF NOT EXISTS last_payment_date DATE`
    ],
    'xero_quotes': `
      CREATE TABLE IF NOT EXISTS xero_quotes (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        xero_quote_id VARCHAR(100) UNIQUE NOT NULL,
        quote_number VARCHAR(50),
        client_id UUID REFERENCES clients(id) ON DELETE SET NULL,
        project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
        status VARCHAR(50),
        total DECIMAL(15,2),
        currency VARCHAR(10) DEFAULT 'USD',
        issue_date DATE,
        expiry_date DATE,
        line_items JSONB,
        synced_at TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `,
    'xero_purchase_orders': `
      CREATE TABLE IF NOT EXISTS xero_purchase_orders (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        xero_po_id VARCHAR(100) UNIQUE,
        po_number VARCHAR(50),
        supplier_id UUID REFERENCES clients(id) ON DELETE SET NULL,
        project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
        status VARCHAR(50) DEFAULT 'DRAFT' CHECK (status IN ('DRAFT', 'SUBMITTED', 'AUTHORISED', 'BILLED', 'CANCELLED')),
        date DATE NOT NULL,
        delivery_date DATE,
        total_amount DECIMAL(15,2) DEFAULT 0,
        currency VARCHAR(10) DEFAULT 'USD',
        line_items JSONB,
        bill_id UUID,
        notes TEXT,
        synced_at TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `,
    'xero_purchase_order_line_items': `
      CREATE TABLE IF NOT EXISTS xero_purchase_order_line_items (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        po_id UUID NOT NULL REFERENCES xero_purchase_orders(id) ON DELETE CASCADE,
        description TEXT,
        quantity DECIMAL(10,2),
        unit_amount DECIMAL(15,2),
        account_code VARCHAR(50),
        cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
        item_id UUID,
        line_amount DECIMAL(15,2),
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `,
    'xero_bills': `
      CREATE TABLE IF NOT EXISTS xero_bills (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        xero_bill_id VARCHAR(100) UNIQUE,
        bill_number VARCHAR(50),
        supplier_id UUID REFERENCES clients(id) ON DELETE SET NULL,
        purchase_order_id UUID REFERENCES xero_purchase_orders(id) ON DELETE SET NULL,
        project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
        amount DECIMAL(15,2) NOT NULL,
        amount_paid DECIMAL(15,2) DEFAULT 0,
        amount_due DECIMAL(15,2),
        currency VARCHAR(10) DEFAULT 'USD',
        date DATE NOT NULL,
        due_date DATE,
        status VARCHAR(50) DEFAULT 'AUTHORISED' CHECK (status IN ('DRAFT', 'SUBMITTED', 'AUTHORISED', 'PAID', 'VOIDED')),
        paid_date DATE,
        line_items JSONB,
        synced_at TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `,
    'xero_expenses': `
      CREATE TABLE IF NOT EXISTS xero_expenses (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        xero_expense_id VARCHAR(100) UNIQUE,
        project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
        cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
        amount DECIMAL(15,2) NOT NULL,
        date DATE NOT NULL,
        description TEXT,
        receipt_url TEXT,
        status VARCHAR(50) DEFAULT 'DRAFT' CHECK (status IN ('DRAFT', 'SUBMITTED', 'APPROVED', 'PAID')),
        synced_at TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `,
    'xero_payments': `
      CREATE TABLE IF NOT EXISTS xero_payments (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        xero_payment_id VARCHAR(100) UNIQUE,
        invoice_id UUID REFERENCES xero_invoices(id) ON DELETE SET NULL,
        amount DECIMAL(15,2) NOT NULL,
        payment_date DATE NOT NULL,
        payment_method VARCHAR(50) NOT NULL,
        reference VARCHAR(255),
        bank_transaction_id UUID,
        account_code VARCHAR(50),
        currency VARCHAR(10) DEFAULT 'USD',
        exchange_rate DECIMAL(10,4) DEFAULT 1,
        synced_at TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `,
    'bank_transactions': `
      CREATE TABLE IF NOT EXISTS bank_transactions (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        xero_bank_transaction_id VARCHAR(100) UNIQUE,
        bank_account_code VARCHAR(50),
        bank_account_name VARCHAR(255),
        date DATE NOT NULL,
        amount DECIMAL(15,2) NOT NULL,
        type VARCHAR(20) NOT NULL CHECK (type IN ('RECEIVE', 'SPEND')),
        description TEXT,
        reference VARCHAR(255),
        contact_id UUID REFERENCES clients(id) ON DELETE SET NULL,
        reconciled BOOLEAN DEFAULT false,
        payment_id UUID REFERENCES xero_payments(id) ON DELETE SET NULL,
        reconciled_date DATE,
        synced_at TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `,
    'xero_credit_notes': `
      CREATE TABLE IF NOT EXISTS xero_credit_notes (
        id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
        xero_credit_note_id VARCHAR(100) UNIQUE,
        credit_note_number VARCHAR(50),
        invoice_id UUID REFERENCES xero_invoices(id) ON DELETE SET NULL,
        amount DECIMAL(15,2) NOT NULL,
        date DATE NOT NULL,
        reason TEXT,
        status VARCHAR(50) DEFAULT 'AUTHORISED' CHECK (status IN ('DRAFT', 'SUBMITTED', 'AUTHORISED', 'VOIDED')),
        synced_at TIMESTAMP,
        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
        updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
      )
    `
  };

  const sql = tableDefinitions[tableName];
  if (!sql) {
    throw new Error(`No table definition found for ${tableName}`);
  }

  // Handle both single SQL string and array of SQL statements
  if (Array.isArray(sql)) {
    for (const statement of sql) {
      await query(statement);
    }
  } else {
    await query(sql);
  }
}

--- FILE: backend/src/db/index.ts ---
import { Pool } from 'pg';
import { env } from '../config/env';

/**
 * Determine SSL configuration based on DATABASE_URL and environment
 * - If DATABASE_URL contains sslmode parameter, respect it
 * - For internal Docker networks, SSL is not needed
 * - For external production databases, require proper SSL with certificate validation
 */
function getSslConfig(): boolean | { rejectUnauthorized: boolean } {
  const dbUrl = env.DATABASE_URL.toLowerCase();
  
  // If DATABASE_URL explicitly specifies SSL mode, parse it
  if (dbUrl.includes('sslmode=')) {
    const sslMode = dbUrl.match(/sslmode=([^&]+)/)?.[1];
    
    if (sslMode === 'require' || sslMode === 'prefer') {
      // For require/prefer, use SSL but allow self-signed certs (common in managed services)
      // In production, you should use verify-full with proper certificates
      return { rejectUnauthorized: false };
    }
    
    if (sslMode === 'verify-full' || sslMode === 'verify-ca') {
      // Full certificate validation - most secure
      return { rejectUnauthorized: true };
    }
    
    if (sslMode === 'disable') {
      // Explicitly disabled
      return false;
    }
  }
  
  // For Docker internal networks (localhost, container names, or internal IPs), SSL not needed
  const isInternalNetwork = 
    dbUrl.includes('@localhost') ||
    dbUrl.includes('@127.0.0.1') ||
    dbUrl.includes('@postgres') ||  // Docker service name
    dbUrl.includes('@172.') ||      // Docker internal network
    dbUrl.includes('@10.') ||       // Private network
    dbUrl.includes('@192.168.');    // Private network
  
  if (isInternalNetwork) {
    return false;
  }
  
  // For external production databases without explicit SSL mode, require SSL with validation
  if (env.NODE_ENV === 'production') {
    // Production external database - require SSL with certificate validation
    // Note: For managed services (AWS RDS, Google Cloud SQL, etc.), you may need to
    // set rejectUnauthorized: false and provide CA certificate, or use verify-full mode
    return { rejectUnauthorized: true };
  }
  
  // Development - no SSL by default
  return false;
}

const pool = new Pool({
  connectionString: env.DATABASE_URL,
  ssl: getSslConfig()
});

export const query = (text: string, params?: any[]) => pool.query(text, params);

export const getClient = () => pool.connect();

export default pool;
--- FILE: backend/src/db/migrate.ts ---
import { query, getClient } from './index';
import dotenv from 'dotenv';
import fs from 'fs';
import path from 'path';

// Load .env file, suppressing parsing warnings (non-critical)
dotenv.config({ 
  debug: false,
  override: false 
});

const isFresh = process.argv.includes('--fresh');

const migrations = `
-- Drop tables if fresh migration
${isFresh ? `
DROP TABLE IF EXISTS backups CASCADE;
DROP TABLE IF EXISTS activity_logs CASCADE;
DROP TABLE IF EXISTS settings CASCADE;
DROP TABLE IF EXISTS xero_tokens CASCADE;
DROP TABLE IF EXISTS timesheets CASCADE;
DROP TABLE IF EXISTS projects CASCADE;
DROP TABLE IF EXISTS clients CASCADE;
DROP TABLE IF EXISTS cost_centers CASCADE;
DROP TABLE IF EXISTS activity_types CASCADE;
DROP TABLE IF EXISTS user_permissions CASCADE;
DROP TABLE IF EXISTS permissions CASCADE;
DROP TABLE IF EXISTS users CASCADE;
DROP TABLE IF EXISTS project_files CASCADE;
DROP TABLE IF EXISTS safety_documents CASCADE;
` : ''}

-- Users table
CREATE TABLE IF NOT EXISTS users (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  email VARCHAR(255) UNIQUE NOT NULL,
  password_hash VARCHAR(255) NOT NULL,
  name VARCHAR(255) NOT NULL,
  role VARCHAR(50) NOT NULL DEFAULT 'user' CHECK (role IN ('admin', 'manager', 'user')),
  avatar VARCHAR(500),
  is_active BOOLEAN DEFAULT true,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- User permissions table
CREATE TABLE IF NOT EXISTS user_permissions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  permission VARCHAR(100) NOT NULL,
  granted BOOLEAN DEFAULT true,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  UNIQUE(user_id, permission)
);

-- Activity Types table
CREATE TABLE IF NOT EXISTS activity_types (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(100) NOT NULL,
  icon VARCHAR(50) NOT NULL DEFAULT 'Wrench',
  color VARCHAR(100) NOT NULL DEFAULT 'bg-electric/20 border-electric text-electric',
  hourly_rate DECIMAL(10,2) DEFAULT 0,
  is_active BOOLEAN DEFAULT true,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Cost Centers table
CREATE TABLE IF NOT EXISTS cost_centers (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  code VARCHAR(20) UNIQUE NOT NULL,
  name VARCHAR(255) NOT NULL,
  description TEXT,
  budget DECIMAL(15,2) DEFAULT 0,
  xero_tracking_category_id VARCHAR(100),
  client_po_number VARCHAR(255),
  is_active BOOLEAN DEFAULT true,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Clients table
CREATE TABLE IF NOT EXISTS clients (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  name VARCHAR(255) NOT NULL,
  contact_name VARCHAR(255),
  email VARCHAR(255),
  phone VARCHAR(50),
  address TEXT,
  location VARCHAR(255),
  billing_address TEXT,
  billing_email VARCHAR(255),
  xero_contact_id VARCHAR(100),
  client_type VARCHAR(20) DEFAULT 'customer' CHECK (client_type IN ('customer', 'supplier', 'both')),
  status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'inactive')),
  notes TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Projects table
CREATE TABLE IF NOT EXISTS projects (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  code VARCHAR(50) UNIQUE NOT NULL,
  name VARCHAR(255) NOT NULL,
  client_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  status VARCHAR(20) DEFAULT 'quoted' CHECK (status IN ('quoted', 'in-progress', 'completed', 'invoiced', 'paid')),
  budget DECIMAL(15,2) DEFAULT 0,
  actual_cost DECIMAL(15,2) DEFAULT 0,
  description TEXT,
  start_date DATE,
  end_date DATE,
  xero_project_id VARCHAR(100),
  files TEXT[],
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Project Cost Centers junction table
CREATE TABLE IF NOT EXISTS project_cost_centers (
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE CASCADE,
  PRIMARY KEY (project_id, cost_center_id)
);

-- Timesheets table
CREATE TABLE IF NOT EXISTS timesheets (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id) ON DELETE SET NULL,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
  client_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  activity_type_id UUID REFERENCES activity_types(id) ON DELETE SET NULL,
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
  date DATE NOT NULL,
  hours DECIMAL(5,2) NOT NULL,
  notes TEXT,
  image_urls TEXT[],
  location VARCHAR(255),
  synced BOOLEAN DEFAULT false,
  xero_timesheet_id VARCHAR(100),
  billing_status VARCHAR(20) DEFAULT 'unbilled' CHECK (billing_status IN ('unbilled', 'billed', 'paid')),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Xero Tokens table
CREATE TABLE IF NOT EXISTS xero_tokens (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  access_token TEXT NOT NULL,
  refresh_token TEXT NOT NULL,
  id_token TEXT,
  token_type VARCHAR(50) DEFAULT 'Bearer',
  tenant_id VARCHAR(100),
  tenant_name VARCHAR(255),
  expires_at TIMESTAMP NOT NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Settings table
CREATE TABLE IF NOT EXISTS settings (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  key VARCHAR(100) NOT NULL,
  value TEXT,
  user_id UUID REFERENCES users(id) ON DELETE CASCADE,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  UNIQUE(key, user_id)
);

-- Xero Invoices table (cached from Xero)
CREATE TABLE IF NOT EXISTS xero_invoices (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_invoice_id VARCHAR(100) UNIQUE NOT NULL,
  invoice_number VARCHAR(50),
  client_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
  status VARCHAR(50),
  amount_due DECIMAL(15,2),
  amount_paid DECIMAL(15,2),
  total DECIMAL(15,2),
  currency VARCHAR(10) DEFAULT 'USD',
  issue_date DATE,
  due_date DATE,
  line_items JSONB,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Xero Quotes table (cached from Xero)
CREATE TABLE IF NOT EXISTS xero_quotes (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_quote_id VARCHAR(100) UNIQUE NOT NULL,
  quote_number VARCHAR(50),
  client_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
  status VARCHAR(50),
  total DECIMAL(15,2),
  currency VARCHAR(10) DEFAULT 'USD',
  issue_date DATE,
  expiry_date DATE,
  line_items JSONB,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Add invoice_id column to timesheets after xero_invoices table exists
ALTER TABLE timesheets 
ADD COLUMN IF NOT EXISTS invoice_id UUID REFERENCES xero_invoices(id) ON DELETE SET NULL;

-- Xero Purchase Orders table
CREATE TABLE IF NOT EXISTS xero_purchase_orders (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_po_id VARCHAR(100) UNIQUE,
  po_number VARCHAR(50),
  supplier_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
  status VARCHAR(50) DEFAULT 'DRAFT' CHECK (status IN ('DRAFT', 'SUBMITTED', 'AUTHORISED', 'BILLED', 'CANCELLED')),
  date DATE NOT NULL,
  delivery_date DATE,
  total_amount DECIMAL(15,2) DEFAULT 0,
  currency VARCHAR(10) DEFAULT 'USD',
  line_items JSONB,
  bill_id UUID,
  notes TEXT,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Make project_id nullable if it was created as NOT NULL (for existing databases)
DO $$ 
BEGIN
  IF EXISTS (
    SELECT 1 FROM information_schema.columns 
    WHERE table_name = 'xero_purchase_orders' 
    AND column_name = 'project_id' 
    AND is_nullable = 'NO'
  ) THEN
    ALTER TABLE xero_purchase_orders ALTER COLUMN project_id DROP NOT NULL;
  END IF;
END $$;

-- Purchase Order Line Items table
CREATE TABLE IF NOT EXISTS xero_purchase_order_line_items (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  po_id UUID NOT NULL REFERENCES xero_purchase_orders(id) ON DELETE CASCADE,
  description TEXT,
  quantity DECIMAL(10,2),
  unit_amount DECIMAL(15,2),
  account_code VARCHAR(50),
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
  item_id UUID,
  line_amount DECIMAL(15,2),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Xero Bills table
CREATE TABLE IF NOT EXISTS xero_bills (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_bill_id VARCHAR(100) UNIQUE,
  bill_number VARCHAR(50),
  supplier_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  purchase_order_id UUID REFERENCES xero_purchase_orders(id) ON DELETE SET NULL,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
  amount DECIMAL(15,2) NOT NULL,
  amount_paid DECIMAL(15,2) DEFAULT 0,
  amount_due DECIMAL(15,2),
  currency VARCHAR(10) DEFAULT 'USD',
  date DATE NOT NULL,
  due_date DATE,
  status VARCHAR(50) DEFAULT 'AUTHORISED' CHECK (status IN ('DRAFT', 'SUBMITTED', 'AUTHORISED', 'PAID', 'VOIDED')),
  paid_date DATE,
  line_items JSONB,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Xero Expenses table
CREATE TABLE IF NOT EXISTS xero_expenses (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_expense_id VARCHAR(100) UNIQUE,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
  amount DECIMAL(15,2) NOT NULL,
  date DATE NOT NULL,
  description TEXT,
  receipt_url TEXT,
  status VARCHAR(50) DEFAULT 'DRAFT' CHECK (status IN ('DRAFT', 'SUBMITTED', 'APPROVED', 'PAID')),
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Xero Payments table
CREATE TABLE IF NOT EXISTS xero_payments (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_payment_id VARCHAR(100) UNIQUE,
  invoice_id UUID REFERENCES xero_invoices(id) ON DELETE SET NULL,
  amount DECIMAL(15,2) NOT NULL,
  payment_date DATE NOT NULL,
  payment_method VARCHAR(50) NOT NULL,
  reference VARCHAR(255),
  bank_transaction_id UUID,
  account_code VARCHAR(50),
  currency VARCHAR(10) DEFAULT 'USD',
  exchange_rate DECIMAL(10,4) DEFAULT 1,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Bank Transactions table
CREATE TABLE IF NOT EXISTS bank_transactions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_bank_transaction_id VARCHAR(100) UNIQUE,
  bank_account_code VARCHAR(50),
  bank_account_name VARCHAR(255),
  date DATE NOT NULL,
  amount DECIMAL(15,2) NOT NULL,
  type VARCHAR(20) NOT NULL CHECK (type IN ('RECEIVE', 'SPEND')),
  description TEXT,
  reference VARCHAR(255),
  contact_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  reconciled BOOLEAN DEFAULT false,
  payment_id UUID REFERENCES xero_payments(id) ON DELETE SET NULL,
  reconciled_date DATE,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Xero Credit Notes table
CREATE TABLE IF NOT EXISTS xero_credit_notes (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_credit_note_id VARCHAR(100) UNIQUE,
  credit_note_number VARCHAR(50),
  invoice_id UUID REFERENCES xero_invoices(id) ON DELETE SET NULL,
  amount DECIMAL(15,2) NOT NULL,
  date DATE NOT NULL,
  reason TEXT,
  status VARCHAR(50) DEFAULT 'AUTHORISED' CHECK (status IN ('DRAFT', 'SUBMITTED', 'AUTHORISED', 'VOIDED')),
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Update projects table to add PO commitments tracking
ALTER TABLE projects 
ADD COLUMN IF NOT EXISTS po_commitments DECIMAL(15,2) DEFAULT 0;

-- Update xero_invoices table to add last_payment_date
ALTER TABLE xero_invoices 
ADD COLUMN IF NOT EXISTS last_payment_date DATE;

-- Activity Logs table
CREATE TABLE IF NOT EXISTS activity_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id UUID REFERENCES users(id) ON DELETE SET NULL,
  action VARCHAR(100) NOT NULL,
  entity_type VARCHAR(50),
  entity_id UUID,
  details JSONB,
  ip_address VARCHAR(45),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Permissions table (defines available permissions)
CREATE TABLE IF NOT EXISTS permissions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  key VARCHAR(100) UNIQUE NOT NULL,
  label VARCHAR(255) NOT NULL,
  description TEXT,
  is_system BOOLEAN DEFAULT false,
  is_custom BOOLEAN DEFAULT false,
  is_active BOOLEAN DEFAULT true,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_timesheets_user_id ON timesheets(user_id);
CREATE INDEX IF NOT EXISTS idx_timesheets_project_id ON timesheets(project_id);
CREATE INDEX IF NOT EXISTS idx_timesheets_date ON timesheets(date);
CREATE INDEX IF NOT EXISTS idx_timesheets_billing_status ON timesheets(billing_status);
CREATE INDEX IF NOT EXISTS idx_timesheets_invoice_id ON timesheets(invoice_id);
CREATE INDEX IF NOT EXISTS idx_projects_client_id ON projects(client_id);
CREATE INDEX IF NOT EXISTS idx_projects_status ON projects(status);
CREATE INDEX IF NOT EXISTS idx_clients_name ON clients(name);
CREATE INDEX IF NOT EXISTS idx_activity_logs_user_id ON activity_logs(user_id);
CREATE INDEX IF NOT EXISTS idx_activity_logs_created_at ON activity_logs(created_at);

-- Xero tables indexes
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_project_id ON xero_purchase_orders(project_id);
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_supplier_id ON xero_purchase_orders(supplier_id);
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_status ON xero_purchase_orders(status);
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_date ON xero_purchase_orders(date);
CREATE INDEX IF NOT EXISTS idx_xero_po_line_items_po_id ON xero_purchase_order_line_items(po_id);
CREATE INDEX IF NOT EXISTS idx_xero_po_line_items_cost_center_id ON xero_purchase_order_line_items(cost_center_id);
CREATE INDEX IF NOT EXISTS idx_xero_bills_supplier_id ON xero_bills(supplier_id);
CREATE INDEX IF NOT EXISTS idx_xero_bills_purchase_order_id ON xero_bills(purchase_order_id);
CREATE INDEX IF NOT EXISTS idx_xero_bills_project_id ON xero_bills(project_id);
CREATE INDEX IF NOT EXISTS idx_xero_bills_status ON xero_bills(status);
CREATE INDEX IF NOT EXISTS idx_xero_expenses_project_id ON xero_expenses(project_id);
CREATE INDEX IF NOT EXISTS idx_xero_expenses_cost_center_id ON xero_expenses(cost_center_id);
CREATE INDEX IF NOT EXISTS idx_xero_expenses_date ON xero_expenses(date);
CREATE INDEX IF NOT EXISTS idx_xero_payments_invoice_id ON xero_payments(invoice_id);
CREATE INDEX IF NOT EXISTS idx_xero_payments_payment_date ON xero_payments(payment_date);
CREATE INDEX IF NOT EXISTS idx_xero_payments_xero_payment_id ON xero_payments(xero_payment_id);
CREATE INDEX IF NOT EXISTS idx_bank_transactions_date ON bank_transactions(date);
CREATE INDEX IF NOT EXISTS idx_bank_transactions_reconciled ON bank_transactions(reconciled);
CREATE INDEX IF NOT EXISTS idx_bank_transactions_payment_id ON bank_transactions(payment_id);
CREATE INDEX IF NOT EXISTS idx_bank_transactions_xero_bank_transaction_id ON bank_transactions(xero_bank_transaction_id);
CREATE INDEX IF NOT EXISTS idx_xero_credit_notes_invoice_id ON xero_credit_notes(invoice_id);
CREATE INDEX IF NOT EXISTS idx_xero_credit_notes_date ON xero_credit_notes(date);
CREATE INDEX IF NOT EXISTS idx_xero_credit_notes_status ON xero_credit_notes(status);
CREATE INDEX IF NOT EXISTS idx_xero_credit_notes_xero_credit_note_id ON xero_credit_notes(xero_credit_note_id);

-- Full-text search indexes
CREATE INDEX IF NOT EXISTS idx_clients_search ON clients USING gin(to_tsvector('english', name || ' ' || COALESCE(contact_name, '') || ' ' || COALESCE(address, '')));
CREATE INDEX IF NOT EXISTS idx_projects_search ON projects USING gin(to_tsvector('english', name || ' ' || COALESCE(description, '')));
CREATE INDEX IF NOT EXISTS idx_timesheets_search ON timesheets USING gin(to_tsvector('english', COALESCE(notes, '')));

-- Project Files table
CREATE TABLE IF NOT EXISTS project_files (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
  file_name VARCHAR(255) NOT NULL,
  file_path VARCHAR(500) NOT NULL,
  file_type VARCHAR(50) NOT NULL,
  file_size BIGINT NOT NULL,
  mime_type VARCHAR(100),
  uploaded_by UUID REFERENCES users(id) ON DELETE SET NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_project_files_project_id ON project_files(project_id);
CREATE INDEX IF NOT EXISTS idx_project_files_cost_center_id ON project_files(cost_center_id);
CREATE INDEX IF NOT EXISTS idx_project_files_file_type ON project_files(file_type);

-- Safety Documents table
CREATE TABLE IF NOT EXISTS safety_documents (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
  document_type VARCHAR(50) NOT NULL CHECK (document_type IN ('jsa', 'electrical_compliance', 'electrical_safety_certificate')),
  title VARCHAR(255) NOT NULL,
  data JSONB NOT NULL,
  file_path VARCHAR(500),
  status VARCHAR(20) DEFAULT 'draft' CHECK (status IN ('draft', 'completed', 'approved')),
  created_by UUID REFERENCES users(id) ON DELETE SET NULL,
  approved_by UUID REFERENCES users(id) ON DELETE SET NULL,
  approved_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_safety_documents_project_id ON safety_documents(project_id);
CREATE INDEX IF NOT EXISTS idx_safety_documents_cost_center_id ON safety_documents(cost_center_id);
CREATE INDEX IF NOT EXISTS idx_safety_documents_type ON safety_documents(document_type);
CREATE INDEX IF NOT EXISTS idx_safety_documents_status ON safety_documents(status);

-- Document Scans table (for OCR processing)
CREATE TABLE IF NOT EXISTS document_scans (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  file_id UUID REFERENCES project_files(id) ON DELETE CASCADE,
  user_id UUID REFERENCES users(id) ON DELETE SET NULL,
  status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'processing', 'completed', 'failed')),
  document_type VARCHAR(50) CHECK (document_type IN ('receipt', 'invoice', 'purchase_order', 'bill', 'expense', 'unknown')),
  extracted_data JSONB,
  confidence DECIMAL(3,2),
  error_message TEXT,
  xero_attachment_id VARCHAR(100),
  processed_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Document Matches table (suggested matches between scans and records)
CREATE TABLE IF NOT EXISTS document_matches (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  scan_id UUID REFERENCES document_scans(id) ON DELETE CASCADE,
  entity_type VARCHAR(50) CHECK (entity_type IN ('purchase_order', 'invoice', 'bill', 'expense')),
  entity_id UUID,
  confidence_score DECIMAL(3,2),
  match_reasons JSONB,
  confirmed BOOLEAN DEFAULT false,
  confirmed_by UUID REFERENCES users(id) ON DELETE SET NULL,
  confirmed_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Add scanned_document_id columns to Xero tables (optional reverse lookup)
ALTER TABLE xero_purchase_orders 
  ADD COLUMN IF NOT EXISTS scanned_document_id UUID REFERENCES document_scans(id) ON DELETE SET NULL;
ALTER TABLE xero_invoices 
  ADD COLUMN IF NOT EXISTS scanned_document_id UUID REFERENCES document_scans(id) ON DELETE SET NULL;
ALTER TABLE xero_bills 
  ADD COLUMN IF NOT EXISTS scanned_document_id UUID REFERENCES document_scans(id) ON DELETE SET NULL;
ALTER TABLE xero_expenses 
  ADD COLUMN IF NOT EXISTS scanned_document_id UUID REFERENCES document_scans(id) ON DELETE SET NULL;

-- Indexes for document scans
CREATE INDEX IF NOT EXISTS idx_document_scans_file_id ON document_scans(file_id);
CREATE INDEX IF NOT EXISTS idx_document_scans_user_id ON document_scans(user_id);
CREATE INDEX IF NOT EXISTS idx_document_scans_status ON document_scans(status);
CREATE INDEX IF NOT EXISTS idx_document_scans_document_type ON document_scans(document_type);
CREATE INDEX IF NOT EXISTS idx_document_scans_created_at ON document_scans(created_at);

-- Indexes for document matches
CREATE INDEX IF NOT EXISTS idx_document_matches_scan_id ON document_matches(scan_id);
CREATE INDEX IF NOT EXISTS idx_document_matches_entity ON document_matches(entity_type, entity_id);
CREATE INDEX IF NOT EXISTS idx_document_matches_confirmed ON document_matches(confirmed);

-- Update projects table status constraint to include 'paid' status
DO $$ 
BEGIN
  -- Drop existing constraint if it exists
  IF EXISTS (
    SELECT 1 FROM information_schema.table_constraints 
    WHERE constraint_name = 'projects_status_check' 
    AND table_name = 'projects'
  ) THEN
    ALTER TABLE projects DROP CONSTRAINT projects_status_check;
  END IF;
  
  -- Add new constraint with 'paid' status
  ALTER TABLE projects ADD CONSTRAINT projects_status_check 
    CHECK (status IN ('quoted', 'in-progress', 'completed', 'invoiced', 'paid'));
END $$;

-- Add client_po_number column to cost_centers table if it doesn't exist
ALTER TABLE cost_centers 
ADD COLUMN IF NOT EXISTS client_po_number VARCHAR(255);

-- Add reference column to xero_invoices table if it doesn't exist (for client PO numbers)
ALTER TABLE xero_invoices 
ADD COLUMN IF NOT EXISTS reference VARCHAR(500);

-- Add client_type column to clients table if it doesn't exist
ALTER TABLE clients 
ADD COLUMN IF NOT EXISTS client_type VARCHAR(20) DEFAULT 'customer' CHECK (client_type IN ('customer', 'supplier', 'both'));

-- Auto-update client_type based on usage (customers have projects, suppliers have POs/bills)
-- This is a one-time update for existing data
DO $$
BEGIN
  -- Update clients that are suppliers (have POs or bills) but not customers
  UPDATE clients c
  SET client_type = CASE
    WHEN EXISTS (SELECT 1 FROM xero_purchase_orders po WHERE po.supplier_id = c.id)
      OR EXISTS (SELECT 1 FROM xero_bills b WHERE b.supplier_id = c.id)
    THEN
      CASE
        WHEN EXISTS (SELECT 1 FROM projects p WHERE p.client_id = c.id) THEN 'both'
        ELSE 'supplier'
      END
    ELSE 'customer'
  END
  WHERE client_type IS NULL OR client_type = 'customer';
END $$;

-- File Migrations table (for tracking file migration to storage abstraction layer)
CREATE TABLE IF NOT EXISTS file_migrations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  file_id UUID, -- References project_files.id or NULL for timesheet images
  entity_type VARCHAR(50) NOT NULL, -- 'project_file', 'timesheet_image', 'safety_document', 'logo', etc.
  entity_id UUID, -- ID of the entity (project_file.id, timesheet.id, safety_document.id, etc.)
  source_path VARCHAR(500) NOT NULL, -- Original file path (e.g., /uploads/projects/...)
  destination_path VARCHAR(500) NOT NULL, -- New partitioned path in storage provider
  status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'in_progress', 'completed', 'failed')),
  error_message TEXT,
  file_size BIGINT,
  checksum VARCHAR(64), -- Optional: SHA-256 hash for verification
  migrated_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_file_migrations_file_id ON file_migrations(file_id);
CREATE INDEX IF NOT EXISTS idx_file_migrations_status ON file_migrations(status);
CREATE INDEX IF NOT EXISTS idx_file_migrations_entity ON file_migrations(entity_type, entity_id);
CREATE INDEX IF NOT EXISTS idx_file_migrations_source_path ON file_migrations(source_path);
CREATE INDEX IF NOT EXISTS idx_file_migrations_destination_path ON file_migrations(destination_path);

COMMENT ON TABLE file_migrations IS 'Tracks migration of files from old filesystem paths to new storage provider paths';
COMMENT ON COLUMN file_migrations.file_id IS 'References project_files.id if applicable, NULL for timesheet images';
COMMENT ON COLUMN file_migrations.entity_type IS 'Type of entity: project_file, timesheet_image, safety_document, logo, favicon';
COMMENT ON COLUMN file_migrations.entity_id IS 'ID of the entity (project_file.id, timesheet.id, etc.)';
COMMENT ON COLUMN file_migrations.source_path IS 'Original file path before migration';
COMMENT ON COLUMN file_migrations.destination_path IS 'New partitioned path in storage provider';
COMMENT ON COLUMN file_migrations.status IS 'Migration status: pending, in_progress, completed, failed';
COMMENT ON COLUMN file_migrations.checksum IS 'SHA-256 hash of file for verification';

-- Backups table (for tracking backup operations)
CREATE TABLE IF NOT EXISTS backups (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  backup_type VARCHAR(50) NOT NULL CHECK (backup_type IN ('full', 'database', 'files')),
  storage_type VARCHAR(50) NOT NULL CHECK (storage_type IN ('local', 'google_drive')),
  file_path TEXT,
  file_size BIGINT,
  google_drive_file_id VARCHAR(255),
  status VARCHAR(50) DEFAULT 'pending' CHECK (status IN ('pending', 'completed', 'failed')),
  error_message TEXT,
  created_by UUID REFERENCES users(id) ON DELETE SET NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  expires_at TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_backups_created_by ON backups(created_by);
CREATE INDEX IF NOT EXISTS idx_backups_status ON backups(status);
CREATE INDEX IF NOT EXISTS idx_backups_created_at ON backups(created_at);
CREATE INDEX IF NOT EXISTS idx_backups_storage_type ON backups(storage_type);
`;

async function runMigration() {
  console.log('üîÑ Running database migrations...');
  
  try {
    const client = await getClient();
    
    try {
      await client.query('BEGIN');
      
      // Run main migrations with error handling for duplicate types
      try {
      await client.query(migrations);
      } catch (err: any) {
        // Handle duplicate type errors (23505) - safe to ignore when using IF NOT EXISTS
        // PostgreSQL creates composite types for tables, and sometimes they persist after table drops
        if (err.code === '23505' && err.constraint === 'pg_type_typname_nsp_index') {
          console.log('  ‚ö†Ô∏è  Some database objects already exist (safe to continue with IF NOT EXISTS)');
          // Continue execution - individual CREATE TABLE IF NOT EXISTS will skip existing tables
        } else {
          throw err;
        }
      }
      
      // Run additional migration files from migrations directory
      const migrationsDir = path.join(__dirname, 'migrations');
      if (fs.existsSync(migrationsDir)) {
        const migrationFiles = fs.readdirSync(migrationsDir)
          .filter(file => file.endsWith('.sql'))
          .sort(); // Run in alphabetical order
        
        for (const file of migrationFiles) {
          const filePath = path.join(migrationsDir, file);
          const sql = fs.readFileSync(filePath, 'utf8');
          try {
          console.log(`  Running migration: ${file}`);
          await client.query(sql);
          } catch (err: any) {
            console.error(`  ‚ùå Error in migration ${file}:`, err.message);
            // If it's a "already exists" error, it's usually safe to continue
            // since we use IF NOT EXISTS everywhere
            if (err.code === '42P07' || err.code === '23505') {
              console.log(`  ‚ö†Ô∏è  Migration ${file} skipped (object already exists)`);
              continue;
            }
            throw err;
          }
        }
      }
      
      await client.query('COMMIT');
      console.log('‚úÖ Migrations completed successfully!');
    } catch (err) {
      await client.query('ROLLBACK');
      throw err;
    } finally {
      client.release();
    }
  } catch (error) {
    console.error('‚ùå Migration failed:', error);
    process.exit(1);
  }
  
  process.exit(0);
}

runMigration();
--- FILE: backend/src/db/migrations/add-backups-table.sql ---
-- Add backups table for tracking backup operations
CREATE TABLE IF NOT EXISTS backups (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  backup_type VARCHAR(50) NOT NULL CHECK (backup_type IN ('full', 'database', 'files')),
  storage_type VARCHAR(50) NOT NULL CHECK (storage_type IN ('local', 'google_drive')),
  file_path TEXT,
  file_size BIGINT,
  google_drive_file_id VARCHAR(255),
  status VARCHAR(50) DEFAULT 'pending' CHECK (status IN ('pending', 'completed', 'failed')),
  error_message TEXT,
  created_by UUID REFERENCES users(id) ON DELETE SET NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  expires_at TIMESTAMP
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_backups_created_by ON backups(created_by);
CREATE INDEX IF NOT EXISTS idx_backups_status ON backups(status);
CREATE INDEX IF NOT EXISTS idx_backups_created_at ON backups(created_at);
CREATE INDEX IF NOT EXISTS idx_backups_storage_type ON backups(storage_type);

--- FILE: backend/src/db/migrations/add-cloud-storage.sql ---
-- Add cloud storage support for timesheet images
-- This migration adds cloud_image_urls column to replace local file paths

-- Timesheets table: Add cloud_image_urls column
ALTER TABLE timesheets 
ADD COLUMN IF NOT EXISTS cloud_image_urls TEXT[] DEFAULT '{}';

-- Note: The existing image_urls column will remain for backward compatibility
-- During migration, we can copy data from image_urls to cloud_image_urls
-- Eventually, image_urls can be deprecated

-- Create index for cloud URLs (if needed for queries)
-- Note: Array indexes in PostgreSQL are less common, but we can add GIN index if needed
-- CREATE INDEX IF NOT EXISTS idx_timesheets_cloud_image_urls ON timesheets USING GIN(cloud_image_urls);
--- FILE: backend/src/db/migrations/add-file-management.sql ---
-- File Management and Safety Documents Migration

-- Project Files table
CREATE TABLE IF NOT EXISTS project_files (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
  file_name VARCHAR(255) NOT NULL,
  file_path VARCHAR(500) NOT NULL,
  file_type VARCHAR(50) NOT NULL,
  file_size BIGINT NOT NULL,
  mime_type VARCHAR(100),
  uploaded_by UUID REFERENCES users(id) ON DELETE SET NULL,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_project_files_project_id ON project_files(project_id);
CREATE INDEX IF NOT EXISTS idx_project_files_cost_center_id ON project_files(cost_center_id);
CREATE INDEX IF NOT EXISTS idx_project_files_file_type ON project_files(file_type);

-- Safety Documents table
CREATE TABLE IF NOT EXISTS safety_documents (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  project_id UUID REFERENCES projects(id) ON DELETE CASCADE,
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
  document_type VARCHAR(50) NOT NULL CHECK (document_type IN ('jsa', 'electrical_compliance', 'electrical_safety_certificate')),
  title VARCHAR(255) NOT NULL,
  data JSONB NOT NULL,
  file_path VARCHAR(500),
  status VARCHAR(20) DEFAULT 'draft' CHECK (status IN ('draft', 'completed', 'approved')),
  created_by UUID REFERENCES users(id) ON DELETE SET NULL,
  approved_by UUID REFERENCES users(id) ON DELETE SET NULL,
  approved_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_safety_documents_project_id ON safety_documents(project_id);
CREATE INDEX IF NOT EXISTS idx_safety_documents_cost_center_id ON safety_documents(cost_center_id);
CREATE INDEX IF NOT EXISTS idx_safety_documents_type ON safety_documents(document_type);
CREATE INDEX IF NOT EXISTS idx_safety_documents_status ON safety_documents(status);

--- FILE: backend/src/db/migrations/add-file-migrations-table.sql ---
-- Migration: Add file_migrations table for tracking file migration progress
-- This table tracks the migration of files from old filesystem paths to new storage provider paths

CREATE TABLE IF NOT EXISTS file_migrations (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  file_id UUID, -- References project_files.id or NULL for timesheet images
  entity_type VARCHAR(50) NOT NULL, -- 'project_file', 'timesheet_image', 'safety_document', 'logo', etc.
  entity_id UUID, -- ID of the entity (project_file.id, timesheet.id, safety_document.id, etc.)
  source_path VARCHAR(500) NOT NULL, -- Original file path (e.g., /uploads/projects/...)
  destination_path VARCHAR(500) NOT NULL, -- New partitioned path in storage provider
  status VARCHAR(20) DEFAULT 'pending' CHECK (status IN ('pending', 'in_progress', 'completed', 'failed')),
  error_message TEXT,
  file_size BIGINT,
  checksum VARCHAR(64), -- Optional: SHA-256 hash for verification
  migrated_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

CREATE INDEX IF NOT EXISTS idx_file_migrations_file_id ON file_migrations(file_id);
CREATE INDEX IF NOT EXISTS idx_file_migrations_status ON file_migrations(status);
CREATE INDEX IF NOT EXISTS idx_file_migrations_entity ON file_migrations(entity_type, entity_id);
CREATE INDEX IF NOT EXISTS idx_file_migrations_source_path ON file_migrations(source_path);
CREATE INDEX IF NOT EXISTS idx_file_migrations_destination_path ON file_migrations(destination_path);

COMMENT ON TABLE file_migrations IS 'Tracks migration of files from old filesystem paths to new storage provider paths';
COMMENT ON COLUMN file_migrations.file_id IS 'References project_files.id if applicable, NULL for timesheet images';
COMMENT ON COLUMN file_migrations.entity_type IS 'Type of entity: project_file, timesheet_image, safety_document, logo, favicon';
COMMENT ON COLUMN file_migrations.entity_id IS 'ID of the entity (project_file.id, timesheet.id, etc.)';
COMMENT ON COLUMN file_migrations.source_path IS 'Original file path before migration';
COMMENT ON COLUMN file_migrations.destination_path IS 'New partitioned path in storage provider';
COMMENT ON COLUMN file_migrations.status IS 'Migration status: pending, in_progress, completed, failed';
COMMENT ON COLUMN file_migrations.checksum IS 'SHA-256 hash of file for verification';
--- FILE: backend/src/db/migrations/add-soft-deletes.sql ---
-- Add soft delete support (deleted_at columns) to main tables
-- This migration adds deleted_at columns to support soft deletes

-- Clients table
ALTER TABLE clients 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

-- Projects table
ALTER TABLE projects 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

-- Timesheets table
ALTER TABLE timesheets 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

-- Xero-related tables
ALTER TABLE xero_invoices 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

ALTER TABLE xero_purchase_orders 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

ALTER TABLE xero_bills 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

ALTER TABLE xero_expenses 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

ALTER TABLE xero_quotes 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

ALTER TABLE xero_payments 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

ALTER TABLE xero_credit_notes 
ADD COLUMN IF NOT EXISTS deleted_at TIMESTAMP NULL;

-- Create indexes for soft delete queries
CREATE INDEX IF NOT EXISTS idx_clients_deleted_at ON clients(deleted_at);
CREATE INDEX IF NOT EXISTS idx_projects_deleted_at ON projects(deleted_at);
CREATE INDEX IF NOT EXISTS idx_timesheets_deleted_at ON timesheets(deleted_at);
CREATE INDEX IF NOT EXISTS idx_xero_invoices_deleted_at ON xero_invoices(deleted_at);
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_deleted_at ON xero_purchase_orders(deleted_at);
--- FILE: backend/src/db/migrations/add-sync-logs.sql ---
-- Create sync_logs table to store audit trail for all Xero API calls
-- This table tracks every call to XeroLib integration library

CREATE TABLE IF NOT EXISTS sync_logs (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  entity_type VARCHAR(50) NOT NULL, -- e.g., 'invoice', 'purchase_order', 'timesheet'
  entity_id UUID NOT NULL,
  request_payload JSONB,
  response_payload JSONB,
  status_code INTEGER,
  error_message TEXT,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for efficient querying
CREATE INDEX IF NOT EXISTS idx_sync_logs_entity_type ON sync_logs(entity_type);
CREATE INDEX IF NOT EXISTS idx_sync_logs_entity_id ON sync_logs(entity_id);
CREATE INDEX IF NOT EXISTS idx_sync_logs_created_at ON sync_logs(created_at);
CREATE INDEX IF NOT EXISTS idx_sync_logs_status_code ON sync_logs(status_code);

-- Composite index for common queries
CREATE INDEX IF NOT EXISTS idx_sync_logs_entity_lookup ON sync_logs(entity_type, entity_id, created_at DESC);
--- FILE: backend/src/db/migrations/add-sync-status.sql ---
-- Add sync status and xero_sync_id columns to support async Xero syncing
-- This migration adds sync tracking to timesheets, invoices, and purchase orders

-- Create sync_status enum type
DO $$ 
BEGIN
  IF NOT EXISTS (SELECT 1 FROM pg_type WHERE typname = 'sync_status_enum') THEN
    CREATE TYPE sync_status_enum AS ENUM ('pending', 'synced', 'failed');
  END IF;
END $$;

-- Timesheets table
ALTER TABLE timesheets 
ADD COLUMN IF NOT EXISTS sync_status sync_status_enum DEFAULT 'pending',
ADD COLUMN IF NOT EXISTS xero_sync_id UUID NULL;

-- Xero Invoices table
ALTER TABLE xero_invoices 
ADD COLUMN IF NOT EXISTS sync_status sync_status_enum DEFAULT 'pending',
ADD COLUMN IF NOT EXISTS xero_sync_id UUID NULL;

-- Xero Purchase Orders table
ALTER TABLE xero_purchase_orders 
ADD COLUMN IF NOT EXISTS sync_status sync_status_enum DEFAULT 'pending',
ADD COLUMN IF NOT EXISTS xero_sync_id UUID NULL;

-- Create indexes for sync status queries
CREATE INDEX IF NOT EXISTS idx_timesheets_sync_status ON timesheets(sync_status);
CREATE INDEX IF NOT EXISTS idx_timesheets_xero_sync_id ON timesheets(xero_sync_id);
CREATE INDEX IF NOT EXISTS idx_xero_invoices_sync_status ON xero_invoices(sync_status);
CREATE INDEX IF NOT EXISTS idx_xero_invoices_xero_sync_id ON xero_invoices(xero_sync_id);
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_sync_status ON xero_purchase_orders(sync_status);
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_xero_sync_id ON xero_purchase_orders(xero_sync_id);
--- FILE: backend/src/db/migrations/add-timesheet-billing.sql ---
-- Add billing status and invoice linking to timesheets
ALTER TABLE timesheets 
ADD COLUMN IF NOT EXISTS billing_status VARCHAR(20) DEFAULT 'unbilled' CHECK (billing_status IN ('unbilled', 'billed', 'paid')),
ADD COLUMN IF NOT EXISTS invoice_id UUID REFERENCES xero_invoices(id) ON DELETE SET NULL;

-- Create index for billing status queries
CREATE INDEX IF NOT EXISTS idx_timesheets_billing_status ON timesheets(billing_status);
CREATE INDEX IF NOT EXISTS idx_timesheets_invoice_id ON timesheets(invoice_id);

--- FILE: backend/src/db/migrations/add-xero-credit-notes.sql ---
-- Add Credit Notes table
CREATE TABLE IF NOT EXISTS xero_credit_notes (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_credit_note_id VARCHAR(100) UNIQUE,
  credit_note_number VARCHAR(50),
  invoice_id UUID REFERENCES xero_invoices(id) ON DELETE SET NULL,
  amount DECIMAL(15,2) NOT NULL,
  date DATE NOT NULL,
  reason TEXT,
  status VARCHAR(50) DEFAULT 'AUTHORISED' CHECK (status IN ('DRAFT', 'SUBMITTED', 'AUTHORISED', 'VOIDED')),
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_xero_credit_notes_invoice_id ON xero_credit_notes(invoice_id);
CREATE INDEX IF NOT EXISTS idx_xero_credit_notes_date ON xero_credit_notes(date);
CREATE INDEX IF NOT EXISTS idx_xero_credit_notes_status ON xero_credit_notes(status);
CREATE INDEX IF NOT EXISTS idx_xero_credit_notes_xero_credit_note_id ON xero_credit_notes(xero_credit_note_id);

--- FILE: backend/src/db/migrations/add-xero-items.sql ---
-- Add Xero Items table
CREATE TABLE IF NOT EXISTS xero_items (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_item_id VARCHAR(100) UNIQUE NOT NULL,
  code VARCHAR(50),
  name VARCHAR(255) NOT NULL,
  description TEXT,
  purchase_price DECIMAL(15,2) DEFAULT 0,
  sale_price DECIMAL(15,2) DEFAULT 0,
  stock_level DECIMAL(10,2) DEFAULT 0,
  is_tracked BOOLEAN DEFAULT false,
  inventory_asset_account_code VARCHAR(50),
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_xero_items_code ON xero_items(code);
CREATE INDEX IF NOT EXISTS idx_xero_items_name ON xero_items(name);
CREATE INDEX IF NOT EXISTS idx_xero_items_is_tracked ON xero_items(is_tracked);
CREATE INDEX IF NOT EXISTS idx_xero_items_xero_item_id ON xero_items(xero_item_id);

--- FILE: backend/src/db/migrations/add-xero-payments.sql ---
-- Add Xero Payments table
CREATE TABLE IF NOT EXISTS xero_payments (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_payment_id VARCHAR(100) UNIQUE,
  invoice_id UUID REFERENCES xero_invoices(id) ON DELETE SET NULL,
  amount DECIMAL(15,2) NOT NULL,
  payment_date DATE NOT NULL,
  payment_method VARCHAR(50) NOT NULL,
  reference VARCHAR(255),
  bank_transaction_id UUID,
  account_code VARCHAR(50),
  currency VARCHAR(10) DEFAULT 'USD',
  exchange_rate DECIMAL(10,4) DEFAULT 1,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Add Bank Transactions table
CREATE TABLE IF NOT EXISTS bank_transactions (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_bank_transaction_id VARCHAR(100) UNIQUE,
  bank_account_code VARCHAR(50),
  bank_account_name VARCHAR(255),
  date DATE NOT NULL,
  amount DECIMAL(15,2) NOT NULL,
  type VARCHAR(20) NOT NULL CHECK (type IN ('RECEIVE', 'SPEND')),
  description TEXT,
  reference VARCHAR(255),
  contact_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  reconciled BOOLEAN DEFAULT false,
  payment_id UUID REFERENCES xero_payments(id) ON DELETE SET NULL,
  reconciled_date DATE,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Update xero_invoices table to add last_payment_date
ALTER TABLE xero_invoices 
ADD COLUMN IF NOT EXISTS last_payment_date DATE;

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_xero_payments_invoice_id ON xero_payments(invoice_id);
CREATE INDEX IF NOT EXISTS idx_xero_payments_payment_date ON xero_payments(payment_date);
CREATE INDEX IF NOT EXISTS idx_xero_payments_xero_payment_id ON xero_payments(xero_payment_id);
CREATE INDEX IF NOT EXISTS idx_bank_transactions_date ON bank_transactions(date);
CREATE INDEX IF NOT EXISTS idx_bank_transactions_reconciled ON bank_transactions(reconciled);
CREATE INDEX IF NOT EXISTS idx_bank_transactions_payment_id ON bank_transactions(payment_id);
CREATE INDEX IF NOT EXISTS idx_bank_transactions_xero_bank_transaction_id ON bank_transactions(xero_bank_transaction_id);

--- FILE: backend/src/db/migrations/add-xero-purchase-orders.sql ---
-- Add Purchase Orders table
CREATE TABLE IF NOT EXISTS xero_purchase_orders (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_po_id VARCHAR(100) UNIQUE,
  po_number VARCHAR(50),
  supplier_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  project_id UUID NOT NULL REFERENCES projects(id) ON DELETE CASCADE,
  status VARCHAR(50) DEFAULT 'DRAFT' CHECK (status IN ('DRAFT', 'SUBMITTED', 'AUTHORISED', 'BILLED', 'CANCELLED')),
  date DATE NOT NULL,
  delivery_date DATE,
  total_amount DECIMAL(15,2) DEFAULT 0,
  currency VARCHAR(10) DEFAULT 'USD',
  line_items JSONB,
  bill_id UUID, -- References xero_bills(id) when converted
  notes TEXT,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Add Purchase Order Line Items table for detailed tracking
CREATE TABLE IF NOT EXISTS xero_purchase_order_line_items (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  po_id UUID NOT NULL REFERENCES xero_purchase_orders(id) ON DELETE CASCADE,
  description TEXT,
  quantity DECIMAL(10,2),
  unit_amount DECIMAL(15,2),
  account_code VARCHAR(50),
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
  item_id UUID, -- References xero_items(id) when items table exists
  line_amount DECIMAL(15,2),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Add Bills table
CREATE TABLE IF NOT EXISTS xero_bills (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_bill_id VARCHAR(100) UNIQUE,
  bill_number VARCHAR(50),
  supplier_id UUID REFERENCES clients(id) ON DELETE SET NULL,
  purchase_order_id UUID REFERENCES xero_purchase_orders(id) ON DELETE SET NULL,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
  amount DECIMAL(15,2) NOT NULL,
  amount_paid DECIMAL(15,2) DEFAULT 0,
  amount_due DECIMAL(15,2),
  currency VARCHAR(10) DEFAULT 'USD',
  date DATE NOT NULL,
  due_date DATE,
  status VARCHAR(50) DEFAULT 'AUTHORISED' CHECK (status IN ('DRAFT', 'SUBMITTED', 'AUTHORISED', 'PAID', 'VOIDED')),
  paid_date DATE,
  line_items JSONB,
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Add Expenses table
CREATE TABLE IF NOT EXISTS xero_expenses (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  xero_expense_id VARCHAR(100) UNIQUE,
  project_id UUID REFERENCES projects(id) ON DELETE SET NULL,
  cost_center_id UUID REFERENCES cost_centers(id) ON DELETE SET NULL,
  amount DECIMAL(15,2) NOT NULL,
  date DATE NOT NULL,
  description TEXT,
  receipt_url TEXT,
  status VARCHAR(50) DEFAULT 'DRAFT' CHECK (status IN ('DRAFT', 'SUBMITTED', 'APPROVED', 'PAID')),
  synced_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Update projects table to add PO commitments tracking
ALTER TABLE projects 
ADD COLUMN IF NOT EXISTS po_commitments DECIMAL(15,2) DEFAULT 0;

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_project_id ON xero_purchase_orders(project_id);
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_supplier_id ON xero_purchase_orders(supplier_id);
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_status ON xero_purchase_orders(status);
CREATE INDEX IF NOT EXISTS idx_xero_purchase_orders_date ON xero_purchase_orders(date);
CREATE INDEX IF NOT EXISTS idx_xero_po_line_items_po_id ON xero_purchase_order_line_items(po_id);
CREATE INDEX IF NOT EXISTS idx_xero_po_line_items_cost_center_id ON xero_purchase_order_line_items(cost_center_id);
CREATE INDEX IF NOT EXISTS idx_xero_bills_supplier_id ON xero_bills(supplier_id);
CREATE INDEX IF NOT EXISTS idx_xero_bills_purchase_order_id ON xero_bills(purchase_order_id);
CREATE INDEX IF NOT EXISTS idx_xero_bills_project_id ON xero_bills(project_id);
CREATE INDEX IF NOT EXISTS idx_xero_bills_status ON xero_bills(status);
CREATE INDEX IF NOT EXISTS idx_xero_expenses_project_id ON xero_expenses(project_id);
CREATE INDEX IF NOT EXISTS idx_xero_expenses_cost_center_id ON xero_expenses(cost_center_id);
CREATE INDEX IF NOT EXISTS idx_xero_expenses_date ON xero_expenses(date);

--- FILE: backend/src/db/migrations/add-xero-reminders.sql ---
-- Add Payment Reminders table
CREATE TABLE IF NOT EXISTS payment_reminders (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  invoice_id UUID REFERENCES xero_invoices(id) ON DELETE CASCADE,
  sent_date DATE NOT NULL,
  reminder_type VARCHAR(50),
  sent_to VARCHAR(255),
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_payment_reminders_invoice_id ON payment_reminders(invoice_id);
CREATE INDEX IF NOT EXISTS idx_payment_reminders_sent_date ON payment_reminders(sent_date);

--- FILE: backend/src/db/migrations/add-xero-webhooks.sql ---
-- Add Webhook Events table
CREATE TABLE IF NOT EXISTS xero_webhook_events (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  event_type VARCHAR(50) NOT NULL,
  entity_id VARCHAR(100),
  payload JSONB,
  processed BOOLEAN DEFAULT false,
  processed_at TIMESTAMP,
  created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for better performance
CREATE INDEX IF NOT EXISTS idx_xero_webhook_events_event_type ON xero_webhook_events(event_type);
CREATE INDEX IF NOT EXISTS idx_xero_webhook_events_processed ON xero_webhook_events(processed);
CREATE INDEX IF NOT EXISTS idx_xero_webhook_events_created_at ON xero_webhook_events(created_at);

--- FILE: backend/src/db/migrations/make-po-project-nullable.sql ---
-- Make project_id nullable in xero_purchase_orders table
-- This allows purchase orders to be imported without a project and linked later
ALTER TABLE xero_purchase_orders 
ALTER COLUMN project_id DROP NOT NULL;

--- FILE: backend/src/db/seed-demo.ts ---
import { query, getClient } from './index';
import dotenv from 'dotenv';

// Suppress dotenv parsing warnings
dotenv.config({ debug: false, override: false });

async function seedDemo() {
  console.log('üå± Seeding demo data...');
  
  const client = await getClient();
  
  try {
    await client.query('BEGIN');
    
    // Seed sample clients (only if no clients exist)
    const existingClients = await client.query(`SELECT id FROM clients LIMIT 1`);
    if (existingClients.rows.length === 0) {
      const sampleClients = [
        {
          name: 'ABC Construction Ltd',
          contact_name: 'John Smith',
          email: 'john@abcconstruction.com',
          phone: '+64 21 123 4567',
          address: '123 Main Street, Auckland',
          billing_address: '123 Main Street, Auckland',
          billing_email: 'accounts@abcconstruction.com',
          status: 'active'
        },
        {
          name: 'XYZ Property Developers',
          contact_name: 'Sarah Johnson',
          email: 'sarah@xyzproperties.com',
          phone: '+64 21 234 5678',
          address: '456 Queen Street, Wellington',
          billing_address: '456 Queen Street, Wellington',
          billing_email: 'finance@xyzproperties.com',
          status: 'active'
        },
        {
          name: 'Metro Electrical Services',
          contact_name: 'Mike Wilson',
          email: 'mike@metroelectrical.co.nz',
          phone: '+64 21 345 6789',
          address: '789 High Street, Christchurch',
          billing_address: '789 High Street, Christchurch',
          billing_email: 'billing@metroelectrical.co.nz',
          status: 'active'
        }
      ];

      for (const sampleClient of sampleClients) {
        await client.query(
          `INSERT INTO clients (name, contact_name, email, phone, address, billing_address, billing_email, status)
           VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`,
          [sampleClient.name, sampleClient.contact_name, sampleClient.email, sampleClient.phone, sampleClient.address, 
           sampleClient.billing_address, sampleClient.billing_email, sampleClient.status]
        );
      }
      console.log('  ‚úì Sample clients seeded');
    } else {
      console.log('  ‚úì Clients already exist, skipping sample clients');
    }

    // Seed sample projects (only if no projects exist and clients exist)
    const existingProjects = await client.query(`SELECT id FROM projects LIMIT 1`);
    const clientsResult = await client.query(`SELECT id, name FROM clients ORDER BY created_at LIMIT 3`);
    
    if (existingProjects.rows.length === 0 && clientsResult.rows.length > 0) {
      const clientIds = clientsResult.rows.map((c: any) => c.id);
      const sampleProjects = [
        {
          code: 'PROJ-001',
          name: 'Office Building Electrical Upgrade',
          client_id: clientIds[0] || null,
          status: 'in-progress',
          budget: 125000,
          description: 'Complete electrical system upgrade for 5-story office building',
          start_date: new Date(Date.now() - 30 * 24 * 60 * 60 * 1000), // 30 days ago
          end_date: new Date(Date.now() + 60 * 24 * 60 * 60 * 1000) // 60 days from now
        },
        {
          code: 'PROJ-002',
          name: 'Residential Complex Wiring',
          client_id: clientIds[1] || null,
          status: 'quoted',
          budget: 85000,
          description: 'New electrical installation for 20-unit residential complex',
          start_date: new Date(Date.now() + 7 * 24 * 60 * 60 * 1000), // 7 days from now
          end_date: new Date(Date.now() + 90 * 24 * 60 * 60 * 1000) // 90 days from now
        },
        {
          code: 'PROJ-003',
          name: 'Commercial Maintenance Contract',
          client_id: clientIds[2] || null,
          status: 'in-progress',
          budget: 45000,
          description: 'Ongoing maintenance and repair services',
          start_date: new Date(Date.now() - 90 * 24 * 60 * 60 * 1000), // 90 days ago
          end_date: new Date(Date.now() + 275 * 24 * 60 * 60 * 1000) // 275 days from now (1 year contract)
        }
      ];

      for (const project of sampleProjects) {
        if (project.client_id) {
          await client.query(
            `INSERT INTO projects (code, name, client_id, status, budget, description, start_date, end_date)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`,
            [project.code, project.name, project.client_id, project.status, project.budget,
             project.description, project.start_date, project.end_date]
          );
        }
      }
      console.log('  ‚úì Sample projects seeded');
    } else {
      if (existingProjects.rows.length > 0) {
        console.log('  ‚úì Projects already exist, skipping sample projects');
      } else {
        console.log('  ‚ö†Ô∏è  No clients found, skipping sample projects');
      }
    }

    // Seed sample timesheets (only if no timesheets exist and we have projects, activity types, cost centers, and users)
    const existingTimesheets = await client.query(`SELECT id FROM timesheets LIMIT 1`);
    const projectsResult = await client.query(`SELECT id, client_id FROM projects ORDER BY created_at LIMIT 3`);
    const activityTypesResult = await client.query(`SELECT id FROM activity_types ORDER BY created_at LIMIT 5`);
    const costCentersResult = await client.query(`SELECT id FROM cost_centers ORDER BY created_at LIMIT 5`);
    const usersResult = await client.query(`SELECT id FROM users WHERE role = 'admin' LIMIT 1`);
    
    if (existingTimesheets.rows.length === 0 && 
        projectsResult.rows.length > 0 && 
        activityTypesResult.rows.length > 0 && 
        costCentersResult.rows.length > 0 && 
        usersResult.rows.length > 0) {
      
      const projectIds = projectsResult.rows.map((p: any) => p.id);
      const activityTypeIds = activityTypesResult.rows.map((a: any) => a.id);
      const costCenterIds = costCentersResult.rows.map((c: any) => c.id);
      const userId = usersResult.rows[0].id;
      
      // Generate timesheets for the last 30 days
      const timesheets = [];
      const today = new Date();
      
      for (let dayOffset = 0; dayOffset < 30; dayOffset++) {
        const date = new Date(today);
        date.setDate(date.getDate() - dayOffset);
        
        // Skip weekends (optional - you can remove this)
        const dayOfWeek = date.getDay();
        if (dayOfWeek === 0 || dayOfWeek === 6) continue;
        
        // Create 1-3 timesheets per day
        const timesheetsPerDay = Math.floor(Math.random() * 3) + 1;
        
        for (let i = 0; i < timesheetsPerDay; i++) {
          const projectId = projectIds[Math.floor(Math.random() * projectIds.length)];
          const activityTypeId = activityTypeIds[Math.floor(Math.random() * activityTypeIds.length)];
          const costCenterId = costCenterIds[Math.floor(Math.random() * costCenterIds.length)];
          const hours = Math.round((Math.random() * 7 + 1) * 100) / 100; // 1-8 hours
          
          // Get client_id from project
          const project = projectsResult.rows.find((p: any) => p.id === projectId);
          const clientId = project?.client_id || null;
          
          timesheets.push({
            user_id: userId,
            project_id: projectId,
            client_id: clientId,
            activity_type_id: activityTypeId,
            cost_center_id: costCenterId,
            date: date.toISOString().split('T')[0],
            hours: hours,
            notes: `Work completed on ${date.toLocaleDateString()}`,
            location: 'Site',
            billing_status: 'unbilled'
          });
        }
      }
      
      for (const timesheet of timesheets) {
        await client.query(
          `INSERT INTO timesheets (user_id, project_id, client_id, activity_type_id, cost_center_id, date, hours, notes, location, billing_status)
           VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)`,
          [timesheet.user_id, timesheet.project_id, timesheet.client_id, timesheet.activity_type_id,
           timesheet.cost_center_id, timesheet.date, timesheet.hours, timesheet.notes, 
           timesheet.location, timesheet.billing_status]
        );
      }
      console.log(`  ‚úì Sample timesheets seeded (${timesheets.length} entries)`);
    } else {
      if (existingTimesheets.rows.length > 0) {
        console.log('  ‚úì Timesheets already exist, skipping sample timesheets');
      } else {
        console.log('  ‚ö†Ô∏è  Missing dependencies, skipping sample timesheets');
      }
    }
    
    await client.query('COMMIT');
    console.log('‚úÖ Demo data seeded successfully!');
    
  } catch (error) {
    await client.query('ROLLBACK');
    console.error('‚ùå Demo seeding failed:', error);
    process.exit(1);
  } finally {
    client.release();
  }
  
  process.exit(0);
}

seedDemo();
--- FILE: backend/src/db/seed.ts ---
import { query, getClient } from './index';
import bcrypt from 'bcryptjs';
import dotenv from 'dotenv';

// Suppress dotenv parsing warnings
dotenv.config({ debug: false, override: false });

async function seed() {
  console.log('üå± Seeding database...');
  
  const client = await getClient();
  
  try {
    await client.query('BEGIN');
    
    // Seed Activity Types
    const activityTypes = [
      { name: 'Labour', icon: 'Briefcase', color: 'bg-electric/20 border-electric text-electric', hourly_rate: 100.00 },
      { name: 'Travel', icon: 'Car', color: 'bg-blue-400/20 border-blue-400 text-blue-400', hourly_rate: 100.00 },
      { name: 'Overnight Allowance', icon: 'Moon', color: 'bg-indigo-400/20 border-indigo-400 text-indigo-400', hourly_rate: 85.00 },
      { name: 'Admin', icon: 'FileText', color: 'bg-gray-400/20 border-gray-400 text-gray-400', hourly_rate: 50.00 },
    ];
    
    for (const type of activityTypes) {
      // Check if activity type with same name (case-insensitive) already exists
      const existing = await client.query(
        `SELECT id FROM activity_types WHERE LOWER(TRIM(name)) = LOWER(TRIM($1))`,
        [type.name]
      );
      
      if (existing.rows.length === 0) {
        await client.query(
          `INSERT INTO activity_types (name, icon, color, hourly_rate) 
           VALUES ($1, $2, $3, $4)`,
          [type.name, type.icon, type.color, type.hourly_rate]
        );
      }
    }
    console.log('  ‚úì Activity types seeded');
    
    // Seed Cost Centers
    const costCenters = [
      { code: 'CC-001', name: 'Default Cost Center', description: '', budget: 0 },
    ];
    
    for (const cc of costCenters) {
      await client.query(
        `INSERT INTO cost_centers (code, name, description, budget) 
         VALUES ($1, $2, $3, $4)
         ON CONFLICT (code) DO NOTHING`,
        [cc.code, cc.name, cc.description, cc.budget]
      );
    }
    console.log('  ‚úì Cost centers seeded');
    
    // Seed default settings
    const defaultSettings = [
      { key: 'company_name', value: 'AmpedFieldOps' },
      { key: 'company_logo', value: null },
      { key: 'timezone', value: 'Pacific/Auckland' },
      { key: 'xero_auto_sync', value: 'false' },
      { key: 'xero_sync_frequency', value: '30' },
      { key: 'setup_completed', value: 'false' },
    ];
    
    for (const setting of defaultSettings) {
      await client.query(
        `INSERT INTO settings (key, value, user_id) 
         VALUES ($1, $2, NULL)
         ON CONFLICT (key, user_id) DO NOTHING`,
        [setting.key, setting.value]
      );
    }
    console.log('  ‚úì Default settings seeded');
    
    // Seed default permissions
    const defaultPermissions = [
      // System-level permissions
      { key: 'can_manage_users', label: 'Manage Users', description: 'Add, edit, and remove users', is_system: true },
      { key: 'can_sync_xero', label: 'Xero Sync', description: 'Sync data with Xero', is_system: true },
      { key: 'can_edit_activity_types', label: 'Manage Activity Types', description: 'Configure activity types', is_system: true },
      { key: 'can_manage_cost_centers', label: 'Manage Cost Centers', description: 'Configure cost centers', is_system: true },
      { key: 'can_view_reports', label: 'View Reports', description: 'Access reports section', is_system: true },
      { key: 'can_export_data', label: 'Export Data', description: 'Export data to CSV/PDF', is_system: true },
      // Projects - granular permissions
      { key: 'can_view_own_projects', label: 'View Own Projects', description: 'View projects created by user', is_system: true },
      { key: 'can_view_all_projects', label: 'View All Projects', description: 'View all projects in the system', is_system: true },
      { key: 'can_create_projects', label: 'Create Projects', description: 'Create new projects', is_system: true },
      { key: 'can_edit_own_projects', label: 'Edit Own Projects', description: 'Edit projects created by user', is_system: true },
      { key: 'can_edit_all_projects', label: 'Edit All Projects', description: 'Edit any project in the system', is_system: true },
      { key: 'can_delete_own_projects', label: 'Delete Own Projects', description: 'Delete projects created by user', is_system: true },
      { key: 'can_delete_all_projects', label: 'Delete All Projects', description: 'Delete any project in the system', is_system: true },
      // Clients - granular permissions
      { key: 'can_view_own_clients', label: 'View Own Clients', description: 'View clients created by user', is_system: true },
      { key: 'can_view_all_clients', label: 'View All Clients', description: 'View all clients in the system', is_system: true },
      { key: 'can_create_clients', label: 'Create Clients', description: 'Create new clients', is_system: true },
      { key: 'can_edit_own_clients', label: 'Edit Own Clients', description: 'Edit clients created by user', is_system: true },
      { key: 'can_edit_all_clients', label: 'Edit All Clients', description: 'Edit any client in the system', is_system: true },
      { key: 'can_delete_own_clients', label: 'Delete Own Clients', description: 'Delete clients created by user', is_system: true },
      { key: 'can_delete_all_clients', label: 'Delete All Clients', description: 'Delete any client in the system', is_system: true },
      // Timesheets - granular permissions
      { key: 'can_view_own_timesheets', label: 'View Own Timesheets', description: 'View own timesheet entries', is_system: true },
      { key: 'can_view_all_timesheets', label: 'View All Timesheets', description: 'View timesheets from all users', is_system: true },
      { key: 'can_create_timesheets', label: 'Create Timesheets', description: 'Create new timesheet entries', is_system: true },
      { key: 'can_edit_own_timesheets', label: 'Edit Own Timesheets', description: 'Edit own timesheet entries', is_system: true },
      { key: 'can_edit_all_timesheets', label: 'Edit All Timesheets', description: 'Edit any timesheet in the system', is_system: true },
      { key: 'can_delete_own_timesheets', label: 'Delete Own Timesheets', description: 'Delete own timesheet entries', is_system: true },
      { key: 'can_delete_all_timesheets', label: 'Delete All Timesheets', description: 'Delete any timesheet in the system', is_system: true },
      // Invoices - granular permissions
      { key: 'can_view_own_invoices', label: 'View Own Invoices', description: 'View invoices created by user', is_system: true },
      { key: 'can_view_all_invoices', label: 'View All Invoices', description: 'View all invoices in the system', is_system: true },
      { key: 'can_create_invoices', label: 'Create Invoices', description: 'Create new invoices and quotes', is_system: true },
      { key: 'can_edit_own_invoices', label: 'Edit Own Invoices', description: 'Edit invoices created by user', is_system: true },
      { key: 'can_edit_all_invoices', label: 'Edit All Invoices', description: 'Edit any invoice in the system', is_system: true },
      { key: 'can_delete_own_invoices', label: 'Delete Own Invoices', description: 'Delete invoices created by user', is_system: true },
      { key: 'can_delete_all_invoices', label: 'Delete All Invoices', description: 'Delete any invoice in the system', is_system: true },
    ];
    
    for (const perm of defaultPermissions) {
      await client.query(
        `INSERT INTO permissions (key, label, description, is_system, is_custom, is_active) 
         VALUES ($1, $2, $3, $4, $5, $6)
         ON CONFLICT (key) DO UPDATE SET label = $2, description = $3, updated_at = CURRENT_TIMESTAMP`,
        [perm.key, perm.label, perm.description, perm.is_system, false, true]
      );
    }
    console.log('  ‚úì Default permissions seeded');
    
    // Create default admin user only if no admin exists
    const existingAdmin = await client.query(`SELECT id FROM users WHERE role = 'admin' LIMIT 1`);
    
    if (existingAdmin.rows.length === 0) {
    const hashedPassword = await bcrypt.hash('admin123', 10);
    
    try {
      await client.query(
        `INSERT INTO users (email, password_hash, name, role, is_active) 
         VALUES ($1, $2, $3, $4, $5)
         ON CONFLICT (email) DO NOTHING`,
        ['admin@ampedfieldops.com', hashedPassword, 'Admin User', 'admin', true]
      );
      console.log('  ‚úì Default admin user created (email: admin@ampedfieldops.com, password: admin123)');
    } catch (error) {
        console.log('  ‚ö†Ô∏è  Failed to create default admin user:', error);
      }
    } else {
      console.log('  ‚úì Admin user already exists, skipping default admin creation');
    }
    
    await client.query('COMMIT');
    console.log('‚úÖ Database seeded successfully!');
    
  } catch (error) {
    await client.query('ROLLBACK');
    console.error('‚ùå Seeding failed:', error);
    process.exit(1);
  } finally {
    client.release();
  }
  
  process.exit(0);
}

seed();
--- FILE: backend/src/jobs/backupScheduler.ts ---
import cron from 'node-cron';
import { query } from '../db';
import { createBackup, cleanupOldBackups } from '../lib/backup';
import { uploadToGoogleDrive } from '../lib/googleDrive';
import path from 'path';
import fs from 'fs/promises';

let scheduledJob: cron.ScheduledTask | null = null;

// Get backup schedule from database
async function getBackupSchedule(): Promise<{
  enabled: boolean;
  frequency: string;
  retention_days: number;
  backup_type: 'full' | 'database' | 'files';
  storage_type: 'local' | 'google_drive';
} | null> {
  try {
    const result = await query(
      "SELECT value FROM settings WHERE key = 'backup_schedule' ORDER BY updated_at DESC LIMIT 1"
    );

    if (result.rows.length === 0) {
      return null;
    }

    return JSON.parse(result.rows[0].value);
  } catch (error) {
    console.error('Failed to get backup schedule:', error);
    return null;
  }
}

// Get cron expression based on frequency
function getCronExpression(frequency: string): string {
  switch (frequency.toLowerCase()) {
    case 'daily':
      return '0 2 * * *'; // 2 AM daily
    case 'weekly':
      return '0 2 * * 0'; // 2 AM every Sunday
    case 'monthly':
      return '0 2 1 * *'; // 2 AM on the 1st of every month
    default:
      return '0 2 * * *'; // Default to daily
  }
}

// Run scheduled backup
async function runScheduledBackup() {
  console.log('[Backup Scheduler] Starting scheduled backup...');
  
  try {
    const schedule = await getBackupSchedule();
    
    if (!schedule || !schedule.enabled) {
      console.log('[Backup Scheduler] Backup schedule is disabled');
      return;
    }

    // Create backup
    const backupResult = await createBackup({
      type: schedule.backup_type,
      storageType: schedule.storage_type,
      userId: undefined // System backup
    });

    if (!backupResult.success || !backupResult.backupId) {
      console.error('[Backup Scheduler] Backup creation failed:', backupResult.error);
      return;
    }

    console.log(`[Backup Scheduler] Backup created: ${backupResult.backupId}`);

    // If Google Drive storage, upload the file
    if (schedule.storage_type === 'google_drive' && backupResult.filePath) {
      try {
        const fileName = path.basename(backupResult.filePath);
        const fileId = await uploadToGoogleDrive(
          backupResult.filePath,
          fileName
        );

        // Update backup record with Google Drive file ID
        await query(
          'UPDATE backups SET google_drive_file_id = $1 WHERE id = $2',
          [fileId, backupResult.backupId]
        );

        console.log(`[Backup Scheduler] Backup uploaded to Google Drive: ${fileId}`);

        // Optionally delete local file after upload to save space
        // await fs.unlink(backupResult.filePath);
      } catch (error: any) {
        console.error('[Backup Scheduler] Failed to upload to Google Drive:', error);
        // Update backup with error but don't fail
        await query(
          'UPDATE backups SET status = $1, error_message = $2 WHERE id = $3',
          ['failed', `Google Drive upload failed: ${error.message}`, backupResult.backupId]
        );
      }
    }

    // Cleanup old backups
    if (schedule.retention_days > 0) {
      const deletedCount = await cleanupOldBackups(schedule.retention_days);
      if (deletedCount > 0) {
        console.log(`[Backup Scheduler] Cleaned up ${deletedCount} old backups`);
      }
    }

    console.log('[Backup Scheduler] Scheduled backup completed successfully');
  } catch (error: any) {
    console.error('[Backup Scheduler] Scheduled backup failed:', error);
  }
}

// Start backup scheduler
export function startBackupScheduler() {
  console.log('[Backup Scheduler] Initializing backup scheduler...');

  // Stop existing job if any
  if (scheduledJob) {
    scheduledJob.stop();
    scheduledJob = null;
  }

  // Check schedule and start job
  getBackupSchedule().then((schedule) => {
    if (!schedule || !schedule.enabled) {
      console.log('[Backup Scheduler] Backup schedule is disabled, scheduler not started');
      return;
    }

    const cronExpression = getCronExpression(schedule.frequency);
    console.log(`[Backup Scheduler] Starting scheduler with frequency: ${schedule.frequency} (${cronExpression})`);

    scheduledJob = cron.schedule(cronExpression, async () => {
      await runScheduledBackup();
    }, {
      scheduled: true,
      timezone: 'UTC'
    });

    console.log('[Backup Scheduler] Backup scheduler started successfully');
  }).catch((error) => {
    console.error('[Backup Scheduler] Failed to start scheduler:', error);
  });
}

// Stop backup scheduler
export function stopBackupScheduler() {
  if (scheduledJob) {
    scheduledJob.stop();
    scheduledJob = null;
    console.log('[Backup Scheduler] Backup scheduler stopped');
  }
}

// Reload backup scheduler (useful when schedule changes)
export function reloadBackupScheduler() {
  stopBackupScheduler();
  startBackupScheduler();
}

--- FILE: backend/src/lib/__tests__/permissions.test.ts ---
import { getDefaultPermissions } from '../permissions';

describe('getDefaultPermissions', () => {
  describe('admin role', () => {
    it('should return all permissions including admin-specific ones', () => {
      const permissions = getDefaultPermissions('admin');
      
      // Base permissions
      expect(permissions).toContain('can_create_timesheets');
      expect(permissions).toContain('can_view_own_timesheets');
      expect(permissions).toContain('can_edit_own_timesheets');
      expect(permissions).toContain('can_delete_own_timesheets');
      expect(permissions).toContain('can_view_projects');
      expect(permissions).toContain('can_view_clients');
      expect(permissions).toContain('can_view_dashboard');
      
      // Admin-specific permissions
      expect(permissions).toContain('can_view_financials');
      expect(permissions).toContain('can_edit_projects');
      expect(permissions).toContain('can_manage_users');
      expect(permissions).toContain('can_sync_xero');
      expect(permissions).toContain('can_view_all_timesheets');
      expect(permissions).toContain('can_edit_activity_types');
      expect(permissions).toContain('can_manage_clients');
      expect(permissions).toContain('can_manage_cost_centers');
      expect(permissions).toContain('can_view_reports');
      expect(permissions).toContain('can_export_data');
      expect(permissions).toContain('can_manage_settings');
    });

    it('should have exactly 18 permissions for admin', () => {
      const permissions = getDefaultPermissions('admin');
      expect(permissions.length).toBe(18);
    });
  });

  describe('manager role', () => {
    it('should return base permissions plus manager-specific ones', () => {
      const permissions = getDefaultPermissions('manager');
      
      // Base permissions
      expect(permissions).toContain('can_create_timesheets');
      expect(permissions).toContain('can_view_own_timesheets');
      expect(permissions).toContain('can_edit_own_timesheets');
      expect(permissions).toContain('can_delete_own_timesheets');
      expect(permissions).toContain('can_view_projects');
      expect(permissions).toContain('can_view_clients');
      expect(permissions).toContain('can_view_dashboard');
      
      // Manager-specific permissions
      expect(permissions).toContain('can_view_financials');
      expect(permissions).toContain('can_edit_projects');
      expect(permissions).toContain('can_view_all_timesheets');
      expect(permissions).toContain('can_manage_clients');
      expect(permissions).toContain('can_view_reports');
      expect(permissions).toContain('can_export_data');
      
      // Should NOT have admin-only permissions
      expect(permissions).not.toContain('can_manage_users');
      expect(permissions).not.toContain('can_sync_xero');
      expect(permissions).not.toContain('can_edit_activity_types');
      expect(permissions).not.toContain('can_manage_cost_centers');
      expect(permissions).not.toContain('can_manage_settings');
    });

    it('should have exactly 13 permissions for manager', () => {
      const permissions = getDefaultPermissions('manager');
      expect(permissions.length).toBe(13);
    });
  });

  describe('user role', () => {
    it('should return only base permissions', () => {
      const permissions = getDefaultPermissions('user');
      
      // Base permissions
      expect(permissions).toContain('can_create_timesheets');
      expect(permissions).toContain('can_view_own_timesheets');
      expect(permissions).toContain('can_edit_own_timesheets');
      expect(permissions).toContain('can_delete_own_timesheets');
      expect(permissions).toContain('can_view_projects');
      expect(permissions).toContain('can_view_clients');
      expect(permissions).toContain('can_view_dashboard');
      
      // Should NOT have manager/admin permissions
      expect(permissions).not.toContain('can_view_financials');
      expect(permissions).not.toContain('can_edit_projects');
      expect(permissions).not.toContain('can_manage_users');
      expect(permissions).not.toContain('can_sync_xero');
      expect(permissions).not.toContain('can_view_all_timesheets');
    });

    it('should have exactly 7 permissions for user', () => {
      const permissions = getDefaultPermissions('user');
      expect(permissions.length).toBe(7);
    });
  });

  describe('invalid role', () => {
    it('should return base permissions for unknown role', () => {
      const permissions = getDefaultPermissions('invalid-role');
      
      expect(permissions).toContain('can_create_timesheets');
      expect(permissions).toContain('can_view_own_timesheets');
      expect(permissions.length).toBe(7);
    });

    it('should return base permissions for empty string', () => {
      const permissions = getDefaultPermissions('');
      
      expect(permissions.length).toBe(7);
    });
  });

  describe('permission uniqueness', () => {
    it('should not have duplicate permissions for admin', () => {
      const permissions = getDefaultPermissions('admin');
      const uniquePermissions = new Set(permissions);
      expect(permissions.length).toBe(uniquePermissions.size);
    });

    it('should not have duplicate permissions for manager', () => {
      const permissions = getDefaultPermissions('manager');
      const uniquePermissions = new Set(permissions);
      expect(permissions.length).toBe(uniquePermissions.size);
    });

    it('should not have duplicate permissions for user', () => {
      const permissions = getDefaultPermissions('user');
      const uniquePermissions = new Set(permissions);
      expect(permissions.length).toBe(uniquePermissions.size);
    });
  });
});
--- FILE: backend/src/lib/backup.ts ---
import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs/promises';
import { createWriteStream, createReadStream } from 'fs';
import path from 'path';
import archiver from 'archiver';
import { query } from '../db';
import dotenv from 'dotenv';
// Suppress dotenv parsing warnings
dotenv.config({ debug: false, override: false });

const env = {
  DATABASE_URL: process.env.DATABASE_URL || ''
};

const execAsync = promisify(exec);

interface BackupOptions {
  type: 'full' | 'database' | 'files';
  userId?: string;
  storageType?: 'local' | 'google_drive';
}

interface BackupResult {
  success: boolean;
  backupId?: string;
  filePath?: string;
  fileSize?: number;
  error?: string;
}

const BACKUP_DIR = path.join(process.cwd(), 'backups');
const UPLOADS_DIR = path.join(process.cwd(), 'uploads');

// Ensure backup directory exists
async function ensureBackupDir() {
  try {
    await fs.mkdir(BACKUP_DIR, { recursive: true });
    // Verify directory was created and is writable
    await fs.access(BACKUP_DIR, fs.constants.W_OK);
  } catch (error: any) {
    const errorMsg = `Failed to create or access backup directory (${BACKUP_DIR}): ${error.message}`;
    console.error(errorMsg, error);
    throw new Error(errorMsg);
  }
}

// Extract database connection details from DATABASE_URL
export function getDatabaseConfig() {
  const dbUrl = env.DATABASE_URL;
  if (!dbUrl) {
    throw new Error('DATABASE_URL not configured');
  }

  // Parse PostgreSQL connection string
  // Format: postgresql://user:password@host:port/database
  const url = new URL(dbUrl);
  return {
    host: url.hostname,
    port: url.port || '5432',
    database: url.pathname.slice(1), // Remove leading /
    user: url.username,
    password: url.password
  };
}

// Create database backup using pg_dump
async function backupDatabase(): Promise<string> {
  const config = getDatabaseConfig();
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const dumpFile = path.join(BACKUP_DIR, `database-${timestamp}.sql`);

  // Build pg_dump command
  const pgDumpCmd = [
    'pg_dump',
    `-h ${config.host}`,
    `-p ${config.port}`,
    `-U ${config.user}`,
    `-d ${config.database}`,
    '-F c', // Custom format (compressed)
    `-f ${dumpFile}`
  ].join(' ');

  // Set PGPASSWORD environment variable
  const envVars = { ...process.env, PGPASSWORD: config.password };

  try {
    await execAsync(pgDumpCmd, { env: envVars, maxBuffer: 10 * 1024 * 1024 }); // 10MB buffer
    // Verify file was created
    await fs.access(dumpFile);
    return dumpFile;
  } catch (error: any) {
    // Check if pg_dump is available
    if (error.message.includes('pg_dump') || error.message.includes('not found') || error.message.includes('ENOENT')) {
      throw new Error('pg_dump command not found. Please ensure PostgreSQL client tools are installed on the server.');
    }
    
    // Try alternative: plain SQL format
    const plainDumpCmd = [
      'pg_dump',
      `-h ${config.host}`,
      `-p ${config.port}`,
      `-U ${config.user}`,
      `-d ${config.database}`,
      `-f ${dumpFile}`
    ].join(' ');

    try {
      await execAsync(plainDumpCmd, { env: envVars, maxBuffer: 10 * 1024 * 1024 });
      // Verify file was created
      await fs.access(dumpFile);
      return dumpFile;
    } catch (retryError: any) {
      // Provide more detailed error message
      const errorDetails = retryError.stderr || retryError.message || 'Unknown error';
      throw new Error(`Database backup failed: ${errorDetails}. Check database connection and permissions.`);
    }
  }
}

// Create files backup (archive uploads directory)
async function backupFiles(): Promise<string> {
  const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
  const archiveFile = path.join(BACKUP_DIR, `files-${timestamp}.tar.gz`);

  return new Promise((resolve, reject) => {
    const output = createWriteStream(archiveFile);
    const archive = archiver('tar', {
      gzip: true,
      gzipOptions: { level: 9 }
    });

    output.on('close', () => {
      resolve(archiveFile);
    });

    archive.on('error', (err) => {
      reject(new Error(`File backup failed: ${err.message}`));
    });

    archive.pipe(output);

    // Check if uploads directory exists
    fs.access(UPLOADS_DIR)
      .then(() => {
        archive.directory(UPLOADS_DIR, false);
        archive.finalize();
      })
      .catch(() => {
        // If uploads directory doesn't exist, create empty archive
        archive.finalize();
      });
  });
}

// Compress multiple backup files into a single archive
async function compressBackup(files: string[], outputPath: string): Promise<string> {
  return new Promise((resolve, reject) => {
    const output = createWriteStream(outputPath);
    const archive = archiver('tar', {
      gzip: true,
      gzipOptions: { level: 9 }
    });

    output.on('close', () => {
      resolve(outputPath);
    });

    archive.on('error', (err: any) => {
      reject(new Error(`Compression failed: ${err.message || 'Unknown error'}`));
    });

    output.on('error', (err: any) => {
      reject(new Error(`Compression failed: ${err.message || 'Unknown error'}`));
    });

    archive.pipe(output);

    for (const file of files) {
      const fileName = path.basename(file);
      archive.file(file, { name: fileName });
    }

    archive.finalize();
  });
}

// Create backup based on type
export async function createBackup(options: BackupOptions): Promise<BackupResult> {
  const { type, userId, storageType = 'local' } = options;

  try {
    await ensureBackupDir();

    // Create backup record in database
    const backupResult = await query(
      `INSERT INTO backups (backup_type, storage_type, status, created_by)
       VALUES ($1, $2, 'pending', $3)
       RETURNING id`,
      [type, storageType, userId || null]
    );

    const backupId = backupResult.rows[0].id;
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    let backupFileList: string[] = [];
    let finalBackupPath: string;

    try {
      if (type === 'database' || type === 'full') {
        const dbBackup = await backupDatabase();
        backupFileList.push(dbBackup);
      }

      if (type === 'files' || type === 'full') {
        const filesBackup = await backupFiles();
        backupFileList.push(filesBackup);
      }

      // If multiple files, compress into single archive
      if (backupFileList.length > 1) {
        finalBackupPath = path.join(BACKUP_DIR, `backup-${backupId}-${timestamp}.tar.gz`);
        await compressBackup(backupFileList, finalBackupPath);
        // Clean up individual files
        for (const file of backupFileList) {
          await fs.unlink(file).catch(() => {});
        }
      } else {
        finalBackupPath = backupFileList[0];
      }

      // Get file size
      const stats = await fs.stat(finalBackupPath);
      const fileSize = stats.size;

      // Update backup record
      await query(
        `UPDATE backups 
         SET file_path = $1, file_size = $2, status = 'completed'
         WHERE id = $3`,
        [finalBackupPath, fileSize, backupId]
      );

      return {
        success: true,
        backupId,
        filePath: finalBackupPath,
        fileSize
      };
    } catch (error: any) {
      // Update backup record with error
      await query(
        `UPDATE backups 
         SET status = 'failed', error_message = $1
         WHERE id = $2`,
        [error.message, backupId]
      );

      return {
        success: false,
        backupId,
        error: error.message
      };
    }
  } catch (error: any) {
    console.error('Backup creation error:', error);
    return {
      success: false,
      error: error.message
    };
  }
}

// Cleanup old backups based on retention period
export async function cleanupOldBackups(retentionDays: number = 30): Promise<number> {
  try {
    const cutoffDate = new Date();
    cutoffDate.setDate(cutoffDate.getDate() - retentionDays);

    // Find backups to delete
    const backupsResult = await query(
      `SELECT id, file_path FROM backups 
       WHERE created_at < $1 AND storage_type = 'local'`,
      [cutoffDate]
    );

    let deletedCount = 0;

    for (const backup of backupsResult.rows) {
      try {
        // Delete file if it exists
        if (backup.file_path) {
          await fs.unlink(backup.file_path).catch(() => {});
        }

        // Delete database record
        await query('DELETE FROM backups WHERE id = $1', [backup.id]);
        deletedCount++;
      } catch (error) {
        console.error(`Failed to delete backup ${backup.id}:`, error);
      }
    }

    return deletedCount;
  } catch (error) {
    console.error('Backup cleanup error:', error);
    return 0;
  }
}

// Get backup file stream for download
export async function getBackupFileStream(backupId: string) {
  const result = await query(
    'SELECT file_path FROM backups WHERE id = $1 AND status = $2',
    [backupId, 'completed']
  );

  if (result.rows.length === 0) {
    throw new Error('Backup not found or not completed');
  }

  const filePath = result.rows[0].file_path;
  if (!filePath) {
    throw new Error('Backup file path not found');
  }

  // Check if file exists
  try {
    await fs.access(filePath);
  } catch {
    throw new Error('Backup file not found on disk');
  }

  return createReadStream(filePath);
}

--- FILE: backend/src/lib/cloudStorage.ts ---
import { Readable } from 'stream';
import { uploadToGoogleDrive, getAuthorizedClient } from './googleDrive';
import { google } from 'googleapis';
import fs from 'fs';
import path from 'path';

export interface CloudStorageConfig {
  provider: 's3' | 'google-drive' | 'local';
  // S3 config
  s3Bucket?: string;
  s3Region?: string;
  s3AccessKeyId?: string;
  s3SecretAccessKey?: string;
  // Google Drive config (uses existing googleDrive.ts)
  googleDriveFolderId?: string;
}

/**
 * Get cloud storage configuration from environment or database
 */
export async function getCloudStorageConfig(): Promise<CloudStorageConfig> {
  // Check environment variables first
  const provider = (process.env.CLOUD_STORAGE_PROVIDER || 'local') as 's3' | 'google-drive' | 'local';
  
  if (provider === 's3') {
    return {
      provider: 's3',
      s3Bucket: process.env.AWS_S3_BUCKET,
      s3Region: process.env.AWS_REGION || 'us-east-1',
      s3AccessKeyId: process.env.AWS_ACCESS_KEY_ID,
      s3SecretAccessKey: process.env.AWS_SECRET_ACCESS_KEY,
    };
  } else if (provider === 'google-drive') {
    return {
      provider: 'google-drive',
      googleDriveFolderId: process.env.GOOGLE_DRIVE_FOLDER_ID,
    };
  }
  
  return { provider: 'local' };
}

/**
 * Upload a file to cloud storage and return the public/signed URL
 */
export async function uploadFileToCloud(
  filePath: string,
  fileName: string,
  folderPath?: string
): Promise<string> {
  const config = await getCloudStorageConfig();
  
  if (config.provider === 'google-drive') {
    return await uploadToGoogleDriveForTimesheets(filePath, fileName, folderPath);
  } else if (config.provider === 's3') {
    return await uploadToS3(filePath, fileName, folderPath, config);
  } else {
    // Local storage - return relative path
    return `/uploads/${folderPath || 'general'}/${path.basename(filePath)}`;
  }
}

/**
 * Upload file to Google Drive for timesheet images
 */
async function uploadToGoogleDriveForTimesheets(
  filePath: string,
  fileName: string,
  folderPath?: string
): Promise<string> {
  const auth = await getAuthorizedClient();
  if (!auth) {
    throw new Error('Google Drive not authorized. Please connect your Google account in Settings.');
  }

  const drive = google.drive({ version: 'v3', auth });

  // Find or create folder structure: AmpedFieldOps/Timesheets/{project_id}
  let folderId: string | null = null;
  
  if (folderPath) {
    // Parse folderPath (e.g., "projects/{project_id}")
    const parts = folderPath.split('/');
    if (parts.length >= 2 && parts[0] === 'projects') {
      const projectId = parts[1];
      folderId = await findOrCreateTimesheetFolder(auth, projectId);
    }
  }

  // If no specific folder, use root or default folder
  if (!folderId) {
    folderId = await findOrCreateTimesheetFolder(auth);
  }

  const fileMetadata: any = {
    name: fileName,
  };

  if (folderId) {
    fileMetadata.parents = [folderId];
  }

  // Determine MIME type from file extension
  const ext = path.extname(fileName).toLowerCase();
  const mimeTypes: Record<string, string> = {
    '.jpg': 'image/jpeg',
    '.jpeg': 'image/jpeg',
    '.png': 'image/png',
    '.gif': 'image/gif',
    '.webp': 'image/webp',
    '.pdf': 'application/pdf',
  };
  const mimeType = mimeTypes[ext] || 'application/octet-stream';

  const media = {
    mimeType,
    body: fs.createReadStream(filePath),
  };

  try {
    const response = await drive.files.create({
      requestBody: fileMetadata,
      media: media,
      fields: 'id, name, webViewLink, webContentLink',
    });

    // Make file publicly viewable (or use service account for better security)
    if (response.data.id) {
      await drive.permissions.create({
        fileId: response.data.id,
        requestBody: {
          role: 'reader',
          type: 'anyone',
        },
      });
    }

    // Return the web view link (public URL)
    return response.data.webViewLink || `https://drive.google.com/file/d/${response.data.id}/view`;
  } catch (error: any) {
    console.error('Failed to upload to Google Drive:', error);
    throw new Error(`Failed to upload to Google Drive: ${error.message}`);
  }
}

/**
 * Find or create timesheet folder in Google Drive
 */
async function findOrCreateTimesheetFolder(
  auth: any,
  projectId?: string
): Promise<string | null> {
  const drive = google.drive({ version: 'v3', auth });
  const baseFolderName = 'AmpedFieldOps';
  const timesheetFolderName = 'Timesheets';

  try {
    // Find or create base folder
    let baseFolderId = await findFolderByName(drive, baseFolderName);
    if (!baseFolderId) {
      const baseFolder = await drive.files.create({
        requestBody: {
          name: baseFolderName,
          mimeType: 'application/vnd.google-apps.folder',
        },
        fields: 'id',
      });
      baseFolderId = baseFolder.data.id || null;
      
      // Make base folder accessible
      if (baseFolderId) {
        await drive.permissions.create({
          fileId: baseFolderId,
          requestBody: {
            role: 'reader',
            type: 'anyone',
          },
        });
      }
    }

    if (!baseFolderId) return null;

    // Find or create Timesheets folder
    let timesheetFolderId = await findFolderByName(drive, timesheetFolderName, baseFolderId);
    if (!timesheetFolderId) {
      const timesheetFolder = await drive.files.create({
        requestBody: {
          name: timesheetFolderName,
          mimeType: 'application/vnd.google-apps.folder',
          parents: [baseFolderId],
        },
        fields: 'id',
      });
      timesheetFolderId = timesheetFolder.data.id || null;
    }

    // If projectId is provided, create project-specific subfolder
    if (projectId && timesheetFolderId) {
      let projectFolderId = await findFolderByName(drive, projectId, timesheetFolderId);
      if (!projectFolderId) {
        const projectFolder = await drive.files.create({
          requestBody: {
            name: projectId,
            mimeType: 'application/vnd.google-apps.folder',
            parents: [timesheetFolderId],
          },
          fields: 'id',
        });
        projectFolderId = projectFolder.data.id || null;
      }
      return projectFolderId;
    }

    return timesheetFolderId;
  } catch (error: any) {
    console.error('Failed to find or create timesheet folder:', error);
    return null;
  }
}

/**
 * Helper to find a folder by name
 */
async function findFolderByName(
  drive: any,
  folderName: string,
  parentId?: string
): Promise<string | null> {
  let query = `name='${folderName}' and mimeType='application/vnd.google-apps.folder' and trashed=false`;
  if (parentId) {
    query += ` and '${parentId}' in parents`;
  }

  const response = await drive.files.list({
    q: query,
    fields: 'files(id, name)',
    spaces: 'drive',
  });

  if (response.data.files && response.data.files.length > 0) {
    return response.data.files[0].id || null;
  }

  return null;
}

/**
 * Upload file to S3
 */
async function uploadToS3(
  filePath: string,
  fileName: string,
  folderPath: string | undefined,
  config: CloudStorageConfig
): Promise<string> {
  // Dynamic import to avoid requiring AWS SDK if not using S3
  const { S3Client, PutObjectCommand } = await import('@aws-sdk/client-s3');
  const { getSignedUrl } = await import('@aws-sdk/s3-request-presigner');
  const { GetObjectCommand } = await import('@aws-sdk/client-s3');

  if (!config.s3Bucket || !config.s3AccessKeyId || !config.s3SecretAccessKey) {
    throw new Error('S3 configuration incomplete. Please set AWS_S3_BUCKET, AWS_ACCESS_KEY_ID, and AWS_SECRET_ACCESS_KEY.');
  }

  const s3Client = new S3Client({
    region: config.s3Region || 'us-east-1',
    credentials: {
      accessKeyId: config.s3AccessKeyId,
      secretAccessKey: config.s3SecretAccessKey,
    },
  });

  // Construct S3 key (path)
  const s3Key = folderPath ? `${folderPath}/${fileName}` : fileName;

  // Read file
  const fileContent = fs.readFileSync(filePath);

  // Upload to S3
  const putCommand = new PutObjectCommand({
    Bucket: config.s3Bucket,
    Key: s3Key,
    Body: fileContent,
    ContentType: getContentType(fileName),
    ACL: 'public-read', // Or use signed URLs for better security
  });

  try {
    await s3Client.send(putCommand);

    // Return public URL
    return `https://${config.s3Bucket}.s3.${config.s3Region || 'us-east-1'}.amazonaws.com/${s3Key}`;
  } catch (error: any) {
    console.error('Failed to upload to S3:', error);
    throw new Error(`Failed to upload to S3: ${error.message}`);
  }
}

/**
 * Get content type from file extension
 */
function getContentType(fileName: string): string {
  const ext = path.extname(fileName).toLowerCase();
  const contentTypes: Record<string, string> = {
    '.jpg': 'image/jpeg',
    '.jpeg': 'image/jpeg',
    '.png': 'image/png',
    '.gif': 'image/gif',
    '.webp': 'image/webp',
    '.pdf': 'application/pdf',
  };
  return contentTypes[ext] || 'application/octet-stream';
}

/**
 * Delete file from cloud storage
 */
export async function deleteFileFromCloud(fileUrl: string): Promise<void> {
  const config = await getCloudStorageConfig();
  
  if (config.provider === 'google-drive') {
    // Extract file ID from Google Drive URL
    const fileIdMatch = fileUrl.match(/\/file\/d\/([a-zA-Z0-9_-]+)/);
    if (fileIdMatch && fileIdMatch[1]) {
      const { deleteFromGoogleDrive } = await import('./googleDrive');
      await deleteFromGoogleDrive(fileIdMatch[1]);
    }
  } else if (config.provider === 's3') {
    // Extract key from S3 URL and delete
    const urlMatch = fileUrl.match(/\.amazonaws\.com\/(.+)$/);
    if (urlMatch && urlMatch[1]) {
      const { S3Client, DeleteObjectCommand } = await import('@aws-sdk/client-s3');
      const s3Client = new S3Client({
        region: config.s3Region || 'us-east-1',
        credentials: {
          accessKeyId: config.s3AccessKeyId!,
          secretAccessKey: config.s3SecretAccessKey!,
        },
      });
      
      await s3Client.send(new DeleteObjectCommand({
        Bucket: config.s3Bucket!,
        Key: urlMatch[1],
      }));
    }
  }
  // Local storage - file deletion handled separately
}
--- FILE: backend/src/lib/constants.ts ---
/**
 * Application constants
 * Centralized configuration values to avoid magic numbers
 */

// Authentication & Security
export const AUTH_CONSTANTS = {
  JWT_EXPIRATION: '7d', // JWT token expiration
  JWT_PASSWORD_RESET_EXPIRATION: '1h', // Password reset token expiration
  BCRYPT_ROUNDS: 12, // Password hashing rounds
  MIN_PASSWORD_LENGTH: 8, // Minimum password length
  MIN_JWT_SECRET_LENGTH: 32, // Minimum JWT secret length
} as const;

// Rate Limiting
export const RATE_LIMIT_CONSTANTS = {
  AUTH_WINDOW_MS: 15 * 60 * 1000, // 15 minutes
  AUTH_MAX_REQUESTS: 5, // Max auth requests per window
  PASSWORD_RESET_WINDOW_MS: 60 * 60 * 1000, // 1 hour
  PASSWORD_RESET_MAX_REQUESTS: 3, // Max password reset requests per hour
  UPLOAD_WINDOW_MS: 15 * 60 * 1000, // 15 minutes
  UPLOAD_MAX_REQUESTS: 50, // Max upload requests per window
  GLOBAL_API_WINDOW_MS: 15 * 60 * 1000, // 15 minutes
  GLOBAL_API_MAX_REQUESTS: 1000, // Max API requests per window (increased for normal app usage)
} as const;

// Pagination
export const PAGINATION_CONSTANTS = {
  DEFAULT_LIMIT: 20, // Default items per page
  MAX_LIMIT: 100, // Maximum items per page
  KANBAN_LIMIT: 100, // Limit for Kanban boards (load more items)
  TIMESHEETS_DEFAULT_LIMIT: 50, // Default limit for timesheets
} as const;

// File Upload
export const FILE_CONSTANTS = {
  MAX_FILE_SIZE: 10 * 1024 * 1024, // 10MB max file size
  ALLOWED_IMAGE_TYPES: ['image/jpeg', 'image/png', 'image/gif', 'image/webp'],
  ALLOWED_DOCUMENT_TYPES: ['application/pdf', 'application/msword', 'application/vnd.openxmlformats-officedocument.wordprocessingml.document'],
  UPLOAD_DIR: 'uploads', // Upload directory
} as const;

// Logging
export const LOG_CONSTANTS = {
  MAX_FILE_SIZE: 5 * 1024 * 1024, // 5MB max log file size
  MAX_FILES: 5, // Maximum number of log files to keep
  LOG_DIR: 'logs', // Log directory
} as const;

// Database
export const DB_CONSTANTS = {
  CONNECTION_POOL_MIN: 2, // Minimum connections in pool
  CONNECTION_POOL_MAX: 10, // Maximum connections in pool
  QUERY_TIMEOUT: 30000, // 30 seconds query timeout
} as const;

// Activity Logs
export const ACTIVITY_LOG_CONSTANTS = {
  MAX_RECENT_SEARCHES: 10, // Maximum recent searches to store
  MAX_ERROR_LOGS: 200, // Maximum error logs in frontend
  MAX_NOTIFICATIONS: 50, // Maximum notifications in frontend
} as const;

// Project Code Generation
export const PROJECT_CODE_CONSTANTS = {
  PREFIX: 'PRJ', // Project code prefix
  YEAR_FORMAT: 'YYYY', // Year format in project code
  PADDING_LENGTH: 3, // Number padding length
} as const;

// Backup
export const BACKUP_CONSTANTS = {
  DEFAULT_RETENTION_DAYS: 30, // Default backup retention period
  MAX_BACKUP_SIZE: 500 * 1024 * 1024, // 500MB max backup size
} as const;
--- FILE: backend/src/lib/csp.ts ---
import { StorageFactory } from './storage/StorageFactory';
import { log } from './logger';

/**
 * Generate Content-Security-Policy header based on storage configuration
 * 
 * When S3 is used, we need to allow S3 bucket domains in CSP to prevent
 * browser blocking of images/files loaded from S3.
 */
export async function generateCSPDirective(): Promise<string> {
  try {
    const storage = await StorageFactory.getInstance();
    const driver = storage.getDriver();
    
    // Base CSP directives
    let csp = "default-src 'self';";
    csp += " style-src 'self' 'unsafe-inline';"; // Allow inline styles for React
    csp += " script-src 'self';";
    csp += " connect-src 'self';";
    csp += " font-src 'self';";
    csp += " object-src 'none';";
    csp += " frame-src 'none';";
    
    // Image sources
    csp += " img-src 'self' data: https:;";
    
    // Media sources
    csp += " media-src 'self';";
    
    // If using S3, add S3 domains to CSP
    if (driver === 's3') {
      try {
        // Get S3 configuration to determine domain
        // For now, we'll use wildcard patterns that cover most S3 setups
        // In production, you might want to read the actual bucket/region from settings
        csp += " img-src 'self' data: https: https://*.s3.amazonaws.com https://*.s3.*.amazonaws.com https://*.s3-*.amazonaws.com;";
        csp += " media-src 'self' https://*.s3.amazonaws.com https://*.s3.*.amazonaws.com https://*.s3-*.amazonaws.com;";
        csp += " object-src 'self' https://*.s3.amazonaws.com https://*.s3.*.amazonaws.com https://*.s3-*.amazonaws.com;";
      } catch (error) {
        log.error('Failed to get S3 config for CSP', error);
        // Fallback to wildcard S3 patterns
        csp += " img-src 'self' data: https: https://*.s3.amazonaws.com https://*.s3.*.amazonaws.com;";
        csp += " media-src 'self' https://*.s3.amazonaws.com https://*.s3.*.amazonaws.com;";
      }
    }
    
    return csp;
  } catch (error) {
    log.error('Failed to generate CSP directive', error);
    // Return safe default CSP
    return "default-src 'self'; style-src 'self' 'unsafe-inline'; script-src 'self'; img-src 'self' data: https:;";
  }
}

/**
 * Extract S3 domain from configuration
 * Helper function to get exact S3 domain for CSP
 */
export function extractS3Domain(bucket?: string, region?: string, endpoint?: string): string {
  if (endpoint) {
    // Custom endpoint (MinIO, DigitalOcean Spaces, etc.)
    try {
      const url = new URL(endpoint);
      return `${url.protocol}//${url.hostname}`;
    } catch {
      return endpoint;
    }
  }
  
  if (bucket && region) {
    // Standard AWS S3: https://bucket.s3.region.amazonaws.com
    return `https://${bucket}.s3.${region}.amazonaws.com`;
  }
  
  // Fallback to wildcard patterns
  return 'https://*.s3.amazonaws.com https://*.s3.*.amazonaws.com';
}
--- FILE: backend/src/lib/documentMatcher.ts ---
/**
 * Document Matching Algorithm
 * Matches scanned documents to existing financial records
 */
import { query } from '../db';
import { log } from './logger';
import { fuzzyMatch } from './utils/stringUtils';
import { distance } from 'fastest-levenshtein';

export interface DocumentMatch {
  id: string;
  entity_type: 'purchase_order' | 'invoice' | 'bill' | 'expense';
  entity_id: string;
  confidence_score: number;
  match_reasons: string[];
  entity_data: any;
}

export interface ExtractedData {
  document_number?: string;
  date?: string;
  amount?: number;
  total_amount?: number;
  vendor_name?: string;
}

/**
 * Find matches for a scanned document
 */
export async function findMatches(
  scanId: string,
  extractedData: ExtractedData,
  documentType: string
): Promise<DocumentMatch[]> {
  const matches: DocumentMatch[] = [];

  try {
    // Match based on document type
    if (documentType === 'purchase_order' || documentType === 'unknown') {
      const poMatches = await matchPurchaseOrders(extractedData);
      matches.push(...poMatches);
    }

    if (documentType === 'invoice' || documentType === 'unknown') {
      const invoiceMatches = await matchInvoices(extractedData);
      matches.push(...invoiceMatches);
    }

    if (documentType === 'bill' || documentType === 'unknown') {
      const billMatches = await matchBills(extractedData);
      matches.push(...billMatches);
    }

    if (documentType === 'receipt' || documentType === 'expense' || documentType === 'unknown') {
      const expenseMatches = await matchExpenses(extractedData);
      matches.push(...expenseMatches);
    }

    // Sort by confidence score (highest first)
    matches.sort((a, b) => b.confidence_score - a.confidence_score);

    // Return top 5 matches
    return matches.slice(0, 5);
  } catch (error) {
    log.error('Error finding document matches', error, { scanId });
    return [];
  }
}

/**
 * Match against purchase orders
 */
async function matchPurchaseOrders(data: ExtractedData): Promise<DocumentMatch[]> {
  const matches: DocumentMatch[] = [];

  if (!data.document_number && !data.amount && !data.vendor_name) {
    return matches;
  }

  let sql = 'SELECT id, po_number, supplier_id, project_id, total_amount, date FROM xero_purchase_orders WHERE 1=1';
  const params: any[] = [];
  let paramCount = 1;

  // Match by PO number
  if (data.document_number) {
    sql += ` AND (po_number ILIKE $${paramCount} OR po_number ILIKE $${paramCount + 1})`;
    params.push(`%${data.document_number}%`, data.document_number);
    paramCount += 2;
  }

  const result = await query(sql, params);

  for (const po of result.rows) {
    const reasons: string[] = [];
    let confidence = 0;

    // Match by PO number (exact or fuzzy)
    if (data.document_number && po.po_number) {
      const poNumberMatch = fuzzyMatch(data.document_number, po.po_number);
      if (poNumberMatch > 0.8) {
        confidence += 0.5;
        reasons.push(`PO number match: ${po.po_number}`);
      } else if (poNumberMatch > 0.6) {
        confidence += 0.3;
        reasons.push(`PO number partial match: ${po.po_number}`);
      }
    }

    // Match by amount (within $0.01 tolerance)
    if (data.total_amount && po.total_amount) {
      const amountDiff = Math.abs(data.total_amount - parseFloat(po.total_amount));
      if (amountDiff < 0.01) {
        confidence += 0.4;
        reasons.push(`Amount match: $${po.total_amount}`);
      } else if (amountDiff < 1.0) {
        confidence += 0.2;
        reasons.push(`Amount close match: $${po.total_amount} (diff: $${amountDiff.toFixed(2)})`);
      }
    }

    // Match by date (within 7 days)
    if (data.date && po.date) {
      const scanDate = new Date(data.date);
      const poDate = new Date(po.date);
      const daysDiff = Math.abs((scanDate.getTime() - poDate.getTime()) / (1000 * 60 * 60 * 24));
      if (daysDiff <= 7) {
        confidence += 0.1;
        reasons.push(`Date within range: ${po.date} (${daysDiff.toFixed(0)} days)`);
      }
    }

    if (confidence > 0.3) {
      matches.push({
        id: po.id,
        entity_type: 'purchase_order',
        entity_id: po.id,
        confidence_score: Math.min(confidence, 1.0),
        match_reasons: reasons,
        entity_data: po,
      });
    }
  }

  return matches;
}

/**
 * Match against invoices
 */
async function matchInvoices(data: ExtractedData): Promise<DocumentMatch[]> {
  const matches: DocumentMatch[] = [];

  if (!data.document_number && !data.amount) {
    return matches;
  }

  let sql = 'SELECT id, invoice_number, client_id, project_id, total, issue_date FROM xero_invoices WHERE 1=1';
  const params: any[] = [];
  let paramCount = 1;

  // Match by invoice number
  if (data.document_number) {
    sql += ` AND invoice_number ILIKE $${paramCount}`;
    params.push(`%${data.document_number}%`);
    paramCount++;
  }

  const result = await query(sql, params);

  for (const invoice of result.rows) {
    const reasons: string[] = [];
    let confidence = 0;

    // Match by invoice number
    if (data.document_number && invoice.invoice_number) {
      const invMatch = fuzzyMatch(data.document_number, invoice.invoice_number);
      if (invMatch > 0.8) {
        confidence += 0.5;
        reasons.push(`Invoice number match: ${invoice.invoice_number}`);
      } else if (invMatch > 0.6) {
        confidence += 0.3;
        reasons.push(`Invoice number partial match: ${invoice.invoice_number}`);
      }
    }

    // Match by amount
    if (data.total_amount && invoice.total) {
      const amountDiff = Math.abs(data.total_amount - parseFloat(invoice.total));
      if (amountDiff < 0.01) {
        confidence += 0.4;
        reasons.push(`Amount match: $${invoice.total}`);
      } else if (amountDiff < 1.0) {
        confidence += 0.2;
        reasons.push(`Amount close match: $${invoice.total}`);
      }
    }

    // Match by date
    if (data.date && invoice.issue_date) {
      const scanDate = new Date(data.date);
      const invDate = new Date(invoice.issue_date);
      const daysDiff = Math.abs((scanDate.getTime() - invDate.getTime()) / (1000 * 60 * 60 * 24));
      if (daysDiff <= 7) {
        confidence += 0.1;
        reasons.push(`Date within range: ${invoice.issue_date}`);
      }
    }

    if (confidence > 0.3) {
      matches.push({
        id: invoice.id,
        entity_type: 'invoice',
        entity_id: invoice.id,
        confidence_score: Math.min(confidence, 1.0),
        match_reasons: reasons,
        entity_data: invoice,
      });
    }
  }

  return matches;
}

/**
 * Match against bills
 */
async function matchBills(data: ExtractedData): Promise<DocumentMatch[]> {
  const matches: DocumentMatch[] = [];

  if (!data.document_number && !data.amount && !data.vendor_name) {
    return matches;
  }

  let sql = 'SELECT id, bill_number, supplier_id, project_id, amount, date FROM xero_bills WHERE 1=1';
  const params: any[] = [];
  let paramCount = 1;

  // Match by bill number
  if (data.document_number) {
    sql += ` AND bill_number ILIKE $${paramCount}`;
    params.push(`%${data.document_number}%`);
    paramCount++;
  }

  const result = await query(sql, params);

  for (const bill of result.rows) {
    const reasons: string[] = [];
    let confidence = 0;

    // Match by bill number
    if (data.document_number && bill.bill_number) {
      const billMatch = fuzzyMatch(data.document_number, bill.bill_number);
      if (billMatch > 0.8) {
        confidence += 0.5;
        reasons.push(`Bill number match: ${bill.bill_number}`);
      }
    }

    // Match by amount
    if (data.total_amount && bill.amount) {
      const amountDiff = Math.abs(data.total_amount - parseFloat(bill.amount));
      if (amountDiff < 0.01) {
        confidence += 0.4;
        reasons.push(`Amount match: $${bill.amount}`);
      }
    }

    // Match by date
    if (data.date && bill.date) {
      const scanDate = new Date(data.date);
      const billDate = new Date(bill.date);
      const daysDiff = Math.abs((scanDate.getTime() - billDate.getTime()) / (1000 * 60 * 60 * 24));
      if (daysDiff <= 7) {
        confidence += 0.1;
        reasons.push(`Date within range: ${bill.date}`);
      }
    }

    // Match by vendor (if we have supplier info)
    if (data.vendor_name && bill.supplier_id) {
      const supplierResult = await query('SELECT name FROM clients WHERE id = $1', [bill.supplier_id]);
      if (supplierResult.rows.length > 0) {
        const supplierName = supplierResult.rows[0].name;
        const vendorMatch = fuzzyMatch(data.vendor_name, supplierName);
        if (vendorMatch > 0.7) {
          confidence += 0.3;
          reasons.push(`Vendor match: ${supplierName}`);
        }
      }
    }

    if (confidence > 0.3) {
      matches.push({
        id: bill.id,
        entity_type: 'bill',
        entity_id: bill.id,
        confidence_score: Math.min(confidence, 1.0),
        match_reasons: reasons,
        entity_data: bill,
      });
    }
  }

  return matches;
}

/**
 * Match against expenses
 */
async function matchExpenses(data: ExtractedData): Promise<DocumentMatch[]> {
  const matches: DocumentMatch[] = [];

  if (!data.amount && !data.vendor_name) {
    return matches;
  }

  let sql = 'SELECT id, project_id, cost_center_id, amount, date, description FROM xero_expenses WHERE 1=1';
  const params: any[] = [];
  let paramCount = 1;

  // Match by amount (within $1 tolerance for expenses)
  if (data.total_amount) {
    sql += ` AND ABS(amount - $${paramCount}) < 1.0`;
    params.push(data.total_amount);
    paramCount++;
  }

  const result = await query(sql, params);

  for (const expense of result.rows) {
    const reasons: string[] = [];
    let confidence = 0;

    // Match by amount
    if (data.total_amount && expense.amount) {
      const amountDiff = Math.abs(data.total_amount - parseFloat(expense.amount));
      if (amountDiff < 0.01) {
        confidence += 0.5;
        reasons.push(`Amount exact match: $${expense.amount}`);
      } else if (amountDiff < 1.0) {
        confidence += 0.3;
        reasons.push(`Amount close match: $${expense.amount}`);
      }
    }

    // Match by date
    if (data.date && expense.date) {
      const scanDate = new Date(data.date);
      const expDate = new Date(expense.date);
      const daysDiff = Math.abs((scanDate.getTime() - expDate.getTime()) / (1000 * 60 * 60 * 24));
      if (daysDiff <= 7) {
        confidence += 0.2;
        reasons.push(`Date within range: ${expense.date}`);
      }
    }

    // Match by vendor name in description
    if (data.vendor_name && expense.description) {
      const descMatch = fuzzyMatch(data.vendor_name, expense.description);
      if (descMatch > 0.6) {
        confidence += 0.2;
        reasons.push(`Vendor name in description`);
      }
    }

    if (confidence > 0.3) {
      matches.push({
        id: expense.id,
        entity_type: 'expense',
        entity_id: expense.id,
        confidence_score: Math.min(confidence, 1.0),
        match_reasons: reasons,
        entity_data: expense,
      });
    }
  }

  return matches;
}
--- FILE: backend/src/lib/email.ts ---
import nodemailer from 'nodemailer';
import { env } from '../config/env';
import { query } from '../db';

// Create reusable transporter
let transporter: nodemailer.Transporter | null = null;
let cachedSettings: {
  smtp_host?: string;
  smtp_port?: string;
  smtp_user?: string;
  smtp_password?: string;
  smtp_from?: string;
} | null = null;

// Cache settings for 5 minutes
let settingsCacheTime = 0;
const SETTINGS_CACHE_DURATION = 5 * 60 * 1000; // 5 minutes

async function getEmailSettings(): Promise<{
  smtp_host?: string;
  smtp_port?: string;
  smtp_user?: string;
  smtp_password?: string;
  smtp_from?: string;
}> {
  // Return cached settings if still valid
  if (cachedSettings && Date.now() - settingsCacheTime < SETTINGS_CACHE_DURATION) {
    return cachedSettings;
  }

  try {
    // Get email settings from database (global settings only)
    const result = await query(
      `SELECT key, value FROM settings 
       WHERE user_id IS NULL 
       AND key IN ('smtp_host', 'smtp_port', 'smtp_user', 'smtp_password', 'smtp_from')`
    );

    const settings: Record<string, string> = {};
    result.rows.forEach((row: any) => {
      settings[row.key] = row.value;
    });

    // Cache the settings
    cachedSettings = {
      smtp_host: settings.smtp_host,
      smtp_port: settings.smtp_port,
      smtp_user: settings.smtp_user,
      smtp_password: settings.smtp_password,
      smtp_from: settings.smtp_from,
    };
    settingsCacheTime = Date.now();

    return cachedSettings;
  } catch (error) {
    console.error('[Email] Failed to load settings from database:', error);
    // Return empty object on error, will fall back to env vars
    return {};
  }
}

// Clear settings cache (call this when settings are updated)
export function clearEmailSettingsCache() {
  cachedSettings = null;
  settingsCacheTime = 0;
  // Also clear transporter so it gets recreated with new settings
  transporter = null;
}

async function getTransporter(): Promise<nodemailer.Transporter | null> {
  // Return cached transporter if available
  if (transporter) {
    return transporter;
  }

  // Get settings from database first, then fall back to env vars
  const dbSettings = await getEmailSettings();
  
  const smtpHost = dbSettings.smtp_host || process.env.SMTP_HOST;
  const smtpPort = dbSettings.smtp_port || process.env.SMTP_PORT;
  const smtpUser = dbSettings.smtp_user || process.env.SMTP_USER;
  const smtpPassword = dbSettings.smtp_password || process.env.SMTP_PASSWORD;
  const smtpFrom = dbSettings.smtp_from || process.env.SMTP_FROM || smtpUser || 'noreply@ampedfieldops.com';

  // If no SMTP configured, return null (emails will be logged only)
  if (!smtpHost || !smtpPort || !smtpUser || !smtpPassword) {
    console.warn('[Email] SMTP not configured. Emails will be logged to console only.');
    console.warn('[Email] Set SMTP_HOST, SMTP_PORT, SMTP_USER, SMTP_PASSWORD, and SMTP_FROM to enable email sending.');
    return null;
  }

  // Create transporter
  transporter = nodemailer.createTransport({
    host: smtpHost,
    port: parseInt(smtpPort, 10),
    secure: parseInt(smtpPort, 10) === 465, // true for 465, false for other ports
    auth: {
      user: smtpUser,
      pass: smtpPassword,
    },
    // For development/testing with services like Mailtrap
    tls: {
      rejectUnauthorized: process.env.NODE_ENV === 'production',
    },
  });

  return transporter;
}

export async function sendPasswordResetEmail(email: string, resetToken: string, userName?: string): Promise<boolean> {
  const resetUrl = `${env.FRONTEND_URL}/forgot-password?token=${resetToken}`;
  const subject = 'Password Reset Request';
  const html = `
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="utf-8">
      <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; color: #333; }
        .container { max-width: 600px; margin: 0 auto; padding: 20px; }
        .header { background-color: #4F46E5; color: white; padding: 20px; text-align: center; border-radius: 8px 8px 0 0; }
        .content { background-color: #f9fafb; padding: 30px; border: 1px solid #e5e7eb; border-top: none; }
        .button { display: inline-block; padding: 12px 24px; background-color: #4F46E5; color: white; text-decoration: none; border-radius: 6px; margin: 20px 0; }
        .footer { text-align: center; margin-top: 20px; color: #6b7280; font-size: 12px; }
        .code { background-color: #f3f4f6; padding: 15px; border-radius: 6px; font-family: monospace; word-break: break-all; margin: 20px 0; }
      </style>
    </head>
    <body>
      <div class="container">
        <div class="header">
          <h1>Password Reset Request</h1>
        </div>
        <div class="content">
          <p>Hello${userName ? ` ${userName}` : ''},</p>
          <p>We received a request to reset your password for your AmpedFieldOps account.</p>
          <p>Click the button below to reset your password:</p>
          <p style="text-align: center;">
            <a href="${resetUrl}" class="button">Reset Password</a>
          </p>
          <p>Or copy and paste this link into your browser:</p>
          <div class="code">${resetUrl}</div>
          <p><strong>This link will expire in 1 hour.</strong></p>
          <p>If you didn't request a password reset, you can safely ignore this email.</p>
        </div>
        <div class="footer">
          <p>This is an automated message from AmpedFieldOps. Please do not reply to this email.</p>
        </div>
      </div>
    </body>
    </html>
  `;

  const text = `
Password Reset Request

Hello${userName ? ` ${userName}` : ''},

We received a request to reset your password for your AmpedFieldOps account.

Click this link to reset your password:
${resetUrl}

This link will expire in 1 hour.

If you didn't request a password reset, you can safely ignore this email.

This is an automated message from AmpedFieldOps.
  `;

  // Get current settings to determine "from" address
  const dbSettings = await getEmailSettings();
  const smtpFrom = dbSettings.smtp_from || process.env.SMTP_FROM || process.env.SMTP_USER || 'noreply@ampedfieldops.com';

  const mailOptions = {
    from: smtpFrom,
    to: email,
    subject: subject,
    text: text,
    html: html,
  };

  const emailTransporter = await getTransporter();

  if (!emailTransporter) {
    // Log email details instead of sending
    console.log('\n=== PASSWORD RESET EMAIL (NOT SENT - SMTP NOT CONFIGURED) ===');
    console.log('To:', email);
    console.log('Subject:', subject);
    console.log('Reset URL:', resetUrl);
    console.log('Reset Token:', resetToken);
    console.log('===============================================================\n');
    return false;
  }

  try {
    await emailTransporter.sendMail(mailOptions);
    console.log(`[Email] Password reset email sent to ${email}`);
    return true;
  } catch (error) {
    console.error('[Email] Failed to send password reset email:', error);
    // Log email details as fallback
    console.log('\n=== PASSWORD RESET EMAIL (FAILED TO SEND) ===');
    console.log('To:', email);
    console.log('Subject:', subject);
    console.log('Reset URL:', resetUrl);
    console.log('Reset Token:', resetToken);
    console.log('===============================================\n');
    return false;
  }
}

// Verify email configuration
export async function verifyEmailConfig(): Promise<boolean> {
  const emailTransporter = await getTransporter();
  if (!emailTransporter) {
    return false;
  }

  try {
    await emailTransporter.verify();
    console.log('[Email] SMTP configuration verified successfully');
    return true;
  } catch (error) {
    console.error('[Email] SMTP configuration verification failed:', error);
    return false;
  }
}

// Send test email
export async function sendTestEmail(to: string): Promise<boolean> {
  const subject = 'Test Email from AmpedFieldOps';
  const html = `
    <!DOCTYPE html>
    <html>
    <head>
      <meta charset="utf-8">
      <style>
        body { font-family: Arial, sans-serif; line-height: 1.6; color: #333; }
        .container { max-width: 600px; margin: 0 auto; padding: 20px; }
        .header { background-color: #4F46E5; color: white; padding: 20px; text-align: center; border-radius: 8px 8px 0 0; }
        .content { background-color: #f9fafb; padding: 30px; border: 1px solid #e5e7eb; border-top: none; }
        .footer { text-align: center; margin-top: 20px; color: #6b7280; font-size: 12px; }
      </style>
    </head>
    <body>
      <div class="container">
        <div class="header">
          <h1>Test Email</h1>
        </div>
        <div class="content">
          <p>Hello,</p>
          <p>This is a test email from your AmpedFieldOps system.</p>
          <p>If you received this email, your SMTP configuration is working correctly!</p>
        </div>
        <div class="footer">
          <p>This is an automated test message from AmpedFieldOps.</p>
        </div>
      </div>
    </body>
    </html>
  `;

  const text = `
Test Email

Hello,

This is a test email from your AmpedFieldOps system.

If you received this email, your SMTP configuration is working correctly!

This is an automated test message from AmpedFieldOps.
  `;

  const dbSettings = await getEmailSettings();
  const smtpFrom = dbSettings.smtp_from || process.env.SMTP_FROM || process.env.SMTP_USER || 'noreply@ampedfieldops.com';

  const mailOptions = {
    from: smtpFrom,
    to: to,
    subject: subject,
    text: text,
    html: html,
  };

  const emailTransporter = await getTransporter();

  if (!emailTransporter) {
    throw new Error('SMTP not configured. Please configure email settings in the Settings page.');
  }

  try {
    await emailTransporter.sendMail(mailOptions);
    console.log(`[Email] Test email sent to ${to}`);
    return true;
  } catch (error) {
    console.error('[Email] Failed to send test email:', error);
    throw error;
  }
}

// Generic email sending function
export async function sendEmail(options: {
  to: string;
  subject: string;
  text: string;
  html?: string;
}): Promise<boolean> {
  const dbSettings = await getEmailSettings();
  const smtpFrom = dbSettings.smtp_from || process.env.SMTP_FROM || process.env.SMTP_USER || 'noreply@ampedfieldops.com';

  const mailOptions = {
    from: smtpFrom,
    to: options.to,
    subject: options.subject,
    text: options.text,
    html: options.html || options.text,
  };

  const emailTransporter = await getTransporter();

  if (!emailTransporter) {
    // Log email details instead of sending
    console.log('\n=== EMAIL (NOT SENT - SMTP NOT CONFIGURED) ===');
    console.log('To:', options.to);
    console.log('Subject:', options.subject);
    console.log('Body:', options.text);
    console.log('================================================\n');
    return false;
  }

  try {
    await emailTransporter.sendMail(mailOptions);
    console.log(`[Email] Email sent to ${options.to}`);
    return true;
  } catch (error) {
    console.error('[Email] Failed to send email:', error);
    return false;
  }
}

--- FILE: backend/src/lib/errors.ts ---
/**
 * Custom error classes for structured error handling
 * Provides consistent error responses and error categorization
 */

export class AppError extends Error {
  public readonly statusCode: number;
  public readonly code: string;
  public readonly isOperational: boolean;
  public readonly details?: any;

  constructor(
    message: string,
    statusCode: number = 500,
    code: string = 'INTERNAL_ERROR',
    isOperational: boolean = true,
    details?: any
  ) {
    super(message);
    this.statusCode = statusCode;
    this.code = code;
    this.isOperational = isOperational;
    this.details = details;

    // Maintains proper stack trace for where error was thrown
    Error.captureStackTrace(this, this.constructor);
  }
}

export class ValidationError extends AppError {
  constructor(message: string, details?: any) {
    super(message, 400, 'VALIDATION_ERROR', true, details);
  }
}

export class NotFoundError extends AppError {
  constructor(resource: string, identifier?: string) {
    const message = identifier
      ? `${resource} with identifier '${identifier}' not found`
      : `${resource} not found`;
    super(message, 404, 'NOT_FOUND', true, { resource, identifier });
  }
}

export class UnauthorizedError extends AppError {
  constructor(message: string = 'Unauthorized') {
    super(message, 401, 'UNAUTHORIZED', true);
  }
}

export class ForbiddenError extends AppError {
  constructor(message: string = 'Forbidden') {
    super(message, 403, 'FORBIDDEN', true);
  }
}

export class ConflictError extends AppError {
  constructor(message: string, details?: any) {
    super(message, 409, 'CONFLICT', true, details);
  }
}

export class DatabaseError extends AppError {
  constructor(message: string, originalError?: any) {
    super(message, 500, 'DATABASE_ERROR', false, {
      originalError: originalError?.message,
      code: originalError?.code,
    });
  }
}

export class FileError extends AppError {
  constructor(message: string, details?: any) {
    super(message, 400, 'FILE_ERROR', true, details);
  }
}

/**
 * Maps PostgreSQL error codes to user-friendly messages
 */
export function mapDatabaseError(error: any): AppError {
  // PostgreSQL error codes: https://www.postgresql.org/docs/current/errcodes-appendix.html
  const code = error.code;
  const message = error.message || 'Database error occurred';

  switch (code) {
    case '23505': // unique_violation
      return new ConflictError('A record with this value already exists', {
        constraint: error.constraint,
        detail: error.detail,
      });

    case '23503': // foreign_key_violation
      return new ValidationError('Referenced record does not exist', {
        constraint: error.constraint,
        detail: error.detail,
      });

    case '23502': // not_null_violation
      return new ValidationError('Required field is missing', {
        column: error.column,
      });

    case '23514': // check_violation
      return new ValidationError('Data validation failed', {
        constraint: error.constraint,
      });

    case '42P01': // undefined_table
      return new DatabaseError('Database table does not exist. Please run migrations.', error);

    case '42703': // undefined_column
      return new DatabaseError('Database column does not exist', error);

    case '08003': // connection_does_not_exist
    case '08006': // connection_failure
      return new DatabaseError('Database connection failed', error);

    case '53300': // too_many_connections
      return new DatabaseError('Database connection limit exceeded', error);

    default:
      return new DatabaseError('Database operation failed', error);
  }
}

/**
 * Standard error response format
 */
export interface ErrorResponse {
  error: string;
  code?: string;
  details?: any;
  requestId?: string;
}

/**
 * Creates a standardized error response
 */
export function createErrorResponse(
  error: Error | AppError,
  requestId?: string
): ErrorResponse {
  if (error instanceof AppError) {
    return {
      error: error.message,
      code: error.code,
      details: error.details,
      requestId,
    };
  }

  // For non-AppError instances, return generic error
  return {
    error: error.message || 'An unexpected error occurred',
    code: 'INTERNAL_ERROR',
    requestId,
  };
}
--- FILE: backend/src/lib/fileValidator.ts ---
import fs from 'fs';
import { StorageFactory } from './storage/StorageFactory';

/**
 * File content validation using magic numbers/file signatures
 * Validates actual file content matches declared MIME type
 * Prevents malicious files disguised as images or documents
 * 
 * Supports both local filesystem paths and storage provider paths
 */

// Magic number signatures for common file types
const FILE_SIGNATURES: { [key: string]: Array<{ offset: number; bytes: number[] }> } = {
  'image/jpeg': [
    { offset: 0, bytes: [0xff, 0xd8, 0xff] },
  ],
  'image/png': [
    { offset: 0, bytes: [0x89, 0x50, 0x4e, 0x47, 0x0d, 0x0a, 0x1a, 0x0a] },
  ],
  'image/gif': [
    { offset: 0, bytes: [0x47, 0x49, 0x46, 0x38, 0x37, 0x61] }, // GIF87a
    { offset: 0, bytes: [0x47, 0x49, 0x46, 0x38, 0x39, 0x61] }, // GIF89a
  ],
  'image/webp': [
    { offset: 0, bytes: [0x52, 0x49, 0x46, 0x46] }, // RIFF
    { offset: 8, bytes: [0x57, 0x45, 0x42, 0x50] }, // WEBP
  ],
  'application/pdf': [
    { offset: 0, bytes: [0x25, 0x50, 0x44, 0x46] }, // %PDF
  ],
  'application/msword': [
    { offset: 0, bytes: [0xd0, 0xcf, 0x11, 0xe0, 0xa1, 0xb1, 0x1a, 0xe1] }, // OLE2 (DOC)
  ],
  'application/vnd.openxmlformats-officedocument.wordprocessingml.document': [
    { offset: 0, bytes: [0x50, 0x4b, 0x03, 0x04] }, // ZIP (DOCX is a ZIP)
  ],
  'application/vnd.ms-excel': [
    { offset: 0, bytes: [0xd0, 0xcf, 0x11, 0xe0, 0xa1, 0xb1, 0x1a, 0xe1] }, // OLE2 (XLS)
  ],
  'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': [
    { offset: 0, bytes: [0x50, 0x4b, 0x03, 0x04] }, // ZIP (XLSX is a ZIP)
  ],
  'text/plain': [
    // Text files don't have a reliable magic number, so we'll check if it's valid UTF-8
    // This is handled separately
  ],
  'text/csv': [
    // CSV files are text files, handled separately
  ],
};

/**
 * Validates file content matches declared MIME type
 * @param filePathOrBuffer Path to the file (string) or file buffer (Buffer)
 * @param declaredMimeType MIME type declared by the client
 * @param isBuffer If true, first param is a Buffer; if false, it's a file path
 * @returns true if file content matches declared type, false otherwise
 */
export async function validateFileContent(
  filePathOrBuffer: string | Buffer,
  declaredMimeType: string,
  isBuffer: boolean = false
): Promise<boolean> {
  try {
    let buffer: Buffer;
    
    if (isBuffer) {
      // First param is already a Buffer (from memory storage)
      buffer = filePathOrBuffer as Buffer;
      // Use first 32 bytes for validation
      buffer = buffer.slice(0, 32);
    } else {
      // First param is a file path (backward compatibility)
      const filePath = filePathOrBuffer as string;
      buffer = Buffer.alloc(32);
      const fd = await fs.promises.open(filePath, 'r');
      const { bytesRead } = await fd.read(buffer, 0, 32, 0);
      await fd.close();
      
      if (bytesRead === 0) {
        return false; // Empty file
      }
    }

    if (buffer.length === 0) {
      return false; // Empty file
    }

    // Get signatures for declared MIME type
    const signatures = FILE_SIGNATURES[declaredMimeType];
    
    if (!signatures || signatures.length === 0) {
      // For text files, check if content is valid UTF-8
      if (declaredMimeType.startsWith('text/')) {
        try {
          const textContent = buffer.toString('utf8');
          // Basic check: if it decodes as UTF-8 without errors, it's likely a text file
          return textContent.length > 0;
        } catch {
          return false;
        }
      }
      
      // Unknown MIME type - allow it but log warning
      return true;
    }

    // Check if any signature matches
    for (const signature of signatures) {
      const { offset, bytes } = signature;
      
      if (offset + bytes.length > buffer.length) {
        continue; // Not enough data
      }

      let matches = true;
      for (let i = 0; i < bytes.length; i++) {
        if (buffer[offset + i] !== bytes[i]) {
          matches = false;
          break;
        }
      }

      if (matches) {
        return true;
      }
    }

    // For Office Open XML formats (DOCX, XLSX), check ZIP signature
    // and verify internal structure
    if (declaredMimeType.includes('openxmlformats')) {
      // Check ZIP signature
      if (buffer[0] === 0x50 && buffer[1] === 0x4b && buffer[2] === 0x03 && buffer[3] === 0x04) {
        // It's a ZIP file, which is correct for OpenXML formats
        return true;
      }
    }

    return false;
  } catch (error) {
    // If we can't read the file, fail validation
    return false;
  }
}

/**
 * Validates file extension matches MIME type
 * Additional validation layer
 */
export function validateFileExtension(filename: string, mimeType: string): boolean {
  const extension = filename.toLowerCase().split('.').pop() || '';
  
  const extensionMap: { [key: string]: string[] } = {
    'image/jpeg': ['jpg', 'jpeg'],
    'image/png': ['png'],
    'image/gif': ['gif'],
    'image/webp': ['webp'],
    'application/pdf': ['pdf'],
    'application/msword': ['doc'],
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document': ['docx'],
    'application/vnd.ms-excel': ['xls'],
    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet': ['xlsx'],
    'text/plain': ['txt'],
    'text/csv': ['csv'],
  };

  const allowedExtensions = extensionMap[mimeType];
  if (!allowedExtensions) {
    return true; // Unknown MIME type, allow it
  }

  return allowedExtensions.includes(extension);
}
--- FILE: backend/src/lib/googleDrive.ts ---
import { google } from 'googleapis';
import { OAuth2Client } from 'google-auth-library';
import fs from 'fs/promises';
import { createReadStream, createWriteStream } from 'fs';
import { query } from '../db';
import dotenv from 'dotenv';
// Suppress dotenv parsing warnings
dotenv.config({ debug: false, override: false });

const GOOGLE_CLIENT_ID = process.env.GOOGLE_CLIENT_ID || '';
const GOOGLE_CLIENT_SECRET = process.env.GOOGLE_CLIENT_SECRET || '';
const GOOGLE_REDIRECT_URI = process.env.GOOGLE_REDIRECT_URI || '';

// Get Google Drive OAuth credentials from database or environment
export async function getGoogleDriveCredentials(): Promise<{ clientId: string; clientSecret: string; redirectUri: string }> {
  try {
    // Try to get credentials from database first
    const clientIdResult = await query("SELECT value FROM settings WHERE key = 'google_drive_client_id' ORDER BY updated_at DESC LIMIT 1");
    const clientSecretResult = await query("SELECT value FROM settings WHERE key = 'google_drive_client_secret' ORDER BY updated_at DESC LIMIT 1");
    const redirectUriResult = await query("SELECT value FROM settings WHERE key = 'google_drive_redirect_uri' ORDER BY updated_at DESC LIMIT 1");
    
    const clientIdFromDb = clientIdResult.rows[0]?.value;
    const clientSecretFromDb = clientSecretResult.rows[0]?.value;
    const redirectUriFromDb = redirectUriResult.rows[0]?.value;
    
    // Use database values if available, otherwise fall back to environment variables
    const clientId = clientIdFromDb || GOOGLE_CLIENT_ID;
    const clientSecret = clientSecretFromDb || GOOGLE_CLIENT_SECRET;
    
    // Construct redirect URI
    let redirectUri = redirectUriFromDb || GOOGLE_REDIRECT_URI;
    if (!redirectUri || redirectUri.trim() === '') {
      // Default to backend URL + callback path
      redirectUri = `${process.env.BACKEND_URL || process.env.API_URL || 'http://localhost:3001'}/api/backups/google-drive/callback`;
    }
    
    if (!clientId || !clientSecret) {
      throw new Error('Google Drive OAuth credentials not configured. Please set Google Drive Client ID and Client Secret in Settings ‚Üí Integrations.');
    }
    
    return { clientId, clientSecret, redirectUri };
  } catch (error: any) {
    console.error('Failed to get Google Drive credentials:', error);
    throw new Error(`Failed to get Google Drive credentials: ${error.message}`);
  }
}

// Get OAuth2 client
async function getOAuth2Client(): Promise<OAuth2Client> {
  const { clientId, clientSecret, redirectUri } = await getGoogleDriveCredentials();
  
  return new google.auth.OAuth2(
    clientId,
    clientSecret,
    redirectUri
  );
}

// Get stored Google Drive tokens from database
export async function getStoredTokens(): Promise<{ access_token?: string; refresh_token?: string; expiry_date?: number } | null> {
  try {
    const result = await query(
      "SELECT value FROM settings WHERE key = 'google_drive_tokens'"
    );

    if (result.rows.length === 0) {
      return null;
    }

    return JSON.parse(result.rows[0].value || '{}');
  } catch (error) {
    console.error('Failed to get stored Google Drive tokens:', error);
    return null;
  }
}

// Store Google Drive tokens in database
export async function storeTokens(tokens: any, userId?: string): Promise<void> {
  try {
    const tokenData = {
      access_token: tokens.access_token,
      refresh_token: tokens.refresh_token,
      expiry_date: tokens.expiry_date,
      scope: tokens.scope,
      token_type: tokens.token_type
    };

    await query(
      `INSERT INTO settings (key, value, user_id)
       VALUES ('google_drive_tokens', $1, $2)
       ON CONFLICT (key, user_id) DO UPDATE SET value = $1, updated_at = CURRENT_TIMESTAMP`,
      [JSON.stringify(tokenData), userId || null]
    );
  } catch (error) {
    console.error('Failed to store Google Drive tokens:', error);
    throw error;
  }
}

// Get authorized OAuth2 client
export async function getAuthorizedClient(userId?: string): Promise<OAuth2Client | null> {
  const oauth2Client = await getOAuth2Client();
  const tokens = await getStoredTokens();

  if (!tokens || !tokens.access_token) {
    return null;
  }

  oauth2Client.setCredentials(tokens);

  // Check if token needs refresh
  if (tokens.expiry_date && tokens.expiry_date <= Date.now()) {
    if (tokens.refresh_token) {
      try {
        const { credentials } = await oauth2Client.refreshAccessToken();
        await storeTokens(credentials, userId);
        oauth2Client.setCredentials(credentials);
      } catch (error) {
        console.error('Failed to refresh Google Drive token:', error);
        return null;
      }
    } else {
      return null;
    }
  }

  return oauth2Client;
}

// Get Google Drive OAuth URL
export async function getAuthUrl(state?: string): Promise<string> {
  try {
    const { clientId, clientSecret, redirectUri } = await getGoogleDriveCredentials();
    const oauth2Client = await getOAuth2Client();
    
    const scopes = [
      'https://www.googleapis.com/auth/drive.file' // Access to files created by the app
    ];

    const authUrl = oauth2Client.generateAuthUrl({
      access_type: 'offline',
      scope: scopes,
      prompt: 'consent',
      state: state || '',
      include_granted_scopes: true
    });

    // Log the redirect URI being used for debugging
    console.log('[Google Drive] Generating auth URL with:', {
      clientId: `${clientId.substring(0, 20)}...`,
      redirectUri: redirectUri,
      redirectUriEncoded: encodeURIComponent(redirectUri),
      scopes: scopes.length + ' scope(s)',
      state: state || 'none',
      authUrlPreview: authUrl.substring(0, 150) + '...'
    });

    return authUrl;
  } catch (error: any) {
    console.error('Failed to generate Google Drive auth URL:', error);
    throw new Error(`Failed to generate auth URL: ${error.message}`);
  }
}

// Exchange authorization code for tokens
export async function exchangeCodeForTokens(code: string, userId?: string): Promise<any> {
  const oauth2Client = await getOAuth2Client();
  
  try {
    const { tokens } = await oauth2Client.getToken(code);
    await storeTokens(tokens, userId);
    return tokens;
  } catch (error: any) {
    console.error('Failed to exchange code for tokens:', error);
    throw new Error(`Failed to exchange authorization code: ${error.message}`);
  }
}

// Upload file to Google Drive
export async function uploadToGoogleDrive(
  filePath: string,
  fileName: string,
  userId?: string
): Promise<string> {
  const auth = await getAuthorizedClient(userId);
  if (!auth) {
    throw new Error('Google Drive not authorized. Please connect your Google account.');
  }

  const drive = google.drive({ version: 'v3', auth });

  // Check if backup folder exists, create if not
  let folderId = await findOrCreateBackupFolder(auth);

  const fileMetadata = {
    name: fileName,
    parents: folderId ? [folderId] : undefined
  };

  const media = {
    mimeType: 'application/gzip',
    body: createReadStream(filePath)
  };

  try {
    const response = await drive.files.create({
      requestBody: fileMetadata,
      media: media,
      fields: 'id, name, size'
    });

    return response.data.id || '';
  } catch (error: any) {
    console.error('Failed to upload to Google Drive:', error);
    throw new Error(`Failed to upload to Google Drive: ${error.message}`);
  }
}

// Find or create backup folder in Google Drive
async function findOrCreateBackupFolder(auth: OAuth2Client): Promise<string | null> {
  const drive = google.drive({ version: 'v3', auth });
  const folderName = 'AmpedFieldOps Backups';

  try {
    // Search for existing folder
    const response = await drive.files.list({
      q: `name='${folderName}' and mimeType='application/vnd.google-apps.folder' and trashed=false`,
      fields: 'files(id, name)',
      spaces: 'drive'
    });

    if (response.data.files && response.data.files.length > 0) {
      return response.data.files[0].id || null;
    }

    // Create folder if it doesn't exist
    const folderResponse = await drive.files.create({
      requestBody: {
        name: folderName,
        mimeType: 'application/vnd.google-apps.folder'
      },
      fields: 'id'
    });

    return folderResponse.data.id || null;
  } catch (error: any) {
    console.error('Failed to find or create backup folder:', error);
    return null; // Continue without folder organization
  }
}

// Delete file from Google Drive
export async function deleteFromGoogleDrive(fileId: string, userId?: string): Promise<void> {
  const auth = await getAuthorizedClient(userId);
  if (!auth) {
    throw new Error('Google Drive not authorized');
  }

  const drive = google.drive({ version: 'v3', auth });

  try {
    await drive.files.delete({ fileId });
  } catch (error: any) {
    console.error('Failed to delete from Google Drive:', error);
    throw new Error(`Failed to delete from Google Drive: ${error.message}`);
  }
}

// Download file from Google Drive
export async function downloadFromGoogleDrive(
  fileId: string,
  outputPath: string,
  userId?: string
): Promise<void> {
  const auth = await getAuthorizedClient(userId);
  if (!auth) {
    throw new Error('Google Drive not authorized');
  }

  const drive = google.drive({ version: 'v3', auth });

  try {
    const response = await drive.files.get(
      { fileId, alt: 'media' },
      { responseType: 'stream' }
    );

    const writeStream = createWriteStream(outputPath);
    response.data.pipe(writeStream);

    return new Promise((resolve, reject) => {
      writeStream.on('finish', resolve);
      writeStream.on('error', reject);
      response.data.on('error', reject);
    });
  } catch (error: any) {
    console.error('Failed to download from Google Drive:', error);
    throw new Error(`Failed to download from Google Drive: ${error.message}`);
  }
}

// Check if Google Drive is connected
export async function isGoogleDriveConnected(): Promise<boolean> {
  const tokens = await getStoredTokens();
  return !!(tokens && tokens.access_token);
}

--- FILE: backend/src/lib/logger.ts ---
import winston from 'winston';
import fs from 'fs';
import path from 'path';
import { env } from '../config/env';
import { LOG_CONSTANTS } from './constants';

/**
 * Winston logger configuration
 * Provides structured logging with different log levels and transports
 */

const logFormat = winston.format.combine(
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
  winston.format.errors({ stack: true }),
  winston.format.splat(),
  winston.format.json()
);

// Console format for development (more readable)
const consoleFormat = winston.format.combine(
  winston.format.colorize(),
  winston.format.timestamp({ format: 'YYYY-MM-DD HH:mm:ss' }),
  winston.format.printf(({ timestamp, level, message, ...meta }) => {
    let msg = `${timestamp} [${level}]: ${message}`;
    if (Object.keys(meta).length > 0) {
      msg += ` ${JSON.stringify(meta)}`;
    }
    return msg;
  })
);

// Create transports array
const transports: winston.transport[] = [
  // Console transport (always enabled)
  new winston.transports.Console({
    format: env.NODE_ENV === 'production' ? logFormat : consoleFormat,
    level: env.NODE_ENV === 'production' ? 'info' : 'debug',
  }),
];

// File transports for production
if (env.NODE_ENV === 'production') {
  try {
    // Ensure logs directory exists
    const logsDir = path.resolve(process.cwd(), LOG_CONSTANTS.LOG_DIR);
    if (!fs.existsSync(logsDir)) {
      fs.mkdirSync(logsDir, { recursive: true });
    }

    // Error log file
    transports.push(
      new winston.transports.File({
        filename: path.join(LOG_CONSTANTS.LOG_DIR, 'error.log'),
        level: 'error',
        format: logFormat,
        maxsize: LOG_CONSTANTS.MAX_FILE_SIZE,
        maxFiles: LOG_CONSTANTS.MAX_FILES,
      })
    );

    // Combined log file
    transports.push(
      new winston.transports.File({
        filename: path.join(LOG_CONSTANTS.LOG_DIR, 'combined.log'),
        format: logFormat,
        maxsize: LOG_CONSTANTS.MAX_FILE_SIZE,
        maxFiles: LOG_CONSTANTS.MAX_FILES,
      })
    );
  } catch (error) {
    // If file transport creation fails (e.g., permission issues), 
    // fall back to console-only logging
    console.warn('Failed to create file transports, using console only:', error);
  }
}

// Create logger instance
export const logger = winston.createLogger({
  level: env.NODE_ENV === 'production' ? 'info' : 'debug',
  format: logFormat,
  defaultMeta: { service: 'ampedfieldops-api' },
  transports,
  // Don't exit on handled exceptions
  exitOnError: false,
});

// If we're not in production, log to console with simpler format
if (env.NODE_ENV !== 'production') {
  logger.add(
    new winston.transports.Console({
      format: consoleFormat,
    })
  );
}

/**
 * Helper functions for common logging patterns
 */
export const log = {
  error: (message: string, error?: Error | any, meta?: any) => {
    if (error instanceof Error) {
      logger.error(message, { error: error.message, stack: error.stack, ...meta });
    } else {
      logger.error(message, { error, ...meta });
    }
  },
  
  warn: (message: string, meta?: any) => {
    logger.warn(message, meta);
  },
  
  info: (message: string, meta?: any) => {
    logger.info(message, meta);
  },
  
  debug: (message: string, meta?: any) => {
    logger.debug(message, meta);
  },
  
  // HTTP request logging
  http: (req: any, res: any, responseTime?: number) => {
    logger.info('HTTP Request', {
      method: req.method,
      url: req.url,
      status: res.statusCode,
      responseTime: responseTime ? `${responseTime}ms` : undefined,
      ip: req.ip,
      userAgent: req.get('user-agent'),
    });
  },
  
  // Database query logging (for debugging)
  db: (query: string, params?: any[]) => {
    if (env.NODE_ENV === 'development') {
      logger.debug('Database Query', { query, params });
    }
  },
};

export default logger;
--- FILE: backend/src/lib/ocrService.ts ---
/**
 * OCR Service Client
 * Communicates with the OCR service to process document images
 */
import FormData from 'form-data';
import fs from 'fs';
import path from 'path';
import { env } from '../config/env';
import { log } from './logger';
import { StorageFactory } from './storage/StorageFactory';

export interface OCRResult {
  success: boolean;
  confidence: number;
  document_type: string;
  extracted_data: {
    document_number?: string;
    date?: string;
    amount?: number;
    total_amount?: number;
    tax_amount?: number;
    vendor_name?: string;
    vendor_address?: string;
    line_items?: any[];
    raw_text?: string;
  };
  raw_text: string;
  error?: string;
}

export interface HealthResponse {
  status: string;
  version: string;
  tesseract_available: boolean;
}

class OCRServiceClient {
  private baseUrl: string;

  constructor() {
    this.baseUrl = env.OCR_SERVICE_URL || 'http://ocr-service:8000';
  }

  /**
   * Process an image file through OCR
   * @param filePath Storage provider path (e.g., 'projects/.../file.jpg') or local file path for backward compatibility
   */
  async processImage(filePath: string): Promise<OCRResult> {
    try {
      let fileStream: NodeJS.ReadableStream;
      let filename: string;
      
      // Check if it's a storage provider path or local file path
      const storage = await StorageFactory.getInstance();
      const isStoragePath = !filePath.startsWith('/') && !path.isAbsolute(filePath);
      
      if (isStoragePath) {
        // Use storage provider
        const exists = await storage.exists(filePath);
        if (!exists) {
          throw new Error(`File not found in storage: ${filePath}`);
        }
        fileStream = await storage.getStream(filePath);
        filename = filePath.split('/').pop() || 'image.jpg';
      } else {
        // Local file path (backward compatibility)
        if (!fs.existsSync(filePath)) {
          throw new Error(`File not found: ${filePath}`);
        }
        fileStream = fs.createReadStream(filePath);
        filename = filePath.split('/').pop() || 'image.jpg';
      }

      const formData = new FormData();
      formData.append('file', fileStream, {
        filename,
        contentType: 'image/jpeg',
      });

      const response = await fetch(`${this.baseUrl}/process`, {
        method: 'POST',
        body: formData as any,
        headers: formData.getHeaders(),
      });

      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`OCR service error: ${response.status} - ${errorText}`);
      }

      const result = await response.json();
      return result as OCRResult;
    } catch (error: any) {
      log.error('OCR processing failed', error, { filePath });
      throw new Error(`OCR processing failed: ${error.message}`);
    }
  }

  /**
   * Check if OCR service is available
   */
  async healthCheck(): Promise<boolean> {
    try {
      const response = await fetch(`${this.baseUrl}/health`, {
        method: 'GET',
        headers: {
          'Content-Type': 'application/json',
        },
      });

      if (response.ok) {
        const health = await response.json() as HealthResponse;
        return health.status === 'healthy' && health.tesseract_available === true;
      }
      return false;
    } catch (error) {
      log.warn('OCR service health check failed', { error: (error as Error).message });
      return false;
    }
  }
}

export const ocrService = new OCRServiceClient();
--- FILE: backend/src/lib/pagination.ts ---
/**
 * Pagination utility functions
 */

import { PAGINATION_CONSTANTS } from './constants';

export interface PaginationParams {
  page?: number;
  limit?: number;
  offset?: number;
}

export interface PaginationResult {
  page: number;
  limit: number;
  total: number;
  totalPages: number;
  hasNext: boolean;
  hasPrev: boolean;
}

export interface PaginatedResponse<T> {
  data: T[];
  pagination: PaginationResult;
}

/**
 * Parse pagination parameters from query string
 * @param query - Express request query object
 * @param defaultLimit - Default items per page (default: 20)
 * @param maxLimit - Maximum items per page (default: 100)
 * @returns Normalized pagination parameters
 */
export function parsePaginationParams(
  query: any,
  defaultLimit = PAGINATION_CONSTANTS.DEFAULT_LIMIT,
  maxLimit = PAGINATION_CONSTANTS.MAX_LIMIT
): { limit: number; offset: number; page: number } {
  const page = Math.max(1, parseInt(query.page as string) || 1);
  let limit = parseInt(query.limit as string) || defaultLimit;
  
  // Enforce maximum limit
  if (limit > maxLimit) {
    limit = maxLimit;
  }
  
  // Ensure limit is at least 1
  if (limit < 1) {
    limit = defaultLimit;
  }
  
  const offset = (page - 1) * limit;
  
  return { page, limit, offset };
}

/**
 * Create pagination metadata
 * @param total - Total number of items
 * @param page - Current page number
 * @param limit - Items per page
 * @returns Pagination metadata
 */
export function createPaginationMeta(
  total: number,
  page: number,
  limit: number
): PaginationResult {
  const totalPages = Math.ceil(total / limit);
  
  return {
    page,
    limit,
    total,
    totalPages,
    hasNext: page < totalPages,
    hasPrev: page > 1,
  };
}

/**
 * Create a paginated response
 * @param data - Array of items for current page
 * @param total - Total number of items
 * @param page - Current page number
 * @param limit - Items per page
 * @returns Paginated response object
 */
export function createPaginatedResponse<T>(
  data: T[],
  total: number,
  page: number,
  limit: number
): PaginatedResponse<T> {
  return {
    data,
    pagination: createPaginationMeta(total, page, limit),
  };
}
--- FILE: backend/src/lib/pdfGenerator.ts ---
import PDFDocument from 'pdfkit';
import fs from 'fs';
import path from 'path';

/**
 * Generate a JSA (Job Safety Analysis) PDF document
 */
export async function generateJSAPDF(data: any, outputPath: string): Promise<void> {
  return new Promise((resolve, reject) => {
    try {
      const doc = new PDFDocument({ margin: 50 });
      const stream = fs.createWriteStream(outputPath);
      doc.pipe(stream);

      // Header
      doc.fontSize(20).text('Job Safety Analysis (JSA)', { align: 'center' });
      doc.moveDown();

      // Job Information
      doc.fontSize(14).text('Job Information', { underline: true });
      doc.fontSize(12);
      doc.text(`Job Description: ${data.job_description || 'N/A'}`);
      doc.text(`Location: ${data.location || 'N/A'}`);
      doc.text(`Date: ${data.date || 'N/A'}`);
      doc.text(`Prepared By: ${data.prepared_by || 'N/A'}`);
      doc.moveDown();

      // Hazards and Controls
      if (data.hazards && Array.isArray(data.hazards)) {
        doc.fontSize(14).text('Hazards and Control Measures', { underline: true });
        doc.fontSize(12);
        data.hazards.forEach((hazard: any, index: number) => {
          doc.text(`${index + 1}. Hazard: ${hazard.description || 'N/A'}`);
          doc.text(`   Risk Level: ${hazard.risk_level || 'N/A'}`);
          doc.text(`   Control Measures: ${hazard.control_measures || 'N/A'}`);
          doc.moveDown(0.5);
        });
      }

      // Sign-offs
      doc.moveDown();
      doc.fontSize(14).text('Sign-offs', { underline: true });
      doc.fontSize(12);
      doc.text(`Prepared By: ${data.prepared_by_name || 'N/A'}`);
      if (data.prepared_by_date) {
        doc.text(`Date: ${data.prepared_by_date}`);
      }
      doc.moveDown();
      doc.text(`Approved By: ${data.approved_by_name || 'N/A'}`);
      if (data.approved_by_date) {
        doc.text(`Date: ${data.approved_by_date}`);
      }

      doc.end();
      stream.on('finish', () => resolve());
      stream.on('error', reject);
    } catch (error) {
      reject(error);
    }
  });
}

/**
 * Generate an Electrical Code of Compliance certificate PDF
 */
export async function generateCompliancePDF(data: any, outputPath: string): Promise<void> {
  return new Promise((resolve, reject) => {
    try {
      const doc = new PDFDocument({ margin: 50 });
      const stream = fs.createWriteStream(outputPath);
      doc.pipe(stream);

      // Header
      doc.fontSize(20).text('Electrical Code of Compliance', { align: 'center' });
      doc.moveDown();

      // Certificate Information
      doc.fontSize(14).text('Certificate Information', { underline: true });
      doc.fontSize(12);
      doc.text(`Certificate Number: ${data.certificate_number || 'N/A'}`);
      doc.text(`Issue Date: ${data.issue_date || 'N/A'}`);
      doc.moveDown();

      // Installation Details
      doc.fontSize(14).text('Installation Details', { underline: true });
      doc.fontSize(12);
      doc.text(`Location: ${data.location || 'N/A'}`);
      doc.text(`Description: ${data.description || 'N/A'}`);
      if (data.installation_date) {
        doc.text(`Installation Date: ${data.installation_date}`);
      }
      doc.moveDown();

      // Testing Results
      if (data.testing_results) {
        doc.fontSize(14).text('Testing Results', { underline: true });
        doc.fontSize(12);
        if (typeof data.testing_results === 'string') {
          doc.text(data.testing_results);
        } else if (Array.isArray(data.testing_results)) {
          data.testing_results.forEach((result: any, index: number) => {
            doc.text(`${index + 1}. ${result.test || 'N/A'}: ${result.result || 'N/A'}`);
          });
        }
        doc.moveDown();
      }

      // Compliance Standards
      if (data.compliance_standards && Array.isArray(data.compliance_standards)) {
        doc.fontSize(14).text('Compliance Standards', { underline: true });
        doc.fontSize(12);
        data.compliance_standards.forEach((standard: string) => {
          doc.text(`‚Ä¢ ${standard}`);
        });
        doc.moveDown();
      }

      // Inspector Details
      doc.fontSize(14).text('Inspector Details', { underline: true });
      doc.fontSize(12);
      doc.text(`Inspector Name: ${data.inspector_name || 'N/A'}`);
      doc.text(`License Number: ${data.inspector_license || 'N/A'}`);
      if (data.inspection_date) {
        doc.text(`Inspection Date: ${data.inspection_date}`);
      }
      doc.moveDown();

      // Sign-offs
      doc.fontSize(14).text('Sign-offs', { underline: true });
      doc.fontSize(12);
      doc.text(`Inspector: ${data.inspector_name || 'N/A'}`);
      if (data.inspector_signature_date) {
        doc.text(`Date: ${data.inspector_signature_date}`);
      }

      doc.end();
      stream.on('finish', () => resolve());
      stream.on('error', reject);
    } catch (error) {
      reject(error);
    }
  });
}

/**
 * Generate an Electrical Safety Certificate PDF
 */
export async function generateSafetyCertificatePDF(data: any, outputPath: string): Promise<void> {
  return new Promise((resolve, reject) => {
    try {
      const doc = new PDFDocument({ margin: 50 });
      const stream = fs.createWriteStream(outputPath);
      doc.pipe(stream);

      // Header
      doc.fontSize(20).text('Electrical Safety Certificate', { align: 'center' });
      doc.moveDown();

      // Certificate Information
      doc.fontSize(14).text('Certificate Information', { underline: true });
      doc.fontSize(12);
      doc.text(`Certificate Number: ${data.certificate_number || 'N/A'}`);
      doc.text(`Issue Date: ${data.issue_date || 'N/A'}`);
      if (data.expiry_date) {
        doc.text(`Expiry Date: ${data.expiry_date}`);
      }
      doc.moveDown();

      // Installation Details
      doc.fontSize(14).text('Installation Details', { underline: true });
      doc.fontSize(12);
      doc.text(`Location: ${data.location || 'N/A'}`);
      doc.text(`Description: ${data.description || 'N/A'}`);
      doc.moveDown();

      // Safety Checks
      if (data.safety_checks && Array.isArray(data.safety_checks)) {
        doc.fontSize(14).text('Safety Checks', { underline: true });
        doc.fontSize(12);
        data.safety_checks.forEach((check: any, index: number) => {
          doc.text(`${index + 1}. ${check.check || 'N/A'}: ${check.status || 'N/A'}`);
          if (check.notes) {
            doc.text(`   Notes: ${check.notes}`);
          }
        });
        doc.moveDown();
      }

      // Inspector Details
      doc.fontSize(14).text('Inspector Details', { underline: true });
      doc.fontSize(12);
      doc.text(`Inspector Name: ${data.inspector_name || 'N/A'}`);
      doc.text(`License Number: ${data.inspector_license || 'N/A'}`);
      if (data.inspection_date) {
        doc.text(`Inspection Date: ${data.inspection_date}`);
      }
      doc.moveDown();

      // Sign-offs
      doc.fontSize(14).text('Sign-offs', { underline: true });
      doc.fontSize(12);
      doc.text(`Inspector: ${data.inspector_name || 'N/A'}`);
      if (data.inspector_signature_date) {
        doc.text(`Date: ${data.inspector_signature_date}`);
      }

      doc.end();
      stream.on('finish', () => resolve());
      stream.on('error', reject);
    } catch (error) {
      reject(error);
    }
  });
}

/**
 * Generate PDF based on document type
 */
export async function generateDocumentPDF(
  documentType: 'jsa' | 'electrical_compliance' | 'electrical_safety_certificate',
  data: any,
  outputPath: string
): Promise<void> {
  // Ensure output directory exists
  const outputDir = path.dirname(outputPath);
  if (!fs.existsSync(outputDir)) {
    fs.mkdirSync(outputDir, { recursive: true });
  }

  switch (documentType) {
    case 'jsa':
      return generateJSAPDF(data, outputPath);
    case 'electrical_compliance':
      return generateCompliancePDF(data, outputPath);
    case 'electrical_safety_certificate':
      return generateSafetyCertificatePDF(data, outputPath);
    default:
      throw new Error(`Unknown document type: ${documentType}`);
  }
}

--- FILE: backend/src/lib/permissions.ts ---
/**
 * Get default permissions for a role
 * This function is shared across auth and user management routes
 */
export function getDefaultPermissions(role: string): string[] {
  const basePermissions = [
    'can_create_timesheets',
    'can_view_own_timesheets',
    'can_edit_own_timesheets',
    'can_delete_own_timesheets',
    'can_view_projects',
    'can_view_clients',
    'can_view_dashboard'
  ];
  
  if (role === 'admin') {
    return [
      ...basePermissions,
      'can_view_financials',
      'can_edit_projects',
      'can_manage_users',
      'can_sync_xero',
      'can_view_all_timesheets',
      'can_edit_activity_types',
      'can_manage_clients',
      'can_manage_cost_centers',
      'can_view_reports',
      'can_export_data',
      'can_manage_settings'
    ];
  }
  
  if (role === 'manager') {
    return [
      ...basePermissions,
      'can_view_financials',
      'can_edit_projects',
      'can_view_all_timesheets',
      'can_manage_clients',
      'can_view_reports',
      'can_export_data'
    ];
  }
  
  return basePermissions;
}
--- FILE: backend/src/lib/queue.ts ---
import { Queue, Worker, QueueEvents } from 'bullmq';
import { query } from '../db';
import { parseXeroError, getErrorMessage } from './xero/errorHandler';
import { fetchWithRateLimit } from './xero/rateLimiter';
import { getValidAccessToken } from './xero/auth';

// Redis connection configuration
const redisConnection = {
  host: process.env.REDIS_HOST || 'localhost',
  port: parseInt(process.env.REDIS_PORT || '6379'),
  password: process.env.REDIS_PASSWORD || undefined,
  maxRetriesPerRequest: null, // Required for BullMQ
  retryStrategy: (times: number) => {
    // Retry with exponential backoff, max 3 times
    if (times > 3) {
      return null; // Stop retrying
    }
    return Math.min(times * 200, 2000);
  },
  enableReadyCheck: false, // Don't fail if Redis isn't ready immediately
};

// Create queues with error handling
let xeroSyncQueue: Queue;
let xeroSyncQueueEvents: QueueEvents;

try {
  xeroSyncQueue = new Queue('xero-sync', {
    connection: redisConnection,
    defaultJobOptions: {
      attempts: 3,
      backoff: {
        type: 'exponential',
        delay: 2000,
      },
      removeOnComplete: {
        age: 24 * 3600, // Keep completed jobs for 24 hours
        count: 1000, // Keep last 1000 completed jobs
      },
      removeOnFail: {
        age: 7 * 24 * 3600, // Keep failed jobs for 7 days
      },
    },
  });

  // Queue event listeners for monitoring
  xeroSyncQueueEvents = new QueueEvents('xero-sync', {
    connection: redisConnection,
  });
} catch (error) {
  console.warn('[Queue] Failed to initialize queues. Redis may not be available. Xero syncs will not work until Redis is configured.');
  // Create dummy queues that will fail gracefully
  xeroSyncQueue = null as any;
  xeroSyncQueueEvents = null as any;
}

export { xeroSyncQueue, xeroSyncQueueEvents };

// Helper function to log sync attempts to sync_logs table
async function logSyncAttempt(
  entityType: string,
  entityId: string,
  requestPayload: any,
  responsePayload: any,
  statusCode: number | null,
  errorMessage: string | null = null
) {
  try {
    await query(
      `INSERT INTO sync_logs (entity_type, entity_id, request_payload, response_payload, status_code, error_message, created_at)
       VALUES ($1, $2, $3, $4, $5, $6, CURRENT_TIMESTAMP)`,
      [
        entityType,
        entityId,
        JSON.stringify(requestPayload),
        JSON.stringify(responsePayload),
        statusCode,
        errorMessage,
      ]
    );
  } catch (error) {
    console.error('Failed to log sync attempt:', error);
    // Don't throw - logging failures shouldn't break the sync
  }
}

// Worker to process Xero sync jobs
let xeroSyncWorker: Worker;

try {
  xeroSyncWorker = new Worker(
  'xero-sync',
  async (job) => {
    const { type, data } = job.data;

    try {
      switch (type) {
        case 'sync_invoice_from_timesheets': {
          const { invoiceId, clientId, projectId, lineItems, total, dueDate, timesheetIds } = data;

          // Check if invoice is already synced to prevent duplicates
          const invoiceCheck = await query(
            'SELECT xero_invoice_id, sync_status FROM xero_invoices WHERE id = $1',
            [invoiceId]
          );

          if (invoiceCheck.rows.length === 0) {
            throw new Error('Invoice not found');
          }

          const invoice = invoiceCheck.rows[0];

          // If invoice already has a Xero ID and is synced, skip processing
          if (invoice.xero_invoice_id && invoice.sync_status === 'synced') {
            console.log(`[Xero Sync Worker] Invoice ${invoiceId} already synced with Xero ID ${invoice.xero_invoice_id}. Skipping.`);
            return { success: true, xeroInvoiceId: invoice.xero_invoice_id, invoiceId, skipped: true };
          }

          // Get Xero token
          const tokenData = await getValidAccessToken();
          if (!tokenData) {
            throw new Error('Xero not connected or token expired');
          }

          // Get client's Xero contact ID
          const clientResult = await query('SELECT xero_contact_id FROM clients WHERE id = $1', [clientId]);
          if (clientResult.rows.length === 0 || !clientResult.rows[0].xero_contact_id) {
            throw new Error('Client does not have a Xero contact ID');
          }

          const xeroContactId = clientResult.rows[0].xero_contact_id;

          // Build Xero invoice payload
          const xeroInvoicePayload = {
            Type: 'ACCREC',
            Contact: { ContactID: xeroContactId },
            Date: new Date().toISOString().split('T')[0],
            DueDate: dueDate || new Date(Date.now() + 30 * 24 * 60 * 60 * 1000).toISOString().split('T')[0],
            LineItems: lineItems.map((item: any) => ({
              Description: item.description,
              Quantity: item.quantity,
              UnitAmount: item.unit_price,
              LineAmount: item.amount,
              AccountCode: '200', // Default revenue account - should be configurable
            })),
            Status: 'DRAFT',
          };

          // Create invoice in Xero
          const requestPayload = { Invoices: [xeroInvoicePayload] };
          let responsePayload: any = {};
          let statusCode: number | null = null;
          let xeroInvoiceId: string | null = null;
          let errorMessage: string | null = null;

          try {
            const response = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Invoices', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${tokenData.accessToken}`,
                'Xero-Tenant-Id': tokenData.tenantId,
                'Content-Type': 'application/json',
                'Accept': 'application/json',
              },
              body: JSON.stringify(requestPayload),
            });

            statusCode = response.status;
            responsePayload = await response.json();

            if (!response.ok) {
              const error = await parseXeroError(response);
              errorMessage = getErrorMessage(error);
              throw new Error(errorMessage);
            }

            const invoices = responsePayload.Invoices || [];
            if (invoices.length > 0) {
              xeroInvoiceId = invoices[0].InvoiceID;
            }

            // Update local invoice with Xero ID and sync status
            // Only update if not already synced (prevent race conditions)
            await query(
              `UPDATE xero_invoices 
               SET xero_invoice_id = $1, sync_status = 'synced', xero_sync_id = $2, synced_at = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP
               WHERE id = $3 AND (xero_invoice_id IS NULL OR sync_status != 'synced')`,
              [xeroInvoiceId, job.id, invoiceId]
            );

            // Log successful sync
            await logSyncAttempt('invoice', invoiceId, requestPayload, responsePayload, statusCode);

            return { success: true, xeroInvoiceId, invoiceId };
          } catch (error: any) {
            errorMessage = error.message || 'Unknown error';
            statusCode = statusCode || 500;

            // Update invoice sync status to failed
            await query(
              `UPDATE xero_invoices 
               SET sync_status = 'failed', xero_sync_id = $1, updated_at = CURRENT_TIMESTAMP
               WHERE id = $2`,
              [job.id, invoiceId]
            );

            // Log failed sync
            await logSyncAttempt('invoice', invoiceId, requestPayload, responsePayload, statusCode, errorMessage);

            throw error;
          }
        }

        case 'sync_purchase_order': {
          const { poId, supplierId, projectId, date, deliveryDate, lineItems, notes, currency, poNumber } = data;

          // Get Xero token
          const tokenData = await getValidAccessToken();
          if (!tokenData) {
            throw new Error('Xero not connected or token expired');
          }

          // Get supplier's Xero contact ID
          const supplierResult = await query('SELECT xero_contact_id FROM clients WHERE id = $1', [supplierId]);
          if (supplierResult.rows.length === 0 || !supplierResult.rows[0].xero_contact_id) {
            throw new Error('Supplier does not have a Xero contact ID');
          }

          const xeroContactId = supplierResult.rows[0].xero_contact_id;

          // Build Xero PO payload
          const xeroPOPayload = {
            Contact: { ContactID: xeroContactId },
            Date: date,
            DeliveryDate: deliveryDate || null,
            LineItems: lineItems.map((item: any) => ({
              Description: item.description,
              Quantity: item.quantity || 1,
              UnitAmount: item.unit_amount || item.line_amount,
              LineAmount: item.line_amount,
              AccountCode: item.account_code || '200',
            })),
            Status: 'DRAFT',
          };

          // Create PO in Xero
          const requestPayload = { PurchaseOrders: [xeroPOPayload] };
          let responsePayload: any = {};
          let statusCode: number | null = null;
          let xeroPoId: string | null = null;
          let errorMessage: string | null = null;

          try {
            const response = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/PurchaseOrders', {
              method: 'POST',
              headers: {
                'Authorization': `Bearer ${tokenData.accessToken}`,
                'Xero-Tenant-Id': tokenData.tenantId,
                'Content-Type': 'application/json',
                'Accept': 'application/json',
              },
              body: JSON.stringify(requestPayload),
            });

            statusCode = response.status;
            responsePayload = await response.json();

            if (!response.ok) {
              const error = await parseXeroError(response);
              errorMessage = getErrorMessage(error);
              throw new Error(errorMessage);
            }

            const purchaseOrders = responsePayload.PurchaseOrders || [];
            if (purchaseOrders.length > 0) {
              xeroPoId = purchaseOrders[0].PurchaseOrderID;
            }

            // Update local PO with Xero ID and sync status
            await query(
              `UPDATE xero_purchase_orders 
               SET xero_po_id = $1, sync_status = 'synced', xero_sync_id = $2, synced_at = CURRENT_TIMESTAMP, updated_at = CURRENT_TIMESTAMP
               WHERE id = $3`,
              [xeroPoId, job.id, poId]
            );

            // Log successful sync
            await logSyncAttempt('purchase_order', poId, requestPayload, responsePayload, statusCode);

            return { success: true, xeroPoId, poId };
          } catch (error: any) {
            errorMessage = error.message || 'Unknown error';
            statusCode = statusCode || 500;

            // Update PO sync status to failed
            await query(
              `UPDATE xero_purchase_orders 
               SET sync_status = 'failed', xero_sync_id = $1, updated_at = CURRENT_TIMESTAMP
               WHERE id = $2`,
              [job.id, poId]
            );

            // Log failed sync
            await logSyncAttempt('purchase_order', poId, requestPayload, responsePayload, statusCode, errorMessage);

            throw error;
          }
        }

        default:
          throw new Error(`Unknown sync job type: ${type}`);
      }
    } catch (error: any) {
      console.error(`[Xero Sync Worker] Job ${job.id} failed:`, error);
      throw error; // Re-throw to mark job as failed
    }
  },
  {
    connection: redisConnection,
    concurrency: 5, // Process up to 5 jobs concurrently
    limiter: {
      max: 10, // Max 10 jobs
      duration: 1000, // Per second (Xero rate limit consideration)
    },
  }
);

  // Worker event listeners
  xeroSyncWorker.on('completed', (job) => {
    console.log(`[Xero Sync Worker] Job ${job.id} completed successfully`);
  });

  xeroSyncWorker.on('failed', (job, err) => {
    console.error(`[Xero Sync Worker] Job ${job?.id} failed:`, err);
  });

  xeroSyncWorker.on('error', (err) => {
    console.error('[Xero Sync Worker] Worker error:', err);
  });
} catch (error) {
  console.warn('[Queue] Failed to initialize worker. Redis may not be available. Xero syncs will not work until Redis is configured.');
  xeroSyncWorker = null as any;
}

export { xeroSyncWorker };

// Export helper function to add jobs to queue
export async function addXeroSyncJob(type: string, data: any, jobId?: string) {
  if (!xeroSyncQueue) {
    throw new Error('Queue not initialized. Please ensure Redis is running and configured.');
  }
  const jobOptions: any = {};
  if (jobId) {
    jobOptions.jobId = jobId; // Use provided jobId for idempotency
  }
  return await xeroSyncQueue.add(type, { type, data }, jobOptions);
}
--- FILE: backend/src/lib/storage/FlystorageStorageProvider.ts ---
import { Readable } from 'stream';
import { IStorageProvider } from './IStorageProvider';
import { StorageConfig, PutOptions, FileMetadata } from './types';
import { log } from '../logger';
import path from 'path';
import fs from 'fs';
import { createHash } from 'crypto';

/**
 * Flystorage Storage Provider
 * 
 * Implements IStorageProvider using @flystorage/file-storage
 * Supports both local filesystem and S3-compatible storage.
 */
export class FlystorageStorageProvider implements IStorageProvider {
  private config: StorageConfig;
  private storage: any; // Flystorage instance
  private driver: 'local' | 's3'; // Note: This provider only supports local and S3

  constructor(config: StorageConfig) {
    // Validate that driver is not 'google-drive' (this provider doesn't support it)
    if (config.driver === 'google-drive') {
      throw new Error('FlystorageStorageProvider does not support Google Drive. Use GoogleDriveStorageProvider instead.');
    }
    
    this.config = config;
    this.driver = config.driver as 'local' | 's3'; // Type assertion is safe after validation

    // Initialize Flystorage based on driver
    if (config.driver === 's3') {
      this.initializeS3();
    } else {
      this.initializeLocal();
    }
  }

  private initializeLocal(): void {
    try {
      // Dynamic import to avoid requiring package if not installed
      const { FileStorage } = require('@flystorage/file-storage');
      const { LocalStorageAdapter } = require('@flystorage/local-fs');
      const basePath = path.resolve(process.cwd(), this.config.basePath || 'uploads');
      
      // Ensure base directory exists
      // Note: This is only needed for local storage. With memory storage for uploads,
      // files are streamed directly to storage, but we still need the base directory
      // for file retrieval and serving.
      // In Docker, the directory should already exist from the Dockerfile, but we
      // try to create it if it doesn't exist (e.g., in development or if volume mount fails)
      if (!fs.existsSync(basePath)) {
        try {
          fs.mkdirSync(basePath, { recursive: true });
          log.info('Created base storage directory', { basePath });
        } catch (mkdirError: any) {
          // If directory creation fails, check if it exists now (race condition)
          // or if we're in a read-only environment
          if (!fs.existsSync(basePath)) {
            log.error('Failed to create base storage directory', mkdirError, {
              basePath,
              resolvedPath: path.resolve(basePath),
              cwd: process.cwd(),
              errorCode: mkdirError.code,
              errorMessage: mkdirError.message
            });
            throw new Error(`Storage directory does not exist and could not be created: ${mkdirError.message} (code: ${mkdirError.code || 'unknown'})`);
          } else {
            // Directory was created by another process, that's fine
            log.info('Base storage directory exists (created by another process)', { basePath });
          }
        }
      } else {
        // Directory exists, verify it's accessible and writable
        try {
          fs.accessSync(basePath, fs.constants.R_OK | fs.constants.W_OK);
          
          // Additional check: try to write a test file to verify write permissions
          const testFile = path.join(basePath, '.write-test');
          try {
            fs.writeFileSync(testFile, 'test');
            fs.unlinkSync(testFile);
          } catch (writeError: any) {
            log.error('Base storage directory exists but is not writable', writeError, {
              basePath,
              errorCode: writeError.code,
              errorMessage: writeError.message
            });
            throw new Error(`Storage directory exists but is not writable: ${writeError.message} (code: ${writeError.code || 'unknown'}). Please check directory permissions.`);
          }
        } catch (accessError: any) {
          log.error('Base storage directory exists but is not accessible', accessError, {
            basePath,
            resolvedPath: path.resolve(basePath),
            cwd: process.cwd(),
            errorCode: accessError.code,
            errorMessage: accessError.message,
            // Include permission debugging info
            uid: process.getuid ? process.getuid() : 'N/A',
            gid: process.getgid ? process.getgid() : 'N/A'
          });
          
          // Provide Docker-specific guidance if in container
          const isDocker = fs.existsSync('/.dockerenv');
          const dockerHint = isDocker 
            ? ' If using Docker, ensure the mounted volume has correct permissions (chmod 755 ./backend/uploads on host, or run container with proper user mapping).'
            : '';
          
          throw new Error(`Storage directory exists but is not accessible: ${accessError.message} (code: ${accessError.code || 'unknown'}). Please check directory permissions.${dockerHint}`);
        }
      }

      const adapter = new LocalStorageAdapter(basePath);
      this.storage = new FileStorage(adapter);
    } catch (error: any) {
      log.error('Failed to initialize local storage', error, {
        basePath: this.config.basePath || 'uploads',
        resolvedPath: path.resolve(process.cwd(), this.config.basePath || 'uploads'),
        errorMessage: error.message,
        errorStack: error.stack
      });
      throw new Error(`Local storage initialization failed: ${error.message}`);
    }
  }

  private initializeS3(): void {
    try {
      if (!this.config.s3Bucket || !this.config.s3AccessKeyId || !this.config.s3SecretAccessKey) {
        throw new Error('S3 configuration incomplete. Missing bucket, access key, or secret key.');
      }

      // Dynamic import
      const { FileStorage } = require('@flystorage/file-storage');
      const { S3StorageAdapter } = require('@flystorage/aws-s3');
      const { S3Client } = require('@aws-sdk/client-s3');

      const s3Client = new S3Client({
        region: this.config.s3Region || 'us-east-1',
        credentials: {
          accessKeyId: this.config.s3AccessKeyId!,
          secretAccessKey: this.config.s3SecretAccessKey!,
        },
        ...(this.config.s3Endpoint && {
          endpoint: this.config.s3Endpoint,
          forcePathStyle: true, // Required for S3-compatible services
        }),
      });

      const prefix = this.config.basePath ? `${this.config.basePath}/` : '';
      const adapter = new S3StorageAdapter({
        client: s3Client,
        bucket: this.config.s3Bucket,
        prefix, // Optional prefix for all files
      });
      
      this.storage = new FileStorage(adapter);
    } catch (error: any) {
      log.error('Failed to initialize S3 storage', error);
      throw new Error(`S3 storage initialization failed: ${error.message}`);
    }
  }

  async put(filePath: string, content: Buffer | Readable, options?: PutOptions): Promise<string> {
    try {
      // Normalize path (remove leading slash, handle Windows paths)
      const normalizedPath = this.normalizePath(filePath);

      // Convert Buffer to Readable if needed
      let stream: Readable;
      if (Buffer.isBuffer(content)) {
        const { Readable } = require('stream');
        stream = Readable.from(content);
      } else {
        stream = content;
      }

      // Put file using Flystorage
      // Flystorage write() accepts string, Uint8Array, or Readable
      await this.storage.write(normalizedPath, stream);

      return normalizedPath;
    } catch (error: any) {
      log.error('Storage put error', error, { filePath });
      throw new Error(`Failed to store file: ${error.message}`);
    }
  }

  async get(filePath: string): Promise<Buffer> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      const stream = await this.storage.read(normalizedPath);
      
      // Convert stream to buffer
      const chunks: Buffer[] = [];
      for await (const chunk of stream) {
        chunks.push(chunk);
      }
      return Buffer.concat(chunks);
    } catch (error: any) {
      log.error('Storage get error', error, { filePath });
      throw new Error(`Failed to read file: ${error.message}`);
    }
  }

  async getStream(filePath: string): Promise<Readable> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      return await this.storage.read(normalizedPath);
    } catch (error: any) {
      log.error('Storage getStream error', error, { filePath });
      throw new Error(`Failed to read file stream: ${error.message}`);
    }
  }

  async exists(filePath: string): Promise<boolean> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      // Flystorage doesn't have exists(), use stat() and catch error
      try {
        await this.storage.stat(normalizedPath);
        return true;
      } catch {
        return false;
      }
    } catch (error: any) {
      log.error('Storage exists error', error, { filePath });
      return false;
    }
  }

  async delete(filePath: string): Promise<void> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      await this.storage.deleteFile(normalizedPath);
    } catch (error: any) {
      log.error('Storage delete error', error, { filePath });
      // Don't throw - file might already be deleted
      // Log but continue
    }
  }

  async copy(source: string, destination: string): Promise<void> {
    try {
      const normalizedSource = this.normalizePath(source);
      const normalizedDest = this.normalizePath(destination);
      
      // Read source file
      const sourceStream = await this.storage.read(normalizedSource);
      // Write to destination
      await this.storage.write(normalizedDest, sourceStream);
    } catch (error: any) {
      log.error('Storage copy error', error, { source, destination });
      throw new Error(`Failed to copy file: ${error.message}`);
    }
  }

  async move(source: string, destination: string): Promise<void> {
    try {
      const normalizedSource = this.normalizePath(source);
      const normalizedDest = this.normalizePath(destination);
      
      // Copy then delete
      await this.copy(source, destination);
      await this.delete(source);
    } catch (error: any) {
      log.error('Storage move error', error, { source, destination });
      throw new Error(`Failed to move file: ${error.message}`);
    }
  }

  async url(filePath: string): Promise<string> {
    const normalizedPath = this.normalizePath(filePath);
    
    if (this.driver === 's3') {
      // For S3, return signed URL for direct access
      return await this.signedUrl(filePath, 3600); // 1 hour default
    } else {
      // For local, return relative URL
      return `/uploads/${normalizedPath}`;
    }
  }

  async signedUrl(filePath: string, expiresIn: number = 3600): Promise<string> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      
      if (this.driver === 's3') {
        // Use S3 presigned URL
        const { getSignedUrl } = require('@aws-sdk/s3-request-presigner');
        const { GetObjectCommand } = require('@aws-sdk/client-s3');
        const { S3Client } = require('@aws-sdk/client-s3');

        const s3Client = new S3Client({
          region: this.config.s3Region || 'us-east-1',
          credentials: {
            accessKeyId: this.config.s3AccessKeyId!,
            secretAccessKey: this.config.s3SecretAccessKey!,
          },
          ...(this.config.s3Endpoint && {
            endpoint: this.config.s3Endpoint,
            forcePathStyle: true,
          }),
        });

        const key = this.config.basePath 
          ? `${this.config.basePath}/${normalizedPath}`.replace(/\/+/g, '/')
          : normalizedPath;

        const command = new GetObjectCommand({
          Bucket: this.config.s3Bucket!,
          Key: key,
        });

        return await getSignedUrl(s3Client, command, { expiresIn });
      } else {
        // Local storage doesn't support signed URLs, return regular URL
        return `/uploads/${normalizedPath}`;
      }
    } catch (error: any) {
      log.error('Storage signedUrl error', error, { filePath });
      throw new Error(`Failed to generate signed URL: ${error.message}`);
    }
  }

  async getMetadata(filePath: string): Promise<FileMetadata> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      const stat = await this.storage.stat(normalizedPath);
      
      return {
        path: normalizedPath,
        name: path.basename(normalizedPath),
        size: stat.size || 0,
        mimeType: stat.mimeType || stat.contentType,
        lastModified: stat.lastModified ? new Date(stat.lastModified) : undefined,
        isDirectory: stat.isDirectory || false,
      };
    } catch (error: any) {
      log.error('Storage getMetadata error', error, { filePath });
      throw new Error(`Failed to get file metadata: ${error.message}`);
    }
  }

  getDriver(): 'local' | 's3' | 'google-drive' {
    // This provider only supports 'local' and 's3', but interface requires union type
    return this.driver;
  }

  async list(prefix?: string): Promise<FileMetadata[]> {
    try {
      const normalizedPrefix = prefix ? this.normalizePath(prefix) : '';
      const files: FileMetadata[] = [];
      
      // Flystorage list() returns async iterator
      for await (const item of this.storage.list(normalizedPrefix, { deep: false })) {
        files.push({
          path: item.path,
          name: path.basename(item.path),
          size: item.size || 0,
          mimeType: item.mimeType,
          lastModified: item.lastModified ? new Date(item.lastModified) : undefined,
          isDirectory: item.isDirectory || false,
        });
      }
      
      return files;
    } catch (error: any) {
      log.error('Storage list error', error, { prefix });
      throw new Error(`Failed to list files: ${error.message}`);
    }
  }

  async makeDirectory(dirPath: string): Promise<void> {
    try {
      // For S3, directories don't exist (object-based storage)
      // For local, ensure directory exists
      if (this.driver === 'local') {
        const normalizedPath = this.normalizePath(dirPath);
        const fullPath = path.resolve(process.cwd(), this.config.basePath || 'uploads', normalizedPath);
        if (!fs.existsSync(fullPath)) {
          fs.mkdirSync(fullPath, { recursive: true });
        }
      }
      // S3 doesn't need directory creation
    } catch (error: any) {
      log.error('Storage makeDirectory error', error, { dirPath });
      throw new Error(`Failed to create directory: ${error.message}`);
    }
  }

  async testConnection(): Promise<{ success: boolean; message: string }> {
    try {
      if (this.driver === 's3') {
        // Test S3 connection by listing bucket (with limit 1)
        try {
          // Try to list first item (limit iteration)
          let count = 0;
          for await (const _ of this.storage.list('', { deep: false })) {
            count++;
            if (count >= 1) break; // Just test we can list
          }
          return { success: true, message: 'S3 connection successful' };
        } catch (error: any) {
          return { 
            success: false, 
            message: `S3 connection failed: ${error.message}` 
          };
        }
      } else {
        // Test local storage by checking directory permissions
        const basePath = path.resolve(process.cwd(), this.config.basePath || 'uploads');
        try {
          fs.accessSync(basePath, fs.constants.W_OK);
          return { success: true, message: 'Local storage accessible' };
        } catch (error: any) {
          return { 
            success: false, 
            message: `Local storage not accessible: ${error.message}` 
          };
        }
      }
    } catch (error: any) {
      return { 
        success: false, 
        message: `Connection test failed: ${error.message}` 
      };
    }
  }

  /**
   * Normalize file path
   * - Remove leading/trailing slashes
   * - Normalize Windows paths to forward slashes
   * - Remove path traversal attempts
   */
  private normalizePath(filePath: string): string {
    if (!filePath) return '';
    
    // Remove leading slash
    let normalized = filePath.replace(/^\/+/, '');
    
    // Normalize Windows paths
    normalized = normalized.replace(/\\/g, '/');
    
    // Remove path traversal attempts
    normalized = normalized.replace(/\.\./g, '');
    
    // Remove multiple slashes
    normalized = normalized.replace(/\/+/g, '/');
    
    return normalized;
  }
}
--- FILE: backend/src/lib/storage/GoogleDriveStorageProvider.ts ---
import { Readable } from 'stream';
import { IStorageProvider } from './IStorageProvider';
import { StorageConfig, PutOptions, FileMetadata } from './types';
import { log } from '../logger';
import { getAuthorizedClient } from '../googleDrive';
import { google } from 'googleapis';
import { OAuth2Client } from 'google-auth-library';
import path from 'path';

/**
 * Google Drive Storage Provider
 * 
 * Implements IStorageProvider using Google Drive API v3.
 * Uses existing OAuth infrastructure from googleDrive.ts.
 * Maps application file paths to Google Drive folder structure.
 */
export class GoogleDriveStorageProvider implements IStorageProvider {
  private config: StorageConfig;
  private drive: any; // Google Drive API client
  private rootFolderId: string | null = null; // Cached root folder ID
  private folderCache: Map<string, string> = new Map(); // Cache folder IDs by path
  private cacheTimestamp: number = 0;
  private readonly CACHE_TTL = 300000; // 5 minutes

  constructor(config: StorageConfig) {
    if (config.driver !== 'google-drive') {
      throw new Error('GoogleDriveStorageProvider requires driver to be "google-drive"');
    }
    this.config = config;
    // Drive client will be initialized lazily in getDriveClient()
  }

  /**
   * Get or initialize Google Drive API client
   */
  private async getDriveClient(): Promise<any> {
    if (this.drive) {
      return this.drive;
    }

    const auth = await getAuthorizedClient();
    if (!auth) {
      throw new Error('Google Drive not authorized. Please connect your Google account in Settings ‚Üí Integrations.');
    }

    this.drive = google.drive({ version: 'v3', auth });
    return this.drive;
  }

  /**
   * Get root folder ID (basePath or configured folder)
   */
  private async getRootFolderId(): Promise<string> {
    // Check cache
    if (this.rootFolderId && (Date.now() - this.cacheTimestamp) < this.CACHE_TTL) {
      return this.rootFolderId;
    }

    const drive = await this.getDriveClient();

    // If specific folder ID is configured, use it
    if (this.config.googleDriveFolderId) {
      try {
        // Verify folder exists and is accessible
        await drive.files.get({
          fileId: this.config.googleDriveFolderId,
          fields: 'id, name, mimeType'
        });
        this.rootFolderId = this.config.googleDriveFolderId;
        this.cacheTimestamp = Date.now();
        return this.rootFolderId;
      } catch (error: any) {
        log.error('Configured Google Drive folder not accessible', error);
        throw new Error(`Configured Google Drive folder is not accessible: ${error.message}`);
      }
    }

    // Otherwise, find or create folder based on basePath
    const basePath = this.config.basePath || 'uploads';
    this.rootFolderId = await this.findOrCreateFolder(basePath, 'root');
    this.cacheTimestamp = Date.now();
    return this.rootFolderId;
  }

  /**
   * Find or create a folder in Google Drive
   * @param folderName Name of the folder
   * @param parentId Parent folder ID or 'root' for root folder
   * @returns Folder ID
   */
  private async findOrCreateFolder(folderName: string, parentId: string): Promise<string> {
    const cacheKey = `${parentId}/${folderName}`;
    
    // Check cache
    if (this.folderCache.has(cacheKey) && (Date.now() - this.cacheTimestamp) < this.CACHE_TTL) {
      return this.folderCache.get(cacheKey)!;
    }

    const drive = await this.getDriveClient();
    const query = `name='${folderName.replace(/'/g, "\\'")}' and mimeType='application/vnd.google-apps.folder' and trashed=false and '${parentId}' in parents`;

    try {
      // Search for existing folder
      const response = await drive.files.list({
        q: query,
        fields: 'files(id, name)',
        spaces: 'drive',
        pageSize: 1
      });

      if (response.data.files && response.data.files.length > 0) {
        const folderId = response.data.files[0].id!;
        this.folderCache.set(cacheKey, folderId);
        return folderId;
      }

      // Create folder if it doesn't exist
      const folderResponse = await drive.files.create({
        requestBody: {
          name: folderName,
          mimeType: 'application/vnd.google-apps.folder',
          parents: parentId === 'root' ? undefined : [parentId]
        },
        fields: 'id'
      });

      const newFolderId = folderResponse.data.id!;
      this.folderCache.set(cacheKey, newFolderId);
      return newFolderId;
    } catch (error: any) {
      log.error('Failed to find or create Google Drive folder', error, { folderName, parentId });
      throw new Error(`Failed to find or create folder: ${error.message}`);
    }
  }

  /**
   * Resolve application path to Google Drive folder structure
   * Returns parent folder ID and filename
   */
  private async resolvePath(applicationPath: string): Promise<{ parentId: string; fileName: string }> {
    // Normalize path (remove leading slash, handle Windows paths)
    const normalizedPath = applicationPath.replace(/^\/+/, '').replace(/\\/g, '/');
    const parts = normalizedPath.split('/').filter(p => p.length > 0);
    
    if (parts.length === 0) {
      throw new Error('Invalid file path');
    }

    const fileName = parts[parts.length - 1];
    const folderParts = parts.slice(0, -1);

    // Start from root folder
    let currentFolderId = await this.getRootFolderId();

    // Navigate/create folder structure
    for (const folderName of folderParts) {
      currentFolderId = await this.findOrCreateFolder(folderName, currentFolderId);
    }

    return { parentId: currentFolderId, fileName };
  }

  /**
   * Find file by path in Google Drive
   * Returns file ID if found, null otherwise
   */
  private async findFileByPath(applicationPath: string): Promise<string | null> {
    try {
      const { parentId, fileName } = await this.resolvePath(applicationPath);
      const drive = await this.getDriveClient();

      const query = `name='${fileName.replace(/'/g, "\\'")}' and '${parentId}' in parents and trashed=false`;
      
      const response = await drive.files.list({
        q: query,
        fields: 'files(id, name)',
        spaces: 'drive',
        pageSize: 1
      });

      if (response.data.files && response.data.files.length > 0) {
        return response.data.files[0].id!;
      }

      return null;
    } catch (error: any) {
      log.error('Failed to find file in Google Drive', error, { path: applicationPath });
      return null;
    }
  }

  /**
   * Normalize path (remove leading slash, handle Windows paths)
   */
  private normalizePath(filePath: string): string {
    return filePath.replace(/^\/+/, '').replace(/\\/g, '/');
  }

  async put(filePath: string, content: Buffer | Readable, options?: PutOptions): Promise<string> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      const { parentId, fileName } = await this.resolvePath(normalizedPath);
      const drive = await this.getDriveClient();

      // Check if file already exists
      const existingFileId = await this.findFileByPath(normalizedPath);
      
      // Convert Buffer to Readable if needed
      let stream: Readable;
      if (Buffer.isBuffer(content)) {
        stream = Readable.from(content);
      } else {
        stream = content;
      }

      const fileMetadata: any = {
        name: fileName,
        parents: [parentId]
      };

      // If file exists, update it; otherwise create new
      if (existingFileId) {
        // Update existing file
        await drive.files.update({
          fileId: existingFileId,
          requestBody: {
            name: fileName
          },
          media: {
            mimeType: options?.contentType || 'application/octet-stream',
            body: stream
          },
          fields: 'id'
        });

        // Return path with file ID for storage
        return `gdrive://${existingFileId}`;
      } else {
        // Create new file
        const response = await drive.files.create({
          requestBody: fileMetadata,
          media: {
            mimeType: options?.contentType || 'application/octet-stream',
            body: stream
          },
          fields: 'id'
        });

        const fileId = response.data.id!;
        // Return path with file ID for storage
        return `gdrive://${fileId}`;
      }
    } catch (error: any) {
      log.error('Google Drive put error', error, { filePath });
      throw new Error(`Failed to store file in Google Drive: ${error.message}`);
    }
  }

  async get(filePath: string): Promise<Buffer> {
    const stream = await this.getStream(filePath);
    
    // Convert stream to buffer
    const chunks: Buffer[] = [];
    for await (const chunk of stream) {
      chunks.push(chunk);
    }
    return Buffer.concat(chunks);
  }

  async getStream(filePath: string): Promise<Readable> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      const drive = await this.getDriveClient();

      // Try to find file by path or extract file ID from gdrive:// format
      let fileId: string | null = null;

      if (normalizedPath.startsWith('gdrive://')) {
        // Extract file ID from gdrive:// format
        fileId = normalizedPath.replace('gdrive://', '');
      } else {
        // Find file by path
        fileId = await this.findFileByPath(normalizedPath);
        if (!fileId) {
          throw new Error('File not found');
        }
      }

      const response = await drive.files.get(
        { fileId, alt: 'media' },
        { responseType: 'stream' }
      );

      return response.data as Readable;
    } catch (error: any) {
      log.error('Google Drive getStream error', error, { filePath });
      throw new Error(`Failed to read file from Google Drive: ${error.message}`);
    }
  }

  async exists(filePath: string): Promise<boolean> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      
      // Check gdrive:// format
      if (normalizedPath.startsWith('gdrive://')) {
        const fileId = normalizedPath.replace('gdrive://', '');
        const drive = await this.getDriveClient();
        try {
          await drive.files.get({
            fileId,
            fields: 'id'
          });
          return true;
        } catch {
          return false;
        }
      }

      // Find by path
      const fileId = await this.findFileByPath(normalizedPath);
      return fileId !== null;
    } catch (error: any) {
      log.error('Google Drive exists error', error, { filePath });
      return false;
    }
  }

  async delete(filePath: string): Promise<void> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      const drive = await this.getDriveClient();

      let fileId: string | null = null;

      if (normalizedPath.startsWith('gdrive://')) {
        fileId = normalizedPath.replace('gdrive://', '');
      } else {
        fileId = await this.findFileByPath(normalizedPath);
        if (!fileId) {
          throw new Error('File not found');
        }
      }

      await drive.files.delete({ fileId });
    } catch (error: any) {
      log.error('Google Drive delete error', error, { filePath });
      throw new Error(`Failed to delete file from Google Drive: ${error.message}`);
    }
  }

  async copy(source: string, destination: string): Promise<void> {
    try {
      const normalizedSource = this.normalizePath(source);
      const normalizedDest = this.normalizePath(destination);
      const drive = await this.getDriveClient();

      // Find source file
      let sourceFileId: string | null = null;
      if (normalizedSource.startsWith('gdrive://')) {
        sourceFileId = normalizedSource.replace('gdrive://', '');
      } else {
        sourceFileId = await this.findFileByPath(normalizedSource);
        if (!sourceFileId) {
          throw new Error('Source file not found');
        }
      }

      // Resolve destination path
      const { parentId, fileName } = await this.resolvePath(normalizedDest);

      // Copy file in Google Drive
      await drive.files.copy({
        fileId: sourceFileId,
        requestBody: {
          name: fileName,
          parents: [parentId]
        },
        fields: 'id'
      });
    } catch (error: any) {
      log.error('Google Drive copy error', error, { source, destination });
      throw new Error(`Failed to copy file in Google Drive: ${error.message}`);
    }
  }

  async move(source: string, destination: string): Promise<void> {
    try {
      const normalizedSource = this.normalizePath(source);
      const normalizedDest = this.normalizePath(destination);
      const drive = await this.getDriveClient();

      // Find source file
      let sourceFileId: string | null = null;
      if (normalizedSource.startsWith('gdrive://')) {
        sourceFileId = normalizedSource.replace('gdrive://', '');
      } else {
        sourceFileId = await this.findFileByPath(normalizedSource);
        if (!sourceFileId) {
          throw new Error('Source file not found');
        }
      }

      // Get current parents
      const fileResponse = await drive.files.get({
        fileId: sourceFileId,
        fields: 'parents, name'
      });

      const previousParents = fileResponse.data.parents?.join(',') || '';

      // Resolve destination path
      const { parentId, fileName } = await this.resolvePath(normalizedDest);

      // Move file (update parents and optionally rename)
      await drive.files.update({
        fileId: sourceFileId,
        addParents: parentId,
        removeParents: previousParents,
        requestBody: {
          name: fileName
        },
        fields: 'id, parents'
      });
    } catch (error: any) {
      log.error('Google Drive move error', error, { source, destination });
      throw new Error(`Failed to move file in Google Drive: ${error.message}`);
    }
  }

  async url(filePath: string): Promise<string> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      const drive = await this.getDriveClient();

      let fileId: string | null = null;
      if (normalizedPath.startsWith('gdrive://')) {
        fileId = normalizedPath.replace('gdrive://', '');
      } else {
        fileId = await this.findFileByPath(normalizedPath);
        if (!fileId) {
          throw new Error('File not found');
        }
      }

      // Get file metadata to get webViewLink
      const response = await drive.files.get({
        fileId,
        fields: 'webViewLink, webContentLink'
      });

      // Prefer webViewLink for viewing, fallback to webContentLink for download
      return response.data.webViewLink || response.data.webContentLink || '';
    } catch (error: any) {
      log.error('Google Drive url error', error, { filePath });
      throw new Error(`Failed to get file URL from Google Drive: ${error.message}`);
    }
  }

  async signedUrl(filePath: string, expiresIn: number = 3600): Promise<string> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      const drive = await this.getDriveClient();

      let fileId: string | null = null;
      if (normalizedPath.startsWith('gdrive://')) {
        fileId = normalizedPath.replace('gdrive://', '');
      } else {
        fileId = await this.findFileByPath(normalizedPath);
        if (!fileId) {
          throw new Error('File not found');
        }
      }

      // Generate temporary download URL
      // Note: Google Drive doesn't support signed URLs like S3, but we can use webContentLink
      // For temporary access, we'd need to make the file temporarily public or use service account
      // For now, return webContentLink which requires authentication
      const response = await drive.files.get({
        fileId,
        fields: 'webContentLink'
      });

      if (!response.data.webContentLink) {
        throw new Error('Unable to generate download URL');
      }

      return response.data.webContentLink;
    } catch (error: any) {
      log.error('Google Drive signedUrl error', error, { filePath });
      throw new Error(`Failed to generate signed URL from Google Drive: ${error.message}`);
    }
  }

  async getMetadata(filePath: string): Promise<FileMetadata> {
    try {
      const normalizedPath = this.normalizePath(filePath);
      const drive = await this.getDriveClient();

      let fileId: string | null = null;
      if (normalizedPath.startsWith('gdrive://')) {
        fileId = normalizedPath.replace('gdrive://', '');
      } else {
        fileId = await this.findFileByPath(normalizedPath);
        if (!fileId) {
          throw new Error('File not found');
        }
      }

      const response = await drive.files.get({
        fileId,
        fields: 'id, name, size, mimeType, modifiedTime, createdTime'
      });

      const file = response.data;
      return {
        path: normalizedPath,
        name: file.name || '',
        size: parseInt(file.size || '0', 10),
        mimeType: file.mimeType || undefined,
        lastModified: file.modifiedTime ? new Date(file.modifiedTime) : undefined,
        isDirectory: file.mimeType === 'application/vnd.google-apps.folder'
      };
    } catch (error: any) {
      log.error('Google Drive getMetadata error', error, { filePath });
      throw new Error(`Failed to get file metadata from Google Drive: ${error.message}`);
    }
  }

  getDriver(): 'google-drive' {
    return 'google-drive';
  }

  async list(prefix?: string): Promise<FileMetadata[]> {
    try {
      const drive = await this.getDriveClient();
      let parentId: string;

      if (prefix) {
        const normalizedPrefix = this.normalizePath(prefix);
        const { parentId: resolvedParentId } = await this.resolvePath(normalizedPrefix);
        parentId = resolvedParentId;
      } else {
        parentId = await this.getRootFolderId();
      }

      const response = await drive.files.list({
        q: `'${parentId}' in parents and trashed=false`,
        fields: 'files(id, name, size, mimeType, modifiedTime, createdTime)',
        spaces: 'drive',
        pageSize: 1000
      });

      const files = response.data.files || [];
      return files.map((file: any) => ({
        path: prefix ? `${prefix}/${file.name}` : file.name || '',
        name: file.name || '',
        size: parseInt(file.size || '0', 10),
        mimeType: file.mimeType || undefined,
        lastModified: file.modifiedTime ? new Date(file.modifiedTime) : undefined,
        isDirectory: file.mimeType === 'application/vnd.google-apps.folder'
      }));
    } catch (error: any) {
      log.error('Google Drive list error', error, { prefix });
      throw new Error(`Failed to list files in Google Drive: ${error.message}`);
    }
  }

  async makeDirectory(dirPath: string): Promise<void> {
    try {
      const normalizedPath = this.normalizePath(dirPath);
      const parts = normalizedPath.split('/').filter(p => p.length > 0);
      
      if (parts.length === 0) {
        throw new Error('Invalid directory path');
      }

      let currentFolderId = await this.getRootFolderId();

      // Create folder structure
      for (const folderName of parts) {
        currentFolderId = await this.findOrCreateFolder(folderName, currentFolderId);
      }
    } catch (error: any) {
      log.error('Google Drive makeDirectory error', error, { dirPath });
      throw new Error(`Failed to create directory in Google Drive: ${error.message}`);
    }
  }

  async testConnection(): Promise<{ success: boolean; message: string }> {
    try {
      const drive = await this.getDriveClient();
      
      // Test connection by listing root folder
      await drive.files.list({
        q: "trashed=false",
        fields: 'files(id, name)',
        pageSize: 1
      });

      // Test root folder access
      await this.getRootFolderId();

      return {
        success: true,
        message: 'Google Drive connection successful'
      };
    } catch (error: any) {
      log.error('Google Drive connection test failed', error);
      return {
        success: false,
        message: error.message || 'Failed to connect to Google Drive. Please check OAuth connection in Settings ‚Üí Integrations.'
      };
    }
  }
}
--- FILE: backend/src/lib/storage/IStorageProvider.ts ---
import { Readable } from 'stream';
import { PutOptions, FileMetadata } from './types';

/**
 * Storage Provider Interface
 * 
 * Abstract interface for file storage operations supporting
 * local filesystem, S3-compatible cloud storage, and Google Drive.
 */
export interface IStorageProvider {
  // Core operations
  put(filePath: string, content: Buffer | Readable, options?: PutOptions): Promise<string>;
  get(filePath: string): Promise<Buffer>;
  getStream(filePath: string): Promise<Readable>; // CRITICAL: For streaming large files
  exists(filePath: string): Promise<boolean>;
  delete(filePath: string): Promise<void>;
  copy(source: string, destination: string): Promise<void>;
  move(source: string, destination: string): Promise<void>;
  
  // URL generation
  url(filePath: string): Promise<string>;
  signedUrl(filePath: string, expiresIn?: number): Promise<string>; // CRITICAL: For S3/Google Drive direct access
  
  // Metadata
  getMetadata(filePath: string): Promise<FileMetadata>;
  getDriver(): 'local' | 's3' | 'google-drive'; // Returns current driver type
  
  // Directory operations
  list(prefix?: string): Promise<FileMetadata[]>;
  makeDirectory(path: string): Promise<void>;
  
  // Connection testing (for UI)
  testConnection(): Promise<{ success: boolean; message: string }>;
}
--- FILE: backend/src/lib/storage/StorageFactory.ts ---
import { query } from '../../db';
import { IStorageProvider } from './IStorageProvider';
import { StorageConfig } from './types';
import { FlystorageStorageProvider } from './FlystorageStorageProvider';
import { GoogleDriveStorageProvider } from './GoogleDriveStorageProvider';
import { log } from '../logger';

let storageInstance: IStorageProvider | null = null;
let configCache: StorageConfig | null = null;
let cacheTimestamp: number = 0;
const CACHE_TTL = 60000; // 1 minute cache

/**
 * Get storage configuration from database settings
 */
async function getStorageConfigFromDB(): Promise<StorageConfig> {
  try {
    const result = await query(
      `SELECT key, value FROM settings 
       WHERE user_id IS NULL 
       AND key IN ('storage_driver', 'storage_base_path', 'storage_s3_bucket', 'storage_s3_region', 'storage_s3_access_key_id', 'storage_s3_secret_access_key', 'storage_s3_endpoint', 'storage_google_drive_folder_id')`
    );

    const settings: Record<string, string> = {};
    result.rows.forEach((row: any) => {
      settings[row.key] = row.value;
    });

    const driver = (settings.storage_driver || 'local') as 'local' | 's3' | 'google-drive';
    const config: StorageConfig = {
      driver,
      basePath: settings.storage_base_path || 'uploads',
    };

    if (driver === 's3') {
      config.s3Bucket = settings.storage_s3_bucket;
      config.s3Region = settings.storage_s3_region || 'us-east-1';
      config.s3AccessKeyId = settings.storage_s3_access_key_id;
      config.s3SecretAccessKey = settings.storage_s3_secret_access_key;
      config.s3Endpoint = settings.storage_s3_endpoint || undefined;
    } else if (driver === 'google-drive') {
      config.googleDriveFolderId = settings.storage_google_drive_folder_id || undefined;
    }

    return config;
  } catch (error) {
    log.error('Failed to load storage config from database', error);
    // Fallback to local storage
    return {
      driver: 'local',
      basePath: 'uploads',
    };
  }
}

/**
 * Decrypt sensitive setting value (if encryption is implemented)
 * For now, returns as-is. Can be enhanced with encryption later.
 */
function decryptSetting(value: string | null): string | null {
  if (!value) return null;
  // TODO: Implement decryption if secret access keys are encrypted
  return value;
}

/**
 * Create storage provider instance from configuration
 */
function createStorageProvider(config: StorageConfig): IStorageProvider {
  if (config.driver === 'google-drive') {
    return new GoogleDriveStorageProvider(config);
  }
  return new FlystorageStorageProvider(config);
}

/**
 * Storage Factory - Singleton pattern with cache invalidation
 * 
 * Reads storage configuration from database settings table and
 * creates appropriate storage provider instance.
 */
export class StorageFactory {
  /**
   * Get storage provider instance (singleton)
   * Caches instance for 1 minute to avoid repeated DB queries
   */
  static async getInstance(): Promise<IStorageProvider> {
    const now = Date.now();
    
    // Check if cache is still valid
    if (storageInstance && configCache && (now - cacheTimestamp) < CACHE_TTL) {
      return storageInstance;
    }

    // Load config from database
    const config = await getStorageConfigFromDB();
    
    // Decrypt sensitive values
    if (config.s3SecretAccessKey) {
      config.s3SecretAccessKey = decryptSetting(config.s3SecretAccessKey) || '';
    }

    // Check if config changed
    const configChanged = !configCache || 
      configCache.driver !== config.driver ||
      configCache.basePath !== config.basePath ||
      configCache.s3Bucket !== config.s3Bucket ||
      configCache.s3Region !== config.s3Region ||
      configCache.s3AccessKeyId !== config.s3AccessKeyId ||
      configCache.s3SecretAccessKey !== config.s3SecretAccessKey ||
      configCache.s3Endpoint !== config.s3Endpoint ||
      configCache.googleDriveFolderId !== config.googleDriveFolderId;

    // Create new instance if config changed or instance doesn't exist
    if (!storageInstance || configChanged) {
      try {
        storageInstance = createStorageProvider(config);
        configCache = { ...config }; // Deep copy for comparison
        cacheTimestamp = now;
      } catch (error: any) {
        log.error('Failed to create storage provider instance', error, {
          driver: config.driver,
          basePath: config.basePath,
          hasS3Config: !!(config.s3Bucket && config.s3AccessKeyId),
          hasGoogleDriveConfig: !!config.googleDriveFolderId,
          errorMessage: error.message,
          errorStack: error.stack
        });
        
        // Provide more helpful error messages for common issues
        let errorMessage = error.message;
        if (error.message.includes('EACCES') || error.message.includes('permission denied')) {
          errorMessage = `Storage permission error: The storage directory exists but the application does not have write permissions. Please check directory permissions or configure a different storage driver (S3/Google Drive) in Settings. Original error: ${error.message}`;
        } else if (error.message.includes('ENOENT') || error.message.includes('does not exist')) {
          errorMessage = `Storage directory not found: The storage directory does not exist and could not be created. Please check the storage configuration. Original error: ${error.message}`;
        }
        
        throw new Error(`Failed to initialize storage provider (${config.driver}): ${errorMessage}`);
      }
    }

    return storageInstance;
  }

  /**
   * Invalidate cache (call when settings are updated)
   */
  static invalidateCache(): void {
    storageInstance = null;
    configCache = null;
    cacheTimestamp = 0;
  }

  /**
   * Create temporary storage provider for testing (doesn't use cache)
   */
  static async createTestInstance(config: StorageConfig): Promise<IStorageProvider> {
    if (config.s3SecretAccessKey) {
      config.s3SecretAccessKey = decryptSetting(config.s3SecretAccessKey) || '';
    }
    return createStorageProvider(config);
  }
}
--- FILE: backend/src/lib/storage/pathUtils.ts ---
import { createHash } from 'crypto';
import { v4 as uuidv4 } from 'uuid';
import path from 'path';

/**
 * Generate partitioned path for file storage
 * 
 * Creates a path structure like: {basePath}/{hash[0:2]}/{hash[2:4]}/{uuid}.{ext}
 * This distributes files across multiple directories to avoid filesystem
 * performance issues with large numbers of files in a single directory.
 * 
 * @param filename Original filename (used to extract extension)
 * @param basePath Base storage path (e.g., 'uploads/projects/{project_id}')
 * @returns Partitioned path string
 */
export function generatePartitionedPath(filename: string, basePath: string): string {
  // Generate UUID for filename
  const fileUuid = uuidv4();
  
  // Create hash from UUID for partitioning
  const hash = createHash('sha256').update(fileUuid).digest('hex');
  
  // Extract extension from original filename
  const ext = path.extname(filename).toLowerCase();
  const safeExt = /^\.(jpg|jpeg|png|gif|webp|pdf|doc|docx|xls|xlsx|txt|csv|bin)$/i.test(ext) 
    ? ext 
    : '.bin';
  
  // Create partitioned path: {basePath}/{hash[0:2]}/{hash[2:4]}/{uuid}.{ext}
  const partition1 = hash.substring(0, 2);
  const partition2 = hash.substring(2, 4);
  
  // Normalize basePath (remove trailing slashes)
  const normalizedBase = basePath.replace(/\/+$/, '');
  
  return `${normalizedBase}/${partition1}/${partition2}/${fileUuid}${safeExt}`;
}

/**
 * Sanitize file path to prevent directory traversal attacks
 * 
 * @param filePath Path to sanitize
 * @returns Sanitized path
 */
export function sanitizePath(filePath: string): string {
  if (!filePath) return '';
  
  // Remove path traversal attempts
  let sanitized = filePath.replace(/\.\./g, '');
  
  // Normalize Windows paths
  sanitized = sanitized.replace(/\\/g, '/');
  
  // Remove leading slashes (paths should be relative)
  sanitized = sanitized.replace(/^\/+/, '');
  
  // Remove multiple slashes
  sanitized = sanitized.replace(/\/+/g, '/');
  
  // Remove trailing slashes
  sanitized = sanitized.replace(/\/+$/, '');
  
  return sanitized;
}

/**
 * Resolve storage path to a storage-agnostic relative path
 * 
 * @param relativePath Relative path from uploads root
 * @returns Normalized storage path
 */
export function resolveStoragePath(relativePath: string): string {
  // Remove /uploads prefix if present
  let resolved = relativePath.replace(/^\/?uploads\/?/, '');
  
  // Apply sanitization
  resolved = sanitizePath(resolved);
  
  return resolved;
}

/**
 * Extract directory path from full file path
 * 
 * @param filePath Full file path
 * @returns Directory path (without filename)
 */
export function getDirectoryPath(filePath: string): string {
  const dir = path.dirname(filePath);
  return dir === '.' ? '' : dir;
}
--- FILE: backend/src/lib/storage/types.ts ---
import { Readable } from 'stream';

export interface PutOptions {
  contentType?: string;
  metadata?: Record<string, string>;
  acl?: string;
}

export interface FileMetadata {
  path: string;
  name: string;
  size: number;
  mimeType?: string;
  lastModified?: Date;
  isDirectory?: boolean;
}

export interface StorageConfig {
  driver: 'local' | 's3' | 'google-drive';
  basePath?: string;
  // S3 config
  s3Bucket?: string;
  s3Region?: string;
  s3AccessKeyId?: string;
  s3SecretAccessKey?: string;
  s3Endpoint?: string;
  // Google Drive config (optional, uses existing OAuth tokens from settings)
  googleDriveFolderId?: string; // Optional: specific folder ID to use as root, otherwise uses basePath
}
--- FILE: backend/src/lib/troubleshooter/routeScanner.ts ---
import fs from 'fs';
import path from 'path';
import { DiscoveredRoute } from './types';

/**
 * Scan route files to discover API endpoints
 */
export async function scanRoutes(): Promise<DiscoveredRoute[]> {
  const routesDir = path.join(__dirname, '../../routes');
  const routes: DiscoveredRoute[] = [];

  try {
    const files = fs.readdirSync(routesDir);
    
    for (const file of files) {
      if (file.endsWith('.ts') && file !== 'troubleshooter.ts') {
        const filePath = path.join(routesDir, file);
        const content = fs.readFileSync(filePath, 'utf-8');
        
        // Extract route definitions
        const routeMatches = content.matchAll(
          /router\.(get|post|put|delete|patch)\s*\(\s*['"`]([^'"`]+)['"`]/g
        );

        for (const match of routeMatches) {
          const method = match[1].toUpperCase();
          const routePath = match[2];
          
          // Extract middleware (simplified - looks for authenticate, requireRole, requirePermission)
          const middleware: string[] = [];
          const lines = content.split('\n');
          const routeIndex = content.indexOf(match[0]);
          const routeLineNumber = content.substring(0, routeIndex).split('\n').length - 1;
          
          // Check a few lines before the route for middleware
          for (let i = Math.max(0, routeLineNumber - 10); i < routeLineNumber; i++) {
            const line = lines[i];
            if (line.includes('authenticate')) middleware.push('authenticate');
            if (line.includes('requireRole')) {
              const roleMatch = line.match(/requireRole\(([^)]+)\)/);
              if (roleMatch) middleware.push(`requireRole(${roleMatch[1]})`);
            }
            if (line.includes('requirePermission')) {
              const permMatch = line.match(/requirePermission\(([^)]+)\)/);
              if (permMatch) middleware.push(`requirePermission(${permMatch[1]})`);
            }
          }

          // Determine base path from file name (matches server.ts route registration)
          let basePath = '';
          const filename = file.replace('.ts', '');
          
          // Map file names to their API paths
          const routeMap: Record<string, string> = {
            'auth': '/api/auth',
            'users': '/api/users',
            'clients': '/api/clients',
            'projects': '/api/projects',
            'timesheets': '/api/timesheets',
            'costCenters': '/api/cost-centers',
            'activityTypes': '/api/activity-types',
            'search': '/api/search',
            'setup': '/api/setup',
            'xero': '/api/xero',
            'settings': '/api/settings',
            'permissions': '/api/permissions',
            'role-permissions': '/api/role-permissions',
            'dashboard': '/api/dashboard',
            'health': '/api/health',
          };
          
          basePath = routeMap[filename] || `/api/${filename}`;
          
          routes.push({
            method,
            path: routePath.startsWith('/') ? `${basePath}${routePath}` : `${basePath}/${routePath}`,
            file,
            middleware: [...new Set(middleware)], // Remove duplicates
          });
        }
      }
    }
  } catch (error) {
    console.error('Error scanning routes:', error);
  }

  return routes;
}

/**
 * Get route file path
 */
export function getRouteFilePath(filename: string): string {
  return path.join(__dirname, '../../routes', filename);
}

--- FILE: backend/src/lib/troubleshooter/testData.ts ---
import bcrypt from 'bcryptjs';
import { query } from '../../db';
import { env } from '../../config/env';
import jwt from 'jsonwebtoken';

const TEST_PREFIX = 'TEST_';

export interface TestUser {
  id: string;
  email: string;
  password: string;
  token: string;
  role: 'admin' | 'manager' | 'user';
}

/**
 * Create test users for different roles
 */
export async function createTestUsers(): Promise<TestUser[]> {
  const users: TestUser[] = [];
  const roles: Array<'admin' | 'manager' | 'user'> = ['admin', 'manager', 'user'];

  for (const role of roles) {
    // Normalize email to match what express-validator does (lowercase)
    const email = `${TEST_PREFIX}${role}@test.com`.toLowerCase();
    const password = 'TestPassword123!';
    const name = `Test ${role}`;

    // Check if user already exists
    const existing = await query('SELECT id FROM users WHERE email = $1', [email]);
    if (existing.rows.length > 0) {
      // Delete existing test user
      await query('DELETE FROM users WHERE email = $1', [email]);
    }

    const passwordHash = await bcrypt.hash(password, 12);
    const result = await query(
      `INSERT INTO users (email, password_hash, name, role) 
       VALUES ($1, $2, $3, $4) 
       RETURNING id, email, name, role`,
      [email, passwordHash, name, role]
    );

    const user = result.rows[0];

    // Set default permissions based on role
    const defaultPermissions = getDefaultPermissions(role);
    for (const permission of defaultPermissions) {
      await query(
        'INSERT INTO user_permissions (user_id, permission, granted) VALUES ($1, $2, true) ON CONFLICT DO NOTHING',
        [user.id, permission]
      );
    }

    // Generate token
    const token = jwt.sign(
      { id: user.id, email: user.email, name: user.name, role: user.role },
      env.JWT_SECRET,
      { expiresIn: '1h' }
    );

    users.push({
      id: user.id,
      email: user.email,
      password,
      token,
      role,
    });
  }

  return users;
}

/**
 * Clean up test users
 */
export async function cleanupTestUsers(): Promise<void> {
  await query(`DELETE FROM users WHERE email LIKE $1`, [`${TEST_PREFIX}%`]);
}

/**
 * Clean up test data by prefix
 */
export async function cleanupTestData(): Promise<void> {
  // Clean up in reverse order of dependencies
  await query(`DELETE FROM timesheets WHERE notes LIKE $1`, [`%${TEST_PREFIX}%`]);
  await query(`DELETE FROM projects WHERE name LIKE $1`, [`${TEST_PREFIX}%`]);
  await query(`DELETE FROM clients WHERE name LIKE $1`, [`${TEST_PREFIX}%`]);
  await query(`DELETE FROM activity_types WHERE name LIKE $1`, [`${TEST_PREFIX}%`]);
  await query(`DELETE FROM cost_centers WHERE code LIKE $1`, [`${TEST_PREFIX}%`]);
  await cleanupTestUsers();
}

/**
 * Get default permissions for a role
 */
function getDefaultPermissions(role: string): string[] {
  const permissions: Record<string, string[]> = {
    admin: [
      'can_view_financials',
      'can_edit_projects',
      'can_manage_users',
      'can_sync_xero',
      'can_view_all_timesheets',
      'can_edit_activity_types',
      'can_manage_clients',
      'can_manage_cost_centers',
    ],
    manager: [
      'can_view_financials',
      'can_edit_projects',
      'can_view_all_timesheets',
      'can_manage_clients',
    ],
    user: [],
  };

  return permissions[role] || [];
}

/**
 * Create a test client
 */
export async function createTestClient(name?: string): Promise<string> {
  const clientName = name || `${TEST_PREFIX}Client ${Date.now()}`;
  const result = await query(
    `INSERT INTO clients (name, contact_name, email, phone, status)
     VALUES ($1, $2, $3, $4, $5)
     RETURNING id`,
    [clientName, 'Test Contact', 'test@example.com', '1234567890', 'active']
  );
  return result.rows[0].id;
}

/**
 * Create a test project
 */
export async function createTestProject(clientId: string, name?: string): Promise<string> {
  const projectName = name || `${TEST_PREFIX}Project ${Date.now()}`;
  const projectCode = `${TEST_PREFIX}PROJ${Date.now()}`;
  const result = await query(
    `INSERT INTO projects (code, name, client_id, status, budget)
     VALUES ($1, $2, $3, $4, $5)
     RETURNING id`,
    [projectCode, projectName, clientId, 'in-progress', 10000]
  );
  return result.rows[0].id;
}

/**
 * Create a test activity type
 */
export async function createTestActivityType(name?: string): Promise<string> {
  const activityName = name || `${TEST_PREFIX}Activity ${Date.now()}`;
  const result = await query(
    `INSERT INTO activity_types (name, icon, color, hourly_rate, is_active)
     VALUES ($1, $2, $3, $4, $5)
     RETURNING id`,
    [activityName, 'Wrench', 'bg-electric/20 border-electric text-electric', 50, true]
  );
  return result.rows[0].id;
}

/**
 * Create a test cost center
 */
export async function createTestCostCenter(code?: string, name?: string): Promise<string> {
  // Cost center code is VARCHAR(20), so we need to keep it short
  // Use a shorter timestamp or just a random number
  const timestamp = Date.now().toString().slice(-8); // Last 8 digits
  const costCenterCode = code || `${TEST_PREFIX}CC${timestamp}`.substring(0, 20); // Max 20 chars
  const costCenterName = name || `${TEST_PREFIX}Cost Center ${Date.now()}`;
  const result = await query(
    `INSERT INTO cost_centers (code, name, budget, is_active)
     VALUES ($1, $2, $3, $4)
     RETURNING id`,
    [costCenterCode, costCenterName, 50000, true]
  );
  return result.rows[0].id;
}

--- FILE: backend/src/lib/troubleshooter/testHelpers.ts ---
import { TestResult } from './types';
import { env } from '../../config/env';

/**
 * Helper function to run a test and capture the result
 */
export async function runTest(
  name: string,
  category: string,
  testFn: () => Promise<void>,
  id?: string
): Promise<TestResult> {
  const startTime = Date.now();
  const testId = id || `${category}-${name}-${Date.now()}`;

  try {
    await testFn();
    const duration = Date.now() - startTime;
    return {
      id: testId,
      name,
      category,
      status: 'passed',
      duration,
      message: 'Test passed',
      timestamp: new Date().toISOString(),
    };
  } catch (error: any) {
    const duration = Date.now() - startTime;
    return {
      id: testId,
      name,
      category,
      status: 'failed',
      duration,
      message: error.message || 'Test failed',
      error: {
        message: error.message || 'Unknown error',
        stack: error.stack,
        details: error.details,
      },
      timestamp: new Date().toISOString(),
    };
  }
}

/**
 * Helper to make API requests during testing
 */
export async function apiRequest(
  endpoint: string,
  options: {
    method?: 'GET' | 'POST' | 'PUT' | 'DELETE';
    body?: any;
    token?: string;
    expectedStatus?: number | number[];
  } = {}
): Promise<any> {
  const { method = 'GET', body, token, expectedStatus } = options;
  
  const headers: Record<string, string> = {
    'Content-Type': 'application/json',
  };

  if (token) {
    headers['Authorization'] = `Bearer ${token}`;
  }

  const config: RequestInit = {
    method,
    headers,
  };

  if (body) {
    config.body = JSON.stringify(body);
  }

  const baseUrl = env.BACKEND_URL || `http://localhost:${env.PORT}`;
  const response = await fetch(`${baseUrl}${endpoint}`, config);
  const data = await response.json().catch(() => ({}));

  if (expectedStatus !== undefined) {
    const expectedStatuses = Array.isArray(expectedStatus) ? expectedStatus : [expectedStatus];
    if (!expectedStatuses.includes(response.status)) {
      throw new Error(`Expected status ${expectedStatuses.join(' or ')}, got ${response.status}: ${JSON.stringify(data)}`);
    }
  }

  if (!response.ok && expectedStatus === undefined) {
    throw new Error(`API request failed: ${response.status} ${JSON.stringify(data)}`);
  }

  return data;
}

/**
 * Skip a test (returns a skipped result)
 */
export function skipTest(name: string, category: string, reason: string, id?: string): TestResult {
  return {
    id: id || `${category}-${name}-${Date.now()}`,
    name,
    category,
    status: 'skipped',
    duration: 0,
    message: reason,
    timestamp: new Date().toISOString(),
  };
}

--- FILE: backend/src/lib/troubleshooter/testRunner.ts ---
import { TestResult, TestSuite, TroubleshooterRunResult, TestContext } from './types';
import { createTestUsers, cleanupTestData, TestUser } from './testData';

interface TestSuiteModule {
  name: string;
  category: string;
  runTests: (context: TestContext) => Promise<TestResult[]>;
}

export class TestRunner {
  private testSuites: TestSuiteModule[] = [];
  private testContext: TestContext | null = null;

  /**
   * Register a test suite
   */
  registerSuite(suite: TestSuiteModule) {
    this.testSuites.push(suite);
  }

  /**
   * Initialize test context (create test users, etc.)
   */
  async initializeContext(): Promise<TestContext> {
    // Clean up any existing test data
    await cleanupTestData();

    // Create test users
    const testUsers = await createTestUsers();

    const context: TestContext = {
      adminToken: testUsers.find(u => u.role === 'admin')!.token,
      managerToken: testUsers.find(u => u.role === 'manager')!.token,
      userToken: testUsers.find(u => u.role === 'user')!.token,
      testData: {
        userIds: testUsers.map(u => u.id),
        clientIds: [],
        projectIds: [],
        timesheetIds: [],
        activityTypeIds: [],
        costCenterIds: [],
      },
    };

    this.testContext = context;
    return context;
  }

  /**
   * Clean up test context
   */
  async cleanupContext(): Promise<void> {
    await cleanupTestData();
    this.testContext = null;
  }

  /**
   * Run all registered test suites
   */
  async runAll(): Promise<TroubleshooterRunResult> {
    const startTime = Date.now();
    const allResults: TestResult[] = [];

    try {
      // Initialize context
      const context = await this.initializeContext();

      // Run each test suite
      for (const suite of this.testSuites) {
        try {
          const suiteResults = await suite.runTests(context);
          allResults.push(...suiteResults);
        } catch (error: any) {
          // If a suite fails to run, add an error result
          allResults.push({
            id: `suite-error-${suite.name}`,
            name: `Suite Error: ${suite.name}`,
            category: suite.category,
            status: 'failed',
            duration: 0,
            message: `Failed to run test suite: ${error.message}`,
            error: {
              message: error.message,
              stack: error.stack,
            },
            timestamp: new Date().toISOString(),
          });
        }
      }

      // Cleanup
      await this.cleanupContext();
    } catch (error: any) {
      // If initialization fails, return error result
      allResults.push({
        id: 'initialization-error',
        name: 'Test Initialization',
        category: 'System',
        status: 'failed',
        duration: 0,
        message: `Failed to initialize tests: ${error.message}`,
        error: {
          message: error.message,
          stack: error.stack,
        },
        timestamp: new Date().toISOString(),
      });
    }

    const duration = Date.now() - startTime;
    const passed = allResults.filter(r => r.status === 'passed').length;
    const failed = allResults.filter(r => r.status === 'failed').length;
    const skipped = allResults.filter(r => r.status === 'skipped').length;

    return {
      success: failed === 0,
      totalTests: allResults.length,
      passed,
      failed,
      skipped,
      duration,
      results: allResults,
      timestamp: new Date().toISOString(),
    };
  }

  /**
   * Run tests for a specific category
   */
  async runCategory(category: string): Promise<TroubleshooterRunResult> {
    const startTime = Date.now();
    const allResults: TestResult[] = [];

    try {
      const context = await this.initializeContext();

      const suites = this.testSuites.filter(s => s.category === category);
      for (const suite of suites) {
        try {
          const suiteResults = await suite.runTests(context);
          allResults.push(...suiteResults);
        } catch (error: any) {
          allResults.push({
            id: `suite-error-${suite.name}`,
            name: `Suite Error: ${suite.name}`,
            category: suite.category,
            status: 'failed',
            duration: 0,
            message: `Failed to run test suite: ${error.message}`,
            error: {
              message: error.message,
              stack: error.stack,
            },
            timestamp: new Date().toISOString(),
          });
        }
      }

      await this.cleanupContext();
    } catch (error: any) {
      allResults.push({
        id: 'initialization-error',
        name: 'Test Initialization',
        category: 'System',
        status: 'failed',
        duration: 0,
        message: `Failed to initialize tests: ${error.message}`,
        error: {
          message: error.message,
          stack: error.stack,
        },
        timestamp: new Date().toISOString(),
      });
    }

    const duration = Date.now() - startTime;
    const passed = allResults.filter(r => r.status === 'passed').length;
    const failed = allResults.filter(r => r.status === 'failed').length;
    const skipped = allResults.filter(r => r.status === 'skipped').length;

    return {
      success: failed === 0,
      totalTests: allResults.length,
      passed,
      failed,
      skipped,
      duration,
      results: allResults,
      timestamp: new Date().toISOString(),
    };
  }

  /**
   * Get list of registered test suites
   */
  getTestSuites(): Array<{ name: string; category: string }> {
    return this.testSuites.map(s => ({ name: s.name, category: s.category }));
  }
}

--- FILE: backend/src/lib/troubleshooter/testSuites/auth.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest, skipTest } from '../testHelpers';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];

  // Test login with invalid credentials
  results.push(
    await runTest(
      'Login with invalid credentials fails',
      'Auth',
      async () => {
        try {
          await apiRequest('/api/auth/login', {
            method: 'POST',
            body: { email: 'invalid@test.com', password: 'wrongpassword' },
            expectedStatus: 401,
          });
        } catch (error: any) {
          if (!error.message.includes('401')) {
            throw error;
          }
        }
      },
      'auth-login-invalid'
    )
  );

  // Test login with valid test credentials (using context tokens means users exist)
  results.push(
    await runTest(
      'Login with valid credentials succeeds',
      'Auth',
      async () => {
        // Use test user credentials (created in testData.ts, email is normalized to lowercase)
        const response = await apiRequest('/api/auth/login', {
          method: 'POST',
          body: { email: 'test_admin@test.com', password: 'TestPassword123!' },
          expectedStatus: 200,
        });
        if (!response.token || !response.user) {
          throw new Error('Login response missing token or user');
        }
      },
      'auth-login-valid'
    )
  );

  // Test get current user with valid token
  results.push(
    await runTest(
      'Get current user with valid token',
      'Auth',
      async () => {
        const response = await apiRequest('/api/auth/me', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!response.id || !response.email) {
          throw new Error('User response missing required fields');
        }
      },
      'auth-me-valid'
    )
  );

  // Test get current user with invalid token
  results.push(
    await runTest(
      'Get current user with invalid token fails',
      'Auth',
      async () => {
        try {
          await apiRequest('/api/auth/me', {
            token: 'invalid-token',
            expectedStatus: 401,
          });
        } catch (error: any) {
          if (!error.message.includes('401')) {
            throw error;
          }
        }
      },
      'auth-me-invalid'
    )
  );

  // Test protected route access
  results.push(
    await runTest(
      'Protected route requires authentication',
      'Auth',
      async () => {
        try {
          await apiRequest('/api/clients', {
            expectedStatus: 401,
          });
        } catch (error: any) {
          if (!error.message.includes('401')) {
            throw error;
          }
        }
      },
      'auth-protected-route'
    )
  );

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/clients.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest } from '../testHelpers';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];
  let createdClientId: string | null = null;

  // Test create client
  results.push(
    await runTest(
      'Create client',
      'CRUD',
      async () => {
        const response = await apiRequest('/api/clients', {
          method: 'POST',
          body: {
            name: `TEST_Client ${Date.now()}`,
            contact_name: 'Test Contact',
            email: 'test@example.com',
            phone: '1234567890',
          },
          token: context.adminToken,
          expectedStatus: 201,
        });
        if (!response.id) {
          throw new Error('Client creation failed - no ID returned');
        }
        createdClientId = response.id;
        context.testData.clientIds.push(response.id);
      },
      'clients-create'
    )
  );

  // Test get all clients
  results.push(
    await runTest(
      'Get all clients',
      'CRUD',
      async () => {
        const response = await apiRequest('/api/clients', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Get clients did not return an array');
        }
      },
      'clients-get-all'
    )
  );

  // Test get single client
  if (createdClientId) {
    results.push(
      await runTest(
        'Get single client',
        'CRUD',
        async () => {
          const response = await apiRequest(`/api/clients/${createdClientId}`, {
            token: context.adminToken,
            expectedStatus: 200,
          });
          if (!response.id || response.id !== createdClientId) {
            throw new Error('Get client returned incorrect client');
          }
        },
        'clients-get-one'
      )
    );
  }

  // Test update client
  if (createdClientId) {
    results.push(
      await runTest(
        'Update client',
        'CRUD',
        async () => {
          const response = await apiRequest(`/api/clients/${createdClientId}`, {
            method: 'PUT',
            body: {
              name: `TEST_Updated Client ${Date.now()}`,
              phone: '9876543210',
            },
            token: context.adminToken,
            expectedStatus: 200,
          });
          if (response.phone !== '9876543210') {
            throw new Error('Client update failed - phone not updated');
          }
        },
        'clients-update'
      )
    );
  }

  // Test delete client (only if created)
  if (createdClientId) {
    results.push(
      await runTest(
        'Delete client',
        'CRUD',
        async () => {
          await apiRequest(`/api/clients/${createdClientId}`, {
            method: 'DELETE',
            token: context.adminToken,
            expectedStatus: 200,
          });
          // Verify deletion
          try {
            await apiRequest(`/api/clients/${createdClientId}`, {
              token: context.adminToken,
              expectedStatus: 404,
            });
          } catch (error: any) {
            if (!error.message.includes('404')) {
              throw new Error('Client was not deleted');
            }
          }
        },
        'clients-delete'
      )
    );
  }

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/dashboard.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest } from '../testHelpers';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];

  // Test dashboard metrics endpoint
  results.push(
    await runTest(
      'Get dashboard metrics',
      'Business Logic',
      async () => {
        const response = await apiRequest('/api/dashboard/metrics', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (typeof response.totalProjects !== 'number') {
          throw new Error('Dashboard metrics missing required fields');
        }
      },
      'dashboard-metrics'
    )
  );

  // Test recent timesheets endpoint
  results.push(
    await runTest(
      'Get recent timesheets',
      'Business Logic',
      async () => {
        const response = await apiRequest('/api/dashboard/recent-timesheets', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Recent timesheets did not return an array');
        }
      },
      'dashboard-recent-timesheets'
    )
  );

  // Test active projects endpoint
  results.push(
    await runTest(
      'Get active projects',
      'Business Logic',
      async () => {
        const response = await apiRequest('/api/dashboard/active-projects', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Active projects did not return an array');
        }
      },
      'dashboard-active-projects'
    )
  );

  // Test quick stats endpoint
  results.push(
    await runTest(
      'Get quick stats',
      'Business Logic',
      async () => {
        const response = await apiRequest('/api/dashboard/quick-stats', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (typeof response.budgetUtilization !== 'number') {
          throw new Error('Quick stats missing required fields');
        }
      },
      'dashboard-quick-stats'
    )
  );

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/email.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest, skipTest } from '../testHelpers';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];

  // Test email configuration endpoint exists (but skip actual test send)
  results.push(
    await runTest(
      'Email settings endpoint accessible',
      'Integration',
      async () => {
        // Just verify the endpoint exists and requires admin
        try {
          await apiRequest('/api/settings/email/test', {
            method: 'POST',
            body: { to: 'test@example.com' },
            token: context.adminToken,
            // Will fail if email not configured, but that's OK for this test
          });
        } catch (error: any) {
          // Any response (even error) means endpoint exists
          // We're just checking it's accessible, not that email works
          if (error.message.includes('Network error')) {
            throw error;
          }
        }
      },
      'email-endpoint'
    )
  );

  // Skip actual email send test (requires SMTP configuration)
  results.push(
    skipTest(
      'Email test send (requires SMTP configuration)',
      'Integration',
      'Skipped: Requires SMTP configuration',
      'email-test-send'
    )
  );

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/health.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest } from '../testHelpers';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];

  // Test health endpoint
  results.push(
    await runTest(
      'Health check endpoint accessible',
      'System',
      async () => {
        const response = await apiRequest('/api/health', { expectedStatus: 200 });
        if (!response.status || response.status !== 'healthy') {
          throw new Error('Health check returned unhealthy status');
        }
      },
      'health-check'
    )
  );

  // Test database connection via health endpoint
  results.push(
    await runTest(
      'Database connection via health endpoint',
      'System',
      async () => {
        const response = await apiRequest('/api/health', { expectedStatus: 200 });
        if (!response.database || !response.database.healthy) {
          throw new Error('Database health check failed');
        }
      },
      'health-database'
    )
  );

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/permissions.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest } from '../testHelpers';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];

  // Test that admin can access protected routes
  results.push(
    await runTest(
      'Admin can access protected routes',
      'Security',
      async () => {
        await apiRequest('/api/users', {
          token: context.adminToken,
          expectedStatus: 200,
        });
      },
      'permissions-admin-access'
    )
  );

  // Test that manager cannot access admin-only routes
  results.push(
    await runTest(
      'Manager cannot access admin-only routes',
      'Security',
      async () => {
        try {
          await apiRequest('/api/users', {
            token: context.managerToken,
            expectedStatus: 403,
          });
        } catch (error: any) {
          if (!error.message.includes('403')) {
            throw error;
          }
        }
      },
      'permissions-manager-restricted'
    )
  );

  // Test that regular user cannot access protected routes
  results.push(
    await runTest(
      'Regular user cannot access protected routes',
      'Security',
      async () => {
        try {
          await apiRequest('/api/users', {
            token: context.userToken,
            expectedStatus: 403,
          });
        } catch (error: any) {
          if (!error.message.includes('403')) {
            throw error;
          }
        }
      },
      'permissions-user-restricted'
    )
  );

  // Test permission-based access control
  results.push(
    await runTest(
      'Permission-based access control works',
      'Security',
      async () => {
        // Test that admin can manage clients (has can_manage_clients permission)
        await apiRequest('/api/clients', {
          method: 'POST',
          body: {
            name: `TEST_Permission Test ${Date.now()}`,
          },
          token: context.adminToken,
          expectedStatus: 201,
        });
      },
      'permissions-permission-check'
    )
  );

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/projects.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest } from '../testHelpers';
import { createTestClient } from '../testData';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];
  let clientId: string | null = null;
  let createdProjectId: string | null = null;

  // Create a test client first
  try {
    clientId = await createTestClient(`TEST_Project Client ${Date.now()}`);
    context.testData.clientIds.push(clientId);
  } catch (error: any) {
    results.push({
      id: 'projects-setup',
      name: 'Setup test client for projects',
      category: 'CRUD',
      status: 'failed',
      duration: 0,
      message: `Failed to create test client: ${error.message}`,
      error: { message: error.message },
      timestamp: new Date().toISOString(),
    });
    return results;
  }

  // Test create project
  results.push(
    await runTest(
      'Create project',
      'CRUD',
      async () => {
        const response = await apiRequest('/api/projects', {
          method: 'POST',
          body: {
            name: `TEST_Project ${Date.now()}`,
            client_id: clientId,
            status: 'in-progress',
            budget: 10000,
          },
          token: context.adminToken,
          expectedStatus: 201,
        });
        if (!response.id) {
          throw new Error('Project creation failed - no ID returned');
        }
        createdProjectId = response.id;
        context.testData.projectIds.push(response.id);
      },
      'projects-create'
    )
  );

  // Test get all projects
  results.push(
    await runTest(
      'Get all projects',
      'CRUD',
      async () => {
        const response = await apiRequest('/api/projects', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Get projects did not return an array');
        }
      },
      'projects-get-all'
    )
  );

  // Test get single project
  if (createdProjectId) {
    results.push(
      await runTest(
        'Get single project',
        'CRUD',
        async () => {
          const response = await apiRequest(`/api/projects/${createdProjectId}`, {
            token: context.adminToken,
            expectedStatus: 200,
          });
          if (!response.id || response.id !== createdProjectId) {
            throw new Error('Get project returned incorrect project');
          }
        },
        'projects-get-one'
      )
    );
  }

  // Test update project
  if (createdProjectId) {
    results.push(
      await runTest(
        'Update project',
        'CRUD',
        async () => {
          const response = await apiRequest(`/api/projects/${createdProjectId}`, {
            method: 'PUT',
            body: {
              status: 'completed',
              budget: 15000,
            },
            token: context.adminToken,
            expectedStatus: 200,
          });
          if (response.status !== 'completed') {
            throw new Error('Project update failed - status not updated');
          }
        },
        'projects-update'
      )
    );
  }

  // Test delete project
  if (createdProjectId) {
    results.push(
      await runTest(
        'Delete project',
        'CRUD',
        async () => {
          await apiRequest(`/api/projects/${createdProjectId}`, {
            method: 'DELETE',
            token: context.adminToken,
            expectedStatus: 200,
          });
        },
        'projects-delete'
      )
    );
  }

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/settings.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest } from '../testHelpers';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];

  // Test get all settings
  results.push(
    await runTest(
      'Get all settings',
      'Configuration',
      async () => {
        const response = await apiRequest('/api/settings', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (typeof response !== 'object') {
          throw new Error('Get settings did not return an object');
        }
      },
      'settings-get-all'
    )
  );

  // Test get specific setting
  results.push(
    await runTest(
      'Get specific setting',
      'Configuration',
      async () => {
        // Try to get a common setting (might not exist, that's OK)
        try {
          await apiRequest('/api/settings/company_name', {
            token: context.adminToken,
            expectedStatus: 200,
          });
        } catch (error: any) {
          // 404 is acceptable if setting doesn't exist
          if (!error.message.includes('404')) {
            throw error;
          }
        }
      },
      'settings-get-one'
    )
  );

  // Test update setting (admin only)
  results.push(
    await runTest(
      'Update setting',
      'Configuration',
      async () => {
        const testKey = `TEST_setting_${Date.now()}`;
        const testValue = 'test-value';
        
        const response = await apiRequest(`/api/settings/${testKey}`, {
          method: 'PUT',
          body: {
            value: testValue,
            global: true,
          },
          token: context.adminToken,
          expectedStatus: 200,
        });
        
        // Verify update
        const getResponse = await apiRequest(`/api/settings/${testKey}`, {
          token: context.adminToken,
          expectedStatus: 200,
        });
        
        if (getResponse.value !== testValue) {
          throw new Error('Setting update failed - value not updated correctly');
        }
      },
      'settings-update'
    )
  );

  // Test that non-admin cannot update global settings
  results.push(
    await runTest(
      'Non-admin cannot update global settings',
      'Configuration',
      async () => {
        try {
          await apiRequest('/api/settings/test_setting', {
            method: 'PUT',
            body: {
              value: 'test',
              global: true,
            },
            token: context.userToken,
            expectedStatus: 403,
          });
        } catch (error: any) {
          if (!error.message.includes('403')) {
            throw error;
          }
        }
      },
      'settings-permission-check'
    )
  );

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/timesheets.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest, skipTest } from '../testHelpers';
import { createTestClient, createTestProject, createTestActivityType, createTestCostCenter } from '../testData';
import { query } from '../../../db';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];
  
  // Check if any timesheets exist - if not, skip all timesheet tests
  try {
    const existingTimesheets = await query('SELECT COUNT(*) as count FROM timesheets LIMIT 1');
    const hasTimesheets = parseInt(existingTimesheets.rows[0]?.count || '0') > 0;
    
    if (!hasTimesheets) {
      results.push(
        skipTest(
          'Timesheet tests',
          'CRUD',
          'Skipped: No timesheets exist in database. Create timesheets to enable these tests.',
          'timesheets-skip-no-data'
        )
      );
      return results;
    }
  } catch (error: any) {
    // If we can't check, skip the tests
    results.push(
      skipTest(
        'Timesheet tests',
        'CRUD',
        `Skipped: Could not check for existing timesheets: ${error.message}`,
        'timesheets-skip-check-failed'
      )
    );
    return results;
  }

  let clientId: string | null = null;
  let projectId: string | null = null;
  let activityTypeId: string | null = null;
  let costCenterId: string | null = null;
  let createdTimesheetId: string | null = null;

  // Setup test data (only if we need to create a test timesheet)
  try {
    clientId = await createTestClient(`TEST_Timesheet Client ${Date.now()}`);
    context.testData.clientIds.push(clientId);
    projectId = await createTestProject(clientId, `TEST_Timesheet Project ${Date.now()}`);
    context.testData.projectIds.push(projectId);
    activityTypeId = await createTestActivityType(`TEST_Timesheet Activity ${Date.now()}`);
    context.testData.activityTypeIds.push(activityTypeId);
    // Cost center code must be max 20 chars - use shorter timestamp
    const timestamp = Date.now().toString().slice(-8);
    costCenterId = await createTestCostCenter(`TEST_TCC${timestamp}`, `TEST_Timesheet Cost Center ${Date.now()}`);
    context.testData.costCenterIds.push(costCenterId);
  } catch (error: any) {
    results.push({
      id: 'timesheets-setup',
      name: 'Setup test data for timesheets',
      category: 'CRUD',
      status: 'failed',
      duration: 0,
      message: `Failed to create test data: ${error.message}`,
      error: { message: error.message },
      timestamp: new Date().toISOString(),
    });
    return results;
  }

  // Test create timesheet
  results.push(
    await runTest(
      'Create timesheet',
      'CRUD',
      async () => {
        const response = await apiRequest('/api/timesheets', {
          method: 'POST',
          body: {
            project_id: projectId,
            client_id: clientId,
            activity_type_id: activityTypeId,
            cost_center_id: costCenterId,
            date: new Date().toISOString().split('T')[0],
            hours: 8,
            notes: 'TEST_Timesheet entry for testing',
          },
          token: context.adminToken,
          expectedStatus: 201,
        });
        if (!response.id) {
          throw new Error('Timesheet creation failed - no ID returned');
        }
        createdTimesheetId = response.id;
        context.testData.timesheetIds.push(response.id);
      },
      'timesheets-create'
    )
  );

  // Test get all timesheets
  results.push(
    await runTest(
      'Get all timesheets',
      'CRUD',
      async () => {
        const response = await apiRequest('/api/timesheets', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Get timesheets did not return an array');
        }
      },
      'timesheets-get-all'
    )
  );

  // Test get single timesheet
  if (createdTimesheetId) {
    results.push(
      await runTest(
        'Get single timesheet',
        'CRUD',
        async () => {
          const response = await apiRequest(`/api/timesheets/${createdTimesheetId}`, {
            token: context.adminToken,
            expectedStatus: 200,
          });
          if (!response.id || response.id !== createdTimesheetId) {
            throw new Error('Get timesheet returned incorrect timesheet');
          }
        },
        'timesheets-get-one'
      )
    );
  }

  // Test update timesheet
  if (createdTimesheetId) {
    results.push(
      await runTest(
        'Update timesheet',
        'CRUD',
        async () => {
          const response = await apiRequest(`/api/timesheets/${createdTimesheetId}`, {
            method: 'PUT',
            body: {
              hours: 9,
              notes: 'TEST_Updated timesheet entry',
            },
            token: context.adminToken,
            expectedStatus: 200,
          });
          if (parseFloat(response.hours) !== 9) {
            throw new Error('Timesheet update failed - hours not updated');
          }
        },
        'timesheets-update'
      )
    );
  }

  // Test delete timesheet
  if (createdTimesheetId) {
    results.push(
      await runTest(
        'Delete timesheet',
        'CRUD',
        async () => {
          await apiRequest(`/api/timesheets/${createdTimesheetId}`, {
            method: 'DELETE',
            token: context.adminToken,
            expectedStatus: 200,
          });
        },
        'timesheets-delete'
      )
    );
  }

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/users.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest } from '../testHelpers';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];
  let createdUserId: string | null = null;

  // Test get all users (admin only)
  results.push(
    await runTest(
      'Get all users',
      'CRUD',
      async () => {
        const response = await apiRequest('/api/users', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Get users did not return an array');
        }
      },
      'users-get-all'
    )
  );

  // Test create user
  results.push(
    await runTest(
      'Create user',
      'CRUD',
      async () => {
        const response = await apiRequest('/api/users', {
          method: 'POST',
          body: {
            email: `TEST_user_${Date.now()}@test.com`,
            password: 'TestPassword123!',
            name: 'Test User',
            role: 'user',
          },
          token: context.adminToken,
          expectedStatus: 201,
        });
        if (!response.id) {
          throw new Error('User creation failed - no ID returned');
        }
        createdUserId = response.id;
        context.testData.userIds.push(response.id);
      },
      'users-create'
    )
  );

  // Test get single user
  if (createdUserId) {
    results.push(
      await runTest(
        'Get single user',
        'CRUD',
        async () => {
          const response = await apiRequest(`/api/users/${createdUserId}`, {
            token: context.adminToken,
            expectedStatus: 200,
          });
          if (!response.id || response.id !== createdUserId) {
            throw new Error('Get user returned incorrect user');
          }
        },
        'users-get-one'
      )
    );
  }

  // Test update user
  if (createdUserId) {
    results.push(
      await runTest(
        'Update user',
        'CRUD',
        async () => {
          const response = await apiRequest(`/api/users/${createdUserId}`, {
            method: 'PUT',
            body: {
              name: 'Updated Test User',
              role: 'manager',
            },
            token: context.adminToken,
            expectedStatus: 200,
          });
          if (response.name !== 'Updated Test User') {
            throw new Error('User update failed - name not updated');
          }
        },
        'users-update'
      )
    );
  }

  // Test delete user
  if (createdUserId) {
    results.push(
      await runTest(
        'Delete user',
        'CRUD',
        async () => {
          await apiRequest(`/api/users/${createdUserId}`, {
            method: 'DELETE',
            token: context.adminToken,
            expectedStatus: 200,
          });
        },
        'users-delete'
      )
    );
  }

  return results;
}

--- FILE: backend/src/lib/troubleshooter/testSuites/xero.test.ts ---
import { TestResult, TestContext } from '../types';
import { runTest, apiRequest, skipTest } from '../testHelpers';
import { query } from '../../../db';
import { createTestClient, createTestProject } from '../testData';

export async function runTests(context: TestContext): Promise<TestResult[]> {
  const results: TestResult[] = [];

  // Test get Xero status
  results.push(
    await runTest(
      'Get Xero connection status',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/status', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (typeof response.connected !== 'boolean') {
          throw new Error('Xero status response missing connected field');
        }
      },
      'xero-status'
    )
  );

  // Test Xero credentials configuration
  results.push(
    await runTest(
      'Xero credentials configured',
      'Integration',
      async () => {
        const credentialsResult = await query(
          `SELECT key, value FROM settings 
           WHERE key IN ('xero_client_id', 'xero_client_secret') 
           AND user_id IS NULL`
        );
        const hasClientId = credentialsResult.rows.some(r => r.key === 'xero_client_id' && r.value);
        const hasClientSecret = credentialsResult.rows.some(r => r.key === 'xero_client_secret' && r.value);
        
        if (!hasClientId || !hasClientSecret) {
          throw new Error('Xero credentials not configured. Please add Client ID and Client Secret in Settings ‚Üí Integrations.');
        }
      },
      'xero-credentials-configured'
    )
  );

  // Test Xero token exists and is valid
  results.push(
    await runTest(
      'Xero token exists',
      'Integration',
      async () => {
        const tokenResult = await query(
          `SELECT tenant_id, tenant_name, expires_at, created_at 
           FROM xero_tokens 
           ORDER BY created_at DESC 
           LIMIT 1`
        );
        
        if (tokenResult.rows.length === 0) {
          throw new Error('Xero token not found. Please connect to Xero in Settings ‚Üí Integrations.');
        }
        
        const token = tokenResult.rows[0];
        const isExpired = new Date(token.expires_at) < new Date();
        
        if (isExpired) {
          throw new Error(`Xero token expired on ${new Date(token.expires_at).toISOString()}. Please reconnect to Xero.`);
        }
      },
      'xero-token-valid'
    )
  );

  // Test get Xero auth URL (if configured)
  results.push(
    await runTest(
      'Get Xero auth URL',
      'Integration',
      async () => {
        try {
          const response = await apiRequest('/api/xero/auth/url', {
            token: context.adminToken,
            expectedStatus: 200,
          });
          // Response should indicate if Xero is configured
          if (typeof response.configured !== 'boolean') {
            throw new Error('Xero auth URL response missing configured field');
          }
        } catch (error: any) {
          // It's OK if Xero is not configured
          if (!error.message.includes('200')) {
            throw error;
          }
        }
      },
      'xero-auth-url'
    )
  );

  // Test Xero sync capability (check if connected)
  results.push(
    await runTest(
      'Xero sync capability',
      'Integration',
      async () => {
        const statusResponse = await apiRequest('/api/xero/status', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        
        if (!statusResponse.connected) {
          throw new Error('Xero is not connected. Connect to Xero in Settings ‚Üí Integrations to enable sync.');
        }
        
        if (!statusResponse.configured) {
          throw new Error('Xero credentials are not configured. Add Client ID and Client Secret in Settings ‚Üí Integrations.');
        }
      },
      'xero-sync-capability'
    )
  );

  // Test Xero invoices endpoint
  results.push(
    await runTest(
      'Get Xero invoices',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/invoices', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero invoices endpoint should return an array');
        }
      },
      'xero-invoices-get'
    )
  );

  // Test Xero quotes endpoint
  results.push(
    await runTest(
      'Get Xero quotes',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/quotes', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero quotes endpoint should return an array');
        }
      },
      'xero-quotes-get'
    )
  );

  // Test Xero payments endpoint
  results.push(
    await runTest(
      'Get Xero payments',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/payments', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero payments endpoint should return an array');
        }
      },
      'xero-payments-get'
    )
  );

  // Test Xero purchase orders endpoint
  results.push(
    await runTest(
      'Get Xero purchase orders',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/purchase-orders', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero purchase orders endpoint should return an array');
        }
      },
      'xero-purchase-orders-get'
    )
  );

  // Test Xero bills endpoint
  results.push(
    await runTest(
      'Get Xero bills',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/bills', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero bills endpoint should return an array');
        }
      },
      'xero-bills-get'
    )
  );

  // Test Xero expenses endpoint
  results.push(
    await runTest(
      'Get Xero expenses',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/expenses', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero expenses endpoint should return an array');
        }
      },
      'xero-expenses-get'
    )
  );

  // Test Xero credit notes endpoint
  results.push(
    await runTest(
      'Get Xero credit notes',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/credit-notes', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero credit notes endpoint should return an array');
        }
      },
      'xero-credit-notes-get'
    )
  );

  // Test Xero items endpoint
  results.push(
    await runTest(
      'Get Xero items',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/items', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero items endpoint should return an array');
        }
      },
      'xero-items-get'
    )
  );

  // Test Xero bank transactions endpoint
  results.push(
    await runTest(
      'Get Xero bank transactions',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/bank-transactions', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero bank transactions endpoint should return an array');
        }
      },
      'xero-bank-transactions-get'
    )
  );

  // Test Xero summary endpoint
  results.push(
    await runTest(
      'Get Xero summary',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/summary', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (typeof response !== 'object' || response === null) {
          throw new Error('Xero summary endpoint should return an object');
        }
      },
      'xero-summary-get'
    )
  );

  // Test Xero reports endpoints
  results.push(
    await runTest(
      'Get Xero profit-loss report endpoint',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/reports/profit-loss', {
          token: context.adminToken,
          expectedStatus: [200, 400, 404], // 400/404 if not connected or no data
        });
        // Should return an object or error message
        if (typeof response !== 'object') {
          throw new Error('Xero profit-loss report should return an object or error');
        }
      },
      'xero-reports-profit-loss'
    )
  );

  results.push(
    await runTest(
      'Get Xero balance-sheet report endpoint',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/reports/balance-sheet', {
          token: context.adminToken,
          expectedStatus: [200, 400, 404],
        });
        if (typeof response !== 'object') {
          throw new Error('Xero balance-sheet report should return an object or error');
        }
      },
      'xero-reports-balance-sheet'
    )
  );

  results.push(
    await runTest(
      'Get Xero cash-flow report endpoint',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/reports/cash-flow', {
          token: context.adminToken,
          expectedStatus: [200, 400, 404],
        });
        if (typeof response !== 'object') {
          throw new Error('Xero cash-flow report should return an object or error');
        }
      },
      'xero-reports-cash-flow'
    )
  );

  results.push(
    await runTest(
      'Get Xero aged-receivables report endpoint',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/reports/aged-receivables', {
          token: context.adminToken,
          expectedStatus: [200, 400, 404],
        });
        if (typeof response !== 'object') {
          throw new Error('Xero aged-receivables report should return an object or error');
        }
      },
      'xero-reports-aged-receivables'
    )
  );

  results.push(
    await runTest(
      'Get Xero aged-payables report endpoint',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/reports/aged-payables', {
          token: context.adminToken,
          expectedStatus: [200, 400, 404],
        });
        if (typeof response !== 'object') {
          throw new Error('Xero aged-payables report should return an object or error');
        }
      },
      'xero-reports-aged-payables'
    )
  );

  // Test Xero reminders endpoints
  results.push(
    await runTest(
      'Get Xero reminders schedule',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/reminders/schedule', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (typeof response !== 'object') {
          throw new Error('Xero reminders schedule should return an object');
        }
      },
      'xero-reminders-schedule-get'
    )
  );

  results.push(
    await runTest(
      'Get Xero reminders history',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/reminders/history', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero reminders history should return an array');
        }
      },
      'xero-reminders-history-get'
    )
  );

  // Test Xero webhooks endpoints
  results.push(
    await runTest(
      'Get Xero webhooks status',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/webhooks/status', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (typeof response !== 'object') {
          throw new Error('Xero webhooks status should return an object');
        }
      },
      'xero-webhooks-status-get'
    )
  );

  results.push(
    await runTest(
      'Get Xero webhooks events',
      'Integration',
      async () => {
        const response = await apiRequest('/api/xero/webhooks/events', {
          token: context.adminToken,
          expectedStatus: 200,
        });
        if (!Array.isArray(response)) {
          throw new Error('Xero webhooks events should return an array');
        }
      },
      'xero-webhooks-events-get'
    )
  );

  // Test purchase order project linking (if we have a purchase order)
  results.push(
    await runTest(
      'Purchase order project linking endpoint accessible',
      'Integration',
      async () => {
        // First check if we have any purchase orders
        const poResult = await query('SELECT id FROM xero_purchase_orders LIMIT 1');
        if (poResult.rows.length === 0) {
          // Skip if no purchase orders exist
          return;
        }
        
        const poId = poResult.rows[0].id;
        // Create a test project to link
        const clientId = await createTestClient();
        const projectId = await createTestProject(clientId);
        
        // Test linking (PUT endpoint)
        const response = await apiRequest(`/api/xero/purchase-orders/${poId}`, {
          token: context.adminToken,
          method: 'PUT',
          body: { project_id: projectId },
          expectedStatus: 200,
        });
        
        if (typeof response !== 'object') {
          throw new Error('Purchase order update should return an object');
        }
        
        // Clean up test project
        await query('DELETE FROM projects WHERE id = $1', [projectId]);
        await query('DELETE FROM clients WHERE id = $1', [clientId]);
      },
      'xero-purchase-order-link-project'
    )
  );

  // Test purchase order by project endpoint
  results.push(
    await runTest(
      'Get purchase orders by project',
      'Integration',
      async () => {
        // Create a test project
        const clientId = await createTestClient();
        const projectId = await createTestProject(clientId);
        
        const response = await apiRequest(`/api/xero/purchase-orders/project/${projectId}`, {
          token: context.adminToken,
          expectedStatus: 200,
        });
        
        if (!Array.isArray(response)) {
          throw new Error('Purchase orders by project should return an array');
        }
        
        // Clean up
        await query('DELETE FROM projects WHERE id = $1', [projectId]);
        await query('DELETE FROM clients WHERE id = $1', [clientId]);
      },
      'xero-purchase-orders-by-project'
    )
  );

  // Test Xero database tables exist
  results.push(
    await runTest(
      'Xero database tables exist',
      'Integration',
      async () => {
        const tables = [
          'xero_invoices',
          'xero_quotes',
          'xero_purchase_orders',
          'xero_purchase_order_line_items',
          'xero_bills',
          'xero_expenses',
          'xero_payments',
          'bank_transactions',
          'xero_credit_notes'
        ];
        
        for (const tableName of tables) {
          const result = await query(
            `SELECT EXISTS (
              SELECT FROM information_schema.tables 
              WHERE table_schema = 'public' 
              AND table_name = $1
            )`,
            [tableName]
          );
          
          if (!result.rows[0].exists) {
            throw new Error(`Xero table ${tableName} does not exist. Run migrations to create it.`);
          }
        }
      },
      'xero-tables-exist'
    )
  );

  // Note: We skip actual Xero API calls (sync, create operations, etc.) since they require
  // actual Xero credentials and could affect real data
  results.push(
    skipTest(
      'Xero sync (requires actual Xero connection)',
      'Integration',
      'Skipped: Requires actual Xero credentials',
      'xero-sync'
    )
  );

  results.push(
    skipTest(
      'Xero invoice creation (requires actual Xero connection)',
      'Integration',
      'Skipped: Requires actual Xero credentials',
      'xero-invoices-create'
    )
  );

  results.push(
    skipTest(
      'Xero purchase order creation (requires actual Xero connection)',
      'Integration',
      'Skipped: Requires actual Xero credentials',
      'xero-purchase-orders-create'
    )
  );

  results.push(
    skipTest(
      'Xero bill creation (requires actual Xero connection)',
      'Integration',
      'Skipped: Requires actual Xero credentials',
      'xero-bills-create'
    )
  );

  results.push(
    skipTest(
      'Xero expense creation (requires actual Xero connection)',
      'Integration',
      'Skipped: Requires actual Xero credentials',
      'xero-expenses-create'
    )
  );

  results.push(
    skipTest(
      'Xero credit note creation (requires actual Xero connection)',
      'Integration',
      'Skipped: Requires actual Xero credentials',
      'xero-credit-notes-create'
    )
  );

  results.push(
    skipTest(
      'Xero items sync (requires actual Xero connection)',
      'Integration',
      'Skipped: Requires actual Xero credentials',
      'xero-items-sync'
    )
  );

  results.push(
    skipTest(
      'Xero bank transactions import (requires actual Xero connection)',
      'Integration',
      'Skipped: Requires actual Xero credentials',
      'xero-bank-transactions-import'
    )
  );

  return results;
}

--- FILE: backend/src/lib/troubleshooter/types.ts ---
export interface TestResult {
  id: string;
  name: string;
  category: string;
  status: 'passed' | 'failed' | 'skipped';
  duration: number;
  message: string;
  error?: {
    message: string;
    stack?: string;
    details?: any;
  };
  timestamp: string;
}

export interface TestSuite {
  name: string;
  category: string;
  tests: TestFunction[];
}

export type TestFunction = () => Promise<TestResult>;

export interface TestContext {
  adminToken: string;
  managerToken: string;
  userToken: string;
  testData: {
    userIds: string[];
    clientIds: string[];
    projectIds: string[];
    timesheetIds: string[];
    activityTypeIds: string[];
    costCenterIds: string[];
  };
}

export interface DiscoveredRoute {
  method: string;
  path: string;
  file: string;
  middleware: string[];
}

export interface TroubleshooterRunResult {
  success: boolean;
  totalTests: number;
  passed: number;
  failed: number;
  skipped: number;
  duration: number;
  results: TestResult[];
  timestamp: string;
}

--- FILE: backend/src/lib/utils/stringUtils.ts ---
/**
 * String utility functions for fuzzy matching
 */
import { distance } from 'fastest-levenshtein';

/**
 * Calculate fuzzy match score between two strings (0-1)
 * Uses Levenshtein distance
 */
export function fuzzyMatch(str1: string, str2: string): number {
  if (!str1 || !str2) return 0;
  
  const s1 = str1.toLowerCase().trim();
  const s2 = str2.toLowerCase().trim();
  
  if (s1 === s2) return 1.0;
  
  const maxLength = Math.max(s1.length, s2.length);
  if (maxLength === 0) return 1.0;
  
  const editDistance = distance(s1, s2);
  const similarity = 1 - (editDistance / maxLength);
  
  return Math.max(0, similarity);
}

/**
 * Normalize string for comparison (remove special chars, lowercase)
 */
export function normalizeString(str: string): string {
  return str
    .toLowerCase()
    .replace(/[^a-z0-9]/g, '')
    .trim();
}

/**
 * Check if string contains all words from another string
 */
export function containsWords(text: string, searchWords: string): boolean {
  const textWords = normalizeString(text).split(/\s+/);
  const searchWordsList = normalizeString(searchWords).split(/\s+/);
  
  return searchWordsList.every(word => 
    textWords.some(textWord => textWord.includes(word) || word.includes(textWord))
  );
}
--- FILE: backend/src/lib/xero/auditTrail.ts ---
import { query } from '../../db';

/**
 * Wraps Xero API calls with audit trail logging
 * Every call to XeroLib integration library should be wrapped with this function
 * 
 * @param entityType - Type of entity being synced (e.g., 'invoice', 'purchase_order')
 * @param entityId - UUID of the entity in the local database
 * @param apiCall - Async function that makes the Xero API call
 * @returns The result of the API call
 */
export async function withAuditTrail<T>(
  entityType: string,
  entityId: string,
  apiCall: () => Promise<{ response: Response; data?: any }>
): Promise<T> {
  let requestPayload: any = null;
  let responsePayload: any = null;
  let statusCode: number | null = null;
  let errorMessage: string | null = null;

  try {
    // Execute the API call
    const result = await apiCall();
    
    // Extract response details
    const response = result.response;
    statusCode = response.status;
    responsePayload = result.data || {};

    // Log successful sync
    await logSyncAttempt(
      entityType,
      entityId,
      requestPayload,
      responsePayload,
      statusCode,
      errorMessage
    );

    return result.data as T;
  } catch (error: any) {
    // Extract error details
    errorMessage = error.message || 'Unknown error';
    statusCode = error.statusCode || error.status || 500;

    // Try to extract response if available
    if (error.response) {
      try {
        responsePayload = await error.response.json();
      } catch {
        responsePayload = { error: errorMessage };
      }
      statusCode = error.response.status || statusCode;
    } else {
      responsePayload = { error: errorMessage };
    }

    // Log failed sync
    await logSyncAttempt(
      entityType,
      entityId,
      requestPayload,
      responsePayload,
      statusCode,
      errorMessage
    );

    // Re-throw the error
    throw error;
  }
}

/**
 * Internal function to log sync attempts to sync_logs table
 */
async function logSyncAttempt(
  entityType: string,
  entityId: string,
  requestPayload: any,
  responsePayload: any,
  statusCode: number | null,
  errorMessage: string | null = null
) {
  try {
    await query(
      `INSERT INTO sync_logs (entity_type, entity_id, request_payload, response_payload, status_code, error_message, created_at)
       VALUES ($1, $2, $3, $4, $5, $6, CURRENT_TIMESTAMP)`,
      [
        entityType,
        entityId,
        requestPayload ? JSON.stringify(requestPayload) : null,
        responsePayload ? JSON.stringify(responsePayload) : null,
        statusCode,
        errorMessage,
      ]
    );
  } catch (error) {
    console.error('Failed to log sync attempt:', error);
    // Don't throw - logging failures shouldn't break the sync
  }
}

// Type for Response (matching fetch Response)
interface Response {
  status: number;
  ok: boolean;
  json(): Promise<any>;
}
--- FILE: backend/src/lib/xero/auth.ts ---
import { query } from '../../db';
import { env } from '../../config/env';

/**
 * Get Xero credentials from settings or environment variables
 */
export async function getXeroCredentials() {
  // First try database settings
  const clientIdResult = await query(
    `SELECT value FROM settings WHERE key = 'xero_client_id' AND user_id IS NULL`
  );
  const clientSecretResult = await query(
    `SELECT value FROM settings WHERE key = 'xero_client_secret' AND user_id IS NULL`
  );
  const redirectUriResult = await query(
    `SELECT value FROM settings WHERE key = 'xero_redirect_uri' AND user_id IS NULL`
  );
  
  const clientIdFromDb = clientIdResult.rows[0]?.value;
  const clientSecretFromDb = clientSecretResult.rows[0]?.value;
  const clientId = clientIdFromDb || env.XERO_CLIENT_ID;
  const clientSecret = clientSecretFromDb || env.XERO_CLIENT_SECRET;
  
  // Construct redirect URI
  const savedRedirectUri = redirectUriResult.rows[0]?.value;
  let redirectUri = savedRedirectUri || env.XERO_REDIRECT_URI;
  
  if (!redirectUri || redirectUri.trim() === '') {
    const frontendUrl = env.FRONTEND_URL;
    if (frontendUrl && !frontendUrl.includes('localhost')) {
      redirectUri = `${frontendUrl}/api/xero/callback`;
    } else {
      const backendUrl = env.BACKEND_URL || 'http://localhost:3001';
      redirectUri = `${backendUrl}/api/xero/callback`;
    }
  }
  
  return { clientId, clientSecret, redirectUri };
}

/**
 * Get a valid Xero access token, refreshing if necessary
 * This is a shared function used by both routes and workers
 */
export async function getValidAccessToken(): Promise<{ accessToken: string; tenantId: string } | null> {
  const tokenResult = await query('SELECT * FROM xero_tokens ORDER BY created_at DESC LIMIT 1');
  if (tokenResult.rows.length === 0) {
    return null;
  }

  const token = tokenResult.rows[0];
  const expiresAt = new Date(token.expires_at);
  
  // If token is expired, try to refresh
  if (expiresAt < new Date()) {
    const { clientId, clientSecret } = await getXeroCredentials();
    
    if (!clientId || !clientSecret || !token.refresh_token) {
      return null;
    }

    try {
      const refreshResponse = await fetch('https://identity.xero.com/connect/token', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/x-www-form-urlencoded',
          'Authorization': 'Basic ' + Buffer.from(`${clientId}:${clientSecret}`).toString('base64')
        },
        body: new URLSearchParams({
          grant_type: 'refresh_token',
          refresh_token: token.refresh_token
        })
      });

      if (!refreshResponse.ok) {
        const errorText = await refreshResponse.text();
        let errorData: any = {};
        try {
          errorData = JSON.parse(errorText);
        } catch {
          errorData = { error: errorText };
        }
        
        console.error('Token refresh failed:', {
          status: refreshResponse.status,
          error: errorData.error || errorData.error_description || 'Unknown error',
          details: errorData
        });
        
        // If refresh token is invalid/expired, clear tokens so user can reconnect
        if (errorData.error === 'invalid_grant' || refreshResponse.status === 401) {
          console.warn('[Xero] Refresh token expired or invalid. Clearing tokens.');
          await query('DELETE FROM xero_tokens WHERE id = $1', [token.id]);
        }
        
        return null;
      }

      interface RefreshTokenResponse {
        access_token: string;
        refresh_token: string; // Xero uses rotating refresh tokens - this is the NEW token
        expires_in: number;
      }

      const newTokens = await refreshResponse.json() as RefreshTokenResponse;
      const newExpiresAt = new Date(Date.now() + newTokens.expires_in * 1000);

      // IMPORTANT: Xero uses rotating refresh tokens
      // The refresh_token in the response is a NEW token that must be used for the next refresh
      // We MUST update the refresh_token in the database
      await query(
        `UPDATE xero_tokens SET access_token = $1, refresh_token = $2, expires_at = $3, updated_at = CURRENT_TIMESTAMP WHERE id = $4`,
        [newTokens.access_token, newTokens.refresh_token, newExpiresAt, token.id]
      );

      console.log('[Xero] Token refreshed successfully. New refresh token stored (rotating tokens).');
      return { accessToken: newTokens.access_token, tenantId: token.tenant_id };
    } catch (e) {
      console.error('Token refresh error:', e);
      return null;
    }
  }

  return { accessToken: token.access_token, tenantId: token.tenant_id };
}
--- FILE: backend/src/lib/xero/bankTransactions.ts ---
import { query } from '../../db';
import { fetchWithRateLimit } from './rateLimiter';
import { parseXeroError, getErrorMessage } from './errorHandler';

export interface BankTransaction {
  id: string;
  xero_bank_transaction_id?: string;
  bank_account_code?: string;
  bank_account_name?: string;
  date: string;
  amount: number;
  type: 'RECEIVE' | 'SPEND';
  description?: string;
  reference?: string;
  contact_id?: string;
  reconciled: boolean;
  payment_id?: string;
}

/**
 * Import bank transactions from Xero
 */
export async function importBankTransactions(
  tokenData: { accessToken: string; tenantId: string },
  dateFrom?: string,
  dateTo?: string
): Promise<number> {
  try {
    let url = 'https://api.xero.com/api.xro/2.0/BankTransactions';
    const params = new URLSearchParams();
    
    if (dateFrom) {
      params.append('where', `Date >= DateTime(${dateFrom})`);
    }
    if (dateTo) {
      const whereClause = dateFrom 
        ? `Date >= DateTime(${dateFrom}) AND Date <= DateTime(${dateTo})`
        : `Date <= DateTime(${dateTo})`;
      params.append('where', whereClause);
    }
    
    if (params.toString()) {
      url += '?' + params.toString();
    }

    const response = await fetchWithRateLimit(url, {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json',
      },
    });

    if (!response.ok) {
      const errorText = await response.text();
      console.error('Xero bank transactions fetch failed:', errorText);
      return 0;
    }

    interface XeroBankTransactionsResponse {
      BankTransactions: Array<{
        BankTransactionID: string;
        Type: string;
        Contact?: { ContactID: string };
        Date: string;
        BankAccount: { Code: string; Name: string };
        LineItems: Array<{ Description: string; LineAmount: number }>;
        Reference?: string;
      }>;
    }

    const data = await response.json() as XeroBankTransactionsResponse;
    const transactions = data.BankTransactions || [];
    let imported = 0;

    for (const txn of transactions) {
      const amount = Math.abs(txn.LineItems.reduce((sum, item) => sum + (item.LineAmount || 0), 0));
      const description = txn.LineItems.map(item => item.Description).join(', ');

      // Check if transaction already exists
      const existing = await query(
        'SELECT id FROM bank_transactions WHERE xero_bank_transaction_id = $1',
        [txn.BankTransactionID]
      );

      if (existing.rows.length === 0) {
        // Look up client by Xero contact ID
        let clientId = null;
        if (txn.Contact?.ContactID) {
          const clientResult = await query(
            'SELECT id FROM clients WHERE xero_contact_id = $1 LIMIT 1',
            [txn.Contact.ContactID]
          );
          if (clientResult.rows.length > 0) {
            clientId = clientResult.rows[0].id;
          }
        }

        await query(
          `INSERT INTO bank_transactions (
            xero_bank_transaction_id, bank_account_code, bank_account_name,
            date, amount, type, description, reference, contact_id, synced_at
          )
          VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, CURRENT_TIMESTAMP)`,
          [
            txn.BankTransactionID,
            txn.BankAccount.Code,
            txn.BankAccount.Name,
            txn.Date.split('T')[0],
            amount,
            txn.Type,
            description,
            txn.Reference || null,
            clientId,
          ]
        );
        imported++;
      }
    }

    return imported;
  } catch (error) {
    console.error('Error importing bank transactions:', error);
    return 0;
  }
}

/**
 * Get bank transactions with filters
 */
export async function getBankTransactions(filters: {
  date_from?: string;
  date_to?: string;
  reconciled?: boolean;
  payment_id?: string;
}): Promise<any[]> {
  let sql = `
    SELECT bt.*, 
      c.name as contact_name,
      CASE 
        WHEN bt.contact_id::text ~ '^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$' THEN c.name
        ELSE NULL
      END as client_name
    FROM bank_transactions bt
    LEFT JOIN clients c ON (
      bt.contact_id::text = c.id::text OR bt.contact_id = c.xero_contact_id
    )
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (filters.date_from) {
    sql += ` AND bt.date >= $${paramCount++}`;
    params.push(filters.date_from);
  }

  if (filters.date_to) {
    sql += ` AND bt.date <= $${paramCount++}`;
    params.push(filters.date_to);
  }

  if (filters.reconciled !== undefined) {
    sql += ` AND bt.reconciled = $${paramCount++}`;
    params.push(filters.reconciled);
  }

  if (filters.payment_id) {
    sql += ` AND bt.payment_id = $${paramCount++}`;
    params.push(filters.payment_id);
  }

  sql += ' ORDER BY bt.date DESC, bt.created_at DESC';

  const result = await query(sql, params);
  return result.rows;
}

/**
 * Reconcile a bank transaction with a payment
 */
export async function reconcileTransaction(transactionId: string, paymentId: string): Promise<void> {
  await query(
    `UPDATE bank_transactions 
     SET payment_id = $1, reconciled = true, reconciled_date = CURRENT_DATE, updated_at = CURRENT_TIMESTAMP
     WHERE id = $2`,
    [paymentId, transactionId]
  );
}

--- FILE: backend/src/lib/xero/bills.ts ---
import { query } from '../../db';
import { fetchWithRateLimit } from './rateLimiter';
import { parseXeroError, getErrorMessage } from './errorHandler';

export interface CreateBillData {
  supplier_id: string;
  purchase_order_id?: string;
  project_id?: string;
  date: string;
  due_date?: string;
  line_items: Array<{
    description: string;
    quantity: number;
    unit_amount: number;
    account_code?: string;
  }>;
  reference?: string;
  currency?: string;
}

export interface XeroBillRequest {
  Contact: { ContactID: string };
  Date: string;
  DueDate?: string;
  LineItems: Array<{
    Description: string;
    Quantity: number;
    UnitAmount: number;
    AccountCode?: string;
  }>;
  Reference?: string;
}

/**
 * Create a bill in Xero
 */
export async function createBillInXero(
  tokenData: { accessToken: string; tenantId: string },
  billData: CreateBillData,
  supplierXeroId: string
): Promise<{ InvoiceID: string; Date: string; Total: number } | null> {
  try {
    const xeroBill: XeroBillRequest = {
      Contact: { ContactID: supplierXeroId },
      Date: billData.date,
      DueDate: billData.due_date,
      LineItems: billData.line_items.map(item => ({
        Description: item.description,
        Quantity: item.quantity,
        UnitAmount: item.unit_amount,
        AccountCode: item.account_code,
      })),
      Reference: billData.reference,
    };

    // Xero Bills are created using the Invoices endpoint with Type: 'ACCPAY'
    // This is the correct approach per Xero API documentation
    const xeroBillWithType = {
      ...xeroBill,
      Type: 'ACCPAY' // Accounts Payable (Bill)
    };

    const response = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Invoices', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json',
      },
      body: JSON.stringify({ Invoices: [xeroBillWithType] }),
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero bill creation failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    const result = await response.json() as { Invoices: Array<{ InvoiceID: string; Date: string; Total: number; Type: string }> };
    const invoice = result.Invoices?.[0];
    
    // Verify it's a bill (ACCPAY type)
    if (invoice && invoice.Type === 'ACCPAY') {
      return invoice;
    }
    
    throw new Error('Created invoice is not a bill (Type is not ACCPAY)');
  } catch (error) {
    console.error('Error creating bill in Xero:', error);
    throw error;
  }
}

/**
 * Store bill in local database
 */
export async function storeBill(billData: CreateBillData & { xero_bill_id?: string; bill_number?: string }): Promise<string> {
  const totalAmount = billData.line_items.reduce((sum, item) => sum + (item.quantity * item.unit_amount), 0);

  const result = await query(
    `INSERT INTO xero_bills (
      xero_bill_id, bill_number, supplier_id, purchase_order_id, project_id,
      date, due_date, amount, amount_due, currency, line_items, synced_at
    )
    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11, $12)
    RETURNING id`,
    [
      billData.xero_bill_id || null,
      billData.bill_number || null,
      billData.supplier_id,
      billData.purchase_order_id || null,
      billData.project_id || null,
      billData.date,
      billData.due_date || null,
      totalAmount,
      totalAmount, // amount_due initially equals total
      billData.currency || 'USD',
      JSON.stringify(billData.line_items),
      billData.xero_bill_id ? new Date() : null,
    ]
  );

  const billId = result.rows[0].id;

  // If bill was created from a purchase order, update PO status and link
  if (billData.purchase_order_id) {
    await query(
      `UPDATE xero_purchase_orders 
       SET status = 'BILLED', bill_id = $1, updated_at = CURRENT_TIMESTAMP
       WHERE id = $2`,
      [billId, billData.purchase_order_id]
    );
  }

  // Update project actual_cost if project_id is provided
  if (billData.project_id) {
    await query(
      `UPDATE projects 
       SET actual_cost = COALESCE(actual_cost, 0) + $1,
           updated_at = CURRENT_TIMESTAMP
       WHERE id = $2`,
      [totalAmount, billData.project_id]
    );

    // Reduce PO commitments if this bill came from a PO
    if (billData.purchase_order_id) {
      const poResult = await query(
        'SELECT total_amount FROM xero_purchase_orders WHERE id = $1',
        [billData.purchase_order_id]
      );
      if (poResult.rows.length > 0) {
        const poAmount = parseFloat(poResult.rows[0].total_amount || '0');
        await query(
          `UPDATE projects 
           SET po_commitments = GREATEST(0, COALESCE(po_commitments, 0) - $1),
               updated_at = CURRENT_TIMESTAMP
           WHERE id = $2`,
          [poAmount, billData.project_id]
        );
      }
    }
  }

  return billId;
}

/**
 * Get bills with filters
 */
export async function getBills(filters: {
  supplier_id?: string;
  project_id?: string;
  purchase_order_id?: string;
  status?: string;
  date_from?: string;
  date_to?: string;
}): Promise<any[]> {
  let sql = `
    SELECT b.*,
      c.name as supplier_name,
      p.code as project_code,
      p.name as project_name,
      po.po_number
    FROM xero_bills b
    LEFT JOIN clients c ON b.supplier_id = c.id
    LEFT JOIN projects p ON b.project_id = p.id
    LEFT JOIN xero_purchase_orders po ON b.purchase_order_id = po.id
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (filters.supplier_id) {
    sql += ` AND b.supplier_id = $${paramCount++}`;
    params.push(filters.supplier_id);
  }

  if (filters.project_id) {
    sql += ` AND b.project_id = $${paramCount++}`;
    params.push(filters.project_id);
  }

  if (filters.purchase_order_id) {
    sql += ` AND b.purchase_order_id = $${paramCount++}`;
    params.push(filters.purchase_order_id);
  }

  if (filters.status) {
    sql += ` AND b.status = $${paramCount++}`;
    params.push(filters.status);
  }

  if (filters.date_from) {
    sql += ` AND b.date >= $${paramCount++}`;
    params.push(filters.date_from);
  }

  if (filters.date_to) {
    sql += ` AND b.date <= $${paramCount++}`;
    params.push(filters.date_to);
  }

  sql += ' ORDER BY b.date DESC, b.created_at DESC';

  try {
    const result = await query(sql, params);
    return result.rows;
  } catch (error: any) {
    const errorMessage = error.message || 'Failed to fetch bills';
    const isTableError = errorMessage.includes('does not exist') || errorMessage.includes('relation') || error.code === '42P01';
    if (isTableError) {
      // Return empty array instead of error - tables will be created when migrations run
      console.warn('[Xero] xero_bills table not found. Returning empty array. Run migrations to create tables.');
      return [];
    }
    throw error;
  }
}

/**
 * Mark bill as paid
 */
export async function markBillAsPaid(billId: string, amount?: number): Promise<void> {
  const billResult = await query('SELECT amount, amount_paid FROM xero_bills WHERE id = $1', [billId]);
  
  if (billResult.rows.length === 0) {
    throw new Error('Bill not found');
  }

  const bill = billResult.rows[0];
  const paymentAmount = amount || parseFloat(bill.amount_due || bill.amount);
  const newAmountPaid = parseFloat(bill.amount_paid || '0') + paymentAmount;
  const newAmountDue = parseFloat(bill.amount) - newAmountPaid;

  await query(
    `UPDATE xero_bills 
     SET amount_paid = $1,
         amount_due = $2,
         status = CASE WHEN $2 <= 0 THEN 'PAID' ELSE status END,
         paid_date = CASE WHEN $2 <= 0 THEN CURRENT_DATE ELSE paid_date END,
         updated_at = CURRENT_TIMESTAMP
     WHERE id = $3`,
    [newAmountPaid, newAmountDue, billId]
  );
}

--- FILE: backend/src/lib/xero/creditNotes.ts ---
import { query } from '../../db';
import { fetchWithRateLimit } from './rateLimiter';
import { parseXeroError, getErrorMessage } from './errorHandler';

export interface CreateCreditNoteData {
  invoice_id: string;
  amount: number;
  date: string;
  reason?: string;
  description?: string;
  currency?: string;
}

export interface XeroCreditNoteRequest {
  Type: string; // 'ACCPAYCREDIT' or 'ACCRECCREDIT'
  Contact: { ContactID: string };
  Date: string;
  CreditNoteNumber?: string;
  LineItems: Array<{
    Description: string;
    Quantity: number;
    UnitAmount: number;
    AccountCode?: string;
  }>;
  Reference?: string;
}

/**
 * Create a credit note in Xero
 */
export async function createCreditNoteInXero(
  tokenData: { accessToken: string; tenantId: string },
  creditNoteData: CreateCreditNoteData,
  invoiceXeroId: string,
  contactXeroId: string,
  creditNoteType: 'ACCPAYCREDIT' | 'ACCRECCREDIT' = 'ACCRECCREDIT'
): Promise<{ CreditNoteID: string; Date: string; Total: number } | null> {
  try {
    const xeroCreditNote: XeroCreditNoteRequest = {
      Type: creditNoteType,
      Contact: { ContactID: contactXeroId },
      Date: creditNoteData.date,
      LineItems: [{
        Description: creditNoteData.description || creditNoteData.reason || 'Credit Note',
        Quantity: 1,
        UnitAmount: creditNoteData.amount,
      }],
      Reference: creditNoteData.reason,
    };

    const response = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/CreditNotes', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json',
      },
      body: JSON.stringify({ CreditNotes: [xeroCreditNote] }),
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero credit note creation failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    const result = await response.json() as { CreditNotes: Array<{ CreditNoteID: string; Date: string; Total: number }> };
    return result.CreditNotes?.[0] || null;
  } catch (error) {
    console.error('Error creating credit note in Xero:', error);
    throw error;
  }
}

/**
 * Apply credit note to invoice in Xero
 */
export async function applyCreditNoteToInvoice(
  tokenData: { accessToken: string; tenantId: string },
  creditNoteXeroId: string,
  invoiceXeroId: string
): Promise<boolean> {
  try {
    // In Xero, credit notes are automatically allocated to invoices when they're created
    // This endpoint is for explicit allocation if needed
    // The allocation happens via the Allocations endpoint
    
    const response = await fetchWithRateLimit(`https://api.xero.com/api.xro/2.0/CreditNotes/${creditNoteXeroId}/Allocations`, {
      method: 'PUT',
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json',
      },
      body: JSON.stringify({
        Allocations: [{
          Invoice: { InvoiceID: invoiceXeroId },
          AppliedAmount: 0, // Will apply full amount if not specified
        }]
      }),
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero credit note allocation failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    return true;
  } catch (error) {
    console.error('Error applying credit note to invoice:', error);
    throw error;
  }
}

/**
 * Store credit note in local database
 */
export async function storeCreditNote(creditNoteData: CreateCreditNoteData & { xero_credit_note_id?: string; credit_note_number?: string }): Promise<string> {
  const result = await query(
    `INSERT INTO xero_credit_notes (
      xero_credit_note_id, credit_note_number, invoice_id, amount, date, reason, status, synced_at
    )
    VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
    RETURNING id`,
    [
      creditNoteData.xero_credit_note_id || null,
      creditNoteData.credit_note_number || null,
      creditNoteData.invoice_id,
      creditNoteData.amount,
      creditNoteData.date,
      creditNoteData.reason || creditNoteData.description || null,
      'AUTHORISED',
      creditNoteData.xero_credit_note_id ? new Date() : null,
    ]
  );

  return result.rows[0].id;
}

/**
 * Get credit notes with filters
 */
export async function getCreditNotes(filters: {
  invoice_id?: string;
  date_from?: string;
  date_to?: string;
  status?: string;
}): Promise<any[]> {
  let sql = `
    SELECT cn.*,
      xi.invoice_number,
      xi.xero_invoice_id,
      c.name as client_name
    FROM xero_credit_notes cn
    LEFT JOIN xero_invoices xi ON cn.invoice_id = xi.id
    LEFT JOIN clients c ON xi.client_id = c.id
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (filters.invoice_id) {
    sql += ` AND cn.invoice_id = $${paramCount++}`;
    params.push(filters.invoice_id);
  }

  if (filters.date_from) {
    sql += ` AND cn.date >= $${paramCount++}`;
    params.push(filters.date_from);
  }

  if (filters.date_to) {
    sql += ` AND cn.date <= $${paramCount++}`;
    params.push(filters.date_to);
  }

  if (filters.status) {
    sql += ` AND cn.status = $${paramCount++}`;
    params.push(filters.status);
  }

  sql += ' ORDER BY cn.date DESC, cn.created_at DESC';

  const result = await query(sql, params);
  return result.rows;
}

--- FILE: backend/src/lib/xero/errorHandler.ts ---
/**
 * Xero API Error Handler
 * 
 * Parses and handles Xero API errors according to their documentation
 */

export interface XeroApiError {
  error: string;
  error_description?: string;
  message?: string;
  validationErrors?: Array<{
    message: string;
    field?: string;
  }>;
  statusCode?: number;
  originalError?: any;
}

/**
 * Parse Xero API error response
 */
export async function parseXeroError(response: Response): Promise<XeroApiError> {
  const statusCode = response.status;
  let errorData: any = {};

  try {
    const text = await response.text();
    if (text) {
      errorData = JSON.parse(text);
    }
  } catch (e) {
    // If response isn't JSON, use status text
    errorData = { message: response.statusText || 'Unknown error' };
  }

  const error: XeroApiError = {
    error: errorData.error || errorData.Message || 'Unknown error',
    error_description: errorData.error_description || errorData.message || errorData.Message,
    message: errorData.message || errorData.Message || errorData.error_description,
    statusCode,
    originalError: errorData
  };

  // Parse validation errors if present
  if (errorData.Elements && Array.isArray(errorData.Elements)) {
    error.validationErrors = errorData.Elements
      .filter((el: any) => el.ValidationErrors && Array.isArray(el.ValidationErrors))
      .flatMap((el: any) => 
        el.ValidationErrors.map((ve: any) => ({
          message: ve.Message || ve.message || 'Validation error',
          field: ve.FieldName || ve.fieldName
        }))
      );
  } else if (errorData.ValidationErrors && Array.isArray(errorData.ValidationErrors)) {
    error.validationErrors = errorData.ValidationErrors.map((ve: any) => ({
      message: ve.Message || ve.message || 'Validation error',
      field: ve.FieldName || ve.fieldName
    }));
  }

  return error;
}

/**
 * Get user-friendly error message from Xero error
 */
export function getErrorMessage(error: XeroApiError): string {
  if (error.statusCode === 401) {
    return 'Authentication failed. Please reconnect to Xero.';
  }
  
  if (error.statusCode === 403) {
    return 'Access denied. Check your Xero app permissions.';
  }
  
  if (error.statusCode === 429) {
    return 'Rate limit exceeded. Please try again in a moment.';
  }
  
  if (error.statusCode === 400) {
    if (error.validationErrors && error.validationErrors.length > 0) {
      const validationMessages = error.validationErrors.map(ve => 
        ve.field ? `${ve.field}: ${ve.message}` : ve.message
      ).join(', ');
      return `Validation error: ${validationMessages}`;
    }
    return error.message || error.error_description || 'Invalid request';
  }
  
  if (error.statusCode === 404) {
    return 'Resource not found in Xero.';
  }
  
  if (error.statusCode === 500 || error.statusCode === 502 || error.statusCode === 503) {
    return 'Xero API is temporarily unavailable. Please try again later.';
  }

  return error.message || error.error_description || error.error || 'Unknown error occurred';
}

/**
 * Check if error is retryable
 */
export function isRetryableError(error: XeroApiError): boolean {
  if (!error.statusCode) return true; // Network errors are retryable
  
  // Retry on server errors and rate limits
  return error.statusCode === 429 || 
         error.statusCode === 500 || 
         error.statusCode === 502 || 
         error.statusCode === 503 ||
         error.statusCode === 504;
}

--- FILE: backend/src/lib/xero/expenses.ts ---
import { query } from '../../db';
import { fetchWithRateLimit } from './rateLimiter';
import { parseXeroError, getErrorMessage } from './errorHandler';

export interface CreateExpenseData {
  project_id?: string;
  cost_center_id?: string;
  amount: number;
  date: string;
  description: string;
  receipt_url?: string;
  currency?: string;
}

export interface XeroExpenseRequest {
  Contact?: { ContactID: string };
  Date: string;
  LineAmount: number;
  LineItems: Array<{
    Description: string;
    Quantity: number;
    UnitAmount: number;
    AccountCode?: string;
    Tracking?: Array<{ Name: string; Option: string }>;
  }>;
  Reference?: string;
}

/**
 * Create an expense claim in Xero
 */
export async function createExpenseInXero(
  tokenData: { accessToken: string; tenantId: string },
  expenseData: CreateExpenseData,
  trackingCategories?: Array<{ name: string; option: string }>
): Promise<{ ExpenseClaimID: string; Date: string; Total: number } | null> {
  try {
    const xeroExpense: XeroExpenseRequest = {
      Date: expenseData.date,
      LineAmount: expenseData.amount,
      LineItems: [{
        Description: expenseData.description,
        Quantity: 1,
        UnitAmount: expenseData.amount,
        Tracking: trackingCategories?.map(tc => ({ Name: tc.name, Option: tc.option })),
      }],
      Reference: expenseData.description,
    };

    const response = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/ExpenseClaims', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json',
      },
      body: JSON.stringify({ ExpenseClaims: [xeroExpense] }),
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero expense creation failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    const result = await response.json() as { ExpenseClaims: Array<{ ExpenseClaimID: string; Date: string; Total: number }> };
    return result.ExpenseClaims?.[0] || null;
  } catch (error) {
    console.error('Error creating expense in Xero:', error);
    throw error;
  }
}

/**
 * Store expense in local database
 */
export async function storeExpense(expenseData: CreateExpenseData & { xero_expense_id?: string }): Promise<string> {
  const result = await query(
    `INSERT INTO xero_expenses (
      xero_expense_id, project_id, cost_center_id, amount, date, description, receipt_url, synced_at
    )
    VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
    RETURNING id`,
    [
      expenseData.xero_expense_id || null,
      expenseData.project_id || null,
      expenseData.cost_center_id || null,
      expenseData.amount,
      expenseData.date,
      expenseData.description,
      expenseData.receipt_url || null,
      expenseData.xero_expense_id ? new Date() : null,
    ]
  );

  const expenseId = result.rows[0].id;

  // Update project actual_cost if project_id is provided
  if (expenseData.project_id) {
    await query(
      `UPDATE projects 
       SET actual_cost = COALESCE(actual_cost, 0) + $1,
           updated_at = CURRENT_TIMESTAMP
       WHERE id = $2`,
      [expenseData.amount, expenseData.project_id]
    );
  }

  return expenseId;
}

/**
 * Get expenses with filters
 */
export async function getExpenses(filters: {
  project_id?: string;
  cost_center_id?: string;
  status?: string;
  date_from?: string;
  date_to?: string;
}): Promise<any[]> {
  let sql = `
    SELECT e.*,
      p.code as project_code,
      p.name as project_name,
      cc.code as cost_center_code,
      cc.name as cost_center_name
    FROM xero_expenses e
    LEFT JOIN projects p ON e.project_id = p.id
    LEFT JOIN cost_centers cc ON e.cost_center_id = cc.id
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (filters.project_id) {
    sql += ` AND e.project_id = $${paramCount++}`;
    params.push(filters.project_id);
  }

  if (filters.cost_center_id) {
    sql += ` AND e.cost_center_id = $${paramCount++}`;
    params.push(filters.cost_center_id);
  }

  if (filters.status) {
    sql += ` AND e.status = $${paramCount++}`;
    params.push(filters.status);
  }

  if (filters.date_from) {
    sql += ` AND e.date >= $${paramCount++}`;
    params.push(filters.date_from);
  }

  if (filters.date_to) {
    sql += ` AND e.date <= $${paramCount++}`;
    params.push(filters.date_to);
  }

  sql += ' ORDER BY e.date DESC, e.created_at DESC';

  try {
    const result = await query(sql, params);
    return result.rows;
  } catch (error: any) {
    const errorMessage = error.message || 'Failed to fetch expenses';
    const isTableError = errorMessage.includes('does not exist') || errorMessage.includes('relation') || error.code === '42P01';
    if (isTableError) {
      // Return empty array instead of error - tables will be created when migrations run
      console.warn('[Xero] xero_expenses table not found. Returning empty array. Run migrations to create tables.');
      return [];
    }
    throw error;
  }
}

--- FILE: backend/src/lib/xero/items.ts ---
import { query } from '../../db';
import { fetchWithRateLimit } from './rateLimiter';
import { parseXeroError, getErrorMessage } from './errorHandler';

export interface XeroItem {
  ItemID: string;
  Code: string;
  Name: string;
  Description?: string;
  PurchaseDetails?: {
    UnitPrice?: number;
  };
  SalesDetails?: {
    UnitPrice?: number;
  };
  IsTrackedAsInventory?: boolean;
  InventoryAssetAccountCode?: string;
}

/**
 * Sync items from Xero
 */
export async function syncItemsFromXero(
  tokenData: { accessToken: string; tenantId: string }
): Promise<number> {
  try {
    const response = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Items', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json',
      },
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero items fetch failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    interface XeroItemsResponse {
      Items: XeroItem[];
    }

    const data = await response.json() as XeroItemsResponse;
    const items = data.Items || [];
    let synced = 0;

    for (const item of items) {
      // Check if item already exists
      const existing = await query(
        'SELECT id FROM xero_items WHERE xero_item_id = $1',
        [item.ItemID]
      );

      const purchasePrice = item.PurchaseDetails?.UnitPrice || 0;
      const salePrice = item.SalesDetails?.UnitPrice || 0;
      const stockLevel = 0; // Xero doesn't provide stock levels via API directly, would need inventory endpoints

      if (existing.rows.length === 0) {
        await query(
          `INSERT INTO xero_items (
            xero_item_id, code, name, description, purchase_price, sale_price, 
            stock_level, is_tracked, synced_at
          )
          VALUES ($1, $2, $3, $4, $5, $6, $7, $8, CURRENT_TIMESTAMP)`,
          [
            item.ItemID,
            item.Code,
            item.Name,
            item.Description || null,
            purchasePrice,
            salePrice,
            stockLevel,
            item.IsTrackedAsInventory || false,
          ]
        );
      } else {
        await query(
          `UPDATE xero_items 
           SET code = $1, name = $2, description = $3, purchase_price = $4, 
               sale_price = $5, is_tracked = $6, synced_at = CURRENT_TIMESTAMP
           WHERE xero_item_id = $7`,
          [
            item.Code,
            item.Name,
            item.Description || null,
            purchasePrice,
            salePrice,
            item.IsTrackedAsInventory || false,
            item.ItemID,
          ]
        );
      }
      synced++;
    }

    return synced;
  } catch (error) {
    console.error('Error syncing items from Xero:', error);
    return 0;
  }
}

/**
 * Get items with filters
 */
export async function getItems(filters: {
  search?: string;
  is_tracked?: boolean;
}): Promise<any[]> {
  let sql = `
    SELECT * FROM xero_items
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (filters.search) {
    sql += ` AND (name ILIKE $${paramCount} OR code ILIKE $${paramCount} OR description ILIKE $${paramCount})`;
    params.push(`%${filters.search}%`);
    paramCount++;
  }

  if (filters.is_tracked !== undefined) {
    sql += ` AND is_tracked = $${paramCount++}`;
    params.push(filters.is_tracked);
  }

  sql += ' ORDER BY name ASC';

  const result = await query(sql, params);
  return result.rows;
}

/**
 * Get item by ID
 */
export async function getItemById(itemId: string): Promise<any | null> {
  const result = await query('SELECT * FROM xero_items WHERE id = $1', [itemId]);
  return result.rows[0] || null;
}

/**
 * Update item stock level
 */
export async function updateItemStock(itemId: string, stockLevel: number): Promise<void> {
  await query(
    `UPDATE xero_items 
     SET stock_level = $1, updated_at = CURRENT_TIMESTAMP
     WHERE id = $2`,
    [stockLevel, itemId]
  );
}

--- FILE: backend/src/lib/xero/payments.ts ---
import { query } from '../../db';
import { fetchWithRateLimit } from './rateLimiter';
import { parseXeroError, getErrorMessage } from './errorHandler';

export interface CreatePaymentData {
  invoice_id: string;
  amount: number;
  payment_date: string; // ISO date string
  payment_method: 'CASH' | 'CHECK' | 'BANK_TRANSFER' | 'CREDIT_CARD' | 'ONLINE';
  reference?: string;
  account_code?: string;
  currency?: string;
}

export interface XeroPaymentRequest {
  Invoice: { InvoiceID: string };
  Account?: { Code: string };
  Date: string;
  Amount: number;
  Reference?: string;
  PaymentMethod?: string;
}

/**
 * Create a payment in Xero
 */
export async function createPaymentInXero(
  tokenData: { accessToken: string; tenantId: string },
  paymentData: CreatePaymentData,
  invoiceXeroId: string
): Promise<{ PaymentID: string; Date: string; Amount: number } | null> {
  try {
    const xeroPayment: XeroPaymentRequest = {
      Invoice: { InvoiceID: invoiceXeroId },
      Date: paymentData.payment_date,
      Amount: paymentData.amount,
      Reference: paymentData.reference,
    };

    // Map payment method to Xero payment method
    const paymentMethodMap: Record<string, string> = {
      'CASH': 'Cash',
      'CHECK': 'Check',
      'BANK_TRANSFER': 'Bank Transfer',
      'CREDIT_CARD': 'Credit Card',
      'ONLINE': 'Online',
    };
    
    if (paymentData.payment_method && paymentMethodMap[paymentData.payment_method]) {
      xeroPayment.PaymentMethod = paymentMethodMap[paymentData.payment_method];
    }

    if (paymentData.account_code) {
      xeroPayment.Account = { Code: paymentData.account_code };
    }

    const response = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Payments', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json',
      },
      body: JSON.stringify({ Payments: [xeroPayment] }),
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero payment creation failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    const result = await response.json() as { Payments: Array<{ PaymentID: string; Date: string; Amount: number }> };
    return result.Payments?.[0] || null;
  } catch (error) {
    console.error('Error creating payment in Xero:', error);
    throw error;
  }
}

/**
 * Store payment in local database
 */
export async function storePayment(paymentData: CreatePaymentData & { xero_payment_id?: string; user_id: string }): Promise<string> {
  const result = await query(
    `INSERT INTO xero_payments (
      xero_payment_id, invoice_id, amount, payment_date, payment_method, 
      reference, account_code, currency, synced_at
    )
    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9)
    RETURNING id`,
    [
      paymentData.xero_payment_id || null,
      paymentData.invoice_id,
      paymentData.amount,
      paymentData.payment_date,
      paymentData.payment_method,
      paymentData.reference || null,
      paymentData.account_code || null,
      paymentData.currency || 'USD',
      paymentData.xero_payment_id ? new Date() : null,
    ]
  );

  const paymentId = result.rows[0].id;

  // Update invoice payment amounts
  await query(
    `UPDATE xero_invoices 
     SET amount_paid = COALESCE(amount_paid, 0) + $1,
         amount_due = GREATEST(0, COALESCE(amount_due, total) - $1),
         last_payment_date = $2,
         updated_at = CURRENT_TIMESTAMP
     WHERE id = $3`,
    [paymentData.amount, paymentData.payment_date, paymentData.invoice_id]
  );

  // Update invoice status if fully paid
  await query(
    `UPDATE xero_invoices 
     SET status = CASE 
       WHEN amount_due <= 0 THEN 'PAID'
       WHEN amount_due < total THEN 'PARTIALLY_PAID'
       ELSE status
     END
     WHERE id = $1`,
    [paymentData.invoice_id]
  );

  return paymentId;
}

/**
 * Get payments with filters
 */
export async function getPayments(filters: {
  invoice_id?: string;
  date_from?: string;
  date_to?: string;
  payment_method?: string;
}): Promise<any[]> {
  let sql = `
    SELECT p.*, 
      xi.invoice_number,
      xi.xero_invoice_id,
      c.name as client_name
    FROM xero_payments p
    LEFT JOIN xero_invoices xi ON p.invoice_id = xi.id
    LEFT JOIN clients c ON xi.client_id = c.id
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (filters.invoice_id) {
    sql += ` AND p.invoice_id = $${paramCount++}`;
    params.push(filters.invoice_id);
  }

  if (filters.date_from) {
    sql += ` AND p.payment_date >= $${paramCount++}`;
    params.push(filters.date_from);
  }

  if (filters.date_to) {
    sql += ` AND p.payment_date <= $${paramCount++}`;
    params.push(filters.date_to);
  }

  if (filters.payment_method) {
    sql += ` AND p.payment_method = $${paramCount++}`;
    params.push(filters.payment_method);
  }

  sql += ' ORDER BY p.payment_date DESC, p.created_at DESC';

  try {
    const result = await query(sql, params);
    return result.rows;
  } catch (error: any) {
    const errorMessage = error.message || 'Failed to fetch payments';
    const isTableError = errorMessage.includes('does not exist') || errorMessage.includes('relation') || error.code === '42P01';
    if (isTableError) {
      // Return empty array instead of error - tables will be created when migrations run
      console.warn('[Xero] xero_payments table not found. Returning empty array. Run migrations to create tables.');
      return [];
    }
    throw error;
  }
}

--- FILE: backend/src/lib/xero/purchaseOrders.ts ---
import { query } from '../../db';
import { fetchWithRateLimit } from './rateLimiter';
import { parseXeroError, getErrorMessage } from './errorHandler';

export interface CreatePurchaseOrderData {
  supplier_id: string;
  project_id: string; // REQUIRED
  date: string;
  delivery_date?: string;
  line_items: Array<{
    description: string;
    quantity: number;
    unit_amount: number;
    account_code?: string;
    cost_center_id?: string;
    item_id?: string;
  }>;
  notes?: string;
  currency?: string;
}

export interface XeroPurchaseOrderRequest {
  Contact: { ContactID: string };
  Date: string;
  DeliveryDate?: string;
  LineItems: Array<{
    Description: string;
    Quantity: number;
    UnitAmount: number;
    AccountCode?: string;
    ItemCode?: string;
    Tracking?: Array<{ Name: string; Option: string }>;
  }>;
  Reference?: string;
}

/**
 * Create a purchase order in Xero
 */
export async function createPurchaseOrderInXero(
  tokenData: { accessToken: string; tenantId: string },
  poData: CreatePurchaseOrderData,
  supplierXeroId: string,
  trackingCategories?: Array<{ name: string; option: string }>
): Promise<{ PurchaseOrderID: string; Date: string; Total: number } | null> {
  try {
    const xeroPO: XeroPurchaseOrderRequest = {
      Contact: { ContactID: supplierXeroId },
      Date: poData.date,
      DeliveryDate: poData.delivery_date,
      LineItems: poData.line_items.map(item => ({
        Description: item.description,
        Quantity: item.quantity,
        UnitAmount: item.unit_amount,
        AccountCode: item.account_code,
        ItemCode: item.item_id,
        Tracking: trackingCategories?.map(tc => ({ Name: tc.name, Option: tc.option })),
      })),
      Reference: poData.notes,
    };

    const response = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/PurchaseOrders', {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json',
      },
      body: JSON.stringify({ PurchaseOrders: [xeroPO] }),
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero purchase order creation failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    const result = await response.json() as { PurchaseOrders: Array<{ PurchaseOrderID: string; Date: string; Total: number }> };
    return result.PurchaseOrders?.[0] || null;
  } catch (error) {
    console.error('Error creating purchase order in Xero:', error);
    throw error;
  }
}

/**
 * Store purchase order in local database
 */
export async function storePurchaseOrder(
  poData: CreatePurchaseOrderData & { xero_po_id?: string; po_number?: string }
): Promise<string> {
  const totalAmount = poData.line_items.reduce((sum, item) => sum + (item.quantity * item.unit_amount), 0);

  const result = await query(
    `INSERT INTO xero_purchase_orders (
      xero_po_id, po_number, supplier_id, project_id, date, delivery_date,
      total_amount, currency, line_items, notes, synced_at
    )
    VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, $11)
    RETURNING id`,
    [
      poData.xero_po_id || null,
      poData.po_number || null,
      poData.supplier_id,
      poData.project_id,
      poData.date,
      poData.delivery_date || null,
      totalAmount,
      poData.currency || 'USD',
      JSON.stringify(poData.line_items),
      poData.notes || null,
      poData.xero_po_id ? new Date() : null,
    ]
  );

  const poId = result.rows[0].id;

  // Store line items separately for detailed tracking
  for (const item of poData.line_items) {
    await query(
      `INSERT INTO xero_purchase_order_line_items (
        po_id, description, quantity, unit_amount, account_code, cost_center_id, item_id, line_amount
      )
      VALUES ($1, $2, $3, $4, $5, $6, $7, $8)`,
      [
        poId,
        item.description,
        item.quantity,
        item.unit_amount,
        item.account_code || null,
        item.cost_center_id || null,
        item.item_id || null,
        item.quantity * item.unit_amount,
      ]
    );
  }

  // Update project PO commitments
  await query(
    `UPDATE projects 
     SET po_commitments = COALESCE(po_commitments, 0) + $1,
         updated_at = CURRENT_TIMESTAMP
     WHERE id = $2`,
    [totalAmount, poData.project_id]
  );

  return poId;
}

/**
 * Get purchase orders with filters
 */
export async function getPurchaseOrders(filters: {
  project_id?: string;
  supplier_id?: string;
  status?: string;
  date_from?: string;
  date_to?: string;
  cost_center_id?: string;
}): Promise<any[]> {
  let sql = `
    SELECT DISTINCT po.*,
      c.name as supplier_name,
      p.code as project_code,
      p.name as project_name
    FROM xero_purchase_orders po
    LEFT JOIN clients c ON po.supplier_id = c.id
    LEFT JOIN projects p ON po.project_id = p.id
  `;
  
  // If filtering by cost_center_id, need to JOIN with line items
  if (filters.cost_center_id) {
    sql += ` INNER JOIN xero_purchase_order_line_items li ON po.id = li.po_id `;
  }
  
  sql += ` WHERE 1=1 `;
  const params: any[] = [];
  let paramCount = 1;

  if (filters.project_id) {
    sql += ` AND po.project_id = $${paramCount++}`;
    params.push(filters.project_id);
  }

  if (filters.supplier_id) {
    sql += ` AND po.supplier_id = $${paramCount++}`;
    params.push(filters.supplier_id);
  }

  if (filters.status) {
    sql += ` AND po.status = $${paramCount++}`;
    params.push(filters.status);
  }

  if (filters.date_from) {
    sql += ` AND po.date >= $${paramCount++}`;
    params.push(filters.date_from);
  }

  if (filters.date_to) {
    sql += ` AND po.date <= $${paramCount++}`;
    params.push(filters.date_to);
  }

  if (filters.cost_center_id) {
    sql += ` AND li.cost_center_id = $${paramCount++}`;
    params.push(filters.cost_center_id);
  }

  sql += ' ORDER BY po.date DESC, po.created_at DESC';

  try {
    const result = await query(sql, params);
    return result.rows;
  } catch (error: any) {
    const errorMessage = error.message || 'Failed to fetch purchase orders';
    const isTableError = errorMessage.includes('does not exist') || errorMessage.includes('relation') || error.code === '42P01';
    if (isTableError) {
      // Return empty array instead of error - tables will be created when migrations run
      console.warn('[Xero] xero_purchase_orders table not found. Returning empty array. Run migrations to create tables.');
      return [];
    }
    throw error;
  }
}

/**
 * Get purchase order with line items
 */
export async function getPurchaseOrderById(poId: string): Promise<any | null> {
  const poResult = await query(
    `SELECT po.*,
      c.name as supplier_name,
      p.code as project_code,
      p.name as project_name
    FROM xero_purchase_orders po
    LEFT JOIN clients c ON po.supplier_id = c.id
    LEFT JOIN projects p ON po.project_id = p.id
    WHERE po.id = $1`,
    [poId]
  );

  if (poResult.rows.length === 0) {
    return null;
  }

  const po = poResult.rows[0];

  // Get line items
  const lineItemsResult = await query(
    `SELECT li.*, cc.code as cost_center_code, cc.name as cost_center_name
     FROM xero_purchase_order_line_items li
     LEFT JOIN cost_centers cc ON li.cost_center_id = cc.id
     WHERE li.po_id = $1
     ORDER BY li.created_at`,
    [poId]
  );

  po.line_items_detail = lineItemsResult.rows;
  return po;
}

/**
 * Update purchase order status
 */
export async function updatePurchaseOrderStatus(poId: string, status: string): Promise<void> {
  await query(
    `UPDATE xero_purchase_orders 
     SET status = $1, updated_at = CURRENT_TIMESTAMP
     WHERE id = $2`,
    [status, poId]
  );
}

--- FILE: backend/src/lib/xero/rateLimiter.ts ---
/**
 * Xero API Rate Limiter
 * 
 * Xero Rate Limits:
 * - 60 calls per minute
 * - 5,000 calls per day
 * - 5 concurrent calls
 * 
 * This utility helps manage rate limits and implements retry logic with exponential backoff
 */

interface RateLimitState {
  minuteCalls: number;
  minuteWindowStart: number;
  dailyCalls: number;
  dailyWindowStart: number;
  concurrentCalls: number;
}

class XeroRateLimiter {
  private state: RateLimitState = {
    minuteCalls: 0,
    minuteWindowStart: Date.now(),
    dailyCalls: 0,
    dailyWindowStart: Date.now(),
    concurrentCalls: 0
  };

  private readonly MINUTE_LIMIT = 60;
  private readonly DAILY_LIMIT = 5000;
  private readonly CONCURRENT_LIMIT = 5;
  private readonly MINUTE_WINDOW = 60 * 1000; // 60 seconds
  private readonly DAILY_WINDOW = 24 * 60 * 60 * 1000; // 24 hours

  /**
   * Check if we can make an API call
   * Returns wait time in milliseconds if we need to wait, 0 if we can proceed
   */
  canMakeCall(): number {
    const now = Date.now();

    // Reset minute window if expired
    if (now - this.state.minuteWindowStart >= this.MINUTE_WINDOW) {
      this.state.minuteCalls = 0;
      this.state.minuteWindowStart = now;
    }

    // Reset daily window if expired
    if (now - this.state.dailyWindowStart >= this.DAILY_WINDOW) {
      this.state.dailyCalls = 0;
      this.state.dailyWindowStart = now;
    }

    // Check concurrent limit
    if (this.state.concurrentCalls >= this.CONCURRENT_LIMIT) {
      return 100; // Wait 100ms before retrying
    }

    // Check minute limit
    if (this.state.minuteCalls >= this.MINUTE_LIMIT) {
      const waitTime = this.MINUTE_WINDOW - (now - this.state.minuteWindowStart);
      return Math.max(waitTime, 100);
    }

    // Check daily limit
    if (this.state.dailyCalls >= this.DAILY_LIMIT) {
      const waitTime = this.DAILY_WINDOW - (now - this.state.dailyWindowStart);
      return Math.max(waitTime, 60000); // Wait at least 1 minute
    }

    return 0; // Can proceed
  }

  /**
   * Record that an API call is starting
   */
  startCall(): void {
    this.state.concurrentCalls++;
    this.state.minuteCalls++;
    this.state.dailyCalls++;
  }

  /**
   * Record that an API call has completed
   */
  endCall(): void {
    if (this.state.concurrentCalls > 0) {
      this.state.concurrentCalls--;
    }
  }

  /**
   * Parse rate limit headers from Xero API response
   */
  updateFromHeaders(headers: Headers): void {
    const dayRemaining = headers.get('X-DayLimit-Remaining');
    const minRemaining = headers.get('X-MinLimit-Remaining');
    const appMinRemaining = headers.get('X-AppMinLimit-Remaining');

    if (dayRemaining !== null) {
      const remaining = parseInt(dayRemaining, 10);
      if (!isNaN(remaining)) {
        this.state.dailyCalls = Math.max(0, this.DAILY_LIMIT - remaining);
      }
    }

    if (minRemaining !== null) {
      const remaining = parseInt(minRemaining, 10);
      if (!isNaN(remaining)) {
        this.state.minuteCalls = Math.max(0, this.MINUTE_LIMIT - remaining);
      }
    }
  }

  /**
   * Get current rate limit status
   */
  getStatus() {
    const now = Date.now();
    return {
      minuteCalls: this.state.minuteCalls,
      minuteLimit: this.MINUTE_LIMIT,
      minuteRemaining: Math.max(0, this.MINUTE_LIMIT - this.state.minuteCalls),
      dailyCalls: this.state.dailyCalls,
      dailyLimit: this.DAILY_LIMIT,
      dailyRemaining: Math.max(0, this.DAILY_LIMIT - this.state.dailyCalls),
      concurrentCalls: this.state.concurrentCalls,
      concurrentLimit: this.CONCURRENT_LIMIT
    };
  }
}

// Singleton instance
export const xeroRateLimiter = new XeroRateLimiter();

/**
 * Execute a fetch request with rate limiting and retry logic
 */
export async function fetchWithRateLimit(
  url: string,
  options: RequestInit,
  maxRetries: number = 3
): Promise<Response> {
  let attempt = 0;

  while (attempt < maxRetries) {
    // Check rate limits
    const waitTime = xeroRateLimiter.canMakeCall();
    if (waitTime > 0) {
      await new Promise(resolve => setTimeout(resolve, waitTime));
    }

    // Start tracking the call
    xeroRateLimiter.startCall();

    try {
      const response = await fetch(url, options);

      // Update rate limiter from response headers
      xeroRateLimiter.updateFromHeaders(response.headers);

      // Handle rate limit errors (429)
      if (response.status === 429) {
        xeroRateLimiter.endCall();
        
        // Get retry-after header
        const retryAfter = response.headers.get('Retry-After');
        const waitTime = retryAfter ? parseInt(retryAfter, 10) * 1000 : Math.pow(2, attempt) * 1000;
        
        if (attempt < maxRetries - 1) {
          console.warn(`[Xero Rate Limit] Hit rate limit, waiting ${waitTime}ms before retry ${attempt + 1}/${maxRetries}`);
          await new Promise(resolve => setTimeout(resolve, waitTime));
          attempt++;
          continue;
        } else {
          throw new Error(`Xero API rate limit exceeded after ${maxRetries} attempts`);
        }
      }

      // Success - end call tracking
      xeroRateLimiter.endCall();
      return response;

    } catch (error) {
      xeroRateLimiter.endCall();
      
      // Retry on network errors with exponential backoff
      if (attempt < maxRetries - 1 && error instanceof Error) {
        const waitTime = Math.pow(2, attempt) * 1000; // Exponential backoff
        console.warn(`[Xero API] Request failed, retrying in ${waitTime}ms (attempt ${attempt + 1}/${maxRetries}):`, error.message);
        await new Promise(resolve => setTimeout(resolve, waitTime));
        attempt++;
        continue;
      }
      
      throw error;
    }
  }

  throw new Error(`Failed after ${maxRetries} attempts`);
}

--- FILE: backend/src/lib/xero/reminders.ts ---
import { query } from '../../db';
import { sendEmail } from '../email';

export interface ReminderSchedule {
  days_after_due: number[];
  email_template?: string;
  enabled: boolean;
}

/**
 * Get reminder schedule settings
 */
export async function getReminderSchedule(): Promise<ReminderSchedule> {
  const result = await query(
    `SELECT value FROM settings WHERE key = 'payment_reminder_schedule' AND user_id IS NULL`
  );

  if (result.rows.length > 0 && result.rows[0].value) {
    try {
      return JSON.parse(result.rows[0].value);
    } catch (e) {
      // Invalid JSON, return default
    }
  }

  // Default schedule: 7, 14, 30 days after due date
  return {
    days_after_due: [7, 14, 30],
    enabled: true,
  };
}

/**
 * Update reminder schedule settings
 */
export async function updateReminderSchedule(schedule: ReminderSchedule): Promise<void> {
  await query(
    `INSERT INTO settings (key, value, user_id, updated_at)
     VALUES ('payment_reminder_schedule', $1, NULL, CURRENT_TIMESTAMP)
     ON CONFLICT (key, user_id) DO UPDATE SET value = $1, updated_at = CURRENT_TIMESTAMP`,
    [JSON.stringify(schedule)]
  );
}

/**
 * Send payment reminder for an invoice
 */
export async function sendPaymentReminder(
  invoiceId: string,
  reminderType: string,
  userEmail?: string
): Promise<boolean> {
  try {
    // Get invoice details with client information
    const invoiceResult = await query(
      `SELECT xi.*, c.name as client_name, c.email as client_email, c.billing_email
       FROM xero_invoices xi
       LEFT JOIN clients c ON xi.client_id = c.id
       WHERE xi.id = $1`,
      [invoiceId]
    );

    if (invoiceResult.rows.length === 0) {
      return false;
    }

    const invoice = invoiceResult.rows[0];
    const recipientEmail = invoice.billing_email || invoice.client_email || userEmail;

    if (!recipientEmail) {
      return false;
    }

    // Send reminder email
    const subject = `Payment Reminder: Invoice ${invoice.invoice_number}`;
    const body = `
      Dear ${invoice.client_name || 'Valued Customer'},

      This is a friendly reminder that payment is due for Invoice ${invoice.invoice_number}.

      Invoice Details:
      - Invoice Number: ${invoice.invoice_number}
      - Amount Due: $${parseFloat(invoice.amount_due || invoice.total).toFixed(2)}
      ${invoice.due_date ? `- Due Date: ${new Date(invoice.due_date).toLocaleDateString()}` : ''}

      Please arrange payment at your earliest convenience.

      Thank you for your business.
    `;

    await sendEmail({
      to: recipientEmail,
      subject,
      text: body,
    });

    // Record reminder in database
    await query(
      `INSERT INTO payment_reminders (invoice_id, sent_date, reminder_type, sent_to)
       VALUES ($1, CURRENT_DATE, $2, $3)`,
      [invoiceId, reminderType, recipientEmail]
    );

    return true;
  } catch (error) {
    console.error('Error sending payment reminder:', error);
    return false;
  }
}

/**
 * Get overdue invoices that need reminders
 */
export async function getOverdueInvoicesForReminders(): Promise<any[]> {
  const schedule = await getReminderSchedule();
  
  if (!schedule.enabled) {
    return [];
  }

  const result = await query(
    `SELECT xi.*, c.name as client_name, c.email as client_email, c.billing_email
     FROM xero_invoices xi
     LEFT JOIN clients c ON xi.client_id = c.id
     WHERE xi.status IN ('AUTHORISED', 'SUBMITTED')
       AND xi.amount_due > 0
       AND xi.due_date < CURRENT_DATE
       AND xi.due_date IS NOT NULL
     ORDER BY xi.due_date ASC`
  );

  return result.rows;
}

/**
 * Check and send reminders for overdue invoices
 */
export async function processPaymentReminders(): Promise<{ sent: number; failed: number }> {
  const schedule = await getReminderSchedule();
  
  if (!schedule.enabled) {
    return { sent: 0, failed: 0 };
  }

  const overdueInvoices = await getOverdueInvoicesForReminders();
  let sent = 0;
  let failed = 0;

  for (const invoice of overdueInvoices) {
    const daysOverdue = Math.floor((new Date().getTime() - new Date(invoice.due_date).getTime()) / (1000 * 60 * 60 * 24));

    // Check if we should send a reminder for this number of days overdue
    const shouldSend = schedule.days_after_due.some(days => daysOverdue >= days);

    if (shouldSend) {
      // Check if we've already sent a reminder for this invoice and days overdue
      const existingReminder = await query(
        `SELECT id FROM payment_reminders 
         WHERE invoice_id = $1 
           AND reminder_type = $2
           AND sent_date >= CURRENT_DATE - INTERVAL '1 day'`,
        [invoice.id, `days_${daysOverdue}`]
      );

      if (existingReminder.rows.length === 0) {
        const success = await sendPaymentReminder(invoice.id, `days_${daysOverdue}`);
        if (success) {
          sent++;
        } else {
          failed++;
        }
      }
    }
  }

  return { sent, failed };
}

/**
 * Get reminder history
 */
export async function getReminderHistory(filters: {
  invoice_id?: string;
  date_from?: string;
  date_to?: string;
}): Promise<any[]> {
  let sql = `
    SELECT pr.*,
      xi.invoice_number,
      c.name as client_name
    FROM payment_reminders pr
    LEFT JOIN xero_invoices xi ON pr.invoice_id = xi.id
    LEFT JOIN clients c ON xi.client_id = c.id
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (filters.invoice_id) {
    sql += ` AND pr.invoice_id = $${paramCount++}`;
    params.push(filters.invoice_id);
  }

  if (filters.date_from) {
    sql += ` AND pr.sent_date >= $${paramCount++}`;
    params.push(filters.date_from);
  }

  if (filters.date_to) {
    sql += ` AND pr.sent_date <= $${paramCount++}`;
    params.push(filters.date_to);
  }

  sql += ' ORDER BY pr.sent_date DESC, pr.created_at DESC';

  const result = await query(sql, params);
  return result.rows;
}

--- FILE: backend/src/lib/xero/reports.ts ---
import { query } from '../../db';
import { fetchWithRateLimit } from './rateLimiter';
import { parseXeroError, getErrorMessage } from './errorHandler';

/**
 * Get Profit & Loss report from Xero
 */
export async function getProfitLossReport(
  tokenData: { accessToken: string; tenantId: string },
  dateFrom?: string,
  dateTo?: string
): Promise<any> {
  try {
    let url = 'https://api.xero.com/api.xro/2.0/Reports/ProfitAndLoss';
    const params = new URLSearchParams();
    
    if (dateFrom) {
      params.append('fromDate', dateFrom);
    }
    if (dateTo) {
      params.append('toDate', dateTo);
    }
    params.append('periods', '12'); // 12 months
    
    if (params.toString()) {
      url += '?' + params.toString();
    }

    const response = await fetchWithRateLimit(url, {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json',
      },
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero P&L report fetch failed:', errorMessage, error);
      return null;
    }

    return await response.json();
  } catch (error) {
    console.error('Error fetching P&L report:', error);
    return null;
  }
}

/**
 * Get Balance Sheet report from Xero
 */
export async function getBalanceSheetReport(
  tokenData: { accessToken: string; tenantId: string },
  date?: string
): Promise<any> {
  try {
    let url = 'https://api.xero.com/api.xro/2.0/Reports/BalanceSheet';
    const params = new URLSearchParams();
    
    if (date) {
      params.append('date', date);
    }
    params.append('periods', '12');
    
    if (params.toString()) {
      url += '?' + params.toString();
    }

    const response = await fetchWithRateLimit(url, {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json',
      },
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero Balance Sheet report fetch failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    return await response.json();
  } catch (error) {
    console.error('Error fetching Balance Sheet report:', error);
    return null;
  }
}

/**
 * Get Cash Flow report from Xero
 */
export async function getCashFlowReport(
  tokenData: { accessToken: string; tenantId: string },
  dateFrom?: string,
  dateTo?: string
): Promise<any> {
  try {
    let url = 'https://api.xero.com/api.xro/2.0/Reports/Cashflow';
    const params = new URLSearchParams();
    
    if (dateFrom) {
      params.append('fromDate', dateFrom);
    }
    if (dateTo) {
      params.append('toDate', dateTo);
    }
    
    if (params.toString()) {
      url += '?' + params.toString();
    }

    const response = await fetchWithRateLimit(url, {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json',
      },
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero Cash Flow report fetch failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    return await response.json();
  } catch (error) {
    console.error('Error fetching Cash Flow report:', error);
    return null;
  }
}

/**
 * Get Aged Receivables report from Xero
 */
export async function getAgedReceivablesReport(
  tokenData: { accessToken: string; tenantId: string },
  date?: string
): Promise<any> {
  try {
    let url = 'https://api.xero.com/api.xro/2.0/Reports/AgedReceivables';
    const params = new URLSearchParams();
    
    if (date) {
      params.append('date', date);
    }
    
    if (params.toString()) {
      url += '?' + params.toString();
    }

    const response = await fetchWithRateLimit(url, {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json',
      },
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero Aged Receivables report fetch failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    return await response.json();
  } catch (error) {
    console.error('Error fetching Aged Receivables report:', error);
    return null;
  }
}

/**
 * Get Aged Payables report from Xero
 */
export async function getAgedPayablesReport(
  tokenData: { accessToken: string; tenantId: string },
  date?: string
): Promise<any> {
  try {
    let url = 'https://api.xero.com/api.xro/2.0/Reports/AgedPayables';
    const params = new URLSearchParams();
    
    if (date) {
      params.append('date', date);
    }
    
    if (params.toString()) {
      url += '?' + params.toString();
    }

    const response = await fetchWithRateLimit(url, {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json',
      },
    });

    if (!response.ok) {
      const error = await parseXeroError(response);
      const errorMessage = getErrorMessage(error);
      console.error('Xero Aged Payables report fetch failed:', errorMessage, error);
      throw new Error(errorMessage);
    }

    return await response.json();
  } catch (error) {
    console.error('Error fetching Aged Payables report:', error);
    return null;
  }
}

--- FILE: backend/src/lib/xero/webhooks.ts ---
import { query } from '../../db';
import * as crypto from 'crypto';

/**
 * Verify webhook signature from Xero
 */
export function verifyWebhookSignature(
  payload: string,
  signature: string,
  webhookKey: string
): boolean {
  try {
    const hash = crypto.createHmac('sha256', webhookKey).update(payload).digest('base64');
    return hash === signature;
  } catch (error) {
    console.error('Error verifying webhook signature:', error);
    return false;
  }
}

/**
 * Store webhook event
 */
export async function storeWebhookEvent(
  eventType: string,
  entityId: string,
  payload: any,
  processed: boolean = false
): Promise<string> {
  const result = await query(
    `INSERT INTO xero_webhook_events (event_type, entity_id, payload, processed, created_at)
     VALUES ($1, $2, $3, $4, CURRENT_TIMESTAMP)
     RETURNING id`,
    [eventType, entityId, JSON.stringify(payload), processed]
  );

  return result.rows[0].id;
}

/**
 * Process webhook event
 */
export async function processWebhookEvent(eventId: string): Promise<boolean> {
  try {
    const eventResult = await query('SELECT * FROM xero_webhook_events WHERE id = $1', [eventId]);
    
    if (eventResult.rows.length === 0) {
      return false;
    }

    const event = eventResult.rows[0];
    
    if (event.processed) {
      return true; // Already processed
    }

    const payload = typeof event.payload === 'string' ? JSON.parse(event.payload) : event.payload;

    // Process based on event type
    switch (event.event_type) {
      case 'INVOICE':
        await handleInvoiceWebhook(event.entity_id, payload);
        break;
      case 'PAYMENT':
        await handlePaymentWebhook(event.entity_id, payload);
        break;
      case 'CONTACT':
        await handleContactWebhook(event.entity_id, payload);
        break;
      case 'BILL':
        await handleBillWebhook(event.entity_id, payload);
        break;
      case 'PURCHASEORDER':
        await handlePurchaseOrderWebhook(event.entity_id, payload);
        break;
      case 'BANKTRANSACTION':
        await handleBankTransactionWebhook(event.entity_id, payload);
        break;
      default:
        console.log(`Unknown webhook event type: ${event.event_type}`);
    }

    // Mark as processed
    await query(
      'UPDATE xero_webhook_events SET processed = true, processed_at = CURRENT_TIMESTAMP WHERE id = $1',
      [eventId]
    );

    return true;
  } catch (error) {
    console.error('Error processing webhook event:', error);
    return false;
  }
}

/**
 * Handle invoice webhook
 */
async function handleInvoiceWebhook(entityId: string, payload: any): Promise<void> {
  // Update invoice status, amounts, etc.
  // This would sync invoice changes from Xero to local database
  if (payload.InvoiceID) {
    // In a full implementation, you would fetch the invoice from Xero and update the local database
    console.log(`Processing invoice webhook for ${payload.InvoiceID}`);
  }
}

/**
 * Handle payment webhook
 */
async function handlePaymentWebhook(entityId: string, payload: any): Promise<void> {
  // Update payment status, link to invoices
  if (payload.PaymentID) {
    console.log(`Processing payment webhook for ${payload.PaymentID}`);
  }
}

/**
 * Handle contact webhook
 */
async function handleContactWebhook(entityId: string, payload: any): Promise<void> {
  // Update client information
  if (payload.ContactID) {
    const result = await query(
      'UPDATE clients SET updated_at = CURRENT_TIMESTAMP WHERE xero_contact_id = $1',
      [payload.ContactID]
    );
    console.log(`Processing contact webhook for ${payload.ContactID}`);
  }
}

/**
 * Handle bill webhook
 */
async function handleBillWebhook(entityId: string, payload: any): Promise<void> {
  if (payload.InvoiceID) {
    console.log(`Processing bill webhook for ${payload.InvoiceID}`);
  }
}

/**
 * Handle purchase order webhook
 */
async function handlePurchaseOrderWebhook(entityId: string, payload: any): Promise<void> {
  if (payload.PurchaseOrderID) {
    console.log(`Processing purchase order webhook for ${payload.PurchaseOrderID}`);
  }
}

/**
 * Handle bank transaction webhook
 */
async function handleBankTransactionWebhook(entityId: string, payload: any): Promise<void> {
  if (payload.BankTransactionID) {
    console.log(`Processing bank transaction webhook for ${payload.BankTransactionID}`);
  }
}

/**
 * Get webhook subscription status
 */
export async function getWebhookStatus(): Promise<any> {
  // In a full implementation, this would query Xero API for webhook subscription status
  return {
    subscribed: false,
    events: [],
  };
}

/**
 * Get webhook events
 */
export async function getWebhookEvents(filters: {
  event_type?: string;
  processed?: boolean;
  date_from?: string;
  date_to?: string;
}): Promise<any[]> {
  let sql = `
    SELECT * FROM xero_webhook_events
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (filters.event_type) {
    sql += ` AND event_type = $${paramCount++}`;
    params.push(filters.event_type);
  }

  if (filters.processed !== undefined) {
    sql += ` AND processed = $${paramCount++}`;
    params.push(filters.processed);
  }

  if (filters.date_from) {
    sql += ` AND created_at >= $${paramCount++}`;
    params.push(filters.date_from);
  }

  if (filters.date_to) {
    sql += ` AND created_at <= $${paramCount++}`;
    params.push(filters.date_to);
  }

  sql += ' ORDER BY created_at DESC LIMIT 100';

  const result = await query(sql, params);
  return result.rows;
}

--- FILE: backend/src/middleware/__tests__/auth.test.ts ---
import jwt from 'jsonwebtoken';
import { env } from '../../config/env';

// Mock the database query function
jest.mock('../../db', () => ({
  query: jest.fn(),
}));

import { query } from '../../db';
import { authenticate, AuthRequest } from '../auth';
import { Response, NextFunction } from 'express';

describe('Authentication Middleware', () => {
  let mockRequest: Partial<AuthRequest>;
  let mockResponse: Partial<Response>;
  let nextFunction: NextFunction;

  beforeEach(() => {
    mockRequest = {
      headers: {},
    };
    mockResponse = {
      status: jest.fn().mockReturnThis(),
      json: jest.fn().mockReturnThis(),
    };
    nextFunction = jest.fn();
    jest.clearAllMocks();
  });

  describe('authenticate middleware', () => {
    it('should call next() when valid token is provided', async () => {
      const userId = 'test-user-id';
      const userEmail = 'test@example.com';
      const userName = 'Test User';
      const userRole = 'admin';

      // Create a valid token
      const token = jwt.sign(
        { id: userId, email: userEmail, name: userName, role: userRole },
        env.JWT_SECRET,
        { expiresIn: '7d' }
      );

      mockRequest.headers = {
        authorization: `Bearer ${token}`,
      };

      // Mock database query for permissions
      (query as jest.Mock).mockResolvedValueOnce({
        rows: [
          { permission: 'can_view_dashboard' },
          { permission: 'can_manage_users' },
        ],
      });

      await authenticate(
        mockRequest as AuthRequest,
        mockResponse as Response,
        nextFunction
      );

      expect(nextFunction).toHaveBeenCalled();
      expect(mockResponse.status).not.toHaveBeenCalled();
      expect(mockRequest.user).toBeDefined();
      expect(mockRequest.user?.id).toBe(userId);
      expect(mockRequest.user?.email).toBe(userEmail);
      expect(mockRequest.user?.role).toBe(userRole);
    });

    it('should return 401 when no token is provided', async () => {
      mockRequest.headers = {};

      await authenticate(
        mockRequest as AuthRequest,
        mockResponse as Response,
        nextFunction
      );

      expect(mockResponse.status).toHaveBeenCalledWith(401);
      expect(mockResponse.json).toHaveBeenCalledWith({
        error: 'No token provided',
      });
      expect(nextFunction).not.toHaveBeenCalled();
    });

    it('should return 401 when token format is invalid', async () => {
      mockRequest.headers = {
        authorization: 'InvalidFormat token',
      };

      await authenticate(
        mockRequest as AuthRequest,
        mockResponse as Response,
        nextFunction
      );

      expect(mockResponse.status).toHaveBeenCalledWith(401);
      expect(nextFunction).not.toHaveBeenCalled();
    });

    it('should return 401 when token is expired', async () => {
      // Create an expired token
      const expiredToken = jwt.sign(
        { id: 'test-id', email: 'test@example.com', name: 'Test', role: 'user' },
        env.JWT_SECRET,
        { expiresIn: '-1h' } // Expired 1 hour ago
      );

      mockRequest.headers = {
        authorization: `Bearer ${expiredToken}`,
      };

      await authenticate(
        mockRequest as AuthRequest,
        mockResponse as Response,
        nextFunction
      );

      expect(mockResponse.status).toHaveBeenCalledWith(401);
      expect(mockResponse.json).toHaveBeenCalledWith({
        error: 'Token expired',
      });
      expect(nextFunction).not.toHaveBeenCalled();
    });

    it('should return 401 when token is invalid', async () => {
      mockRequest.headers = {
        authorization: 'Bearer invalid-token-string',
      };

      await authenticate(
        mockRequest as AuthRequest,
        mockResponse as Response,
        nextFunction
      );

      expect(mockResponse.status).toHaveBeenCalledWith(401);
      expect(mockResponse.json).toHaveBeenCalledWith({
        error: 'Invalid token',
      });
      expect(nextFunction).not.toHaveBeenCalled();
    });

    it('should load user permissions from database', async () => {
      const userId = 'test-user-id';
      const token = jwt.sign(
        { id: userId, email: 'test@example.com', name: 'Test', role: 'admin' },
        env.JWT_SECRET,
        { expiresIn: '7d' }
      );

      mockRequest.headers = {
        authorization: `Bearer ${token}`,
      };

      const mockPermissions = [
        { permission: 'can_view_dashboard' },
        { permission: 'can_manage_users' },
        { permission: 'can_view_financials' },
      ];

      (query as jest.Mock).mockResolvedValueOnce({
        rows: mockPermissions,
      });

      await authenticate(
        mockRequest as AuthRequest,
        mockResponse as Response,
        nextFunction
      );

      expect(query).toHaveBeenCalledWith(
        'SELECT permission FROM user_permissions WHERE user_id = $1 AND granted = true',
        [userId]
      );
      expect(mockRequest.user?.permissions).toEqual([
        'can_view_dashboard',
        'can_manage_users',
        'can_view_financials',
      ]);
    });
  });
});
--- FILE: backend/src/middleware/asyncHandler.ts ---
import { Request, Response, NextFunction } from 'express';

/**
 * Async route handler wrapper
 * Automatically catches promise rejections and forwards them to error handling middleware
 * 
 * Usage:
 *   router.get('/route', asyncHandler(async (req, res) => {
 *     // async code here
 *   }));
 */
export const asyncHandler = (
  fn: (req: Request, res: Response, next: NextFunction) => Promise<any>
) => {
  return (req: Request, res: Response, next: NextFunction) => {
    Promise.resolve(fn(req, res, next)).catch(next);
  };
};
--- FILE: backend/src/middleware/auth.ts ---
import { Request, Response, NextFunction } from 'express';
import jwt from 'jsonwebtoken';
import { query } from '../db';
import { env } from '../config/env';

export interface AuthRequest extends Request {
  user?: {
    id: string;
    email: string;
    name: string;
    role: 'admin' | 'manager' | 'user';
    permissions: string[];
  };
}

export const authenticate = async (req: AuthRequest, res: Response, next: NextFunction) => {
  try {
    const authHeader = req.headers.authorization;
    
    if (!authHeader || !authHeader.startsWith('Bearer ')) {
      return res.status(401).json({ error: 'No token provided' });
    }
    
    const token = authHeader.split(' ')[1];
    
    const decoded = jwt.verify(token, env.JWT_SECRET) as {
      id: string;
      email: string;
      name: string;
      role: string;
    };
    
    // Get user permissions
    const permResult = await query(
      'SELECT permission FROM user_permissions WHERE user_id = $1 AND granted = true',
      [decoded.id]
    );
    
    const permissions = permResult.rows.map(p => p.permission);
    
    req.user = {
      id: decoded.id,
      email: decoded.email,
      name: decoded.name,
      role: decoded.role as 'admin' | 'manager' | 'user',
      permissions
    };
    
    next();
  } catch (error) {
    if (error instanceof jwt.TokenExpiredError) {
      return res.status(401).json({ error: 'Token expired' });
    }
    return res.status(401).json({ error: 'Invalid token' });
  }
};

export const requireRole = (...roles: string[]) => {
  return (req: AuthRequest, res: Response, next: NextFunction) => {
    if (!req.user) {
      return res.status(401).json({ error: 'Not authenticated' });
    }
    
    if (!roles.includes(req.user.role)) {
      return res.status(403).json({ error: 'Insufficient permissions' });
    }
    
    next();
  };
};

export const requirePermission = (...permissions: string[]) => {
  return (req: AuthRequest, res: Response, next: NextFunction) => {
    if (!req.user) {
      return res.status(401).json({ error: 'Not authenticated' });
    }
    
    // Admins have all permissions
    if (req.user.role === 'admin') {
      return next();
    }
    
    const hasPermission = permissions.some(p => req.user!.permissions.includes(p));
    
    if (!hasPermission) {
      return res.status(403).json({ error: 'Permission denied' });
    }
    
    next();
  };
};

export const optionalAuth = async (req: AuthRequest, res: Response, next: NextFunction) => {
  try {
    const authHeader = req.headers.authorization;
    
    if (authHeader && authHeader.startsWith('Bearer ')) {
      const token = authHeader.split(' ')[1];
      const decoded = jwt.verify(token, env.JWT_SECRET) as {
        id: string;
        email: string;
        name: string;
        role: string;
      };
      
      const permResult = await query(
        'SELECT permission FROM user_permissions WHERE user_id = $1 AND granted = true',
        [decoded.id]
      );
      
      req.user = {
        id: decoded.id,
        email: decoded.email,
        name: decoded.name,
        role: decoded.role as 'admin' | 'manager' | 'user',
        permissions: permResult.rows.map(p => p.permission)
      };
    }
    
    next();
  } catch (error) {
    // Silently continue without auth
    next();
  }
};
--- FILE: backend/src/middleware/errorHandler.ts ---
import { Request, Response, NextFunction } from 'express';
import { AppError, mapDatabaseError, createErrorResponse } from '../lib/errors';
import { env } from '../config/env';
import { log } from '../lib/logger';
import { ValidationError as ExpressValidationError } from 'express-validator';

/**
 * Centralized error handling middleware
 * Handles all errors and returns standardized error responses
 */
export const errorHandler = (
  err: Error | AppError,
  req: Request,
  res: Response,
  next: NextFunction
) => {
  // Get request ID if available
  const requestId = (req as any).requestId;

  // Handle express-validator errors
  if (err.name === 'ValidationError' || Array.isArray((err as any).errors)) {
    const validationErrors = (err as any).errors || [];
    return res.status(400).json({
      error: 'Validation failed',
      code: 'VALIDATION_ERROR',
      details: validationErrors,
      requestId,
    });
  }

  // Handle PostgreSQL errors
  if ((err as any).code && (err as any).code.match(/^[0-9A-Z]{5}$/)) {
    const dbError = mapDatabaseError(err);
    log.error('Database error', dbError, {
      requestId,
      method: req.method,
      url: req.url,
      ip: req.ip,
      userId: (req as any).user?.id,
    });

    return res.status(dbError.statusCode).json(createErrorResponse(dbError, requestId));
  }

  // Handle AppError instances
  if (err instanceof AppError) {
    // Only log non-operational errors (unexpected errors)
    if (!err.isOperational) {
      log.error('Application error', err, {
        requestId,
        method: req.method,
        url: req.url,
        ip: req.ip,
        userId: (req as any).user?.id,
        stack: err.stack,
      });
    } else {
      // Log operational errors at warn level (expected errors like validation)
      log.warn('Operational error', {
        requestId,
        method: req.method,
        url: req.url,
        code: err.code,
        message: err.message,
        userId: (req as any).user?.id,
      });
    }

    return res.status(err.statusCode).json(createErrorResponse(err, requestId));
  }

  // Handle JWT errors
  if (err.name === 'JsonWebTokenError' || err.name === 'TokenExpiredError') {
    log.warn('JWT error', {
      requestId,
      method: req.method,
      url: req.url,
      error: err.name,
      message: err.message,
    });

    return res.status(401).json({
      error: err.name === 'TokenExpiredError' ? 'Token expired' : 'Invalid token',
      code: 'UNAUTHORIZED',
      requestId,
    });
  }

  // Handle multer errors (file upload)
  if (err.name === 'MulterError') {
    const multerError = err as any;
    let message = 'File upload error';
    
    if (multerError.code === 'LIMIT_FILE_SIZE') {
      message = 'File size exceeds maximum allowed size';
    } else if (multerError.code === 'LIMIT_FILE_COUNT') {
      message = 'Too many files uploaded';
    } else if (multerError.code === 'LIMIT_UNEXPECTED_FILE') {
      message = 'Unexpected file field';
    }

    log.warn('File upload error', {
      requestId,
      method: req.method,
      url: req.url,
      code: multerError.code,
      message,
    });

    return res.status(400).json({
      error: message,
      code: 'FILE_UPLOAD_ERROR',
      details: { code: multerError.code },
      requestId,
    });
  }

  // Handle unknown errors
  log.error('Unhandled error', err, {
    requestId,
    method: req.method,
    url: req.url,
    ip: req.ip,
    userId: (req as any).user?.id,
    stack: err.stack,
  });

  // Return generic error response
  // Never expose internal error details in production
  const errorResponse: any = {
    error: 'Internal server error',
    code: 'INTERNAL_ERROR',
    requestId,
  };

  // Only include error details in development
  if (env.NODE_ENV === 'development') {
    errorResponse.details = {
      message: err.message,
      stack: err.stack,
    };
  }

  return res.status(500).json(errorResponse);
};
--- FILE: backend/src/middleware/requestLogger.ts ---
import { Request, Response, NextFunction } from 'express';
import { v4 as uuidv4 } from 'uuid';
import { log } from '../lib/logger';

/**
 * Request ID middleware
 * Generates a unique request ID for each request and attaches it to the request object
 * This ID is included in all logs and error responses for traceability
 */
export const requestIdMiddleware = (
  req: Request,
  res: Response,
  next: NextFunction
) => {
  // Generate or use existing request ID from header (for distributed systems)
  const requestId = req.headers['x-request-id'] as string || uuidv4();
  
  // Attach to request object
  (req as any).requestId = requestId;
  
  // Add to response header
  res.setHeader('X-Request-ID', requestId);
  
  next();
};

/**
 * Request logging middleware
 * Logs all HTTP requests with relevant context information
 * Excludes health check and other noise endpoints
 */
export const requestLogger = (
  req: Request,
  res: Response,
  next: NextFunction
) => {
  const startTime = Date.now();
  const requestId = (req as any).requestId;

  // Skip logging for health checks and other noise
  const skipPaths = ['/api/health', '/health'];
  if (skipPaths.includes(req.path)) {
    return next();
  }

  // Log request start
  log.info('HTTP Request', {
    requestId,
    method: req.method,
    url: req.url,
    path: req.path,
    ip: req.ip,
    userAgent: req.get('user-agent'),
    userId: (req as any).user?.id,
  });

  // Override res.end to log response
  const originalEnd = res.end.bind(res);
  (res as any).end = function (chunk?: any, encoding?: any, cb?: () => void): Response {
    const duration = Date.now() - startTime;
    
    log.info('HTTP Response', {
      requestId,
      method: req.method,
      url: req.url,
      statusCode: res.statusCode,
      duration: `${duration}ms`,
      userId: (req as any).user?.id,
    });

    // Call original end and return the result
    return originalEnd(chunk, encoding, cb);
  };

  next();
};
--- FILE: backend/src/middleware/sanitize.ts ---
import { Request, Response, NextFunction } from 'express';

/**
 * Input sanitization middleware
 * Removes potentially dangerous characters and HTML/script tags from user input
 * 
 * Note: This is a basic sanitization. For production, consider using a library like DOMPurify
 * or validator.js for more comprehensive sanitization.
 */

/**
 * Sanitizes a string by removing HTML tags and dangerous characters
 */
function sanitizeString(input: string): string {
  if (typeof input !== 'string') {
    return input;
  }

  // Remove HTML tags
  let sanitized = input.replace(/<[^>]*>/g, '');
  
  // Remove script tags and their content (more aggressive)
  sanitized = sanitized.replace(/<script\b[^<]*(?:(?!<\/script>)<[^<]*)*<\/script>/gi, '');
  
  // Remove event handlers (onclick, onerror, etc.)
  sanitized = sanitized.replace(/\s*on\w+\s*=\s*["'][^"']*["']/gi, '');
  
  // Remove javascript: and data: protocols
  sanitized = sanitized.replace(/javascript:/gi, '');
  sanitized = sanitized.replace(/data:text\/html/gi, '');
  
  // Trim whitespace
  sanitized = sanitized.trim();
  
  return sanitized;
}

/**
 * Recursively sanitizes an object's string values
 */
function sanitizeObject(obj: any): any {
  if (obj === null || obj === undefined) {
    return obj;
  }

  if (typeof obj === 'string') {
    return sanitizeString(obj);
  }

  if (Array.isArray(obj)) {
    return obj.map(item => sanitizeObject(item));
  }

  if (typeof obj === 'object') {
    const sanitized: any = {};
    for (const key in obj) {
      if (Object.prototype.hasOwnProperty.call(obj, key)) {
        // Skip sanitization for certain fields that may legitimately contain HTML
        // or special characters (like file paths, URLs, etc.)
        const skipSanitization = [
          'password',
          'password_hash',
          'token',
          'access_token',
          'refresh_token',
          'file_path',
          'url',
          'image_url',
          'redirect_uri',
          'details', // JSON fields that may contain structured data
        ];

        if (skipSanitization.includes(key.toLowerCase())) {
          sanitized[key] = obj[key];
        } else {
          sanitized[key] = sanitizeObject(obj[key]);
        }
      }
    }
    return sanitized;
  }

  return obj;
}

/**
 * Middleware to sanitize request body, query, and params
 * 
 * Note: This middleware should be used carefully as it modifies the request object.
 * Consider using it selectively on routes that accept user-generated content.
 */
export const sanitizeInput = (
  req: Request,
  res: Response,
  next: NextFunction
) => {
  // Sanitize request body
  if (req.body && typeof req.body === 'object') {
    req.body = sanitizeObject(req.body);
  }

  // Sanitize query parameters
  if (req.query && typeof req.query === 'object') {
    req.query = sanitizeObject(req.query);
  }

  // Sanitize route parameters (be careful with UUIDs and IDs)
  if (req.params && typeof req.params === 'object') {
    // Only sanitize string params, preserve IDs as-is
    const sanitizedParams: any = {};
    for (const key in req.params) {
      if (Object.prototype.hasOwnProperty.call(req.params, key)) {
        const value = req.params[key];
        // Don't sanitize IDs (UUIDs, numeric IDs)
        if (key.toLowerCase().includes('id') || /^[0-9a-f-]{36}$/i.test(value)) {
          sanitizedParams[key] = value;
        } else {
          sanitizedParams[key] = sanitizeString(value);
        }
      }
    }
    req.params = sanitizedParams;
  }

  next();
};

/**
 * Selective sanitization - only sanitize specific fields
 * Use this when you want to preserve most data but sanitize specific fields
 */
export const sanitizeFields = (fields: string[]) => {
  return (req: Request, res: Response, next: NextFunction) => {
    if (req.body && typeof req.body === 'object') {
      for (const field of fields) {
        if (req.body[field] && typeof req.body[field] === 'string') {
          req.body[field] = sanitizeString(req.body[field]);
        }
      }
    }
    next();
  };
};
--- FILE: backend/src/middleware/upload.ts ---
import multer from 'multer';
import path from 'path';
import fs from 'fs';
import { v4 as uuidv4 } from 'uuid';
import { sanitizeProjectId } from './validateProject';
import { Readable } from 'stream';

/**
 * Validates UUID format
 */
function isValidUUID(uuid: string): boolean {
  const uuidRegex = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;
  return uuidRegex.test(uuid);
}

// Use memory storage for all uploads - files will be streamed directly to storage provider
// This avoids filesystem permission issues and works with all storage drivers (local, S3, Google Drive)
const memoryStorage = multer.memoryStorage();

// All uploads use memory storage - no filesystem directory creation needed

const fileFilter = (req: Express.Request, file: Express.Multer.File, cb: multer.FileFilterCallback) => {
  const allowedTypes = ['image/jpeg', 'image/png', 'image/gif', 'image/webp', 'application/pdf'];
  
  if (allowedTypes.includes(file.mimetype)) {
    cb(null, true);
  } else {
    cb(new Error('Invalid file type. Only images and PDFs are allowed.'));
  }
};

// Enhanced file filter with size and dimension validation
const enhancedFileFilter = (req: Express.Request, file: Express.Multer.File, cb: multer.FileFilterCallback) => {
  const allowedTypes = ['image/jpeg', 'image/png', 'image/gif', 'image/webp'];
  
  if (!allowedTypes.includes(file.mimetype)) {
    return cb(new Error('Invalid file type. Only images (JPEG, PNG, GIF, WebP) are allowed.'));
  }
  
  // File size is already limited by multer limits, but we can add additional checks here
  cb(null, true);
};

export const upload = multer({
  storage: memoryStorage,
  fileFilter,
  limits: {
    fileSize: 10 * 1024 * 1024 // 10MB
  }
});

// Project-specific upload for timesheet images (uses memory storage)
export const projectUpload = multer({
  storage: memoryStorage,
  fileFilter,
  limits: {
    fileSize: 10 * 1024 * 1024 // 10MB
  }
});

export const logoUpload = multer({
  storage: memoryStorage,
  fileFilter: (req, file, cb) => {
    const allowedTypes = ['image/jpeg', 'image/png', 'image/svg+xml', 'image/webp'];
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true);
    } else {
      cb(new Error('Invalid file type. Only images are allowed.'));
    }
  },
  limits: {
    fileSize: 5 * 1024 * 1024 // 5MB
  }
});

export const faviconUpload = multer({
  storage: memoryStorage,
  fileFilter: (req, file, cb) => {
    const allowedTypes = ['image/x-icon', 'image/vnd.microsoft.icon', 'image/png', 'image/svg+xml', 'image/jpeg'];
    if (allowedTypes.includes(file.mimetype) || file.originalname.toLowerCase().endsWith('.ico')) {
      cb(null, true);
    } else {
      cb(new Error('Invalid file type. Only ICO, PNG, SVG, or JPEG images are allowed for favicons.'));
    }
  },
  limits: {
    fileSize: 2 * 1024 * 1024 // 2MB (favicons should be small)
  }
});

// File filter for project files - allows images, PDFs, and common document types
const fileUploadFilter = (req: Express.Request, file: Express.Multer.File, cb: multer.FileFilterCallback) => {
  const allowedTypes = [
    'image/jpeg', 'image/png', 'image/gif', 'image/webp',
    'application/pdf',
    'application/msword',
    'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    'application/vnd.ms-excel',
    'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    'text/plain',
    'text/csv'
  ];
  
  if (allowedTypes.includes(file.mimetype)) {
    cb(null, true);
  } else {
    cb(new Error(`Invalid file type: ${file.mimetype}. Allowed types: images, PDFs, documents, spreadsheets, text files.`));
  }
};

// File upload middleware for project files
// Uses memory storage - files are streamed directly to storage provider after validation
export const fileUpload = multer({
  storage: memoryStorage,
  fileFilter: fileUploadFilter,
  limits: {
    fileSize: 50 * 1024 * 1024 // 50MB
  }
});

// Helper function to convert Buffer to Readable stream for storage provider
export function bufferToStream(buffer: Buffer): Readable {
  const stream = new Readable();
  stream.push(buffer);
  stream.push(null);
  return stream;
}
--- FILE: backend/src/middleware/validateProject.ts ---
import { Request, Response, NextFunction } from 'express';
import { query } from '../db';
import { ValidationError, ForbiddenError } from '../lib/errors';
import { AuthRequest } from './auth';

/**
 * Validates UUID format
 */
function isValidUUID(uuid: string): boolean {
  const uuidRegex = /^[0-9a-f]{8}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{4}-[0-9a-f]{12}$/i;
  return uuidRegex.test(uuid);
}

/**
 * Sanitizes project_id to prevent path traversal
 * Ensures project_id is a valid UUID and doesn't contain path traversal sequences
 */
export function sanitizeProjectId(projectId: string): string {
  if (!projectId || typeof projectId !== 'string') {
    throw new ValidationError('Invalid project_id');
  }

  // Remove any path traversal attempts
  const sanitized = projectId.replace(/\.\./g, '').replace(/\//g, '').replace(/\\/g, '');

  // Validate UUID format
  if (!isValidUUID(sanitized)) {
    throw new ValidationError('project_id must be a valid UUID');
  }

  return sanitized;
}

/**
 * Middleware to validate project_id and verify user has access
 * Must be used after authentication middleware
 */
export const validateProjectAccess = async (
  req: AuthRequest,
  res: Response,
  next: NextFunction
) => {
  try {
    const projectId = req.body?.project_id || req.params?.project_id;

    if (!projectId) {
      return next(new ValidationError('project_id is required'));
    }

    // Sanitize and validate UUID format
    const sanitizedProjectId = sanitizeProjectId(projectId);

    // Verify project exists
    const projectResult = await query(
      'SELECT id, client_id FROM projects WHERE id = $1',
      [sanitizedProjectId]
    );

    if (projectResult.rows.length === 0) {
      return next(new ValidationError('Project not found'));
    }

    const project = projectResult.rows[0];

    // Check if user has access to the project
    // Admins and managers can access all projects
    // Regular users can only access projects they're assigned to (via timesheets)
    if (req.user!.role === 'admin' || req.user!.role === 'manager') {
      // Update request with sanitized project_id
      if (req.body) req.body.project_id = sanitizedProjectId;
      if (req.params) req.params.project_id = sanitizedProjectId;
      return next();
    }

    // For regular users, check if they have any timesheets for this project
    // This is a simple access check - you may want to implement a more sophisticated
    // permission system with explicit project assignments
    const accessResult = await query(
      'SELECT 1 FROM timesheets WHERE project_id = $1 AND user_id = $2 LIMIT 1',
      [sanitizedProjectId, req.user!.id]
    );

    if (accessResult.rows.length === 0) {
      return next(new ForbiddenError('You do not have access to this project'));
    }

    // Update request with sanitized project_id
    if (req.body) req.body.project_id = sanitizedProjectId;
    if (req.params) req.params.project_id = sanitizedProjectId;

    next();
  } catch (error) {
    next(error);
  }
};

/**
 * Middleware to validate project_id format only (no access check)
 * Use this when you need to validate format but access is checked elsewhere
 */
export const validateProjectId = (
  req: Request,
  res: Response,
  next: NextFunction
) => {
  try {
    const projectId = req.body?.project_id || req.params?.project_id;

    if (!projectId) {
      return next(new ValidationError('project_id is required'));
    }

    const sanitized = sanitizeProjectId(projectId);

    // Update request with sanitized project_id
    if (req.body) req.body.project_id = sanitized;
    if (req.params) req.params.project_id = sanitized;

    next();
  } catch (error) {
    next(error);
  }
};
--- FILE: backend/src/routes/activityTypes.ts ---
import { Router, Response } from 'express';
import { body, validationResult } from 'express-validator';
import { query } from '../db';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';

const router = Router();

// Get all activity types
router.get('/', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { active_only } = req.query;
    
    let sql = `
      SELECT at.*,
        (SELECT COUNT(*) FROM timesheets t WHERE t.activity_type_id = at.id) as usage_count
      FROM activity_types at
      WHERE 1=1
    `;

    if (active_only === 'true') {
      sql += ' AND at.is_active = true';
    }

    sql += ' ORDER BY at.name ASC';

    const result = await query(sql);
    res.json(result.rows);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch activity types' });
  }
});

// Get single activity type
router.get('/:id', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT at.*,
        (SELECT COUNT(*) FROM timesheets t WHERE t.activity_type_id = at.id) as usage_count
       FROM activity_types at
       WHERE at.id = $1`,
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Activity type not found' });
    }

    res.json(result.rows[0]);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch activity type' });
  }
});

// Create activity type (admin only)
router.post('/', authenticate, requirePermission('can_edit_activity_types'),
  body('name').trim().notEmpty(),
  body('icon').trim().notEmpty(),
  body('color').trim().notEmpty(),
  body('hourly_rate').optional().isFloat({ min: 0 }),
  async (req: AuthRequest, res: Response) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { name, icon, color, hourly_rate = 0 } = req.body;

    try {
      const result = await query(
        `INSERT INTO activity_types (name, icon, color, hourly_rate)
         VALUES ($1, $2, $3, $4)
         RETURNING *`,
        [name, icon, color, hourly_rate]
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'create', 'activity_type', result.rows[0].id, JSON.stringify({ name })]
      );

      res.status(201).json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to create activity type' });
    }
  }
);

// Update activity type (admin only)
router.put('/:id', authenticate, requirePermission('can_edit_activity_types'),
  async (req: AuthRequest, res: Response) => {
    const { name, icon, color, hourly_rate, is_active } = req.body;

    try {
      const updates: string[] = [];
      const values: any[] = [];
      let paramCount = 1;

      const fields = { name, icon, color, hourly_rate, is_active };
      
      for (const [key, value] of Object.entries(fields)) {
        if (value !== undefined) {
          updates.push(`${key} = $${paramCount++}`);
          values.push(value);
        }
      }

      if (updates.length === 0) {
        return res.status(400).json({ error: 'No updates provided' });
      }

      updates.push('updated_at = CURRENT_TIMESTAMP');
      values.push(req.params.id);

      const result = await query(
        `UPDATE activity_types SET ${updates.join(', ')} WHERE id = $${paramCount} RETURNING *`,
        values
      );

      if (result.rows.length === 0) {
        return res.status(404).json({ error: 'Activity type not found' });
      }

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'update', 'activity_type', req.params.id, JSON.stringify(fields)]
      );

      res.json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to update activity type' });
    }
  }
);

// Delete activity type (admin only)
router.delete('/:id', authenticate, requirePermission('can_edit_activity_types'), async (req: AuthRequest, res: Response) => {
  try {
    // Check if activity type is in use
    const timesheets = await query(
      'SELECT COUNT(*) FROM timesheets WHERE activity_type_id = $1',
      [req.params.id]
    );

    if (parseInt(timesheets.rows[0].count) > 0) {
      return res.status(400).json({ 
        error: 'Cannot delete activity type with existing timesheets. Deactivate instead.',
        usage_count: parseInt(timesheets.rows[0].count)
      });
    }

    const result = await query(
      'DELETE FROM activity_types WHERE id = $1 RETURNING id, name',
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Activity type not found' });
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'delete', 'activity_type', req.params.id, JSON.stringify({ name: result.rows[0].name })]
    );

    res.json({ message: 'Activity type deleted' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to delete activity type' });
  }
});

export default router;
--- FILE: backend/src/routes/auth.ts ---
import { Router, Response } from 'express';
import bcrypt from 'bcryptjs';
import jwt from 'jsonwebtoken';
import { body, validationResult } from 'express-validator';
import rateLimit from 'express-rate-limit';
import { query } from '../db';
import { authenticate, AuthRequest } from '../middleware/auth';
import { env } from '../config/env';
import { getDefaultPermissions } from '../lib/permissions';
import { log } from '../lib/logger';
import { AUTH_CONSTANTS, RATE_LIMIT_CONSTANTS } from '../lib/constants';
import { asyncHandler } from '../middleware/asyncHandler';
import { UnauthorizedError, ValidationError as AppValidationError } from '../lib/errors';

const router = Router();

// Rate limiting for authentication endpoints
// Stricter limits to prevent brute force attacks
const authRateLimit = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 5, // Limit each IP to 5 requests per windowMs
  message: 'Too many authentication attempts, please try again later.',
  standardHeaders: true,
  legacyHeaders: false,
  skipSuccessfulRequests: true, // Don't count successful requests
});

// Rate limiting for password reset (more lenient)
const passwordResetRateLimit = rateLimit({
  windowMs: 60 * 60 * 1000, // 1 hour
  max: 3, // Limit each IP to 3 password reset requests per hour
  message: 'Too many password reset requests, please try again later.',
  standardHeaders: true,
  legacyHeaders: false,
});

// Register
router.post('/register',
  body('email').isEmail().normalizeEmail(),
  body('password').isLength({ min: AUTH_CONSTANTS.MIN_PASSWORD_LENGTH }),
  body('name').trim().notEmpty(),
  async (req, res) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { email, password, name, role = 'user' } = req.body;

    try {
      // Check if user exists
      const existingUser = await query('SELECT id FROM users WHERE email = $1', [email]);
      if (existingUser.rows.length > 0) {
        return res.status(400).json({ error: 'Email already registered' });
      }

      // Hash password
      const passwordHash = await bcrypt.hash(password, AUTH_CONSTANTS.BCRYPT_ROUNDS);

      // Create user
      const result = await query(
        `INSERT INTO users (email, password_hash, name, role) 
         VALUES ($1, $2, $3, $4) 
         RETURNING id, email, name, role, created_at`,
        [email, passwordHash, name, role]
      );

      const user = result.rows[0];

      // Set default permissions based on role
      const defaultPermissions = getDefaultPermissions(role);
      for (const permission of defaultPermissions) {
        await query(
          'INSERT INTO user_permissions (user_id, permission, granted) VALUES ($1, $2, true)',
          [user.id, permission]
        );
      }

      // Generate token
      const token = jwt.sign(
        { id: user.id, email: user.email, name: user.name, role: user.role },
        env.JWT_SECRET,
        { expiresIn: '7d' }
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [user.id, 'register', 'user', user.id, JSON.stringify({ email })]
      );

      res.status(201).json({
        user: {
          id: user.id,
          email: user.email,
          name: user.name,
          role: user.role,
          permissions: defaultPermissions
        },
        token
      });
    } catch (error) {
      log.error('Registration error', error, { email: req.body.email });
      res.status(500).json({ error: 'Registration failed' });
    }
  }
);

// Login
router.post('/login',
  authRateLimit,
  body('email').isEmail().normalizeEmail(),
  body('password').notEmpty(),
  async (req, res) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { email, password } = req.body;

    try {
      // Find user
      const result = await query(
        'SELECT id, email, password_hash, name, role, is_active FROM users WHERE email = $1',
        [email]
      );

      if (result.rows.length === 0) {
        return res.status(401).json({ error: 'Invalid credentials' });
      }

      const user = result.rows[0];

      if (!user.is_active) {
        return res.status(401).json({ error: 'Account is deactivated' });
      }

      // Verify password
      const isValid = await bcrypt.compare(password, user.password_hash);
      if (!isValid) {
        return res.status(401).json({ error: 'Invalid credentials' });
      }

      // Get permissions
      const permResult = await query(
        'SELECT permission FROM user_permissions WHERE user_id = $1 AND granted = true',
        [user.id]
      );
      const permissions = permResult.rows.map(p => p.permission);

      // Generate token
      const token = jwt.sign(
        { id: user.id, email: user.email, name: user.name, role: user.role },
        env.JWT_SECRET,
        { expiresIn: '7d' }
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, details, ip_address) 
         VALUES ($1, $2, $3, $4, $5)`,
        [user.id, 'login', 'user', JSON.stringify({ email }), req.ip]
      );

      res.json({
        user: {
          id: user.id,
          email: user.email,
          name: user.name,
          role: user.role,
          permissions
        },
        token
      });
    } catch (error) {
      log.error('Login error', error, { email: req.body.email });
      res.status(500).json({ error: 'Login failed' });
    }
  }
);

// Refresh token
router.post('/refresh', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const token = jwt.sign(
      { id: req.user!.id, email: req.user!.email, name: req.user!.name, role: req.user!.role },
      env.JWT_SECRET,
      { expiresIn: AUTH_CONSTANTS.JWT_EXPIRATION }
    );

    res.json({ token });
  } catch (error) {
    res.status(500).json({ error: 'Token refresh failed' });
  }
});

// Forgot password
router.post('/forgot-password',
  body('email').isEmail().normalizeEmail(),
  async (req, res) => {
    const { email } = req.body;

    try {
      const result = await query('SELECT id, name FROM users WHERE email = $1', [email]);
      
      if (result.rows.length === 0) {
        // Don't reveal if email exists
        return res.json({ message: 'If an account exists, a reset link will be sent' });
      }

      // Generate reset token
      const resetToken = jwt.sign(
        { id: result.rows[0].id, type: 'password-reset' },
        env.JWT_SECRET,
        { expiresIn: '1h' }
      );

      // Send password reset email
      const { sendPasswordResetEmail } = await import('../lib/email');
      const emailSent = await sendPasswordResetEmail(email, resetToken, result.rows[0].name);

      // Always return success message (don't reveal if email exists)
      // If email failed to send, it's logged to console/server logs
      res.json({ message: 'If an account exists, a reset link will be sent' });
    } catch (error) {
      res.status(500).json({ error: 'Failed to process request' });
    }
  }
);

// Reset password
router.post('/reset-password',
  passwordResetRateLimit,
  body('token').notEmpty(),
  body('password').isLength({ min: AUTH_CONSTANTS.MIN_PASSWORD_LENGTH }),
  async (req, res) => {
    const { token, password } = req.body;

    try {
      const decoded = jwt.verify(token, env.JWT_SECRET) as { id: string; type: string };
      
      if (decoded.type !== 'password-reset') {
        return res.status(400).json({ error: 'Invalid reset token' });
      }

      const passwordHash = await bcrypt.hash(password, AUTH_CONSTANTS.BCRYPT_ROUNDS);
      
      await query(
        'UPDATE users SET password_hash = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
        [passwordHash, decoded.id]
      );

      res.json({ message: 'Password reset successful' });
    } catch (error) {
      if (error instanceof jwt.TokenExpiredError) {
        return res.status(400).json({ error: 'Reset token expired' });
      }
      res.status(400).json({ error: 'Invalid reset token' });
    }
  }
);

// Get current user
router.get('/me', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      'SELECT id, email, name, role, avatar, created_at FROM users WHERE id = $1',
      [req.user!.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'User not found' });
    }

    // Get permissions from database (more reliable than JWT)
    const permResult = await query(
      'SELECT permission FROM user_permissions WHERE user_id = $1 AND granted = true',
      [req.user!.id]
    );
    const permissions = permResult.rows.map(p => p.permission);

    res.json({
      ...result.rows[0],
      permissions
    });
  } catch (error) {
    log.error('Get current user error', error, { userId: req.user?.id });
    res.status(500).json({ error: 'Failed to fetch user' });
  }
});

// Update profile
router.put('/profile', authenticate,
  body('name').optional().trim().notEmpty(),
  body('email').optional().isEmail().normalizeEmail(),
  async (req: AuthRequest, res: Response) => {
    const { name, email, avatar } = req.body;

    try {
      const updates: string[] = [];
      const values: any[] = [];
      let paramCount = 1;

      if (name) {
        updates.push(`name = $${paramCount++}`);
        values.push(name);
      }
      if (email) {
        // Check if email is already taken by another user
        const emailCheck = await query('SELECT id FROM users WHERE email = $1 AND id != $2', [email, req.user!.id]);
        if (emailCheck.rows.length > 0) {
          return res.status(400).json({ error: 'Email already in use' });
        }
        updates.push(`email = $${paramCount++}`);
        values.push(email);
      }
      if (avatar !== undefined) {
        updates.push(`avatar = $${paramCount++}`);
        values.push(avatar);
      }

      if (updates.length === 0) {
        return res.status(400).json({ error: 'No updates provided' });
      }

      updates.push('updated_at = CURRENT_TIMESTAMP');
      values.push(req.user!.id);

      const result = await query(
        `UPDATE users SET ${updates.join(', ')} WHERE id = $${paramCount} 
         RETURNING id, email, name, role, avatar`,
        values
      );

      res.json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to update profile' });
    }
  }
);

// Change password
router.put('/change-password', authenticate,
  body('currentPassword').notEmpty(),
  body('newPassword').isLength({ min: AUTH_CONSTANTS.MIN_PASSWORD_LENGTH }),
  async (req: AuthRequest, res: Response) => {
    const { currentPassword, newPassword } = req.body;

    try {
      const result = await query(
        'SELECT password_hash FROM users WHERE id = $1',
        [req.user!.id]
      );

      if (result.rows.length === 0) {
        return res.status(404).json({ error: 'User not found' });
      }

      const isValid = await bcrypt.compare(currentPassword, result.rows[0].password_hash);
      if (!isValid) {
        return res.status(400).json({ error: 'Current password is incorrect' });
      }

      const newHash = await bcrypt.hash(newPassword, 12);
      await query(
        'UPDATE users SET password_hash = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
        [newHash, req.user!.id]
      );

      res.json({ message: 'Password changed successfully' });
    } catch (error) {
      res.status(500).json({ error: 'Failed to change password' });
    }
  }
);

export default router;
--- FILE: backend/src/routes/backups.ts ---
import { Router, Response } from 'express';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';
import { query } from '../db';
import { createBackup, cleanupOldBackups, getBackupFileStream, getDatabaseConfig } from '../lib/backup';
import { 
  getAuthUrl,
  getGoogleDriveCredentials,
  exchangeCodeForTokens, 
  uploadToGoogleDrive, 
  deleteFromGoogleDrive,
  downloadFromGoogleDrive,
  isGoogleDriveConnected
} from '../lib/googleDrive';
import { exec } from 'child_process';
import { promisify } from 'util';
import fs from 'fs/promises';
import path from 'path';
import dotenv from 'dotenv';
// Suppress dotenv parsing warnings
dotenv.config({ debug: false, override: false });

const execAsync = promisify(exec);
const router = Router();

// Get all backups
router.get('/', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT b.*, u.name as created_by_name
       FROM backups b
       LEFT JOIN users u ON b.created_by = u.id
       ORDER BY b.created_at DESC
       LIMIT 100`
    );

    res.json(result.rows);
  } catch (error: any) {
    console.error('Failed to get backups:', error);
    res.status(500).json({ error: 'Failed to get backups' });
  }
});

// Get single backup
router.get('/:id', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const { id } = req.params;
    const result = await query(
      `SELECT b.*, u.name as created_by_name
       FROM backups b
       LEFT JOIN users u ON b.created_by = u.id
       WHERE b.id = $1`,
      [id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Backup not found' });
    }

    res.json(result.rows[0]);
  } catch (error: any) {
    console.error('Failed to get backup:', error);
    res.status(500).json({ error: 'Failed to get backup' });
  }
});

// Create backup
router.post('/', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const { type = 'full', storage_type = 'local' } = req.body;

    if (!['full', 'database', 'files'].includes(type)) {
      return res.status(400).json({ error: 'Invalid backup type' });
    }

    if (!['local', 'google_drive'].includes(storage_type)) {
      return res.status(400).json({ error: 'Invalid storage type' });
    }

    // Create backup
    let backupResult;
    try {
      backupResult = await createBackup({
        type: type as 'full' | 'database' | 'files',
        userId: req.user!.id,
        storageType: storage_type as 'local' | 'google_drive'
      });
    } catch (error: any) {
      console.error('Backup creation error:', error);
      return res.status(500).json({ 
        error: 'Backup creation failed', 
        details: error.message || 'Unknown error occurred'
      });
    }

    if (!backupResult.success) {
      return res.status(500).json({ 
        error: 'Backup creation failed', 
        details: backupResult.error || 'Unknown error occurred'
      });
    }

    // If Google Drive storage, upload the file
    if (storage_type === 'google_drive' && backupResult.filePath) {
      try {
        const fileName = path.basename(backupResult.filePath);
        const fileId = await uploadToGoogleDrive(
          backupResult.filePath,
          fileName,
          req.user!.id
        );

        // Update backup record with Google Drive file ID
        await query(
          'UPDATE backups SET google_drive_file_id = $1 WHERE id = $2',
          [fileId, backupResult.backupId]
        );

        // Optionally delete local file after upload
        // await fs.unlink(backupResult.filePath);
      } catch (error: any) {
        console.error('Failed to upload to Google Drive:', error);
        // Update backup with error but don't fail the request
        await query(
          'UPDATE backups SET status = $1, error_message = $2 WHERE id = $3',
          ['failed', `Google Drive upload failed: ${error.message}`, backupResult.backupId]
        );
      }
    }

    // Get updated backup record
    const updatedResult = await query(
      'SELECT * FROM backups WHERE id = $1',
      [backupResult.backupId]
    );

    res.json(updatedResult.rows[0]);
  } catch (error: any) {
    console.error('Backup creation error:', error);
    res.status(500).json({ error: 'Failed to create backup', details: error.message });
  }
});

// Download backup
router.get('/:id/download', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const { id } = req.params;
    const result = await query(
      'SELECT * FROM backups WHERE id = $1 AND status = $2',
      [id, 'completed']
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Backup not found or not completed' });
    }

    const backup = result.rows[0];

    // If Google Drive backup, download first
    if (backup.storage_type === 'google_drive' && backup.google_drive_file_id) {
      const tempPath = path.join(process.cwd(), 'backups', `temp-${id}.tar.gz`);
      try {
        await downloadFromGoogleDrive(
          backup.google_drive_file_id,
          tempPath,
          req.user!.id
        );
        backup.file_path = tempPath;
      } catch (error: any) {
        return res.status(500).json({ error: 'Failed to download from Google Drive', details: error.message });
      }
    }

    if (!backup.file_path) {
      return res.status(404).json({ error: 'Backup file not found' });
    }

    // Check if file exists
    try {
      await fs.access(backup.file_path);
    } catch {
      return res.status(404).json({ error: 'Backup file not found on disk' });
    }

    const fileName = path.basename(backup.file_path);
    res.setHeader('Content-Type', 'application/gzip');
    res.setHeader('Content-Disposition', `attachment; filename="${fileName}"`);

    const fileStream = await getBackupFileStream(id);
    fileStream.pipe(res);

    // Clean up temp file after download if it was from Google Drive
    if (backup.storage_type === 'google_drive') {
      fileStream.on('end', () => {
        fs.unlink(backup.file_path).catch(() => {});
      });
    }
  } catch (error: any) {
    console.error('Backup download error:', error);
    res.status(500).json({ error: 'Failed to download backup', details: error.message });
  }
});

// Delete backup
router.delete('/:id', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const { id } = req.params;
    const result = await query('SELECT * FROM backups WHERE id = $1', [id]);

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Backup not found' });
    }

    const backup = result.rows[0];

    // Delete from Google Drive if applicable
    if (backup.storage_type === 'google_drive' && backup.google_drive_file_id) {
      try {
        await deleteFromGoogleDrive(backup.google_drive_file_id, req.user!.id);
      } catch (error: any) {
        console.error('Failed to delete from Google Drive:', error);
        // Continue with local deletion even if Google Drive deletion fails
      }
    }

    // Delete local file if exists
    if (backup.file_path) {
      try {
        await fs.unlink(backup.file_path);
      } catch (error) {
        console.error('Failed to delete local backup file:', error);
      }
    }

    // Delete database record
    await query('DELETE FROM backups WHERE id = $1', [id]);

    res.json({ message: 'Backup deleted successfully' });
  } catch (error: any) {
    console.error('Backup deletion error:', error);
    res.status(500).json({ error: 'Failed to delete backup', details: error.message });
  }
});

// Restore from backup
router.post('/:id/restore', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const { id } = req.params;
    const { confirm } = req.body;

    if (!confirm) {
      return res.status(400).json({ error: 'Restore confirmation required. Set confirm: true' });
    }

    const result = await query(
      'SELECT * FROM backups WHERE id = $1 AND status = $2',
      [id, 'completed']
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Backup not found or not completed' });
    }

    const backup = result.rows[0];
    let backupPath = backup.file_path;

    // If Google Drive backup, download first
    if (backup.storage_type === 'google_drive' && backup.google_drive_file_id) {
      const tempPath = path.join(process.cwd(), 'backups', `restore-${id}.tar.gz`);
      try {
        await downloadFromGoogleDrive(
          backup.google_drive_file_id,
          tempPath,
          req.user!.id
        );
        backupPath = tempPath;
      } catch (error: any) {
        return res.status(500).json({ error: 'Failed to download from Google Drive', details: error.message });
      }
    }

    if (!backupPath) {
      return res.status(404).json({ error: 'Backup file not found' });
    }

    // Extract and restore based on backup type
    if (backup.backup_type === 'database' || backup.backup_type === 'full') {
      // Extract database backup file
      const extractDir = path.join(process.cwd(), 'backups', `restore-${id}`);
      await fs.mkdir(extractDir, { recursive: true });

      try {
        // Extract tar.gz
        await execAsync(`tar -xzf "${backupPath}" -C "${extractDir}"`, { maxBuffer: 10 * 1024 * 1024 });

        // Find database dump file
        const files = await fs.readdir(extractDir);
        const dbFile = files.find(f => (f.startsWith('database-') && (f.endsWith('.sql') || f.endsWith('.dump') || !f.includes('.'))));

        if (!dbFile) {
          throw new Error('Database backup file not found in archive');
        }

        const dbFilePath = path.join(extractDir, dbFile);
        const dbConfig = getDatabaseConfig();
        const envVars = { ...process.env, PGPASSWORD: dbConfig.password };

        // Determine if it's custom format (pg_dump -F c) or plain SQL
        const isCustomFormat = !dbFile.endsWith('.sql');
        
        if (isCustomFormat) {
          // Use pg_restore for custom format
          const restoreCmd = `pg_restore -h ${dbConfig.host} -p ${dbConfig.port} -U ${dbConfig.user} -d ${dbConfig.database} --clean --if-exists --no-owner --no-acl "${dbFilePath}"`;
          try {
            await execAsync(restoreCmd, { env: envVars, maxBuffer: 10 * 1024 * 1024 });
          } catch (restoreError: any) {
            // If pg_restore fails, try with --no-privileges flag
            const restoreCmd2 = `pg_restore -h ${dbConfig.host} -p ${dbConfig.port} -U ${dbConfig.user} -d ${dbConfig.database} --clean --if-exists --no-owner --no-acl --no-privileges "${dbFilePath}"`;
            await execAsync(restoreCmd2, { env: envVars, maxBuffer: 10 * 1024 * 1024 });
          }
        } else {
          // Use psql for plain SQL format
          const restoreCmd = `psql -h ${dbConfig.host} -p ${dbConfig.port} -U ${dbConfig.user} -d ${dbConfig.database} -f "${dbFilePath}"`;
          await execAsync(restoreCmd, { env: envVars, maxBuffer: 10 * 1024 * 1024 });
        }
      } catch (error: any) {
        // Cleanup extract directory on error
        await fs.rm(extractDir, { recursive: true, force: true }).catch(() => {});
        throw new Error(`Database restore failed: ${error.message || error.stderr || 'Unknown error'}`);
      }

      // Cleanup extract directory
      await fs.rm(extractDir, { recursive: true, force: true }).catch(() => {});
    }

    if (backup.backup_type === 'files' || backup.backup_type === 'full') {
      // Extract files backup
      const uploadsDir = path.join(process.cwd(), 'uploads');
      await fs.mkdir(uploadsDir, { recursive: true });

      try {
        // Extract tar.gz to uploads directory
        // If it's a full backup, the files archive is inside the main archive
        if (backup.backup_type === 'full') {
          // For full backups, files are already extracted above, or we need to extract the files archive
          const extractDir = path.join(process.cwd(), 'backups', `restore-files-${id}`);
          await fs.mkdir(extractDir, { recursive: true });
          await execAsync(`tar -xzf "${backupPath}" -C "${extractDir}"`, { maxBuffer: 10 * 1024 * 1024 });
          
          // Find files archive
          const files = await fs.readdir(extractDir);
          const filesArchive = files.find(f => f.startsWith('files-') && f.endsWith('.tar.gz'));
          
          if (filesArchive) {
            await execAsync(`tar -xzf "${path.join(extractDir, filesArchive)}" -C "${path.dirname(uploadsDir)}"`, { maxBuffer: 10 * 1024 * 1024 });
          }
          
          await fs.rm(extractDir, { recursive: true, force: true }).catch(() => {});
        } else {
          // For files-only backup, extract directly
          await execAsync(`tar -xzf "${backupPath}" -C "${path.dirname(uploadsDir)}"`, { maxBuffer: 10 * 1024 * 1024 });
        }
      } catch (error: any) {
        throw new Error(`Files restore failed: ${error.message || 'Unknown error'}`);
      }
    }

    // Clean up temp file if from Google Drive
    if (backup.storage_type === 'google_drive' && backupPath !== backup.file_path) {
      await fs.unlink(backupPath).catch(() => {});
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details)
       VALUES ($1, 'restore_backup', 'backup', $2, $3)`,
      [req.user!.id, id, JSON.stringify({ backup_type: backup.backup_type })]
    );

    res.json({ message: 'Backup restored successfully' });
  } catch (error: any) {
    console.error('Backup restore error:', error);
    res.status(500).json({ error: 'Failed to restore backup', details: error.message });
  }
});

// Get Google Drive OAuth URL
router.get('/google-drive/auth', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const state = req.user!.id; // Use user ID as state
    const authUrl = await getAuthUrl(state);
    
    // Get credentials to return redirect URI for verification
    const { redirectUri } = await getGoogleDriveCredentials();
    
    res.json({ 
      url: authUrl,
      redirectUri: redirectUri, // Return redirect URI so frontend can verify
      verification: {
        redirectUriMatch: 'Ensure this exact URI is in your Google Cloud Console OAuth app: ' + redirectUri,
        googleConsoleUrl: 'https://console.cloud.google.com/apis/credentials'
      }
    });
  } catch (error: any) {
    console.error('Failed to get Google Drive auth URL:', error);
    res.status(500).json({ 
      error: 'Failed to get Google Drive auth URL', 
      details: error.message || 'Unknown error. Please check your Google OAuth configuration in Settings ‚Üí Integrations.'
    });
  }
});

// Handle Google Drive OAuth callback
// Note: This endpoint should NOT require authentication as it's called by Google
router.get('/google-drive/callback', async (req: any, res: Response) => {
  try {
    const { code, state, error } = req.query;

    // Handle OAuth errors from Google
    if (error) {
      console.error('Google OAuth error:', error);
      const frontendUrl = process.env.FRONTEND_URL || 'http://localhost:3000';
      return res.redirect(`${frontendUrl}/settings?tab=integrations&google_drive_error=${encodeURIComponent(error)}`);
    }

    if (!code || typeof code !== 'string') {
      const frontendUrl = process.env.FRONTEND_URL || 'http://localhost:3000';
      return res.redirect(`${frontendUrl}/settings?tab=integrations&google_drive_error=${encodeURIComponent('Authorization code missing')}`);
    }

    // Use state as userId if provided
    const userId = (state && typeof state === 'string') ? state : undefined;

    await exchangeCodeForTokens(code, userId);

    // Redirect to frontend with success
    const frontendUrl = process.env.FRONTEND_URL || 'http://localhost:3000';
    res.redirect(`${frontendUrl}/settings?tab=integrations&google_drive_connected=true`);
  } catch (error: any) {
    console.error('Google Drive callback error:', error);
    const frontendUrl = process.env.FRONTEND_URL || 'http://localhost:3000';
    res.redirect(`${frontendUrl}/settings?tab=integrations&google_drive_error=${encodeURIComponent(error.message || 'Unknown error')}`);
  }
});

// Get Google Drive connection status
router.get('/google-drive/status', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const connected = await isGoogleDriveConnected();
    res.json({ connected });
  } catch (error: any) {
    console.error('Failed to get Google Drive status:', error);
    res.status(500).json({ error: 'Failed to get Google Drive status' });
  }
});

// Configure scheduled backups
router.post('/schedule', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const { enabled, frequency, retention_days, backup_type, storage_type } = req.body;

    const scheduleConfig = {
      enabled: enabled !== false,
      frequency: frequency || 'daily', // daily, weekly, monthly
      retention_days: retention_days || 30,
      backup_type: backup_type || 'full',
      storage_type: storage_type || 'local'
    };

    await query(
      `INSERT INTO settings (key, value, user_id)
       VALUES ('backup_schedule', $1, $2)
       ON CONFLICT (key, user_id) DO UPDATE SET value = $1, updated_at = CURRENT_TIMESTAMP`,
      [JSON.stringify(scheduleConfig), req.user!.id]
    );

    res.json({ message: 'Backup schedule configured', schedule: scheduleConfig });
  } catch (error: any) {
    console.error('Failed to configure backup schedule:', error);
    res.status(500).json({ error: 'Failed to configure backup schedule', details: error.message });
  }
});

// Get backup schedule
router.get('/schedule', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    // Try to get user-specific schedule first, then global
    let result = await query(
      "SELECT value FROM settings WHERE key = 'backup_schedule' AND user_id = $1",
      [req.user!.id]
    );

    // If no user-specific schedule, try global (user_id IS NULL)
    if (result.rows.length === 0) {
      result = await query(
        "SELECT value FROM settings WHERE key = 'backup_schedule' AND user_id IS NULL ORDER BY updated_at DESC LIMIT 1"
      );
    }

    if (result.rows.length === 0) {
      return res.json({
        enabled: false,
        frequency: 'daily',
        retention_days: 30,
        backup_type: 'full',
        storage_type: 'local'
      });
    }

    res.json(JSON.parse(result.rows[0].value));
  } catch (error: any) {
    console.error('Failed to get backup schedule:', error);
    // Return default schedule on error instead of 500
    res.json({
      enabled: false,
      frequency: 'daily',
      retention_days: 30,
      backup_type: 'full',
      storage_type: 'local'
    });
  }
});

// Cleanup old backups
router.post('/cleanup', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const { retention_days = 30 } = req.body;
    const deletedCount = await cleanupOldBackups(retention_days);
    res.json({ message: `Cleaned up ${deletedCount} old backups` });
  } catch (error: any) {
    console.error('Backup cleanup error:', error);
    res.status(500).json({ error: 'Failed to cleanup backups', details: error.message });
  }
});

export default router;

--- FILE: backend/src/routes/clients.ts ---
import { Router, Response } from 'express';
import { body, validationResult } from 'express-validator';
import { query } from '../db';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';
import { env } from '../config/env';
import { parsePaginationParams, createPaginatedResponse } from '../lib/pagination';
import { log } from '../lib/logger';

const router = Router();

// Get all clients
router.get('/', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { status, search, sort = 'name', order = 'asc', client_type } = req.query;
    
    // Parse pagination parameters
    const { page, limit, offset } = parsePaginationParams(req.query);
    
    // Build WHERE clause for both count and data queries
    let whereClause = 'WHERE 1=1';
    const params: any[] = [];
    let paramCount = 1;

    if (status) {
      whereClause += ` AND c.status = $${paramCount++}`;
      params.push(status);
    }

    if (client_type) {
      if (client_type === 'customer') {
        whereClause += ` AND (c.client_type IN ('customer', 'both') OR (c.client_type IS NULL AND EXISTS (SELECT 1 FROM projects p WHERE p.client_id = c.id)))`;
      } else if (client_type === 'supplier') {
        whereClause += ` AND (c.client_type IN ('supplier', 'both') OR (c.client_type IS NULL AND (EXISTS (SELECT 1 FROM xero_purchase_orders po WHERE po.supplier_id = c.id) OR EXISTS (SELECT 1 FROM xero_bills b WHERE b.supplier_id = c.id))))`;
      }
    }

    if (search) {
      whereClause += ` AND (
        c.name ILIKE $${paramCount} OR 
        c.contact_name ILIKE $${paramCount} OR 
        c.address ILIKE $${paramCount}
      )`;
      params.push(`%${search}%`);
      paramCount++;
    }

    // Get total count
    const countSql = `SELECT COUNT(*) as total FROM clients c ${whereClause}`;
    const countResult = await query(countSql, params);
    const total = parseInt(countResult.rows[0].total);

    // Build data query
    let sql = `
      SELECT c.*, 
        (SELECT COUNT(*) FROM projects p WHERE p.client_id = c.id AND p.status IN ('quoted', 'in-progress')) as active_projects,
        (SELECT COALESCE(SUM(t.hours), 0) FROM timesheets t WHERE t.client_id = c.id) as total_hours,
        (SELECT MAX(t.date) FROM timesheets t WHERE t.client_id = c.id) as last_contact,
        (SELECT COUNT(*) FROM xero_purchase_orders po WHERE po.supplier_id = c.id) as total_purchase_orders,
        (SELECT COUNT(*) FROM xero_bills b WHERE b.supplier_id = c.id) as total_bills,
        (SELECT COALESCE(SUM(b.amount), 0) FROM xero_bills b WHERE b.supplier_id = c.id) as total_spent
      FROM clients c
      ${whereClause}
    `;

    const validSorts = ['name', 'created_at', 'total_hours'];
    const sortColumn = validSorts.includes(sort as string) ? sort : 'name';
    const sortOrder = order === 'desc' ? 'DESC' : 'ASC';
    sql += ` ORDER BY ${sortColumn} ${sortOrder}`;
    
    // Add pagination
    sql += ` LIMIT $${paramCount++} OFFSET $${paramCount++}`;
    params.push(limit, offset);

    const result = await query(sql, params);
    
    // Return paginated response
    const paginatedResponse = createPaginatedResponse(result.rows, total, page, limit);
    res.json(paginatedResponse);
  } catch (error: any) {
    log.error('Get clients error', error, { userId: req.user?.id });
    const errorMessage = error.message || 'Failed to fetch clients';
    const isTableError = errorMessage.includes('does not exist') || errorMessage.includes('relation') || error.code === '42P01';
    res.status(500).json({ 
      error: isTableError ? 'Database tables not found. Please run migrations.' : 'Failed to fetch clients',
      details: env.NODE_ENV === 'development' ? errorMessage : undefined
    });
  }
});

// Get single client
router.get('/:id', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT c.*, 
        (SELECT COUNT(*) FROM projects p WHERE p.client_id = c.id AND p.status IN ('quoted', 'in-progress')) as active_projects,
        (SELECT COALESCE(SUM(t.hours), 0) FROM timesheets t WHERE t.client_id = c.id) as total_hours,
        (SELECT COUNT(*) FROM xero_purchase_orders po WHERE po.supplier_id = c.id) as total_purchase_orders,
        (SELECT COUNT(*) FROM xero_bills b WHERE b.supplier_id = c.id) as total_bills,
        (SELECT COALESCE(SUM(b.amount), 0) FROM xero_bills b WHERE b.supplier_id = c.id) as total_spent
       FROM clients c
       WHERE c.id = $1`,
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Client not found' });
    }

    // Get related projects
    const projects = await query(
      'SELECT id, code, name, status, budget, actual_cost FROM projects WHERE client_id = $1 ORDER BY created_at DESC',
      [req.params.id]
    );

    res.json({
      ...result.rows[0],
      projects: projects.rows
    });
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch client' });
  }
});

// Create client
router.post('/', authenticate, requirePermission('can_manage_clients'),
  body('name').trim().notEmpty(),
  body('email').optional().isEmail().normalizeEmail(),
  async (req: AuthRequest, res: Response) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { name, contact_name, email, phone, address, location, billing_address, billing_email, client_type, notes } = req.body;

    try {
      const result = await query(
        `INSERT INTO clients (name, contact_name, email, phone, address, location, billing_address, billing_email, client_type, notes)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10)
         RETURNING *`,
        [name, contact_name, email, phone, address, location, billing_address, billing_email, client_type || 'customer', notes]
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'create', 'client', result.rows[0].id, JSON.stringify({ name })]
      );

      res.status(201).json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to create client' });
    }
  }
);

// Update client
router.put('/:id', authenticate, requirePermission('can_manage_clients'),
  body('name').optional().trim().notEmpty(),
  body('email').optional().isEmail().normalizeEmail(),
  async (req: AuthRequest, res: Response) => {
    const { name, contact_name, email, phone, address, location, billing_address, billing_email, client_type, status, notes, xero_contact_id } = req.body;

    try {
      const updates: string[] = [];
      const values: any[] = [];
      let paramCount = 1;

      const fields = { name, contact_name, email, phone, address, location, billing_address, billing_email, client_type, status, notes, xero_contact_id };
      
      for (const [key, value] of Object.entries(fields)) {
        if (value !== undefined) {
          updates.push(`${key} = $${paramCount++}`);
          values.push(value);
        }
      }

      if (updates.length === 0) {
        return res.status(400).json({ error: 'No updates provided' });
      }

      updates.push('updated_at = CURRENT_TIMESTAMP');
      values.push(req.params.id);

      const result = await query(
        `UPDATE clients SET ${updates.join(', ')} WHERE id = $${paramCount} RETURNING *`,
        values
      );

      if (result.rows.length === 0) {
        return res.status(404).json({ error: 'Client not found' });
      }

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'update', 'client', req.params.id, JSON.stringify(fields)]
      );

      res.json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to update client' });
    }
  }
);

// Delete client
router.delete('/:id', authenticate, requirePermission('can_manage_clients'), async (req: AuthRequest, res: Response) => {
  try {
    // Check for related projects
    const projects = await query(
      'SELECT COUNT(*) FROM projects WHERE client_id = $1',
      [req.params.id]
    );

    if (parseInt(projects.rows[0].count) > 0) {
      return res.status(400).json({ 
        error: 'Cannot delete client with existing projects. Deactivate instead.' 
      });
    }

    const result = await query(
      'DELETE FROM clients WHERE id = $1 RETURNING id, name',
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Client not found' });
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'delete', 'client', req.params.id, JSON.stringify({ name: result.rows[0].name })]
    );

    res.json({ message: 'Client deleted' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to delete client' });
  }
});

export default router;
--- FILE: backend/src/routes/costCenters.ts ---
import { Router, Response } from 'express';
import { body, validationResult } from 'express-validator';
import { query } from '../db';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';

const router = Router();

// Get all cost centers
router.get('/', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { active_only } = req.query;
    
    let sql = `
      SELECT cc.*,
        (SELECT COUNT(*) FROM project_cost_centers pcc WHERE pcc.cost_center_id = cc.id) as project_count,
        (SELECT COALESCE(SUM(t.hours), 0) FROM timesheets t WHERE t.cost_center_id = cc.id) as total_hours,
        (SELECT COALESCE(SUM(t.hours * at.hourly_rate), 0) 
         FROM timesheets t 
         JOIN activity_types at ON t.activity_type_id = at.id 
         WHERE t.cost_center_id = cc.id) as total_cost
      FROM cost_centers cc
      WHERE 1=1
    `;

    if (active_only === 'true') {
      sql += ' AND cc.is_active = true';
    }

    sql += ' ORDER BY cc.code ASC';

    const result = await query(sql);
    res.json(result.rows);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch cost centers' });
  }
});

// Get single cost center
router.get('/:id', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT cc.*,
        (SELECT COUNT(*) FROM project_cost_centers pcc WHERE pcc.cost_center_id = cc.id) as project_count,
        (SELECT COALESCE(SUM(t.hours), 0) FROM timesheets t WHERE t.cost_center_id = cc.id) as total_hours
       FROM cost_centers cc
       WHERE cc.id = $1`,
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Cost center not found' });
    }

    // Get related projects
    const projects = await query(
      `SELECT p.id, p.code, p.name, p.status 
       FROM projects p
       JOIN project_cost_centers pcc ON p.id = pcc.project_id
       WHERE pcc.cost_center_id = $1`,
      [req.params.id]
    );

    res.json({
      ...result.rows[0],
      projects: projects.rows
    });
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch cost center' });
  }
});

// Create cost center (admin only)
router.post('/', authenticate, requirePermission('can_manage_cost_centers'),
  body('code').trim().notEmpty(),
  body('name').trim().notEmpty(),
  async (req: AuthRequest, res: Response) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { code, name, description, budget = 0, xero_tracking_category_id, client_po_number } = req.body;

    try {
      // Check for duplicate code
      const existing = await query('SELECT id FROM cost_centers WHERE code = $1', [code]);
      if (existing.rows.length > 0) {
        return res.status(400).json({ error: 'Cost center code already exists' });
      }

      const result = await query(
        `INSERT INTO cost_centers (code, name, description, budget, xero_tracking_category_id, client_po_number)
         VALUES ($1, $2, $3, $4, $5, $6)
         RETURNING *`,
        [code, name, description, budget, xero_tracking_category_id, client_po_number || null]
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'create', 'cost_center', result.rows[0].id, JSON.stringify({ code, name })]
      );

      res.status(201).json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to create cost center' });
    }
  }
);

// Update cost center (admin only)
router.put('/:id', authenticate, requirePermission('can_manage_cost_centers'),
  async (req: AuthRequest, res: Response) => {
    const { code, name, description, budget, is_active, xero_tracking_category_id, client_po_number } = req.body;

    try {
      const updates: string[] = [];
      const values: any[] = [];
      let paramCount = 1;

      const fields = { code, name, description, budget, is_active, xero_tracking_category_id, client_po_number };
      
      for (const [key, value] of Object.entries(fields)) {
        if (value !== undefined) {
          updates.push(`${key} = $${paramCount++}`);
          values.push(value === '' ? null : value);
        }
      }

      if (updates.length === 0) {
        return res.status(400).json({ error: 'No updates provided' });
      }

      // Check for duplicate code if updating code
      if (code) {
        const existing = await query(
          'SELECT id FROM cost_centers WHERE code = $1 AND id != $2',
          [code, req.params.id]
        );
        if (existing.rows.length > 0) {
          return res.status(400).json({ error: 'Cost center code already exists' });
        }
      }

      updates.push('updated_at = CURRENT_TIMESTAMP');
      values.push(req.params.id);

      const result = await query(
        `UPDATE cost_centers SET ${updates.join(', ')} WHERE id = $${paramCount} RETURNING *`,
        values
      );

      if (result.rows.length === 0) {
        return res.status(404).json({ error: 'Cost center not found' });
      }

      res.json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to update cost center' });
    }
  }
);

// Delete cost center (admin only)
router.delete('/:id', authenticate, requirePermission('can_manage_cost_centers'), async (req: AuthRequest, res: Response) => {
  try {
    // Check if cost center is in use
    const timesheets = await query(
      'SELECT COUNT(*) FROM timesheets WHERE cost_center_id = $1',
      [req.params.id]
    );

    if (parseInt(timesheets.rows[0].count) > 0) {
      return res.status(400).json({ 
        error: 'Cannot delete cost center with existing timesheets. Deactivate instead.' 
      });
    }

    const result = await query(
      'DELETE FROM cost_centers WHERE id = $1 RETURNING id, code, name',
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Cost center not found' });
    }

    res.json({ message: 'Cost center deleted' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to delete cost center' });
  }
});

export default router;
--- FILE: backend/src/routes/dashboard.ts ---
import { Router, Response } from 'express';
import { query } from '../db';
import { authenticate, AuthRequest } from '../middleware/auth';
import { log } from '../lib/logger';

const router = Router();

// Root endpoint - returns available dashboard endpoints
router.get('/', authenticate, async (req: AuthRequest, res: Response) => {
  res.json({
    message: 'Dashboard API',
    availableEndpoints: [
      '/api/dashboard/metrics',
      '/api/dashboard/recent-timesheets',
      '/api/dashboard/active-projects',
      '/api/dashboard/quick-stats'
    ]
  });
});

// Get dashboard metrics
router.get('/metrics', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    // Total and active projects
    const projectsResult = await query(`
      SELECT 
        COUNT(*) as total,
        COUNT(*) FILTER (WHERE status IN ('quoted', 'in-progress')) as active
      FROM projects
    `);

    // Total hours (all time and this month)
    const hoursResult = await query(`
      SELECT 
        COALESCE(SUM(hours), 0) as total,
        COALESCE(SUM(hours) FILTER (WHERE date >= date_trunc('month', CURRENT_DATE)), 0) as this_month,
        COALESCE(SUM(hours) FILTER (WHERE date >= date_trunc('month', CURRENT_DATE - INTERVAL '1 month') AND date < date_trunc('month', CURRENT_DATE)), 0) as last_month
      FROM timesheets
    `);

    // Total revenue (from projects)
    const revenueResult = await query(`
      SELECT 
        COALESCE(SUM(actual_cost), 0) as total,
        COALESCE(SUM(actual_cost) FILTER (WHERE updated_at >= date_trunc('month', CURRENT_DATE)), 0) as this_month,
        COALESCE(SUM(actual_cost) FILTER (WHERE updated_at >= date_trunc('month', CURRENT_DATE - INTERVAL '1 month') AND updated_at < date_trunc('month', CURRENT_DATE)), 0) as last_month
      FROM projects
    `);

    // Active technicians (users with timesheets this week)
    const techsResult = await query(`
      SELECT COUNT(DISTINCT user_id) as active
      FROM timesheets
      WHERE date >= date_trunc('week', CURRENT_DATE)
    `);

    // Calculate trends
    const hours = hoursResult.rows[0];
    const revenue = revenueResult.rows[0];
    
    const hoursTrend = hours.last_month > 0 
      ? ((hours.this_month - hours.last_month) / hours.last_month * 100) 
      : 0;
    
    const revenueTrend = revenue.last_month > 0 
      ? ((revenue.this_month - revenue.last_month) / revenue.last_month * 100) 
      : 0;

    // Recent activity (last 7 days)
    const recentActivity = await query(`
      SELECT 
        date,
        COALESCE(SUM(hours), 0) as hours
      FROM timesheets
      WHERE date >= CURRENT_DATE - INTERVAL '7 days'
      GROUP BY date
      ORDER BY date ASC
    `);

    res.json({
      totalProjects: parseInt(projectsResult.rows[0].total),
      activeProjects: parseInt(projectsResult.rows[0].active),
      totalHours: parseFloat(hours.total),
      totalRevenue: parseFloat(revenue.total),
      projectsTrend: 0, // Could calculate from projects created this month vs last
      hoursTrend: Math.round(hoursTrend * 10) / 10,
      revenueTrend: Math.round(revenueTrend * 10) / 10,
      activeTeam: parseInt(techsResult.rows[0].active),
      recentActivity: recentActivity.rows.map(r => ({
        date: r.date,
        hours: parseFloat(r.hours)
      }))
    });
  } catch (error) {
    log.error('Dashboard metrics error', error);
    res.status(500).json({ error: 'Failed to fetch dashboard metrics' });
  }
});

// Get recent timesheets
router.get('/recent-timesheets', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { limit = 5 } = req.query;

    const result = await query(`
      SELECT t.*, 
        u.name as user_name,
        p.name as project_name,
        c.name as client_name,
        at.name as activity_type_name
      FROM timesheets t
      LEFT JOIN users u ON t.user_id = u.id
      LEFT JOIN projects p ON t.project_id = p.id
      LEFT JOIN clients c ON t.client_id = c.id
      LEFT JOIN activity_types at ON t.activity_type_id = at.id
      ORDER BY t.date DESC, t.created_at DESC
      LIMIT $1
    `, [parseInt(limit as string)]);

    res.json(result.rows);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch recent timesheets' });
  }
});

// Get active projects with progress
router.get('/active-projects', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { limit = 5 } = req.query;

    const result = await query(`
      SELECT p.*, 
        c.name as client_name,
        COALESCE(SUM(t.hours), 0) as hours_logged
      FROM projects p
      LEFT JOIN clients c ON p.client_id = c.id
      LEFT JOIN timesheets t ON t.project_id = p.id
      WHERE p.status = 'in-progress'
      GROUP BY p.id, c.name
      ORDER BY p.updated_at DESC
      LIMIT $1
    `, [parseInt(limit as string)]);

    res.json(result.rows);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch active projects' });
  }
});

// Get quick stats (budget utilization, projects on track, overdue)
router.get('/quick-stats', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    // Budget utilization
    const budgetResult = await query(`
      SELECT 
        COALESCE(SUM(budget), 0) as total_budget,
        COALESCE(SUM(actual_cost), 0) as total_actual
      FROM projects
      WHERE status IN ('in-progress', 'completed')
    `);

    const budget = budgetResult.rows[0];
    const budgetUtilization = budget.total_budget > 0 
      ? (budget.total_actual / budget.total_budget * 100) 
      : 0;

    // Projects on track (under budget)
    const onTrackResult = await query(`
      SELECT 
        COUNT(*) FILTER (WHERE actual_cost <= budget OR budget = 0) as on_track,
        COUNT(*) as total
      FROM projects
      WHERE status IN ('in-progress')
    `);

    const onTrack = onTrackResult.rows[0];
    const onTrackPercent = onTrack.total > 0 
      ? (onTrack.on_track / onTrack.total * 100) 
      : 100;

    // Overdue projects (past end_date but not completed)
    const overdueResult = await query(`
      SELECT COUNT(*) as count
      FROM projects
      WHERE status = 'in-progress'
      AND end_date < CURRENT_DATE
    `);

    const totalActive = await query(`
      SELECT COUNT(*) as count FROM projects WHERE status IN ('quoted', 'in-progress')
    `);

    const overduePercent = parseInt(totalActive.rows[0].count) > 0
      ? (parseInt(overdueResult.rows[0].count) / parseInt(totalActive.rows[0].count) * 100)
      : 0;

    res.json({
      budgetUtilization: Math.round(budgetUtilization),
      projectsOnTrack: Math.round(onTrackPercent),
      overdueProjects: Math.round(overduePercent)
    });
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch quick stats' });
  }
});

export default router;
--- FILE: backend/src/routes/documentScan.ts ---
import { Router, Response } from 'express';
import { query } from '../db';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';
import { fileUpload } from '../middleware/upload';
import { validateProjectAccess } from '../middleware/validateProject';
import { asyncHandler } from '../middleware/asyncHandler';
import { NotFoundError, ValidationError, FileError } from '../lib/errors';
import { log } from '../lib/logger';
import { ocrService, OCRResult } from '../lib/ocrService';
import { findMatches } from '../lib/documentMatcher';
import { StorageFactory } from '../lib/storage/StorageFactory';
import { generatePartitionedPath, resolveStoragePath } from '../lib/storage/pathUtils';
import { bufferToStream } from '../middleware/upload';
import path from 'path';
import fs from 'fs';

const router = Router();

/**
 * Upload and process document
 */
router.post(
  '/upload',
  authenticate,
  requirePermission('can_edit_projects'),
  validateProjectAccess,
  fileUpload.single('file'),
  asyncHandler(async (req: AuthRequest, res: Response) => {
    if (!req.file) {
      throw new ValidationError('No file uploaded');
    }

    // Extract project_id from body (FormData fields are parsed by multer)
    const project_id = req.body?.project_id || req.body?.projectId;
    const cost_center_id = req.body?.cost_center_id || req.body?.costCenterId;

    // Validate project_id - check for empty string, null, or undefined
    if (!project_id || (typeof project_id === 'string' && project_id.trim() === '')) {
      log.error('Document scan upload failed: project_id missing or empty', { 
        body: req.body, 
        hasFile: !!req.file,
        project_id: project_id,
        projectId: req.body?.projectId
      });
      throw new ValidationError('project_id is required and cannot be empty');
    }

    // Check if file is an image (validate before uploading)
    const isImage = req.file.mimetype.startsWith('image/');
    if (!isImage) {
      throw new FileError('Only image files can be processed for OCR');
    }

    // Get storage provider
    let storage;
    try {
      storage = await StorageFactory.getInstance();
    } catch (storageInitError: any) {
      log.error('Failed to initialize storage provider for document scan', storageInitError, { project_id });
      throw new ValidationError(`Failed to initialize storage: ${storageInitError.message || 'Unknown error'}`);
    }

    const { sanitizeProjectId } = await import('../middleware/validateProject');
    let projectId: string;
    try {
      projectId = sanitizeProjectId(project_id);
    } catch (validationError: any) {
      log.error('Invalid project_id in document scan upload', validationError, { project_id });
      throw new ValidationError(validationError.message || 'Invalid project_id');
    }
    
    // Generate partitioned path for storage
    const basePath = `projects/${projectId}/files${cost_center_id ? `/${cost_center_id}` : ''}`;
    const storagePath = generatePartitionedPath(req.file.originalname, basePath);
    
    // Stream file from memory buffer to storage provider
    try {
      const fileStream = bufferToStream(req.file.buffer);
      await storage.put(storagePath, fileStream, {
        contentType: req.file.mimetype,
      });
    } catch (storageError: any) {
      log.error('Failed to upload file to storage', storageError, { 
        project_id, 
        storagePath,
        errorMessage: storageError.message,
        errorStack: storageError.stack
      });
      throw new ValidationError(`Failed to save file to storage: ${storageError.message}`);
    }

    // Determine file type from mime type
    let fileType = 'document';
    if (req.file.mimetype.startsWith('image/')) {
      fileType = 'image';
    }

    // Get file URL from storage provider
    const fileUrl = await storage.url(storagePath);
    
    // Store file in project_files table
    const fileResult = await query(
      `INSERT INTO project_files (
        project_id, cost_center_id, file_name, file_path, file_type, file_size, mime_type, uploaded_by
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
      RETURNING *`,
      [
        project_id,
        cost_center_id || null,
        req.file.originalname,
        fileUrl,
        fileType,
        req.file.size,
        req.file.mimetype,
        req.user!.id
      ]
    );

    const file = fileResult.rows[0];

    // Create document_scan record with pending status
    const scanResult = await query(
      `INSERT INTO document_scans (
        file_id, user_id, status
      ) VALUES ($1, $2, 'pending')
      RETURNING *`,
      [file.id, req.user!.id]
    );

    const scan = scanResult.rows[0];

    // Process OCR asynchronously (don't block response)
    // Pass storage path instead of local file path
    processDocumentScan(scan.id, storagePath).catch(error => {
      log.error('Background OCR processing failed', error, { scanId: scan.id });
    });

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details)
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'scan_document', 'document_scan', scan.id, JSON.stringify({ file_name: req.file.originalname })]
    );

    res.status(201).json({
      scan: {
        id: scan.id,
        file_id: file.id,
        status: scan.status,
      },
      file: file,
    });
  })
);

/**
 * Process document scan in background
 */
async function processDocumentScan(scanId: string, filePath: string) {
  try {
    // Update status to processing
    await query(
      'UPDATE document_scans SET status = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
      ['processing', scanId]
    );

    // Check OCR service availability
    const isAvailable = await ocrService.healthCheck();
    if (!isAvailable) {
      throw new Error('OCR service is not available');
    }

    // Process image through OCR
    const ocrResult: OCRResult = await ocrService.processImage(filePath);

    if (!ocrResult.success) {
      await query(
        `UPDATE document_scans 
         SET status = 'failed', 
             error_message = $1, 
             updated_at = CURRENT_TIMESTAMP 
         WHERE id = $2`,
        [ocrResult.error || 'OCR processing failed', scanId]
      );
      return;
    }

    // Store extracted data
    await query(
      `UPDATE document_scans 
       SET status = 'completed',
           document_type = $1,
           extracted_data = $2,
           confidence = $3,
           processed_at = CURRENT_TIMESTAMP,
           updated_at = CURRENT_TIMESTAMP
       WHERE id = $4`,
      [
        ocrResult.document_type,
        JSON.stringify(ocrResult.extracted_data),
        ocrResult.confidence,
        scanId
      ]
    );

    // Find matches
    const matches = await findMatches(
      scanId,
      ocrResult.extracted_data,
      ocrResult.document_type
    );

    // Store matches
    for (const match of matches) {
      await query(
        `INSERT INTO document_matches (
          scan_id, entity_type, entity_id, confidence_score, match_reasons
        ) VALUES ($1, $2, $3, $4, $5)`,
        [
          scanId,
          match.entity_type,
          match.entity_id,
          match.confidence_score,
          JSON.stringify(match.match_reasons)
        ]
      );
    }

    log.info('Document scan completed', { scanId, matchesFound: matches.length });
  } catch (error: any) {
    log.error('Document scan processing error', error, { scanId });
    await query(
      `UPDATE document_scans 
       SET status = 'failed', 
           error_message = $1, 
           updated_at = CURRENT_TIMESTAMP 
       WHERE id = $2`,
      [error.message || 'Processing failed', scanId]
    );
  }
}

/**
 * Get scan status and extracted data
 */
router.get('/:id', authenticate, requirePermission('can_view_financials'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const result = await query(
    `SELECT ds.*, 
      pf.file_name, pf.file_path, pf.mime_type,
      u.name as user_name
    FROM document_scans ds
    LEFT JOIN project_files pf ON ds.file_id = pf.id
    LEFT JOIN users u ON ds.user_id = u.id
    WHERE ds.id = $1`,
    [req.params.id]
  );

  if (result.rows.length === 0) {
    throw new NotFoundError('Document scan', req.params.id);
  }

  res.json(result.rows[0]);
}));

/**
 * Get suggested matches for a scan
 */
router.get('/:id/matches', authenticate, requirePermission('can_view_financials'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const matches = await query(
    `SELECT dm.*,
      CASE 
        WHEN dm.entity_type = 'purchase_order' THEN (SELECT po_number FROM xero_purchase_orders WHERE id = dm.entity_id)
        WHEN dm.entity_type = 'invoice' THEN (SELECT invoice_number FROM xero_invoices WHERE id = dm.entity_id)
        WHEN dm.entity_type = 'bill' THEN (SELECT bill_number FROM xero_bills WHERE id = dm.entity_id)
        WHEN dm.entity_type = 'expense' THEN (SELECT description FROM xero_expenses WHERE id = dm.entity_id)
      END as entity_name,
      CASE 
        WHEN dm.entity_type = 'purchase_order' THEN (SELECT total_amount FROM xero_purchase_orders WHERE id = dm.entity_id)
        WHEN dm.entity_type = 'invoice' THEN (SELECT total FROM xero_invoices WHERE id = dm.entity_id)
        WHEN dm.entity_type = 'bill' THEN (SELECT amount FROM xero_bills WHERE id = dm.entity_id)
        WHEN dm.entity_type = 'expense' THEN (SELECT amount FROM xero_expenses WHERE id = dm.entity_id)
      END as entity_amount
    FROM document_matches dm
    WHERE dm.scan_id = $1 AND dm.confirmed = false
    ORDER BY dm.confidence_score DESC
    LIMIT 5`,
    [req.params.id]
  );

  res.json(matches.rows);
}));

/**
 * Confirm and link a match
 */
router.post('/:id/match/:matchId/confirm', authenticate, requirePermission('can_edit_projects'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const { id: scanId, matchId } = req.params;

  // Get match details
  const matchResult = await query(
    'SELECT * FROM document_matches WHERE id = $1 AND scan_id = $2',
    [matchId, scanId]
  );

  if (matchResult.rows.length === 0) {
    throw new NotFoundError('Document match', matchId);
  }

  const match = matchResult.rows[0];

  // Update match as confirmed
  await query(
    `UPDATE document_matches 
     SET confirmed = true, 
         confirmed_by = $1, 
         confirmed_at = CURRENT_TIMESTAMP 
     WHERE id = $2`,
    [req.user!.id, matchId]
  );

  // Link document scan to entity
  const updateColumn = `${match.entity_type}_scanned_document_id`;
  const tableName = match.entity_type === 'purchase_order' ? 'xero_purchase_orders' :
                    match.entity_type === 'invoice' ? 'xero_invoices' :
                    match.entity_type === 'bill' ? 'xero_bills' :
                    'xero_expenses';

  // Use scanned_document_id column (we added this to all tables)
  await query(
    `UPDATE ${tableName} 
     SET scanned_document_id = $1, updated_at = CURRENT_TIMESTAMP 
     WHERE id = $2`,
    [scanId, match.entity_id]
  );

  // Update document_scan to link to entity
  await query(
    `UPDATE document_scans 
     SET updated_at = CURRENT_TIMESTAMP 
     WHERE id = $1`,
    [scanId]
  );

  // Reject all other matches for this scan
  await query(
    `UPDATE document_matches 
     SET confirmed = false 
     WHERE scan_id = $1 AND id != $2`,
    [scanId, matchId]
  );

  // Log activity
  await query(
    `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details)
     VALUES ($1, $2, $3, $4, $5)`,
    [
      req.user!.id,
      'confirm_document_match',
      match.entity_type,
      match.entity_id,
      JSON.stringify({ scan_id: scanId, match_id: matchId })
    ]
  );

  res.json({
    success: true,
    message: 'Match confirmed and document linked',
    match: {
      ...match,
      confirmed: true,
      confirmed_by: req.user!.id,
      confirmed_at: new Date().toISOString(),
    }
  });
}));

/**
 * Reject all matches (manual linking)
 */
router.post('/:id/match/reject', authenticate, requirePermission('can_edit_projects'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const { id: scanId } = req.params;

  // Mark all matches as rejected (we'll delete them or mark as rejected)
  await query(
    `DELETE FROM document_matches WHERE scan_id = $1 AND confirmed = false`,
    [scanId]
  );

  // Log activity
  await query(
    `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details)
     VALUES ($1, $2, $3, $4, $5)`,
    [req.user!.id, 'reject_document_matches', 'document_scan', scanId, JSON.stringify({})]
  );

  res.json({
    success: true,
    message: 'All matches rejected. You can manually link the document.'
  });
}));

/**
 * List all scanned documents
 */
router.get('/', authenticate, requirePermission('can_view_financials'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const { project_id, status, document_type } = req.query;

  let sql = `
    SELECT ds.*,
      pf.file_name, pf.file_path, pf.project_id,
      u.name as user_name,
      p.code as project_code, p.name as project_name
    FROM document_scans ds
    LEFT JOIN project_files pf ON ds.file_id = pf.id
    LEFT JOIN users u ON ds.user_id = u.id
    LEFT JOIN projects p ON pf.project_id = p.id
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (project_id) {
    sql += ` AND pf.project_id = $${paramCount++}`;
    params.push(project_id);
  }

  if (status) {
    sql += ` AND ds.status = $${paramCount++}`;
    params.push(status);
  }

  if (document_type) {
    sql += ` AND ds.document_type = $${paramCount++}`;
    params.push(document_type);
  }

  sql += ' ORDER BY ds.created_at DESC';

  const result = await query(sql, params);
  res.json(result.rows);
}));

/**
 * Retry failed scan
 */
router.post('/:id/retry', authenticate, requirePermission('can_edit_projects'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const { id: scanId } = req.params;

  // Get scan and file info
  const scanResult = await query(
    `SELECT ds.*, pf.file_path 
     FROM document_scans ds
     LEFT JOIN project_files pf ON ds.file_id = pf.id
     WHERE ds.id = $1`,
    [scanId]
  );

  if (scanResult.rows.length === 0) {
    throw new NotFoundError('Document scan', scanId);
  }

  const scan = scanResult.rows[0];
  // Extract storage path from file_path (could be URL or path)
  let storagePath: string;
  if (scan.file_path.startsWith('http://') || scan.file_path.startsWith('https://')) {
    // For S3/Google Drive URLs, we need to extract the storage path
    // The URL format depends on the storage provider
    // For now, we'll use the file_path as-is and let the OCR service handle it
    storagePath = scan.file_path;
  } else {
    // Local path - extract relative path
    storagePath = scan.file_path.startsWith('/') 
      ? scan.file_path.substring(1) // Remove leading slash
      : scan.file_path;
  }

  // Reset scan status and clear previous matches
  await query(
    `UPDATE document_scans 
     SET status = 'pending', 
         error_message = NULL, 
         updated_at = CURRENT_TIMESTAMP 
     WHERE id = $1`,
    [scanId]
  );

  await query('DELETE FROM document_matches WHERE scan_id = $1', [scanId]);

  // Process in background (pass storage path)
  processDocumentScan(scanId, storagePath).catch(error => {
    log.error('Retry OCR processing failed', error, { scanId });
  });

  res.json({
    success: true,
    message: 'Scan retry initiated',
    scan: {
      id: scanId,
      status: 'pending'
    }
  });
}));

export default router;
--- FILE: backend/src/routes/files.ts ---
import { Router, Response } from 'express';
import { query } from '../db';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';
import { fileUpload } from '../middleware/upload';
import { validateProjectAccess } from '../middleware/validateProject';
import { asyncHandler } from '../middleware/asyncHandler';
import { NotFoundError, ValidationError, FileError, ForbiddenError } from '../lib/errors';
import { log } from '../lib/logger';
import { validateFileContent, validateFileExtension } from '../lib/fileValidator';
import { ocrService } from '../lib/ocrService';
import { findMatches } from '../lib/documentMatcher';
import { StorageFactory } from '../lib/storage/StorageFactory';
import { generatePartitionedPath, resolveStoragePath } from '../lib/storage/pathUtils';
import { createReadStream } from 'fs';
import path from 'path';
import fs from 'fs';
import { bufferToStream } from '../middleware/upload';
import { Readable } from 'stream';

const router = Router();

// Get all files with filters
router.get('/', authenticate, requirePermission('can_view_financials'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const { project_id, cost_center_id, file_type } = req.query;
  
  let sql = `
    SELECT f.*,
      u.name as uploaded_by_name,
      p.code as project_code,
      p.name as project_name,
      c.name as client_name,
      cc.code as cost_center_code,
      cc.name as cost_center_name
    FROM project_files f
    LEFT JOIN users u ON f.uploaded_by = u.id
    LEFT JOIN projects p ON f.project_id = p.id
    LEFT JOIN clients c ON p.client_id = c.id
    LEFT JOIN cost_centers cc ON f.cost_center_id = cc.id
    WHERE 1=1
  `;
  const params: any[] = [];
  let paramCount = 1;

  if (project_id) {
    sql += ` AND f.project_id = $${paramCount++}`;
    params.push(project_id);
  }

  if (cost_center_id) {
    sql += ` AND f.cost_center_id = $${paramCount++}`;
    params.push(cost_center_id);
  }

  if (file_type) {
    sql += ` AND f.file_type = $${paramCount++}`;
    params.push(file_type);
  }

  sql += ' ORDER BY f.created_at DESC';

  const result = await query(sql, params);
  res.json(result.rows);
}));

// Get all logo files (must be before /:id route)
router.get('/logos', authenticate, requirePermission('can_manage_settings'), asyncHandler(async (req: AuthRequest, res: Response) => {
  try {
    const storage = await StorageFactory.getInstance();
    const basePath = 'logos';
    
    // List all files in the logos directory
    const files = await storage.list(basePath);
    
    // Filter to only files (not directories) and map to response format
    // Use storage.url() to get proper URLs (signed URLs for S3, /uploads/... for local)
    const logos = await Promise.all(
      files
        .filter((file) => !file.isDirectory)
        .map(async (file) => {
          // Get proper URL from storage provider
          // For S3, this will be a signed URL; for local, it will be /uploads/...
          const url = await storage.url(file.path);
          return {
            url,
            filename: file.name,
            upload_date: file.lastModified || new Date(),
            file_size: file.size || 0
          };
        })
    );
    
    // Sort by upload date (newest first)
    logos.sort((a, b) => new Date(b.upload_date).getTime() - new Date(a.upload_date).getTime());

    res.json(logos);
  } catch (error: any) {
    log.error('Failed to list logos', error);
    // Return empty array on error
    res.json([]);
  }
}));

// Get all timesheet images across all projects (summary) - must be before /:id route
router.get('/timesheet-images', authenticate, asyncHandler(async (req: AuthRequest, res: Response) => {
  // Check if user can view all timesheets
  const canViewAll = req.user!.role === 'admin' || 
                     req.user!.role === 'manager' || 
                     (req.user!.permissions && req.user!.permissions.includes('can_view_all_timesheets'));

  let sql = `
    SELECT 
      t.project_id,
      p.code as project_code,
      p.name as project_name,
      c.name as client_name,
      COUNT(*) FILTER (WHERE t.image_urls IS NOT NULL AND array_length(t.image_urls, 1) > 0) as timesheets_with_images,
      SUM(array_length(t.image_urls, 1)) FILTER (WHERE t.image_urls IS NOT NULL) as total_images
    FROM timesheets t
    LEFT JOIN projects p ON t.project_id = p.id
    LEFT JOIN clients c ON p.client_id = c.id
    WHERE t.image_urls IS NOT NULL AND array_length(t.image_urls, 1) > 0
  `;
  const params: any[] = [];

  // If user can't view all, only show their own timesheet images
  if (!canViewAll) {
    sql += ` AND t.user_id = $1`;
    params.push(req.user!.id);
  }

  sql += ` GROUP BY t.project_id, p.code, p.name, c.name ORDER BY c.name, p.code`;

  const result = await query(sql, params);

  // Convert numeric strings to numbers
  const rows = result.rows.map((row: any) => ({
    ...row,
    timesheets_with_images: parseInt(row.timesheets_with_images) || 0,
    total_images: parseInt(row.total_images) || 0
  }));

  res.json(rows);
}));

// Get timesheet images for a specific project - must be before /:id route
router.get('/timesheet-images/:projectId', authenticate, asyncHandler(async (req: AuthRequest, res: Response) => {
  // Check if user can view all timesheets
  const canViewAll = req.user!.role === 'admin' || 
                     req.user!.role === 'manager' || 
                     (req.user!.permissions && req.user!.permissions.includes('can_view_all_timesheets'));

  let sql = `
    SELECT 
      t.id as timesheet_id,
      t.user_id,
      t.date as timesheet_date,
      t.image_urls,
      t.created_at,
      u.name as user_name,
      p.code as project_code,
      p.name as project_name
    FROM timesheets t
    LEFT JOIN users u ON t.user_id = u.id
    LEFT JOIN projects p ON t.project_id = p.id
    WHERE t.project_id = $1 
      AND t.image_urls IS NOT NULL 
      AND array_length(t.image_urls, 1) > 0
  `;
  const params: any[] = [req.params.projectId];

  // If user can't view all, only show their own timesheet images
  if (!canViewAll) {
    sql += ` AND t.user_id = $2`;
    params.push(req.user!.id);
  }

  sql += ` ORDER BY t.date DESC, t.created_at DESC`;

  const result = await query(sql, params);

  // Flatten image_urls into individual image objects
  const images: any[] = [];
  result.rows.forEach((row: any) => {
    if (row.image_urls && Array.isArray(row.image_urls)) {
      row.image_urls.forEach((url: string, index: number) => {
        const filename = url.split('/').pop() || '';
        images.push({
          url,
          filename,
          timesheet_id: row.timesheet_id,
          timesheet_date: row.timesheet_date,
          upload_date: row.created_at,
          user_name: row.user_name,
          project_code: row.project_code,
          project_name: row.project_name,
          image_index: index
        });
      });
    }
  });

  res.json(images);
}));

// Get single file metadata (must be after specific routes)
router.get('/:id', authenticate, requirePermission('can_view_financials'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const result = await query(
    `SELECT f.*,
      u.name as uploaded_by_name,
      p.code as project_code,
      p.name as project_name,
      c.name as client_name,
      cc.code as cost_center_code,
      cc.name as cost_center_name
    FROM project_files f
    LEFT JOIN users u ON f.uploaded_by = u.id
    LEFT JOIN projects p ON f.project_id = p.id
    LEFT JOIN clients c ON p.client_id = c.id
    LEFT JOIN cost_centers cc ON f.cost_center_id = cc.id
    WHERE f.id = $1`,
    [req.params.id]
  );

  if (result.rows.length === 0) {
    throw new NotFoundError('File', req.params.id);
  }

  res.json(result.rows[0]);
}));

// Download file with access control
router.get('/:id/download', authenticate, requirePermission('can_view_financials'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const result = await query(
    `SELECT f.*, p.id as project_id, p.client_id
     FROM project_files f
     LEFT JOIN projects p ON f.project_id = p.id
     WHERE f.id = $1`,
    [req.params.id]
  );

  if (result.rows.length === 0) {
    throw new NotFoundError('File', req.params.id);
  }

  const file = result.rows[0];

  // Verify user has access to the project
  if (file.project_id) {
    // Admins and managers can access all files
    if (req.user!.role !== 'admin' && req.user!.role !== 'manager') {
      // Check if user has access to this project
      const accessResult = await query(
        'SELECT 1 FROM timesheets WHERE project_id = $1 AND user_id = $2 LIMIT 1',
        [file.project_id, req.user!.id]
      );

      if (accessResult.rows.length === 0) {
        throw new ForbiddenError('You do not have access to this file');
      }
    }
  }

  // Get storage provider
  const storage = await StorageFactory.getInstance();
  
  // Extract storage path from file_path
  // file_path could be: /uploads/projects/... (local) or https://... (S3 signed URL)
  let storagePath: string;
  let useOldPath = false;
  
  if (file.file_path.startsWith('http://') || file.file_path.startsWith('https://')) {
    // S3 signed URL - redirect directly
    return res.redirect(file.file_path);
  } else {
    // Local path - extract relative path
    storagePath = resolveStoragePath(file.file_path);
  }
  
  // Check if file exists in storage (new path)
  let exists = await storage.exists(storagePath);
  
  // Hybrid support: If not found in new storage, try old filesystem path
  if (!exists) {
    // Try old path format: /uploads/projects/{project_id}/files/{filename}
    const oldPath = file.file_path.startsWith('/') 
      ? file.file_path.substring(1) // Remove leading slash
      : file.file_path;
    
    // Check if old path exists in filesystem (only for local storage)
    if (storage.getDriver() === 'local') {
      const absoluteOldPath = path.join(process.cwd(), oldPath);
      if (fs.existsSync(absoluteOldPath)) {
        // File exists in old location - use it for now
        storagePath = oldPath;
        exists = true;
        useOldPath = true;
        log.info('File found in old location, serving from old path', { fileId: file.id, oldPath });
      }
    }
  }
  
  if (!exists) {
    throw new NotFoundError('File', 'in storage');
  }
  
  // Get file stream from storage
  const fileStream = useOldPath && storage.getDriver() === 'local'
    ? fs.createReadStream(path.join(process.cwd(), storagePath))
    : await storage.getStream(storagePath);
  
  const metadata = useOldPath && storage.getDriver() === 'local'
    ? { mimeType: file.mime_type, name: file.file_name, size: 0 }
    : await storage.getMetadata(storagePath);
  
  // Set headers
  res.setHeader('Content-Disposition', `attachment; filename="${file.file_name}"`);
  res.setHeader('Content-Type', metadata.mimeType || file.mime_type || 'application/octet-stream');
  res.setHeader('Cache-Control', 'public, max-age=3600');
  
  // Stream file to response
  fileStream.pipe(res);
}));

// Upload file with validation and content checking
router.post(
  '/',
  authenticate,
  requirePermission('can_edit_projects'),
  fileUpload.single('file'), // Multer must run first to parse FormData into req.body
  validateProjectAccess, // Then validate project_id from parsed body
  asyncHandler(async (req: AuthRequest, res: Response) => {
    if (!req.file) {
      throw new ValidationError('No file uploaded');
    }

    // Extract project_id from body (FormData fields are parsed by multer)
    const project_id = req.body?.project_id || req.body?.projectId;
    const cost_center_id = req.body?.cost_center_id || req.body?.costCenterId;

    if (!project_id) {
      log.error('File upload failed: project_id missing', { body: req.body, hasFile: !!req.file });
      throw new ValidationError('project_id is required');
    }

    // Validate file extension matches MIME type (before uploading to storage)
    if (!validateFileExtension(req.file.originalname, req.file.mimetype)) {
      throw new FileError('File extension does not match declared file type');
    }

    // Validate file content (magic number validation) - using buffer
    const isValidContent = await validateFileContent(req.file.buffer, req.file.mimetype, true);
    if (!isValidContent) {
      throw new FileError('File content does not match declared file type. The file may be corrupted or malicious.');
    }

    // Get storage provider
    let storage;
    try {
      storage = await StorageFactory.getInstance();
    } catch (storageInitError: any) {
      log.error('Failed to initialize storage provider', storageInitError, { project_id });
      throw new ValidationError(`Failed to initialize storage: ${storageInitError.message || 'Unknown error'}`);
    }

    const { sanitizeProjectId } = await import('../middleware/validateProject');
    const projectId = sanitizeProjectId(project_id);
    
    // Generate partitioned path for storage
    const basePath = `projects/${projectId}/files${cost_center_id ? `/${cost_center_id}` : ''}`;
    const storagePath = generatePartitionedPath(req.file.originalname, basePath);
    
    // Stream file from memory buffer to storage provider
    try {
      const fileStream = bufferToStream(req.file.buffer);
      await storage.put(storagePath, fileStream, {
        contentType: req.file.mimetype,
      });
    } catch (storageError: any) {
      log.error('Failed to upload file to storage', storageError, { 
        project_id, 
        storagePath,
        storageDriver: storage?.getDriver(),
        errorMessage: storageError.message,
        errorStack: storageError.stack
      });
      const errorMessage = storageError.message || 'Unknown storage error';
      throw new ValidationError(`Failed to save file to storage: ${errorMessage}`);
    }

    // Determine file type from mime type
    let fileType = 'document';
    if (req.file.mimetype.startsWith('image/')) {
      fileType = 'image';
    } else if (req.file.mimetype === 'application/pdf') {
      fileType = 'pdf';
    } else if (req.file.mimetype.includes('document') || req.file.mimetype.includes('spreadsheet')) {
      fileType = 'document';
    }

    // Generate file URL for database storage
    // Use storage provider to get the URL (will be signed URL for S3, regular path for local)
    const fileUrl = await storage.url(storagePath);
    
    const result = await query(
      `INSERT INTO project_files (
        project_id, cost_center_id, file_name, file_path, file_type, file_size, mime_type, uploaded_by
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
      RETURNING *`,
      [
        project_id,
        cost_center_id || null,
        req.file.originalname,
        fileUrl, // Storage provider URL (signed for S3, /uploads/... for local)
        fileType,
        req.file.size,
        req.file.mimetype,
        req.user!.id
      ]
    );

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details)
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'upload', 'file', result.rows[0].id, JSON.stringify({ file_name: req.file.originalname })]
    );

    // Check if user wants OCR processing (optional parameter)
    const processOCR = req.body.process_ocr === 'true' || req.body.process_ocr === true;
    
    if (processOCR && req.file.mimetype.startsWith('image/')) {
      // Create document_scan record and process in background
      try {
        const scanResult = await query(
          `INSERT INTO document_scans (file_id, user_id, status)
           VALUES ($1, $2, 'pending')
           RETURNING id`,
          [result.rows[0].id, req.user!.id]
        );

        // Process OCR in background
        // For OCR, we need to get the file from storage
        // For now, use the storage path - OCR service will need to be updated to use storage provider
        processDocumentOCR(scanResult.rows[0].id, storagePath).catch(error => {
          log.error('Background OCR processing failed', error, { fileId: result.rows[0].id });
        });
      } catch (ocrError) {
        // Don't fail file upload if OCR setup fails
        log.error('Failed to initiate OCR processing', ocrError);
      }
    }

    res.status(201).json(result.rows[0]);
  })
);

// Delete file
router.delete('/:id', authenticate, requirePermission('can_edit_projects'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const result = await query(
    `SELECT f.*, p.id as project_id
     FROM project_files f
     LEFT JOIN projects p ON f.project_id = p.id
     WHERE f.id = $1`,
    [req.params.id]
  );

  if (result.rows.length === 0) {
    throw new NotFoundError('File', req.params.id);
  }

  const file = result.rows[0];

  // Verify user has access to delete this file (must have access to the project)
  if (file.project_id) {
    if (req.user!.role !== 'admin' && req.user!.role !== 'manager') {
      const accessResult = await query(
        'SELECT 1 FROM timesheets WHERE project_id = $1 AND user_id = $2 LIMIT 1',
        [file.project_id, req.user!.id]
      );

      if (accessResult.rows.length === 0) {
        throw new ForbiddenError('You do not have permission to delete this file');
      }
    }
  }

  // Get storage provider
  const storage = await StorageFactory.getInstance();
  
  // Extract storage path from file_path
  let storagePath: string | undefined;
  if (file.file_path.startsWith('http://') || file.file_path.startsWith('https://')) {
    // S3 signed URL - extract key from URL or use file_path as-is for deletion
    // For S3, we need the key, not the URL. Store key separately or extract from URL
    // For now, if it's a URL, we can't delete it (would need to store S3 key separately)
    log.warn('Cannot delete file with S3 URL - key not stored', { fileId: req.params.id, filePath: file.file_path });
    storagePath = undefined;
  } else {
    // Local path - extract relative path
    storagePath = resolveStoragePath(file.file_path);
  }
  
  // Delete from database first
  await query('DELETE FROM project_files WHERE id = $1', [req.params.id]);

  // Delete file from storage (if we have a valid path)
  if (storagePath && !storagePath.startsWith('http')) {
    try {
      await storage.delete(storagePath);
    } catch (deleteError: any) {
      log.error('Failed to delete file from storage', deleteError, {
        fileId: req.params.id,
        storagePath,
      });
      // Continue even if file deletion fails - it's already removed from DB
    }
  }

  // Log activity
  await query(
    `INSERT INTO activity_logs (user_id, action, entity_type, entity_id)
     VALUES ($1, $2, $3, $4)`,
    [req.user!.id, 'delete', 'file', req.params.id]
  );

  res.json({ message: 'File deleted successfully' });
}));

// Get files for a project
router.get('/projects/:projectId', authenticate, requirePermission('can_view_financials'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const result = await query(
    `SELECT f.*,
      u.name as uploaded_by_name,
      cc.code as cost_center_code,
      cc.name as cost_center_name
    FROM project_files f
    LEFT JOIN users u ON f.uploaded_by = u.id
    LEFT JOIN cost_centers cc ON f.cost_center_id = cc.id
    WHERE f.project_id = $1
    ORDER BY f.created_at DESC`,
    [req.params.projectId]
  );

  res.json(result.rows);
}));

// Get files for a cost center
router.get('/cost-centers/:costCenterId', authenticate, requirePermission('can_view_financials'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const result = await query(
    `SELECT f.*,
      u.name as uploaded_by_name,
      p.code as project_code,
      p.name as project_name
    FROM project_files f
    LEFT JOIN users u ON f.uploaded_by = u.id
    LEFT JOIN projects p ON f.project_id = p.id
    WHERE f.cost_center_id = $1
    ORDER BY f.created_at DESC`,
    [req.params.costCenterId]
  );

  res.json(result.rows);
}));

// Get timesheet images for a specific project
router.get('/timesheet-images/:projectId', authenticate, asyncHandler(async (req: AuthRequest, res: Response) => {
  // Check if user can view all timesheets
  const canViewAll = req.user!.role === 'admin' || 
                     req.user!.role === 'manager' || 
                     (req.user!.permissions && req.user!.permissions.includes('can_view_all_timesheets'));

  let sql = `
    SELECT 
      t.id as timesheet_id,
      t.user_id,
      t.date as timesheet_date,
      t.image_urls,
      t.created_at,
      u.name as user_name,
      p.code as project_code,
      p.name as project_name
    FROM timesheets t
    LEFT JOIN users u ON t.user_id = u.id
    LEFT JOIN projects p ON t.project_id = p.id
    WHERE t.project_id = $1 
      AND t.image_urls IS NOT NULL 
      AND array_length(t.image_urls, 1) > 0
  `;
  const params: any[] = [req.params.projectId];

  // If user can't view all, only show their own timesheet images
  if (!canViewAll) {
    sql += ` AND t.user_id = $2`;
    params.push(req.user!.id);
  }

  sql += ` ORDER BY t.date DESC, t.created_at DESC`;

  const result = await query(sql, params);

  // Flatten image_urls into individual image objects
  const images: any[] = [];
  result.rows.forEach((row: any) => {
    if (row.image_urls && Array.isArray(row.image_urls)) {
      row.image_urls.forEach((url: string, index: number) => {
        const filename = url.split('/').pop() || '';
        images.push({
          url,
          filename,
          timesheet_id: row.timesheet_id,
          timesheet_date: row.timesheet_date,
          upload_date: row.created_at,
          user_name: row.user_name,
          project_code: row.project_code,
          project_name: row.project_name,
          image_index: index
        });
      });
    }
  });

  res.json(images);
}));

// Delete a logo file
router.delete('/logos/:filename', authenticate, requirePermission('can_manage_settings'), asyncHandler(async (req: AuthRequest, res: Response) => {
  const filename = req.params.filename;
  // Sanitize filename to prevent directory traversal
  const safeFilename = path.basename(filename);
  const baseDir = path.resolve(__dirname, '../../uploads/logos');
  const filePath = path.resolve(path.join(baseDir, safeFilename));

  // Ensure file is within the logos directory
  if (!filePath.startsWith(baseDir)) {
    log.error('Path traversal attempt detected in logo delete', null, {
      userId: req.user!.id,
      filename,
    });
    throw new FileError('Invalid file path');
  }

  if (!fs.existsSync(filePath)) {
    throw new NotFoundError('Logo file', filename);
  }

  // Delete file from filesystem
  fs.unlinkSync(filePath);

  // Check if this logo is set as company_logo in settings and remove it
  await query(
    `UPDATE settings 
     SET value = NULL, updated_at = CURRENT_TIMESTAMP
     WHERE key = 'company_logo' AND value = $1`,
    [`/uploads/logos/${safeFilename}`]
  );

  // Log activity
  await query(
    `INSERT INTO activity_logs (user_id, action, entity_type, details) 
     VALUES ($1, $2, $3, $4)`,
    [req.user!.id, 'delete', 'logo', JSON.stringify({ filename: safeFilename })]
  );

  res.json({ message: 'Logo deleted successfully' });
}));

/**
 * Process document OCR in background
 */
async function processDocumentOCR(scanId: string, filePath: string) {
  try {
    // Update status to processing
    await query(
      'UPDATE document_scans SET status = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
      ['processing', scanId]
    );

    // Check OCR service availability
    const isAvailable = await ocrService.healthCheck();
    if (!isAvailable) {
      throw new Error('OCR service is not available');
    }

    // Process image through OCR
    const ocrResult = await ocrService.processImage(filePath);

    if (!ocrResult.success) {
      await query(
        `UPDATE document_scans 
         SET status = 'failed', 
             error_message = $1, 
             updated_at = CURRENT_TIMESTAMP 
         WHERE id = $2`,
        [ocrResult.error || 'OCR processing failed', scanId]
      );
      return;
    }

    // Store extracted data
    await query(
      `UPDATE document_scans 
       SET status = 'completed',
           document_type = $1,
           extracted_data = $2,
           confidence = $3,
           processed_at = CURRENT_TIMESTAMP,
           updated_at = CURRENT_TIMESTAMP
       WHERE id = $4`,
      [
        ocrResult.document_type,
        JSON.stringify(ocrResult.extracted_data),
        ocrResult.confidence,
        scanId
      ]
    );

    // Find matches
    const matches = await findMatches(
      scanId,
      ocrResult.extracted_data,
      ocrResult.document_type
    );

    // Store matches
    for (const match of matches) {
      await query(
        `INSERT INTO document_matches (
          scan_id, entity_type, entity_id, confidence_score, match_reasons
        ) VALUES ($1, $2, $3, $4, $5)`,
        [
          scanId,
          match.entity_type,
          match.entity_id,
          match.confidence_score,
          JSON.stringify(match.match_reasons)
        ]
      );
    }

    log.info('Document OCR completed', { scanId, matchesFound: matches.length });
  } catch (error: any) {
    log.error('Document OCR processing error', error, { scanId });
    await query(
      `UPDATE document_scans 
       SET status = 'failed', 
           error_message = $1, 
           updated_at = CURRENT_TIMESTAMP 
       WHERE id = $2`,
      [error.message || 'Processing failed', scanId]
    );
  }
}

export default router;
--- FILE: backend/src/routes/health.ts ---
import { Router, Response } from 'express';
import { query } from '../db';

// Helper to get Xero credentials (duplicated from xero.ts to avoid circular dependency)
async function getXeroCredentials() {
  const clientIdResult = await query(
    `SELECT value FROM settings WHERE key = 'xero_client_id' AND user_id IS NULL`
  );
  const clientSecretResult = await query(
    `SELECT value FROM settings WHERE key = 'xero_client_secret' AND user_id IS NULL`
  );
  
  const clientId = clientIdResult.rows[0]?.value;
  const clientSecret = clientSecretResult.rows[0]?.value;
  
  return { clientId, clientSecret };
}

const router = Router();

// Health check endpoint (public)
router.get('/', async (req, res: Response) => {
  try {
    // Check database connection
    let dbHealthy = false;
    try {
      await query('SELECT 1');
      dbHealthy = true;
    } catch (error) {
      console.error('Database health check failed:', error);
    }

    // Check Xero connection status (if credentials exist)
    let xeroConfigured = false;
    let xeroConnected = false;
    try {
      const { clientId, clientSecret } = await getXeroCredentials();
      xeroConfigured = !!(clientId && clientSecret);
      
      if (xeroConfigured) {
        // Check if tokens exist
        const tokenResult = await query(
          `SELECT expires_at FROM xero_tokens ORDER BY created_at DESC LIMIT 1`
        );
        if (tokenResult.rows.length > 0) {
          const expiresAt = new Date(tokenResult.rows[0].expires_at);
          xeroConnected = expiresAt > new Date();
        }
      }
    } catch (error) {
      console.error('Xero health check failed:', error);
    }

    res.json({
      status: dbHealthy ? 'healthy' : 'unhealthy',
      database: {
        healthy: dbHealthy,
        status: dbHealthy ? 'connected' : 'disconnected'
      },
      xero: {
        configured: xeroConfigured,
        connected: xeroConnected,
        status: xeroConfigured 
          ? (xeroConnected ? 'connected' : 'not_connected')
          : 'not_configured'
      },
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    res.status(500).json({
      status: 'error',
      error: 'Health check failed'
    });
  }
});

export default router;

--- FILE: backend/src/routes/permissions.ts ---
import { Router, Response } from 'express';
import { body, validationResult } from 'express-validator';
import { query } from '../db';
import { authenticate, requireRole, AuthRequest } from '../middleware/auth';

const router = Router();

// Get all permissions (admin only)
router.get('/', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT id, key, label, description, is_system, is_custom, is_active, created_at, updated_at
       FROM permissions
       ORDER BY is_system DESC, label ASC`
    );
    res.json(result.rows);
  } catch (error) {
    console.error('Failed to fetch permissions:', error);
    res.status(500).json({ error: 'Failed to fetch permissions' });
  }
});

// Get single permission (admin only)
router.get('/:id', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT id, key, label, description, is_system, is_custom, is_active, created_at, updated_at
       FROM permissions
       WHERE id = $1`,
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Permission not found' });
    }

    res.json(result.rows[0]);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch permission' });
  }
});

// Create custom permission (admin only)
router.post('/', authenticate, requireRole('admin'),
  body('key').trim().notEmpty().matches(/^[a-z_]+$/).withMessage('Key must be lowercase with underscores'),
  body('label').trim().notEmpty(),
  body('description').optional().trim(),
  async (req: AuthRequest, res: Response) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { key, label, description } = req.body;

    try {
      // Check if permission key already exists
      const existing = await query('SELECT id FROM permissions WHERE key = $1', [key]);
      if (existing.rows.length > 0) {
        return res.status(400).json({ error: 'Permission key already exists' });
      }

      const result = await query(
        `INSERT INTO permissions (key, label, description, is_system, is_custom, is_active)
         VALUES ($1, $2, $3, false, true, true)
         RETURNING id, key, label, description, is_system, is_custom, is_active, created_at, updated_at`,
        [key, label, description || '']
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'create', 'permission', result.rows[0].id, JSON.stringify({ key, label })]
      );

      res.status(201).json(result.rows[0]);
    } catch (error) {
      console.error('Failed to create permission:', error);
      res.status(500).json({ error: 'Failed to create permission' });
    }
  }
);

// Update permission (admin only)
router.put('/:id', authenticate, requireRole('admin'),
  body('label').optional().trim().notEmpty(),
  body('description').optional().trim(),
  body('is_active').optional().isBoolean(),
  async (req: AuthRequest, res: Response) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { label, description, is_active } = req.body;

    try {
      // Check if permission exists
      const existing = await query('SELECT id, is_system FROM permissions WHERE id = $1', [req.params.id]);
      if (existing.rows.length === 0) {
        return res.status(404).json({ error: 'Permission not found' });
      }

      const permission = existing.rows[0];

      // System permissions can only have label/description updated, not key or is_active
      if (permission.is_system) {
        const updates: string[] = [];
        const params: any[] = [];
        let paramCount = 1;

        if (label !== undefined) {
          updates.push(`label = $${paramCount++}`);
          params.push(label);
        }
        if (description !== undefined) {
          updates.push(`description = $${paramCount++}`);
          params.push(description);
        }

        if (updates.length === 0) {
          return res.status(400).json({ error: 'No valid fields to update for system permission' });
        }

        updates.push(`updated_at = CURRENT_TIMESTAMP`);
        params.push(req.params.id);

        const result = await query(
          `UPDATE permissions SET ${updates.join(', ')} WHERE id = $${paramCount} RETURNING *`,
          params
        );

        // Log activity
        await query(
          `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
           VALUES ($1, $2, $3, $4, $5)`,
          [req.user!.id, 'update', 'permission', req.params.id, JSON.stringify({ label, description })]
        );

        return res.json(result.rows[0]);
      }

      // Custom permissions can be fully updated
      const updates: string[] = [];
      const params: any[] = [];
      let paramCount = 1;

      if (label !== undefined) {
        updates.push(`label = $${paramCount++}`);
        params.push(label);
      }
      if (description !== undefined) {
        updates.push(`description = $${paramCount++}`);
        params.push(description);
      }
      if (is_active !== undefined) {
        updates.push(`is_active = $${paramCount++}`);
        params.push(is_active);
      }

      if (updates.length === 0) {
        return res.status(400).json({ error: 'No fields to update' });
      }

      updates.push(`updated_at = CURRENT_TIMESTAMP`);
      params.push(req.params.id);

      const result = await query(
        `UPDATE permissions SET ${updates.join(', ')} WHERE id = $${paramCount} RETURNING *`,
        params
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'update', 'permission', req.params.id, JSON.stringify({ label, description, is_active })]
      );

      res.json(result.rows[0]);
    } catch (error) {
      console.error('Failed to update permission:', error);
      res.status(500).json({ error: 'Failed to update permission' });
    }
  }
);

// Delete custom permission (admin only, cannot delete system permissions)
router.delete('/:id', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    // Check if permission exists and is custom
    const existing = await query('SELECT id, is_system, key FROM permissions WHERE id = $1', [req.params.id]);
    if (existing.rows.length === 0) {
      return res.status(404).json({ error: 'Permission not found' });
    }

    if (existing.rows[0].is_system) {
      return res.status(400).json({ error: 'Cannot delete system permissions' });
    }

    // Check if permission is assigned to any users
    const assigned = await query(
      'SELECT COUNT(*) as count FROM user_permissions WHERE permission = $1',
      [existing.rows[0].key]
    );

    if (parseInt(assigned.rows[0].count) > 0) {
      return res.status(400).json({ 
        error: 'Cannot delete permission that is assigned to users. Remove assignments first.' 
      });
    }

    await query('DELETE FROM permissions WHERE id = $1', [req.params.id]);

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'delete', 'permission', req.params.id, JSON.stringify({ key: existing.rows[0].key })]
    );

    res.json({ message: 'Permission deleted' });
  } catch (error) {
    console.error('Failed to delete permission:', error);
    res.status(500).json({ error: 'Failed to delete permission' });
  }
});

export default router;

--- FILE: backend/src/routes/projects.ts ---
import { Router, Response } from 'express';
import { body, validationResult } from 'express-validator';
import { query, getClient } from '../db';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';
import { parsePaginationParams, createPaginatedResponse } from '../lib/pagination';
import { log } from '../lib/logger';
import { PROJECT_CODE_CONSTANTS } from '../lib/constants';
import { StorageFactory } from '../lib/storage/StorageFactory';
import { resolveStoragePath } from '../lib/storage/pathUtils';

const router = Router();

// Generate project code
const generateProjectCode = async (): Promise<string> => {
  const year = new Date().getFullYear();
  const result = await query(
    `SELECT COUNT(*) FROM projects WHERE code LIKE $1`,
    [`${PROJECT_CODE_CONSTANTS.PREFIX}-${year}-%`]
  );
  const count = parseInt(result.rows[0].count) + 1;
  return `${PROJECT_CODE_CONSTANTS.PREFIX}-${year}-${String(count).padStart(PROJECT_CODE_CONSTANTS.PADDING_LENGTH, '0')}`;
};

// Get all projects
router.get('/', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { status, client_id, search, sort = 'created_at', order = 'desc' } = req.query;
    
    // Parse pagination parameters
    const { page, limit, offset } = parsePaginationParams(req.query);
    
    // Build WHERE clause for both count and data queries
    let whereClause = 'WHERE 1=1';
    const params: any[] = [];
    let paramCount = 1;

    if (status) {
      whereClause += ` AND p.status = $${paramCount++}`;
      params.push(status);
    }

    if (client_id) {
      whereClause += ` AND p.client_id = $${paramCount++}`;
      params.push(client_id);
    }

    if (search) {
      whereClause += ` AND (p.name ILIKE $${paramCount} OR p.code ILIKE $${paramCount} OR p.description ILIKE $${paramCount})`;
      params.push(`%${search}%`);
      paramCount++;
    }

    // Get total count (without GROUP BY for accurate count)
    const countSql = `
      SELECT COUNT(DISTINCT p.id) as total 
      FROM projects p
      LEFT JOIN clients c ON p.client_id = c.id
      ${whereClause}
    `;
    const countResult = await query(countSql, params);
    const total = parseInt(countResult.rows[0].total);

    // Build data query
    let sql = `
      SELECT p.*, 
        c.name as client_name,
        (SELECT COALESCE(SUM(t.hours), 0) FROM timesheets t WHERE t.project_id = p.id) as hours_logged,
        array_agg(DISTINCT cc.id) as cost_center_ids,
        array_agg(DISTINCT cc.code) as cost_center_codes
      FROM projects p
      LEFT JOIN clients c ON p.client_id = c.id
      LEFT JOIN project_cost_centers pcc ON p.id = pcc.project_id
      LEFT JOIN cost_centers cc ON pcc.cost_center_id = cc.id
      ${whereClause}
      GROUP BY p.id, c.name
    `;

    const validSorts = ['name', 'created_at', 'budget', 'status'];
    const sortColumn = validSorts.includes(sort as string) ? `p.${sort}` : 'p.created_at';
    const sortOrder = order === 'asc' ? 'ASC' : 'DESC';
    sql += ` ORDER BY ${sortColumn} ${sortOrder}`;
    
    // Add pagination
    sql += ` LIMIT $${paramCount++} OFFSET $${paramCount++}`;
    params.push(limit, offset);

    const result = await query(sql, params);
    
    // Return paginated response
    const paginatedResponse = createPaginatedResponse(result.rows, total, page, limit);
    res.json(paginatedResponse);
  } catch (error) {
    log.error('Get projects error', error, { userId: req.user?.id });
    res.status(500).json({ error: 'Failed to fetch projects' });
  }
});

// Get single project
router.get('/:id', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT p.*, 
        c.name as client_name,
        (SELECT COALESCE(SUM(t.hours), 0) FROM timesheets t WHERE t.project_id = p.id) as hours_logged
       FROM projects p
       LEFT JOIN clients c ON p.client_id = c.id
       WHERE p.id = $1`,
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Project not found' });
    }

    // Get cost centers
    const costCenters = await query(
      `SELECT cc.* FROM cost_centers cc
       JOIN project_cost_centers pcc ON cc.id = pcc.cost_center_id
       WHERE pcc.project_id = $1`,
      [req.params.id]
    );

    // Get recent timesheets
    const timesheets = await query(
      `SELECT t.*, u.name as user_name, at.name as activity_type_name
       FROM timesheets t
       LEFT JOIN users u ON t.user_id = u.id
       LEFT JOIN activity_types at ON t.activity_type_id = at.id
       WHERE t.project_id = $1
       ORDER BY t.date DESC
       LIMIT 10`,
      [req.params.id]
    );

    // Get financials including PO commitments
    const financialsResult = await query(
      `SELECT 
        COALESCE(budget, 0) as budget,
        COALESCE(po_commitments, 0) as po_commitments,
        COALESCE(actual_cost, 0) as actual_cost,
        COALESCE(budget, 0) - COALESCE(po_commitments, 0) - COALESCE(actual_cost, 0) as available_budget
      FROM projects
      WHERE id = $1`,
      [req.params.id]
    );

    res.json({
      ...result.rows[0],
      cost_centers: costCenters.rows,
      timesheets: timesheets.rows,
      financials: financialsResult.rows[0] || { budget: 0, po_commitments: 0, actual_cost: 0, available_budget: 0 }
    });
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch project' });
  }
});

// Get project financials
router.get('/:id/financials', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const projectResult = await query('SELECT id, code, name FROM projects WHERE id = $1', [req.params.id]);
    if (projectResult.rows.length === 0) {
      return res.status(404).json({ error: 'Project not found' });
    }

    // Get budget, PO commitments, and actual costs
    const financialsResult = await query(
      `SELECT 
        COALESCE(p.budget, 0) as budget,
        COALESCE(p.po_commitments, 0) as po_commitments,
        COALESCE(p.actual_cost, 0) as actual_cost,
        COALESCE(p.budget, 0) - COALESCE(p.po_commitments, 0) - COALESCE(p.actual_cost, 0) as available_budget
      FROM projects p
      WHERE p.id = $1`,
      [req.params.id]
    );

    // Get purchase orders summary
    const poSummary = await query(
      `SELECT 
        COUNT(*) as total_count,
        COALESCE(SUM(total_amount), 0) as total_committed,
        COUNT(*) FILTER (WHERE status = 'DRAFT') as draft_count,
        COUNT(*) FILTER (WHERE status = 'AUTHORISED') as authorised_count,
        COUNT(*) FILTER (WHERE status = 'BILLED') as billed_count
      FROM xero_purchase_orders
      WHERE project_id = $1`,
      [req.params.id]
    );

    // Get bills summary
    const billsSummary = await query(
      `SELECT 
        COUNT(*) as total_count,
        COALESCE(SUM(amount), 0) as total_amount,
        COALESCE(SUM(amount_paid), 0) as total_paid,
        COALESCE(SUM(amount_due), 0) as total_due
      FROM xero_bills
      WHERE project_id = $1`,
      [req.params.id]
    );

    // Get expenses summary
    const expensesSummary = await query(
      `SELECT 
        COUNT(*) as total_count,
        COALESCE(SUM(amount), 0) as total_amount
      FROM xero_expenses
      WHERE project_id = $1`,
      [req.params.id]
    );

    res.json({
      project: projectResult.rows[0],
      financials: financialsResult.rows[0] || { budget: 0, po_commitments: 0, actual_cost: 0, available_budget: 0 },
      purchase_orders: poSummary.rows[0] || { total_count: 0, total_committed: 0, draft_count: 0, authorised_count: 0, billed_count: 0 },
      bills: billsSummary.rows[0] || { total_count: 0, total_amount: 0, total_paid: 0, total_due: 0 },
      expenses: expensesSummary.rows[0] || { total_count: 0, total_amount: 0 }
    });
  } catch (error) {
    log.error('Failed to fetch project financials', error, { projectId: req.params.id });
    res.status(500).json({ error: 'Failed to fetch project financials' });
  }
});

// Create project
router.post('/', authenticate, requirePermission('can_edit_projects'),
  body('name').trim().notEmpty(),
  body('client_id').optional().isUUID(),
  body('budget').optional().isNumeric(),
  async (req: AuthRequest, res: Response) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { name, client_id, status = 'quoted', budget = 0, description, start_date, end_date, cost_center_ids = [] } = req.body;

    const client = await getClient();
    
    try {
      await client.query('BEGIN');

      const code = await generateProjectCode();

      const result = await client.query(
        `INSERT INTO projects (code, name, client_id, status, budget, description, start_date, end_date)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8)
         RETURNING *`,
        [code, name, client_id, status, budget, description, start_date, end_date]
      );

      const project = result.rows[0];

      // Add cost centers
      for (const ccId of cost_center_ids) {
        await client.query(
          'INSERT INTO project_cost_centers (project_id, cost_center_id) VALUES ($1, $2)',
          [project.id, ccId]
        );
      }

      await client.query('COMMIT');

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'create', 'project', project.id, JSON.stringify({ name, code })]
      );

      res.status(201).json(project);
    } catch (error) {
      await client.query('ROLLBACK');
      log.error('Create project error', error, { userId: req.user?.id, projectName: name });
      res.status(500).json({ error: 'Failed to create project' });
    } finally {
      client.release();
    }
  }
);

// Update project
router.put('/:id', authenticate, requirePermission('can_edit_projects'),
  async (req: AuthRequest, res: Response) => {
    const { name, client_id, status, budget, actual_cost, description, start_date, end_date, cost_center_ids, xero_project_id } = req.body;

    const client = await getClient();

    try {
      await client.query('BEGIN');

      const updates: string[] = [];
      const values: any[] = [];
      let paramCount = 1;

      const fields = { name, client_id, status, budget, actual_cost, description, start_date, end_date, xero_project_id };
      
      for (const [key, value] of Object.entries(fields)) {
        if (value !== undefined) {
          updates.push(`${key} = $${paramCount++}`);
          values.push(value);
        }
      }

      if (updates.length > 0) {
        updates.push('updated_at = CURRENT_TIMESTAMP');
        values.push(req.params.id);

        const result = await client.query(
          `UPDATE projects SET ${updates.join(', ')} WHERE id = $${paramCount} RETURNING *`,
          values
        );

        if (result.rows.length === 0) {
          await client.query('ROLLBACK');
          return res.status(404).json({ error: 'Project not found' });
        }
      }

      // Update cost centers if provided
      if (cost_center_ids !== undefined) {
        await client.query('DELETE FROM project_cost_centers WHERE project_id = $1', [req.params.id]);
        for (const ccId of cost_center_ids) {
          await client.query(
            'INSERT INTO project_cost_centers (project_id, cost_center_id) VALUES ($1, $2)',
            [req.params.id, ccId]
          );
        }
      }

      await client.query('COMMIT');

      // Get updated project
      const project = await query(
        `SELECT p.*, c.name as client_name
         FROM projects p
         LEFT JOIN clients c ON p.client_id = c.id
         WHERE p.id = $1`,
        [req.params.id]
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'update', 'project', req.params.id, JSON.stringify(fields)]
      );

      res.json(project.rows[0]);
    } catch (error) {
      await client.query('ROLLBACK');
      res.status(500).json({ error: 'Failed to update project' });
    } finally {
      client.release();
    }
  }
);

// Delete project
router.delete('/:id', authenticate, requirePermission('can_edit_projects'), async (req: AuthRequest, res: Response) => {
  try {
    const projectId = req.params.id;

    // Get project info before deletion
    const projectResult = await query(
      'SELECT id, name, code FROM projects WHERE id = $1',
      [projectId]
    );

    if (projectResult.rows.length === 0) {
      return res.status(404).json({ error: 'Project not found' });
    }

    const project = projectResult.rows[0];

    // Get all associated files before deletion
    const projectFiles = await query(
      'SELECT id, file_path FROM project_files WHERE project_id = $1',
      [projectId]
    );

    // Get all timesheet images
    const timesheets = await query(
      'SELECT id, image_urls FROM timesheets WHERE project_id = $1',
      [projectId]
    );

    // Get all safety document PDFs
    const safetyDocuments = await query(
      'SELECT id, file_path FROM safety_documents WHERE project_id = $1 AND file_path IS NOT NULL',
      [projectId]
    );

    // Delete project from database
    await query('DELETE FROM projects WHERE id = $1', [projectId]);

    // Cleanup orphaned files in parallel (don't block response)
    const storage = await StorageFactory.getInstance();
    const cleanupPromises: Promise<void>[] = [];

    // Cleanup project files
    for (const file of projectFiles.rows) {
      if (file.file_path && !file.file_path.startsWith('http://') && !file.file_path.startsWith('https://')) {
        const storagePath = resolveStoragePath(file.file_path);
        cleanupPromises.push(
          storage.delete(storagePath).catch((err) => {
            log.error('Failed to delete project file', err, { fileId: file.id, path: storagePath });
          })
        );
      }
    }

    // Cleanup timesheet images
    for (const timesheet of timesheets.rows) {
      const imageUrls = timesheet.image_urls || [];
      for (const imageUrl of imageUrls) {
        if (imageUrl && !imageUrl.startsWith('http://') && !imageUrl.startsWith('https://')) {
          const storagePath = resolveStoragePath(imageUrl);
          cleanupPromises.push(
            storage.delete(storagePath).catch((err) => {
              log.error('Failed to delete timesheet image', err, { timesheetId: timesheet.id, path: storagePath });
            })
          );
        }
      }
    }

    // Cleanup safety document PDFs
    for (const doc of safetyDocuments.rows) {
      if (doc.file_path && !doc.file_path.startsWith('http://') && !doc.file_path.startsWith('https://')) {
        const storagePath = resolveStoragePath(doc.file_path);
        cleanupPromises.push(
          storage.delete(storagePath).catch((err) => {
            log.error('Failed to delete safety document PDF', err, { docId: doc.id, path: storagePath });
          })
        );
      }
    }

    // Run cleanup in background (don't await)
    Promise.all(cleanupPromises).then(() => {
      log.info('Project cleanup completed', { projectId, filesDeleted: cleanupPromises.length });
    }).catch((err) => {
      log.error('Error during project cleanup', err, { projectId });
    });

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'delete', 'project', projectId, JSON.stringify({ name: project.name })]
    );

    res.json({ message: 'Project deleted' });
  } catch (error) {
    log.error('Delete project error', error, { projectId: req.params.id });
    res.status(500).json({ error: 'Failed to delete project' });
  }
});

export default router;
--- FILE: backend/src/routes/role-permissions.ts ---
import { Router, Response } from 'express';
import { query } from '../db';
import { authenticate, requireRole, AuthRequest } from '../middleware/auth';

const router = Router();

// Define all available permissions with descriptions
const ALL_PERMISSIONS = [
  { key: 'can_view_financials', label: 'View Financials', description: 'Access invoices and quotes' },
  { key: 'can_edit_projects', label: 'Manage Projects', description: 'Create/edit projects' },
  { key: 'can_manage_users', label: 'User Administration', description: 'User administration' },
  { key: 'can_sync_xero', label: 'Xero Integration', description: 'Xero integration control' },
  { key: 'can_view_all_timesheets', label: 'View All Timesheets', description: 'See all team timesheets' },
  { key: 'can_edit_activity_types', label: 'Configure Activity Types', description: 'Configure activity types' },
  { key: 'can_manage_clients', label: 'Client Administration', description: 'Client administration' },
  { key: 'can_manage_cost_centers', label: 'Cost Center Setup', description: 'Cost center setup' },
  { key: 'can_view_reports', label: 'View Reports', description: 'Access reports section' },
  { key: 'can_export_data', label: 'Export Data', description: 'Export data to CSV/Excel' },
  { key: 'can_create_timesheets', label: 'Create Timesheets', description: 'Create new timesheet entries' },
  { key: 'can_view_own_timesheets', label: 'View Own Timesheets', description: 'View own timesheet entries' },
  { key: 'can_edit_own_timesheets', label: 'Edit Own Timesheets', description: 'Edit own timesheet entries' },
  { key: 'can_delete_own_timesheets', label: 'Delete Own Timesheets', description: 'Delete own timesheet entries' },
  { key: 'can_view_projects', label: 'View Projects', description: 'View project details' },
  { key: 'can_view_clients', label: 'View Clients', description: 'View client information' },
  { key: 'can_manage_settings', label: 'Manage Settings', description: 'Access system settings' },
  { key: 'can_view_dashboard', label: 'View Dashboard', description: 'Access dashboard' },
];

// Get role-based permissions (admin only)
router.get('/', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    // Get all permissions from database
    const permResult = await query('SELECT key, label, description FROM permissions WHERE is_active = true ORDER BY key');
    const dbPermissions = permResult.rows;
    
    // Merge with predefined permissions (database takes precedence)
    const permissions = ALL_PERMISSIONS.map(perm => {
      const dbPerm = dbPermissions.find(p => p.key === perm.key);
      return dbPerm || perm;
    });

    // Get default permissions for each role
    const roles = ['admin', 'manager', 'user'];
    const rolePermissions: Record<string, Record<string, boolean>> = {};

    for (const role of roles) {
      // Get all users with this role
      const usersResult = await query(
        'SELECT id FROM users WHERE role = $1 LIMIT 1',
        [role]
      );

      if (usersResult.rows.length > 0) {
        // Get permissions for a user with this role (as a sample)
        const userId = usersResult.rows[0].id;
        const userPermsResult = await query(
          'SELECT permission, granted FROM user_permissions WHERE user_id = $1',
          [userId]
        );

        // Build permission map
        const permMap: Record<string, boolean> = {};
        userPermsResult.rows.forEach((row: any) => {
          permMap[row.permission] = row.granted;
        });

        // Set defaults based on role
        permissions.forEach(perm => {
          if (!permMap.hasOwnProperty(perm.key)) {
            // Use default permissions based on role
            if (role === 'admin') {
              permMap[perm.key] = true; // Admins have all permissions
            } else if (role === 'manager') {
              permMap[perm.key] = [
                'can_view_financials',
                'can_edit_projects',
                'can_view_all_timesheets',
                'can_manage_clients',
                'can_view_reports',
                'can_create_timesheets',
                'can_view_own_timesheets',
                'can_edit_own_timesheets',
                'can_view_projects',
                'can_view_clients',
                'can_view_dashboard'
              ].includes(perm.key);
            } else {
              permMap[perm.key] = [
                'can_create_timesheets',
                'can_view_own_timesheets',
                'can_edit_own_timesheets',
                'can_view_projects',
                'can_view_clients',
                'can_view_dashboard'
              ].includes(perm.key);
            }
          }
        });

        rolePermissions[role] = permMap;
      } else {
        // No users with this role, use defaults
        const permMap: Record<string, boolean> = {};
        permissions.forEach(perm => {
          if (role === 'admin') {
            permMap[perm.key] = true;
          } else if (role === 'manager') {
            permMap[perm.key] = [
              'can_view_financials',
              'can_edit_projects',
              'can_view_all_timesheets',
              'can_manage_clients',
              'can_view_reports',
              'can_create_timesheets',
              'can_view_own_timesheets',
              'can_edit_own_timesheets',
              'can_view_projects',
              'can_view_clients',
              'can_view_dashboard'
            ].includes(perm.key);
          } else {
            permMap[perm.key] = [
              'can_create_timesheets',
              'can_view_own_timesheets',
              'can_edit_own_timesheets',
              'can_view_projects',
              'can_view_clients',
              'can_view_dashboard'
            ].includes(perm.key);
          }
        });
        rolePermissions[role] = permMap;
      }
    }

    res.json({
      permissions,
      rolePermissions
    });
  } catch (error) {
    console.error('Failed to fetch role permissions:', error);
    res.status(500).json({ error: 'Failed to fetch role permissions' });
  }
});

// Update role-based permissions (admin only)
router.put('/', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const { rolePermissions } = req.body;

    if (!rolePermissions || typeof rolePermissions !== 'object') {
      return res.status(400).json({ error: 'Invalid role permissions data' });
    }

    // Update permissions for all users with each role
    for (const [role, permissions] of Object.entries(rolePermissions)) {
      if (!['admin', 'manager', 'user'].includes(role)) {
        continue;
      }

      // Get all users with this role
      const usersResult = await query('SELECT id FROM users WHERE role = $1', [role]);

      for (const user of usersResult.rows) {
        // Delete existing permissions
        await query('DELETE FROM user_permissions WHERE user_id = $1', [user.id]);

        // Insert new permissions
        const permMap = permissions as Record<string, boolean>;
        for (const [permission, granted] of Object.entries(permMap)) {
          if (granted) {
            await query(
              'INSERT INTO user_permissions (user_id, permission, granted) VALUES ($1, $2, true)',
              [user.id, permission]
            );
          }
        }
      }
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, details) 
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'update_role_permissions', 'role', JSON.stringify({ rolePermissions })]
    );

    res.json({ message: 'Role permissions updated successfully' });
  } catch (error) {
    console.error('Failed to update role permissions:', error);
    res.status(500).json({ error: 'Failed to update role permissions' });
  }
});

export default router;

--- FILE: backend/src/routes/safetyDocuments.ts ---
import { Router, Response } from 'express';
import { body, validationResult } from 'express-validator';
import { query } from '../db';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';
import { generateDocumentPDF } from '../lib/pdfGenerator';
import { StorageFactory } from '../lib/storage/StorageFactory';
import { generatePartitionedPath, resolveStoragePath } from '../lib/storage/pathUtils';
import { createReadStream } from 'fs';
import path from 'path';
import fs from 'fs';
import { log } from '../lib/logger';

const router = Router();

// Get all safety documents with filters
router.get('/', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { project_id, cost_center_id, document_type, status } = req.query;
    
    let sql = `
      SELECT d.*,
        u1.name as created_by_name,
        u2.name as approved_by_name,
        p.code as project_code,
        p.name as project_name,
        c.name as client_name,
        cc.code as cost_center_code,
        cc.name as cost_center_name
      FROM safety_documents d
      LEFT JOIN users u1 ON d.created_by = u1.id
      LEFT JOIN users u2 ON d.approved_by = u2.id
      LEFT JOIN projects p ON d.project_id = p.id
      LEFT JOIN clients c ON p.client_id = c.id
      LEFT JOIN cost_centers cc ON d.cost_center_id = cc.id
      WHERE 1=1
    `;
    const params: any[] = [];
    let paramCount = 1;

    if (project_id) {
      sql += ` AND d.project_id = $${paramCount++}`;
      params.push(project_id);
    }

    if (cost_center_id) {
      sql += ` AND d.cost_center_id = $${paramCount++}`;
      params.push(cost_center_id);
    }

    if (document_type) {
      sql += ` AND d.document_type = $${paramCount++}`;
      params.push(document_type);
    }

    if (status) {
      sql += ` AND d.status = $${paramCount++}`;
      params.push(status);
    }

    sql += ' ORDER BY d.created_at DESC';

    const result = await query(sql, params);
    res.json(result.rows);
  } catch (error) {
    console.error('Get safety documents error:', error);
    res.status(500).json({ error: 'Failed to fetch safety documents' });
  }
});

// Get single safety document
router.get('/:id', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT d.*,
        u1.name as created_by_name,
        u2.name as approved_by_name,
        p.code as project_code,
        p.name as project_name,
        c.name as client_name,
        cc.code as cost_center_code,
        cc.name as cost_center_name
      FROM safety_documents d
      LEFT JOIN users u1 ON d.created_by = u1.id
      LEFT JOIN users u2 ON d.approved_by = u2.id
      LEFT JOIN projects p ON d.project_id = p.id
      LEFT JOIN clients c ON p.client_id = c.id
      LEFT JOIN cost_centers cc ON d.cost_center_id = cc.id
      WHERE d.id = $1`,
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Safety document not found' });
    }

    res.json(result.rows[0]);
  } catch (error) {
    console.error('Get safety document error:', error);
    res.status(500).json({ error: 'Failed to fetch safety document' });
  }
});

// Create safety document
router.post(
  '/',
  authenticate,
  requirePermission('can_edit_projects'),
  [
    body('project_id').notEmpty().withMessage('Project ID is required'),
    body('document_type').isIn(['jsa', 'electrical_compliance', 'electrical_safety_certificate']).withMessage('Invalid document type'),
    body('title').notEmpty().withMessage('Title is required'),
    body('data').isObject().withMessage('Data must be an object'),
  ],
  async (req: AuthRequest, res: Response) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        return res.status(400).json({ errors: errors.array() });
      }

      const { project_id, cost_center_id, document_type, title, data, status } = req.body;

      const result = await query(
        `INSERT INTO safety_documents (
          project_id, cost_center_id, document_type, title, data, status, created_by
        ) VALUES ($1, $2, $3, $4, $5, $6, $7)
        RETURNING *`,
        [
          project_id,
          cost_center_id || null,
          document_type,
          title,
          JSON.stringify(data),
          status || 'draft',
          req.user!.id
        ]
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details)
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'create', 'safety_document', result.rows[0].id, JSON.stringify({ document_type, title })]
      );

      res.status(201).json(result.rows[0]);
    } catch (error) {
      console.error('Create safety document error:', error);
      res.status(500).json({ error: 'Failed to create safety document' });
    }
  }
);

// Update safety document
router.put(
  '/:id',
  authenticate,
  requirePermission('can_edit_projects'),
  [
    body('title').optional().notEmpty().withMessage('Title cannot be empty'),
    body('data').optional().isObject().withMessage('Data must be an object'),
  ],
  async (req: AuthRequest, res: Response) => {
    try {
      const errors = validationResult(req);
      if (!errors.isEmpty()) {
        return res.status(400).json({ errors: errors.array() });
      }

      const { title, data, status } = req.body;

      // Build update query dynamically
      const updates: string[] = [];
      const params: any[] = [];
      let paramCount = 1;

      if (title !== undefined) {
        updates.push(`title = $${paramCount++}`);
        params.push(title);
      }

      if (data !== undefined) {
        updates.push(`data = $${paramCount++}`);
        params.push(JSON.stringify(data));
      }

      if (status !== undefined) {
        updates.push(`status = $${paramCount++}`);
        params.push(status);
      }

      updates.push(`updated_at = CURRENT_TIMESTAMP`);
      params.push(req.params.id);

      const result = await query(
        `UPDATE safety_documents
         SET ${updates.join(', ')}
         WHERE id = $${paramCount}
         RETURNING *`,
        params
      );

      if (result.rows.length === 0) {
        return res.status(404).json({ error: 'Safety document not found' });
      }

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details)
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'update', 'safety_document', req.params.id, JSON.stringify({ changes: Object.keys(req.body) })]
      );

      res.json(result.rows[0]);
    } catch (error) {
      console.error('Update safety document error:', error);
      res.status(500).json({ error: 'Failed to update safety document' });
    }
  }
);

// Delete safety document
router.delete('/:id', authenticate, requirePermission('can_edit_projects'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query('SELECT file_path FROM safety_documents WHERE id = $1', [req.params.id]);

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Safety document not found' });
    }

    const filePath = result.rows[0].file_path;

    // Delete from database first
    await query('DELETE FROM safety_documents WHERE id = $1', [req.params.id]);

    // Delete PDF file from storage if it exists
    if (filePath) {
      const storage = await StorageFactory.getInstance();
      try {
        // Extract storage path from file_path
        let storagePath: string;
        if (filePath.startsWith('http://') || filePath.startsWith('https://')) {
          // S3 signed URL - can't delete directly
          log.warn('Cannot delete S3 file from signed URL', { filePath, documentId: req.params.id });
        } else {
          // Local path - extract relative path
          storagePath = resolveStoragePath(filePath);
          await storage.delete(storagePath);
        }
      } catch (deleteError: any) {
        log.error('Failed to delete PDF from storage', deleteError, {
          documentId: req.params.id,
          filePath,
        });
        // Continue - file is already removed from DB
      }
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id)
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'delete', 'safety_document', req.params.id]
    );

    res.json({ message: 'Safety document deleted successfully' });
  } catch (error) {
    console.error('Delete safety document error:', error);
    res.status(500).json({ error: 'Failed to delete safety document' });
  }
});

// Generate PDF from safety document
router.post('/:id/generate-pdf', authenticate, requirePermission('can_edit_projects'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      'SELECT id, project_id, document_type, title, data FROM safety_documents WHERE id = $1',
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Safety document not found' });
    }

    const doc = result.rows[0];
    const rawProjectId = doc.project_id;
    
    if (!rawProjectId) {
      return res.status(400).json({ error: 'Safety document does not have an associated project' });
    }

    // Sanitize project_id for security (even though it comes from database)
    const { sanitizeProjectId } = await import('../middleware/validateProject');
    let projectId: string;
    try {
      projectId = sanitizeProjectId(rawProjectId);
    } catch (validationError: any) {
      log.error('Invalid project_id from database', validationError, { docId: doc.id, rawProjectId });
      return res.status(500).json({ error: 'Invalid project data' });
    }

    // Parse JSON data
    const documentData = typeof doc.data === 'string' ? JSON.parse(doc.data) : doc.data;

    // Generate PDF to temp file first
    const tempDir = path.join(__dirname, '../../uploads/temp');
    if (!fs.existsSync(tempDir)) {
      fs.mkdirSync(tempDir, { recursive: true });
    }
    const tempPath = path.join(tempDir, `${doc.id}.pdf`);

    let fileUrl: string;
    try {
      // Generate PDF to temp file
      await generateDocumentPDF(doc.document_type, documentData, tempPath);

      // Upload PDF to storage provider
      let storage;
      try {
        storage = await StorageFactory.getInstance();
      } catch (storageInitError: any) {
        log.error('Failed to initialize storage provider for PDF generation', storageInitError, { docId: doc.id, projectId });
        throw new Error(`Failed to initialize storage: ${storageInitError.message || 'Unknown error'}`);
      }

      const basePath = `projects/${projectId}/safety-documents`;
      const storagePath = generatePartitionedPath(`${doc.id}.pdf`, basePath);
      
      // Stream PDF from temp to storage
      try {
        const pdfStream = createReadStream(tempPath);
        await storage.put(storagePath, pdfStream, {
          contentType: 'application/pdf',
        });
        
        // Get URL from storage provider
        fileUrl = await storage.url(storagePath);
      } catch (storageError: any) {
        log.error('Failed to upload PDF to storage', storageError, {
          docId: doc.id,
          projectId,
          storagePath,
          errorMessage: storageError.message,
          errorStack: storageError.stack
        });
        throw new Error(`Failed to upload PDF to storage: ${storageError.message || 'Unknown error'}`);
      }
    } finally {
      // Always cleanup temp file, even if upload fails
      try {
        if (fs.existsSync(tempPath)) {
          fs.unlinkSync(tempPath);
        }
      } catch (cleanupError) {
        log.error('Failed to cleanup temp PDF file', cleanupError, { tempPath });
      }
    }

    // Update document with file path (URL from storage provider)
    await query(
      'UPDATE safety_documents SET file_path = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
      [fileUrl, doc.id]
    );

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details)
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'generate_pdf', 'safety_document', doc.id, JSON.stringify({ document_type: doc.document_type })]
    );

    res.json({ message: 'PDF generated successfully', file_path: fileUrl });
  } catch (error: any) {
    log.error('Generate PDF error', error, {
      docId: req.params.id,
      errorMessage: error.message,
      errorStack: error.stack
    });
    const errorMessage = error?.message || 'Failed to generate PDF';
    res.status(500).json({ 
      error: 'Failed to generate PDF',
      details: process.env.NODE_ENV === 'development' ? errorMessage : undefined
    });
  }
});

// Download generated PDF
router.get('/:id/pdf', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query('SELECT file_path, title, document_type FROM safety_documents WHERE id = $1', [req.params.id]);

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Safety document not found' });
    }

    const doc = result.rows[0];

    if (!doc.file_path) {
      return res.status(404).json({ error: 'PDF not generated yet. Please generate PDF first.' });
    }

    // Get storage provider
    const storage = await StorageFactory.getInstance();
    
    // Extract storage path from file_path
    let storagePath: string;
    let useOldPath = false;
    
    if (doc.file_path.startsWith('http://') || doc.file_path.startsWith('https://')) {
      // S3 signed URL - redirect directly (short-circuit for performance)
      return res.redirect(doc.file_path);
    } else {
      // Local path - extract relative path
      storagePath = resolveStoragePath(doc.file_path);
    }
    
    // Check if file exists in storage (new path)
    let exists = await storage.exists(storagePath);
    
    // Hybrid support: If not found in new storage, try old filesystem path
    if (!exists) {
      // Try old path format: /uploads/projects/{project_id}/safety-documents/{filename}
      const oldPath = doc.file_path.startsWith('/') 
        ? doc.file_path.substring(1) // Remove leading slash
        : doc.file_path;
      
      // Check if old path exists in filesystem (only for local storage)
      if (storage.getDriver() === 'local') {
        const absoluteOldPath = path.join(process.cwd(), oldPath);
        if (fs.existsSync(absoluteOldPath)) {
          // File exists in old location - use it for now
          storagePath = oldPath;
          exists = true;
          useOldPath = true;
          log.info('PDF found in old location, serving from old path', { documentId: req.params.id, oldPath });
        }
      }
    }
    
    if (!exists) {
      return res.status(404).json({ error: 'PDF file not found in storage' });
    }
    
    // Get file stream from storage
    const fileStream = useOldPath && storage.getDriver() === 'local'
      ? fs.createReadStream(path.join(process.cwd(), storagePath))
      : await storage.getStream(storagePath);
    
    // Set headers
    const fileName = `${doc.title || doc.document_type}_${req.params.id}.pdf`;
    res.setHeader('Content-Disposition', `attachment; filename="${fileName}"`);
    res.setHeader('Content-Type', 'application/pdf');
    res.setHeader('Cache-Control', 'public, max-age=3600');
    
    // Stream PDF to response
    fileStream.pipe(res);
  } catch (error: any) {
    log.error('Download PDF error', error, {
      docId: req.params.id,
      errorMessage: error.message,
      errorStack: error.stack
    });
    res.status(500).json({ 
      error: 'Failed to download PDF',
      details: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

export default router;

--- FILE: backend/src/routes/search.ts ---
import { Router, Response } from 'express';
import { query } from '../db';
import { authenticate, AuthRequest } from '../middleware/auth';

const router = Router();

// Global search
router.get('/', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { q, type, limit = 20 } = req.query;
    
    if (!q || (q as string).length < 2) {
      return res.json({ clients: [], projects: [], timesheets: [] });
    }

    const searchTerm = `%${q}%`;
    const searchLimit = Math.min(parseInt(limit as string) || 20, 50);

    const results: any = {};

    // Search based on type or search all
    if (!type || type === 'clients') {
      const clients = await query(
        `SELECT id, name, contact_name, email, location, status
         FROM clients
         WHERE name ILIKE $1 OR contact_name ILIKE $1 OR address ILIKE $1 OR email ILIKE $1
         ORDER BY name ASC
         LIMIT $2`,
        [searchTerm, searchLimit]
      );
      results.clients = clients.rows;
    }

    if (!type || type === 'projects') {
      const projects = await query(
        `SELECT p.id, p.code, p.name, p.status, c.name as client_name
         FROM projects p
         LEFT JOIN clients c ON p.client_id = c.id
         WHERE p.name ILIKE $1 OR p.code ILIKE $1 OR p.description ILIKE $1 OR c.name ILIKE $1
         ORDER BY p.created_at DESC
         LIMIT $2`,
        [searchTerm, searchLimit]
      );
      results.projects = projects.rows;
    }

    if (!type || type === 'timesheets') {
      const canViewAll = req.user!.role === 'admin' || 
                         req.user!.role === 'manager' || 
                         req.user!.permissions.includes('can_view_all_timesheets');

      let timesheetSql = `
        SELECT t.id, t.date, t.hours, t.notes,
          p.name as project_name,
          c.name as client_name,
          u.name as user_name
        FROM timesheets t
        LEFT JOIN projects p ON t.project_id = p.id
        LEFT JOIN clients c ON t.client_id = c.id
        LEFT JOIN users u ON t.user_id = u.id
        WHERE t.notes ILIKE $1 OR p.name ILIKE $1 OR c.name ILIKE $1
      `;

      const params: any[] = [searchTerm];

      if (!canViewAll) {
        timesheetSql += ' AND t.user_id = $3';
        params.push(req.user!.id);
      }

      timesheetSql += ` ORDER BY t.date DESC LIMIT $2`;
      params.splice(1, 0, searchLimit);

      const timesheets = await query(timesheetSql, params);
      results.timesheets = timesheets.rows;
    }

    res.json(results);
  } catch (error) {
    console.error('Search error:', error);
    res.status(500).json({ error: 'Search failed' });
  }
});

// Save recent search (optional feature)
router.post('/recent', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { query: searchQuery, type } = req.body;
    
    // Store in settings as JSON
    const existing = await query(
      `SELECT value FROM settings WHERE key = 'recent_searches' AND user_id = $1`,
      [req.user!.id]
    );

    let searches = [];
    if (existing.rows.length > 0 && existing.rows[0].value) {
      searches = JSON.parse(existing.rows[0].value);
    }

    // Add new search to front, limit to 10
    searches = [{ query: searchQuery, type, timestamp: new Date() }, ...searches].slice(0, 10);

    await query(
      `INSERT INTO settings (key, value, user_id) VALUES ('recent_searches', $1, $2)
       ON CONFLICT (key, user_id) DO UPDATE SET value = $1, updated_at = CURRENT_TIMESTAMP`,
      [JSON.stringify(searches), req.user!.id]
    );

    res.json({ message: 'Search saved' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to save search' });
  }
});

// Get recent searches
router.get('/recent', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT value FROM settings WHERE key = 'recent_searches' AND user_id = $1`,
      [req.user!.id]
    );

    if (result.rows.length === 0 || !result.rows[0].value) {
      return res.json([]);
    }

    res.json(JSON.parse(result.rows[0].value));
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch recent searches' });
  }
});

// Clear recent searches
router.delete('/recent', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    await query(
      `DELETE FROM settings WHERE key = 'recent_searches' AND user_id = $1`,
      [req.user!.id]
    );

    res.json({ message: 'Recent searches cleared' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to clear recent searches' });
  }
});

export default router;
--- FILE: backend/src/routes/settings.ts ---
import { Router, Response } from 'express';
import { query } from '../db';
import { authenticate, requireRole, AuthRequest } from '../middleware/auth';
import { logoUpload, faviconUpload } from '../middleware/upload';
import { clearEmailSettingsCache, sendTestEmail } from '../lib/email';
import { StorageFactory } from '../lib/storage/StorageFactory';
import { StorageConfig } from '../lib/storage/types';
import { generatePartitionedPath } from '../lib/storage/pathUtils';
import { bufferToStream } from '../middleware/upload';
import { log } from '../lib/logger';
import { isGoogleDriveConnected } from '../lib/googleDrive';
import fs from 'fs';
import path from 'path';
import { env } from '../config/env';

const router = Router();

// Get all settings (admin gets global, users get their own)
router.get('/', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const isAdmin = req.user!.role === 'admin';
    
    // Get user-specific settings
    const userSettings = await query(
      `SELECT key, value FROM settings WHERE user_id = $1`,
      [req.user!.id]
    );

    // Get global settings if admin
    let globalSettings: any[] = [];
    if (isAdmin) {
      const global = await query(
        `SELECT key, value FROM settings WHERE user_id IS NULL`
      );
      globalSettings = global.rows;
    } else {
      // Non-admins only get public global settings
      const publicGlobal = await query(
        `SELECT key, value FROM settings 
         WHERE user_id IS NULL AND key IN ('company_name', 'company_logo', 'timezone')`
      );
      globalSettings = publicGlobal.rows;
    }

    const result: Record<string, any> = {};
    
    globalSettings.forEach(row => {
      result[row.key] = row.value;
    });
    
    userSettings.rows.forEach(row => {
      result[`user_${row.key}`] = row.value;
    });

    res.json(result);
  } catch (error: any) {
    console.error('Failed to fetch settings:', error);
    res.status(500).json({ 
      error: 'Failed to fetch settings',
      details: env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

// Get storage configuration (admin only) - MUST be before /:key route
router.get('/storage', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT key, value FROM settings 
       WHERE user_id IS NULL 
       AND key IN ('storage_driver', 'storage_base_path', 'storage_s3_bucket', 'storage_s3_region', 'storage_s3_access_key_id', 'storage_s3_secret_access_key', 'storage_s3_endpoint', 'storage_google_drive_folder_id')`
    );

    const settings: Record<string, string> = {};
    result.rows.forEach((row: any) => {
      settings[row.key] = row.value;
    });

    // Don't return secret access key in response (security)
    const response: any = {
      driver: settings.storage_driver || 'local',
      basePath: settings.storage_base_path || 'uploads',
    };

    if (settings.storage_driver === 's3') {
      response.s3Bucket = settings.storage_s3_bucket || '';
      response.s3Region = settings.storage_s3_region || 'us-east-1';
      response.s3AccessKeyId = settings.storage_s3_access_key_id || '';
      // Only return masked secret key
      if (settings.storage_s3_secret_access_key) {
        const secret = settings.storage_s3_secret_access_key;
        response.s3SecretAccessKey = secret.length > 8 
          ? `${secret.substring(0, 4)}${'*'.repeat(secret.length - 8)}${secret.substring(secret.length - 4)}`
          : '****';
      }
      response.s3Endpoint = settings.storage_s3_endpoint || '';
    } else if (settings.storage_driver === 'google-drive') {
      response.googleDriveFolderId = settings.storage_google_drive_folder_id || '';
      // Check OAuth connection status
      try {
        response.googleDriveConnected = await isGoogleDriveConnected();
      } catch (error: any) {
        log.error('Failed to check Google Drive connection status', error);
        response.googleDriveConnected = false;
      }
    }

    res.json(response);
  } catch (error: any) {
    console.error('Failed to fetch storage settings:', error);
    res.status(500).json({ 
      error: 'Failed to fetch storage settings',
      details: env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

// Update storage configuration (admin only) - MUST be before /:key route
router.put('/storage', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const { driver, basePath, s3Bucket, s3Region, s3AccessKeyId, s3SecretAccessKey, s3Endpoint, googleDriveFolderId } = req.body;

    // Validate driver
    if (driver && !['local', 's3', 'google-drive'].includes(driver)) {
      return res.status(400).json({ error: 'Invalid storage driver. Must be "local", "s3", or "google-drive"' });
    }

    // Validate S3 configuration if switching to S3
    if (driver === 's3') {
      if (!s3Bucket || !s3AccessKeyId || !s3SecretAccessKey) {
        return res.status(400).json({ 
          error: 'S3 configuration incomplete',
          missing: [
            !s3Bucket && 'bucket',
            !s3AccessKeyId && 'accessKeyId',
            !s3SecretAccessKey && 'secretAccessKey'
          ].filter(Boolean)
        });
      }
    }

    // Validate Google Drive configuration if switching to Google Drive
    if (driver === 'google-drive') {
      // Check OAuth connection
      const isConnected = await isGoogleDriveConnected();
      if (!isConnected) {
        return res.status(400).json({ 
          error: 'Google Drive not connected',
          message: 'Please connect your Google Drive account in Settings ‚Üí Integrations before using Google Drive storage.'
        });
      }
    }

    // Test connection before saving (if switching to S3/Google Drive or updating config)
    if (driver === 's3' || driver === 'google-drive' || (driver && driver !== 'local')) {
      try {
        const testConfig: StorageConfig = {
          driver: driver || 's3',
          basePath: basePath || 'uploads',
          s3Bucket,
          s3Region: s3Region || 'us-east-1',
          s3AccessKeyId,
          s3SecretAccessKey,
          s3Endpoint,
          googleDriveFolderId,
        };

        const testProvider = await StorageFactory.createTestInstance(testConfig);
        const testResult = await testProvider.testConnection();

        if (!testResult.success) {
          return res.status(400).json({ 
            error: 'Storage connection test failed',
            message: testResult.message
          });
        }
      } catch (testError: any) {
        return res.status(400).json({ 
          error: 'Storage connection test failed',
          message: testError.message
        });
      }
    }

    // Save settings
    const settingsToSave = [
      { key: 'storage_driver', value: driver || 'local' },
      { key: 'storage_base_path', value: basePath || 'uploads' },
    ];

    if (driver === 's3') {
      settingsToSave.push(
        { key: 'storage_s3_bucket', value: s3Bucket },
        { key: 'storage_s3_region', value: s3Region || 'us-east-1' },
        { key: 'storage_s3_access_key_id', value: s3AccessKeyId },
        { key: 'storage_s3_secret_access_key', value: s3SecretAccessKey }, // TODO: Encrypt this
        ...(s3Endpoint ? [{ key: 'storage_s3_endpoint', value: s3Endpoint }] : [])
      );
    } else if (driver === 'google-drive') {
      // Save Google Drive folder ID if provided
      if (googleDriveFolderId) {
        settingsToSave.push(
          { key: 'storage_google_drive_folder_id', value: googleDriveFolderId }
        );
      } else {
        // Clear folder ID if not provided
        await query('DELETE FROM settings WHERE key = $1 AND user_id IS NULL', ['storage_google_drive_folder_id']);
      }
    }

    // Clear settings for other drivers when switching
    if (driver === 'local') {
      // Clear S3 and Google Drive settings
      const otherSettings = ['storage_s3_bucket', 'storage_s3_region', 'storage_s3_access_key_id', 'storage_s3_secret_access_key', 'storage_s3_endpoint', 'storage_google_drive_folder_id'];
      for (const key of otherSettings) {
        await query('DELETE FROM settings WHERE key = $1 AND user_id IS NULL', [key]);
      }
    } else if (driver === 's3') {
      // Clear Google Drive settings
      await query('DELETE FROM settings WHERE key = $1 AND user_id IS NULL', ['storage_google_drive_folder_id']);
    } else if (driver === 'google-drive') {
      // Clear S3 settings
      const s3Settings = ['storage_s3_bucket', 'storage_s3_region', 'storage_s3_access_key_id', 'storage_s3_secret_access_key', 'storage_s3_endpoint'];
      for (const key of s3Settings) {
        await query('DELETE FROM settings WHERE key = $1 AND user_id IS NULL', [key]);
      }
    }

    // Save all settings
    for (const { key, value } of settingsToSave) {
      await query(
        `INSERT INTO settings (key, value, user_id)
         VALUES ($1, $2, NULL)
         ON CONFLICT (key, user_id) DO UPDATE SET value = $2, updated_at = CURRENT_TIMESTAMP`,
        [key, value]
      );
    }

    // Invalidate storage factory cache
    StorageFactory.invalidateCache();

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, details) 
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'update', 'storage_settings', JSON.stringify({ driver })]
    );

    res.json({ message: 'Storage configuration updated successfully' });
  } catch (error: any) {
    console.error('Failed to update storage settings:', error);
    res.status(500).json({ 
      error: 'Failed to update storage settings',
      details: env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

// Test storage connection without saving (admin only) - MUST be before /:key route
router.post('/storage/test', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const { driver, basePath, s3Bucket, s3Region, s3AccessKeyId, s3SecretAccessKey, s3Endpoint, googleDriveFolderId } = req.body;

    // Validate driver
    if (!driver || !['local', 's3', 'google-drive'].includes(driver)) {
      return res.status(400).json({ error: 'Invalid storage driver. Must be "local", "s3", or "google-drive"' });
    }

    // Validate S3 configuration
    if (driver === 's3') {
      if (!s3Bucket || !s3AccessKeyId || !s3SecretAccessKey) {
        return res.status(400).json({ 
          error: 'S3 configuration incomplete',
          missing: [
            !s3Bucket && 'bucket',
            !s3AccessKeyId && 'accessKeyId',
            !s3SecretAccessKey && 'secretAccessKey'
          ].filter(Boolean)
        });
      }
    }

    // Validate Google Drive - check OAuth connection
    if (driver === 'google-drive') {
      const isConnected = await isGoogleDriveConnected();
      if (!isConnected) {
        return res.status(400).json({ 
          success: false,
          message: 'Google Drive not connected. Please connect your Google Drive account in Settings ‚Üí Integrations first.'
        });
      }
    }

    // Create test instance
    const testConfig: StorageConfig = {
      driver,
      basePath: basePath || 'uploads',
      s3Bucket,
      s3Region: s3Region || 'us-east-1',
      s3AccessKeyId,
      s3SecretAccessKey,
      s3Endpoint,
      googleDriveFolderId,
    };

    const testProvider = await StorageFactory.createTestInstance(testConfig);
    const testResult = await testProvider.testConnection();

    res.json(testResult);
  } catch (error: any) {
    console.error('Storage connection test error:', error);
    res.status(500).json({ 
      success: false,
      message: error.message || 'Connection test failed'
    });
  }
});

// Get specific setting
router.get('/:key', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    // Try user-specific first
    let result = await query(
      `SELECT value FROM settings WHERE key = $1 AND user_id = $2`,
      [req.params.key, req.user!.id]
    );

    if (result.rows.length === 0) {
      // Try global
      result = await query(
        `SELECT value FROM settings WHERE key = $1 AND user_id IS NULL`,
        [req.params.key]
      );
    }

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Setting not found' });
    }

    res.json({ key: req.params.key, value: result.rows[0].value });
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch setting' });
  }
});

// Update setting
router.put('/:key', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { value, global = false } = req.body;

    // Only admins can update global settings
    if (global && req.user!.role !== 'admin') {
      return res.status(403).json({ error: 'Only admins can update global settings' });
    }

    const userId = global ? null : req.user!.id;

    await query(
      `INSERT INTO settings (key, value, user_id)
       VALUES ($1, $2, $3)
       ON CONFLICT (key, user_id) DO UPDATE SET value = $2, updated_at = CURRENT_TIMESTAMP`,
      [req.params.key, value, userId]
    );

    // Clear email settings cache if an email setting was updated
    if (global && ['smtp_host', 'smtp_port', 'smtp_user', 'smtp_password', 'smtp_from'].includes(req.params.key)) {
      clearEmailSettingsCache();
    }

    res.json({ key: req.params.key, value });
  } catch (error) {
    res.status(500).json({ error: 'Failed to update setting' });
  }
});

// Bulk update settings
router.put('/', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { settings, global = false } = req.body;

    if (!Array.isArray(settings)) {
      return res.status(400).json({ error: 'Settings must be an array' });
    }

    if (global && req.user!.role !== 'admin') {
      return res.status(403).json({ error: 'Only admins can update global settings' });
    }

    const userId = global ? null : req.user!.id;

    for (const { key, value } of settings) {
      await query(
        `INSERT INTO settings (key, value, user_id)
         VALUES ($1, $2, $3)
         ON CONFLICT (key, user_id) DO UPDATE SET value = $2, updated_at = CURRENT_TIMESTAMP`,
        [key, value, userId]
      );
    }

    // Clear email settings cache if any email settings were updated
    if (global) {
      const emailSettings = ['smtp_host', 'smtp_port', 'smtp_user', 'smtp_password', 'smtp_from'];
      if (settings.some((s: any) => emailSettings.includes(s.key))) {
        clearEmailSettingsCache();
      }
    }

    res.json({ message: 'Settings updated', count: settings.length });
  } catch (error) {
    res.status(500).json({ error: 'Failed to update settings' });
  }
});

// Delete setting
router.delete('/:key', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { global = false } = req.query;

    if (global === 'true' && req.user!.role !== 'admin') {
      return res.status(403).json({ error: 'Only admins can delete global settings' });
    }

    const userId = global === 'true' ? null : req.user!.id;

    await query(
      `DELETE FROM settings WHERE key = $1 AND user_id ${userId ? '= $2' : 'IS NULL'}`,
      userId ? [req.params.key, userId] : [req.params.key]
    );

    res.json({ message: 'Setting deleted' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to delete setting' });
  }
});

// Upload company logo (admin only)
router.post('/logo', authenticate, requireRole('admin'), logoUpload.single('logo'), async (req: AuthRequest, res: Response) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No file uploaded' });
    }

    // Get storage provider
    let storage;
    try {
      storage = await StorageFactory.getInstance();
    } catch (storageInitError: any) {
      log.error('Failed to initialize storage provider for logo upload', storageInitError, { userId: req.user!.id });
      return res.status(500).json({ 
        error: 'Failed to initialize storage',
        message: env.NODE_ENV === 'development' ? storageInitError.message : 'Storage initialization failed'
      });
    }

    // Upload logo to storage provider
    const basePath = 'logos';
    const storagePath = generatePartitionedPath(req.file.originalname, basePath);
    
    // Stream file from memory buffer to storage provider
    let logoUrl: string;
    try {
      const fileStream = bufferToStream(req.file.buffer);
      await storage.put(storagePath, fileStream, {
        contentType: req.file.mimetype,
      });
      
      // Get URL from storage provider
      logoUrl = await storage.url(storagePath);
    } catch (storageError: any) {
      log.error('Failed to upload logo to storage', storageError, {
        storagePath,
        userId: req.user!.id,
        errorMessage: storageError.message,
        errorStack: storageError.stack
      });
      return res.status(500).json({ 
        error: 'Failed to upload logo',
        message: env.NODE_ENV === 'development' ? storageError.message : 'An error occurred while uploading the logo'
      });
    }

    // Save logo URL to settings
    try {
      await query(
        `INSERT INTO settings (key, value, user_id)
         VALUES ('company_logo', $1, NULL)
         ON CONFLICT (key, user_id) DO UPDATE SET value = $1, updated_at = CURRENT_TIMESTAMP`,
        [logoUrl]
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, details) 
         VALUES ($1, $2, $3, $4)`,
        [req.user!.id, 'update', 'settings', JSON.stringify({ key: 'company_logo', value: logoUrl })]
      );
    } catch (dbError: any) {
      log.error('Failed to save logo URL to database', dbError, { logoUrl, userId: req.user!.id });
      // Still return success since file was uploaded, but log the error
    }

    res.json({ logo_url: logoUrl });
  } catch (error: any) {
    log.error('Logo upload error', error, {
      userId: req.user!.id,
      errorMessage: error.message,
      errorStack: error.stack
    });
    res.status(500).json({ 
      error: 'Failed to upload logo',
      message: env.NODE_ENV === 'development' ? error.message : 'An error occurred while uploading the logo'
    });
  }
});

// Upload favicon (admin only)
router.post('/favicon', authenticate, requireRole('admin'), faviconUpload.single('favicon'), async (req: AuthRequest, res: Response) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No file uploaded' });
    }

    // Get storage provider
    let storage;
    try {
      storage = await StorageFactory.getInstance();
    } catch (storageInitError: any) {
      log.error('Failed to initialize storage provider for favicon upload', storageInitError, { userId: req.user!.id });
      return res.status(500).json({ 
        error: 'Failed to initialize storage',
        message: env.NODE_ENV === 'development' ? storageInitError.message : 'Storage initialization failed'
      });
    }

    // Upload favicon to storage provider
    const basePath = 'logos';
    // For favicon, use a consistent name
    const isIco = path.extname(req.file.originalname).toLowerCase() === '.ico';
    const faviconFilename = isIco ? 'favicon.ico' : `favicon-${Date.now()}${path.extname(req.file.originalname)}`;
    const storagePath = generatePartitionedPath(faviconFilename, basePath);
    
    // Stream file from memory buffer to storage provider
    let faviconUrl: string;
    try {
      const fileStream = bufferToStream(req.file.buffer);
      await storage.put(storagePath, fileStream, {
        contentType: req.file.mimetype,
      });
      
      // Get URL from storage provider
      faviconUrl = await storage.url(storagePath);
    } catch (storageError: any) {
      log.error('Failed to upload favicon to storage', storageError, {
        storagePath,
        userId: req.user!.id,
        errorMessage: storageError.message,
        errorStack: storageError.stack
      });
      return res.status(500).json({ 
        error: 'Failed to upload favicon',
        message: env.NODE_ENV === 'development' ? storageError.message : 'An error occurred while uploading the favicon'
      });
    }

    // Save favicon URL to settings
    try {
      await query(
        `INSERT INTO settings (key, value, user_id)
         VALUES ('company_favicon', $1, NULL)
         ON CONFLICT (key, user_id) DO UPDATE SET value = $1, updated_at = CURRENT_TIMESTAMP`,
        [faviconUrl]
      );

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, details) 
         VALUES ($1, $2, $3, $4)`,
        [req.user!.id, 'update', 'settings', JSON.stringify({ key: 'company_favicon', value: faviconUrl })]
      );
    } catch (dbError: any) {
      log.error('Failed to save favicon URL to database', dbError, { faviconUrl, userId: req.user!.id });
      // Still return success since file was uploaded, but log the error
    }

    res.json({ favicon_url: faviconUrl });
  } catch (error: any) {
    log.error('Favicon upload error', error, {
      userId: req.user!.id,
      errorMessage: error.message,
      errorStack: error.stack
    });
    res.status(500).json({ 
      error: 'Failed to upload favicon',
      message: env.NODE_ENV === 'development' ? error.message : 'An error occurred while uploading the favicon'
    });
  }
});

// Send test email (admin only)
router.post('/email/test', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const { email } = req.body;

    if (!email) {
      return res.status(400).json({ error: 'Email address is required' });
    }

    // Validate email format
    const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
    if (!emailRegex.test(email)) {
      return res.status(400).json({ error: 'Invalid email address format' });
    }

    await sendTestEmail(email);
    res.json({ message: 'Test email sent successfully' });
  } catch (error: any) {
    console.error('[Settings] Test email error:', error);
    res.status(500).json({ 
      error: error.message || 'Failed to send test email',
      details: error.message 
    });
  }
});

// Get activity logs (admin only)
router.get('/logs/activity', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const { user_id, action, entity_type, limit = 50, offset = 0 } = req.query;

    let sql = `
      SELECT al.*, u.name as user_name, u.email as user_email
      FROM activity_logs al
      LEFT JOIN users u ON al.user_id = u.id
      WHERE 1=1
    `;
    const params: any[] = [];
    let paramCount = 1;

    if (user_id) {
      sql += ` AND al.user_id = $${paramCount++}`;
      params.push(user_id);
    }

    if (action) {
      sql += ` AND al.action = $${paramCount++}`;
      params.push(action);
    }

    if (entity_type) {
      sql += ` AND al.entity_type = $${paramCount++}`;
      params.push(entity_type);
    }

    sql += ` ORDER BY al.created_at DESC LIMIT $${paramCount++} OFFSET $${paramCount}`;
    params.push(parseInt(limit as string), parseInt(offset as string));

    const result = await query(sql, params);

    // Get total count
    const countResult = await query(
      `SELECT COUNT(*) FROM activity_logs al WHERE 1=1 
       ${user_id ? `AND al.user_id = '${user_id}'` : ''}
       ${action ? `AND al.action = '${action}'` : ''}
       ${entity_type ? `AND al.entity_type = '${entity_type}'` : ''}`
    );

    res.json({
      logs: result.rows,
      total: parseInt(countResult.rows[0].count),
      limit: parseInt(limit as string),
      offset: parseInt(offset as string)
    });
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch activity logs' });
  }
});

// Test S3 connection
router.post('/test-s3', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const { accessKeyId, secretAccessKey, region, bucket } = req.body;

    if (!accessKeyId || !secretAccessKey || !region || !bucket) {
      return res.status(400).json({ error: 'Missing required S3 configuration fields' });
    }

    // Dynamic import to avoid requiring AWS SDK if not using S3
    const { S3Client, ListBucketsCommand, HeadBucketCommand } = await import('@aws-sdk/client-s3');

    const s3Client = new S3Client({
      region: region,
      credentials: {
        accessKeyId: accessKeyId,
        secretAccessKey: secretAccessKey,
      },
    });

    // Test connection by checking if bucket exists and is accessible
    try {
      await s3Client.send(new HeadBucketCommand({ Bucket: bucket }));
      res.json({ message: 'S3 connection successful! Bucket is accessible.' });
    } catch (error: any) {
      if (error.name === 'NotFound' || error.$metadata?.httpStatusCode === 404) {
        res.status(404).json({ error: 'Bucket not found. Please verify the bucket name.' });
      } else if (error.name === 'Forbidden' || error.$metadata?.httpStatusCode === 403) {
        res.status(403).json({ error: 'Access denied. Please verify your credentials and bucket permissions.' });
      } else {
        throw error;
      }
    }
  } catch (error: any) {
    console.error('S3 connection test error:', error);
    res.status(500).json({ 
      error: 'Failed to test S3 connection',
      message: error.message || 'Unknown error'
    });
  }
});

export default router;
--- FILE: backend/src/routes/setup.ts ---
import { Router, Response } from 'express';
import bcrypt from 'bcryptjs';
import jwt from 'jsonwebtoken';
import { body, validationResult } from 'express-validator';
import { query } from '../db';
import { logoUpload, bufferToStream } from '../middleware/upload';
import { env } from '../config/env';
import { StorageFactory } from '../lib/storage/StorageFactory';
import { generatePartitionedPath } from '../lib/storage/pathUtils';
import { log } from '../lib/logger';

const router = Router();

// Check setup status
router.get('/status', async (req, res) => {
  try {
    // Check if setup is completed
    const setupCompleted = await query(
      `SELECT value FROM settings WHERE key = 'setup_completed' AND user_id IS NULL`
    );

    if (setupCompleted.rows.length > 0 && setupCompleted.rows[0].value === 'true') {
      return res.json({ 
        completed: true,
        step: null
      });
    }

    // Check for existing admin user
    const adminUser = await query(`SELECT id FROM users WHERE role = 'admin' LIMIT 1`);
    
    if (adminUser.rows.length === 0) {
      return res.json({ 
        completed: false, 
        step: 1,
        message: 'Create admin account'
      });
    }

    // Mark setup as completed after admin is created (company name prompt removed)
    // Company name can be changed later in Settings
    await query(
      `INSERT INTO settings (key, value, user_id)
       VALUES ('setup_completed', 'true', NULL)
       ON CONFLICT (key, user_id) DO UPDATE SET value = 'true', updated_at = CURRENT_TIMESTAMP`
    );

    return res.json({ 
      completed: true,
      step: null
    });

  } catch (error) {
    console.error('Setup status error:', error);
    res.status(500).json({ error: 'Failed to check setup status' });
  }
});

// Check if default admin exists
router.get('/default-admin-status', async (req, res) => {
  try {
    const defaultAdmin = await query(
      `SELECT id, email FROM users WHERE email = 'admin@ampedfieldops.com' AND role = 'admin' LIMIT 1`
    );
    
    res.json({ hasDefaultAdmin: defaultAdmin.rows.length > 0 });
  } catch (error) {
    console.error('Failed to check default admin status:', error);
    res.status(500).json({ error: 'Failed to check default admin status' });
  }
});

// Delete default admin user (only if another admin exists)
router.delete('/default-admin', async (req, res) => {
  try {
    // Check if default admin exists
    const defaultAdmin = await query(
      `SELECT id FROM users WHERE email = 'admin@ampedfieldops.com' AND role = 'admin' LIMIT 1`
    );

    if (defaultAdmin.rows.length === 0) {
      return res.json({ message: 'Default admin does not exist' });
    }

    // Check if there's at least one other admin
    const otherAdmins = await query(
      `SELECT id FROM users WHERE role = 'admin' AND email != 'admin@ampedfieldops.com' LIMIT 1`
    );

    if (otherAdmins.rows.length === 0) {
      return res.status(400).json({ 
        error: 'Cannot delete default admin: No other admin exists. Please create a new admin first.' 
      });
    }

    // Delete default admin
    await query(
      `DELETE FROM users WHERE email = 'admin@ampedfieldops.com' AND role = 'admin'`
    );

    res.json({ message: 'Default admin deleted successfully' });
  } catch (error) {
    console.error('Failed to delete default admin:', error);
    res.status(500).json({ error: 'Failed to delete default admin' });
  }
});

// Step 1: Create admin account
router.post('/admin',
  body('email').isEmail().normalizeEmail(),
  body('password').isLength({ min: 8 }),
  body('name').trim().notEmpty(),
  body('company_name').optional().trim(),
  body('timezone').optional().trim(),
  async (req, res) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { email, password, name, company_name, timezone } = req.body;

    try {
      // Check if a non-default admin already exists
      const existingAdmin = await query(
        `SELECT id FROM users WHERE role = 'admin' AND email != 'admin@ampedfieldops.com' LIMIT 1`
      );
      if (existingAdmin.rows.length > 0) {
        return res.status(400).json({ error: 'Admin account already exists' });
      }

      // Allow creating admin if only default admin exists

      // Create admin user
      const passwordHash = await bcrypt.hash(password, 12);
      
      const userResult = await query(
        `INSERT INTO users (email, password_hash, name, role)
         VALUES ($1, $2, $3, 'admin')
         RETURNING id, email, name, role`,
        [email, passwordHash, name]
      );

      const user = userResult.rows[0];

      // Set all permissions for admin
      const adminPermissions = [
        'can_view_financials', 'can_edit_projects', 'can_manage_users',
        'can_sync_xero', 'can_view_all_timesheets', 'can_edit_activity_types',
        'can_manage_clients', 'can_manage_cost_centers', 'can_view_reports',
        'can_export_data', 'can_create_timesheets', 'can_view_own_timesheets'
      ];

      for (const permission of adminPermissions) {
        await query(
          'INSERT INTO user_permissions (user_id, permission, granted) VALUES ($1, $2, true)',
          [user.id, permission]
        );
      }

      // Update company settings if provided
      if (company_name) {
        await query(
          `UPDATE settings SET value = $1, updated_at = CURRENT_TIMESTAMP 
           WHERE key = 'company_name' AND user_id IS NULL`,
          [company_name]
        );
      }

      if (timezone) {
        await query(
          `UPDATE settings SET value = $1, updated_at = CURRENT_TIMESTAMP 
           WHERE key = 'timezone' AND user_id IS NULL`,
          [timezone]
        );
      }

      // Generate token
      const token = jwt.sign(
        { id: user.id, email: user.email, name: user.name, role: user.role },
        env.JWT_SECRET,
        { expiresIn: '7d' }
      );

      // Auto-complete setup after admin creation
      await query(
        `INSERT INTO settings (key, value, user_id)
         VALUES ('setup_completed', 'true', NULL)
         ON CONFLICT (key, user_id) DO UPDATE SET value = 'true', updated_at = CURRENT_TIMESTAMP`
      );

      res.status(201).json({
        user: { ...user, permissions: adminPermissions },
        token,
        completed: true
      });
    } catch (error) {
      console.error('Admin creation error:', error);
      res.status(500).json({ error: 'Failed to create admin account' });
    }
  }
);

// Step 2: Upload company logo
router.post('/logo', logoUpload.single('logo'), async (req, res) => {
  try {
    if (!req.file) {
      return res.status(400).json({ error: 'No file uploaded' });
    }

    // Get storage provider
    let storage;
    try {
      storage = await StorageFactory.getInstance();
    } catch (storageInitError: any) {
      log.error('Failed to initialize storage provider for setup logo', storageInitError);
      return res.status(500).json({ 
        error: 'Failed to initialize storage',
        message: env.NODE_ENV === 'development' ? storageInitError.message : 'Storage initialization failed'
      });
    }

    // Upload logo to storage provider
    const basePath = 'logos';
    const storagePath = generatePartitionedPath(req.file.originalname, basePath);
    
    // Stream file from memory buffer to storage provider
    let logoUrl: string;
    try {
      const fileStream = bufferToStream(req.file.buffer);
      await storage.put(storagePath, fileStream, {
        contentType: req.file.mimetype,
      });
      
      // Get URL from storage provider
      logoUrl = await storage.url(storagePath);
    } catch (storageError: any) {
      log.error('Failed to upload logo to storage', storageError, {
        storagePath,
        errorMessage: storageError.message,
        errorStack: storageError.stack
      });
      return res.status(500).json({ 
        error: 'Failed to upload logo',
        message: env.NODE_ENV === 'development' ? storageError.message : 'An error occurred while uploading the logo'
      });
    }

    // Save logo URL to settings
    await query(
      `UPDATE settings SET value = $1, updated_at = CURRENT_TIMESTAMP 
       WHERE key = 'company_logo' AND user_id IS NULL`,
      [logoUrl]
    );

    // Insert if doesn't exist
    await query(
      `INSERT INTO settings (key, value, user_id)
       VALUES ('company_logo', $1, NULL)
       ON CONFLICT (key, user_id) DO UPDATE SET value = $1, updated_at = CURRENT_TIMESTAMP`,
      [logoUrl]
    );

    res.json({ logo_url: logoUrl });
  } catch (error: any) {
    log.error('Setup logo upload error', error, {
      errorMessage: error.message,
      errorStack: error.stack
    });
    res.status(500).json({ 
      error: 'Failed to upload logo',
      message: env.NODE_ENV === 'development' ? error.message : 'An error occurred while uploading the logo'
    });
  }
});

// Step 2: Update company details
router.post('/company',
  body('company_name').trim().notEmpty(),
  body('timezone').optional().trim(),
  async (req, res) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { company_name, timezone } = req.body;

    try {
      await query(
        `INSERT INTO settings (key, value, user_id)
         VALUES ('company_name', $1, NULL)
         ON CONFLICT (key, user_id) DO UPDATE SET value = $1, updated_at = CURRENT_TIMESTAMP`,
        [company_name]
      );

      if (timezone) {
        await query(
          `INSERT INTO settings (key, value, user_id)
           VALUES ('timezone', $1, NULL)
           ON CONFLICT (key, user_id) DO UPDATE SET value = $1, updated_at = CURRENT_TIMESTAMP`,
          [timezone]
        );
      }

      res.json({ message: 'Company details updated', step: 3 });
    } catch (error) {
      res.status(500).json({ error: 'Failed to update company details' });
    }
  }
);

// Step 3: Add initial client (optional)
router.post('/client',
  body('name').trim().notEmpty(),
  async (req, res) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { name, contact_name, email, phone, address } = req.body;

    try {
      const result = await query(
        `INSERT INTO clients (name, contact_name, email, phone, address)
         VALUES ($1, $2, $3, $4, $5)
         RETURNING *`,
        [name, contact_name, email, phone, address]
      );

      res.status(201).json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to create client' });
    }
  }
);

// Complete setup
router.post('/complete', async (req, res) => {
  try {
    await query(
      `INSERT INTO settings (key, value, user_id)
       VALUES ('setup_completed', 'true', NULL)
       ON CONFLICT (key, user_id) DO UPDATE SET value = 'true', updated_at = CURRENT_TIMESTAMP`
    );

    res.json({ message: 'Setup completed successfully' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to complete setup' });
  }
});

// Get company settings (public - for login page branding)
router.get('/branding', async (req, res) => {
  try {
    const settings = await query(
      `SELECT key, value FROM settings 
       WHERE key IN ('company_name', 'company_logo', 'company_favicon') AND user_id IS NULL`
    );

    const result: any = {};
    settings.rows.forEach(row => {
      result[row.key] = row.value;
    });

    res.json({
      company_name: result.company_name || 'AmpedFieldOps',
      company_logo: result.company_logo || null,
      company_favicon: result.company_favicon || null
    });
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch branding' });
  }
});

export default router;
--- FILE: backend/src/routes/timesheets.ts ---
import { Router, Response } from 'express';
import rateLimit from 'express-rate-limit';
import multer from 'multer';
import fs from 'fs';
import path from 'path';
import { createReadStream } from 'fs';
import { query } from '../db';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';
import { projectUpload } from '../middleware/upload';
import { parsePaginationParams, createPaginatedResponse } from '../lib/pagination';
import { log } from '../lib/logger';
import { StorageFactory } from '../lib/storage/StorageFactory';
import { generatePartitionedPath, resolveStoragePath } from '../lib/storage/pathUtils';
import { bufferToStream } from '../middleware/upload';

const router = Router();

// Rate limiting for uploads
const uploadLimiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 20, // Limit to 20 timesheet creations per 15 minutes
  message: 'Too many timesheet creation requests, please try again later.',
});

// Get all timesheets
router.get('/', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const { user_id, project_id, client_id, date_from, date_to, cost_center_id } = req.query;
    
    // Parse pagination parameters
    const { page, limit, offset } = parsePaginationParams(req.query);
    
    // Check if user can view all timesheets
    const canViewAll = req.user!.role === 'admin' || 
                       req.user!.role === 'manager' || 
                       (req.user!.permissions && req.user!.permissions.includes('can_view_all_timesheets'));
    
    // Build WHERE clause for both count and data queries
    let whereClause = 'WHERE 1=1';
    const params: any[] = [];
    let paramCount = 1;

    // If user can't view all, only show their own
    if (!canViewAll) {
      whereClause += ` AND t.user_id = $${paramCount++}`;
      params.push(req.user!.id);
    } else if (user_id) {
      whereClause += ` AND t.user_id = $${paramCount++}`;
      params.push(user_id);
    }

    if (project_id) {
      whereClause += ` AND t.project_id = $${paramCount++}`;
      params.push(project_id);
    }

    if (client_id) {
      whereClause += ` AND t.client_id = $${paramCount++}`;
      params.push(client_id);
    }

    if (cost_center_id) {
      whereClause += ` AND t.cost_center_id = $${paramCount++}`;
      params.push(cost_center_id);
    }

    if (date_from) {
      whereClause += ` AND t.date >= $${paramCount++}`;
      params.push(date_from);
    }

    if (date_to) {
      whereClause += ` AND t.date <= $${paramCount++}`;
      params.push(date_to);
    }

    // Filter by billing status if provided
    const billing_status = req.query.billing_status;
    if (billing_status) {
      whereClause += ` AND COALESCE(t.billing_status, 'unbilled') = $${paramCount++}`;
      params.push(billing_status);
    }

    // Get total count
    const countSql = `
      SELECT COUNT(*) as total 
      FROM timesheets t
      LEFT JOIN projects p ON t.project_id = p.id
      LEFT JOIN clients c ON t.client_id = c.id
      ${whereClause}
    `;
    const countResult = await query(countSql, params);
    const total = parseInt(countResult.rows[0].total);

    // Build data query
    let sql = `
      SELECT t.*, 
        u.name as user_name,
        p.name as project_name,
        p.code as project_code,
        c.name as client_name,
        at.name as activity_type_name,
        at.icon as activity_type_icon,
        at.color as activity_type_color,
        cc.code as cost_center_code,
        cc.name as cost_center_name,
        COALESCE(t.billing_status, 'unbilled') as billing_status,
        t.invoice_id
      FROM timesheets t
      LEFT JOIN users u ON t.user_id = u.id
      LEFT JOIN projects p ON t.project_id = p.id
      LEFT JOIN clients c ON t.client_id = c.id
      LEFT JOIN activity_types at ON t.activity_type_id = at.id
      LEFT JOIN cost_centers cc ON t.cost_center_id = cc.id
      ${whereClause}
      ORDER BY t.date DESC, t.created_at DESC
    `;
    
    // Add pagination
    sql += ` LIMIT $${paramCount++} OFFSET $${paramCount++}`;
    params.push(limit, offset);

    const result = await query(sql, params);
    
    // Return paginated response
    const paginatedResponse = createPaginatedResponse(result.rows, total, page, limit);
    res.json(paginatedResponse);
  } catch (error: any) {
    log.error('Get timesheets error', error, { 
      userId: req.user?.id, 
      query: req.query,
      errorMessage: error?.message,
      errorStack: error?.stack 
    });
    res.status(500).json({ 
      error: 'Failed to fetch timesheets',
      details: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

// Get single timesheet
router.get('/:id', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `      SELECT t.*, 
        u.name as user_name,
        p.name as project_name,
        c.name as client_name,
        at.name as activity_type_name,
        cc.code as cost_center_code,
        COALESCE(t.billing_status, 'unbilled') as billing_status,
        t.invoice_id
       FROM timesheets t
       LEFT JOIN users u ON t.user_id = u.id
       LEFT JOIN projects p ON t.project_id = p.id AND p.deleted_at IS NULL
       LEFT JOIN clients c ON t.client_id = c.id AND c.deleted_at IS NULL
       LEFT JOIN activity_types at ON t.activity_type_id = at.id
       LEFT JOIN cost_centers cc ON t.cost_center_id = cc.id
       WHERE t.id = $1`,
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Timesheet not found' });
    }

    // Check permission
    const canViewAll = req.user!.role === 'admin' || 
                       req.user!.role === 'manager' || 
                       (req.user!.permissions && req.user!.permissions.includes('can_view_all_timesheets'));
    
    if (!canViewAll && result.rows[0].user_id !== req.user!.id) {
      return res.status(403).json({ error: 'Not authorized to view this timesheet' });
    }

    res.json(result.rows[0]);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch timesheet' });
  }
});

// Create timesheet (handles both JSON and FormData with images)
router.post('/', authenticate, uploadLimiter, 
  (req, res, next) => {
    // Only use multer for multipart/form-data requests
    if (req.headers['content-type']?.includes('multipart/form-data')) {
      // Handle multer errors with better messages
      projectUpload.array('images', 5)(req, res, (err) => {
        if (err) {
          if (err instanceof multer.MulterError) {
            if (err.code === 'LIMIT_FILE_COUNT') {
              return res.status(400).json({ error: 'Maximum 5 images allowed per timesheet' });
            }
            if (err.code === 'LIMIT_FILE_SIZE') {
              return res.status(400).json({ error: 'File size exceeds 10MB limit. Please compress your images.' });
            }
            if (err.code === 'LIMIT_UNEXPECTED_FILE') {
              return res.status(400).json({ error: 'Unexpected file field. Use "images" field for file uploads.' });
            }
          }
          // Other multer errors (file type validation, etc.)
          return res.status(400).json({ error: err.message || 'File upload validation failed' });
        }
        next();
      });
    } else {
      // For JSON requests, skip multer
      next();
    }
  },
  async (req: AuthRequest, res: Response) => {
    // Check if this is FormData (has files) or JSON
    const files = req.files as Express.Multer.File[];
    const isFormData = files && files.length > 0;
  
  // Extract and validate required fields from body (works for both JSON and FormData)
  const { sanitizeProjectId } = await import('../middleware/validateProject');
  let project_id: string;
  try {
    project_id = sanitizeProjectId(req.body.project_id);
  } catch (validationError: any) {
    return res.status(400).json({ 
      error: 'Invalid project_id',
      details: validationError.message
    });
  }
  const timesheetDate = req.body.date;
  const hoursValue = req.body.hours;
  const timesheetActivityTypeId = req.body.activity_type_id;
  const timesheetCostCenterId = req.body.cost_center_id;
  
  // Manual validation (since express-validator doesn't work well with FormData)
  if (!project_id || !timesheetDate || hoursValue === undefined || hoursValue === null || !timesheetActivityTypeId || !timesheetCostCenterId) {
    const missing = [];
    if (!project_id) missing.push('project_id');
    if (!timesheetDate) missing.push('date');
    if (hoursValue === undefined || hoursValue === null) missing.push('hours');
    if (!timesheetActivityTypeId) missing.push('activity_type_id');
    if (!timesheetCostCenterId) missing.push('cost_center_id');
    return res.status(400).json({ 
      error: 'Missing required fields',
      missing_fields: missing,
      details: `Missing: ${missing.join(', ')}`
    });
  }
  
  const timesheetHours = parseFloat(hoursValue);
  if (isNaN(timesheetHours)) {
    return res.status(400).json({ error: 'Invalid hours value. Must be a number.' });
  }
  
  if (timesheetHours < 0.25 || timesheetHours > 24) {
    return res.status(400).json({ error: 'Hours must be between 0.25 and 24' });
  }

  // Get image URLs from uploaded files or from body
  let imageUrls: string[] = [];
  
  if (isFormData && files.length > 0) {
    // Files were uploaded - upload to storage provider
    let storage;
    try {
      storage = await StorageFactory.getInstance();
    } catch (storageError: any) {
      log.error('Failed to initialize storage provider', storageError, { project_id });
      return res.status(500).json({ 
        error: 'Failed to initialize file storage',
        details: process.env.NODE_ENV === 'development' ? storageError.message : undefined
      });
    }
    
    const basePath = `projects/${project_id}`;
    const uploadErrors: string[] = [];
    
    // Upload each file to storage provider
    for (const file of files) {
      let storagePath: string | undefined;
      try {
        // Generate partitioned path
        storagePath = generatePartitionedPath(file.originalname, basePath);
        
        // Stream file from memory buffer to storage provider
        const fileStream = bufferToStream(file.buffer);
        await storage.put(storagePath, fileStream, {
          contentType: file.mimetype,
        });
        
        // Get URL from storage provider (signed URL for S3, regular path for local)
        const fileUrl = await storage.url(storagePath);
        imageUrls.push(fileUrl);
      } catch (uploadError: any) {
        const errorMsg = `Failed to upload ${file.originalname}: ${uploadError.message}`;
        uploadErrors.push(errorMsg);
        log.error(`Failed to upload ${file.originalname} to storage`, uploadError, { 
          filename: file.originalname, 
          project_id,
          storagePath: storagePath || 'unknown',
          errorMessage: uploadError.message,
          errorStack: uploadError.stack
        });
      }
    }
    
    // If all files failed to upload, return error
    if (files.length > 0 && imageUrls.length === 0) {
      return res.status(500).json({ 
        error: 'All file uploads failed',
        details: uploadErrors.join('; ')
      });
    }
    
    // If some files failed, log warning but continue
    if (uploadErrors.length > 0) {
      log.warn('Some files failed to upload', { 
        project_id, 
        failedCount: uploadErrors.length,
        successCount: imageUrls.length,
        errors: uploadErrors
      });
    }
  } else {
    // JSON request with pre-uploaded URLs
    imageUrls = req.body.image_urls || [];
  }

  const { client_id, notes, location } = req.body;

    try {
      // Get client_id from project if not provided
      let finalClientId = client_id;
      if (!finalClientId) {
        const project = await query('SELECT client_id FROM projects WHERE id = $1', [project_id]);
        if (project.rows.length > 0) {
          finalClientId = project.rows[0].client_id;
        }
      }

      // Allow user_id to be specified in request body (for admin/manager creating timesheets for other users)
      // Otherwise use the authenticated user's ID
      const userId = req.body.user_id || req.user!.id;
      
      // Validate user_id if provided (only admins/managers can create timesheets for other users)
      if (req.body.user_id && req.body.user_id !== req.user!.id) {
        const canManageOthers = req.user!.role === 'admin' || 
                                req.user!.role === 'manager' ||
                                (req.user!.permissions && req.user!.permissions.includes('can_view_all_timesheets'));
        if (!canManageOthers) {
          return res.status(403).json({ error: 'Not authorized to create timesheets for other users' });
        }
      }

      const result = await query(
        `INSERT INTO timesheets (user_id, project_id, client_id, date, hours, activity_type_id, cost_center_id, notes, image_urls, location, billing_status)
         VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, 'unbilled')
         RETURNING *`,
        [userId, project_id, finalClientId, timesheetDate, timesheetHours, timesheetActivityTypeId, timesheetCostCenterId, notes, imageUrls, location]
      );

      // Update project actual_cost based on activity hourly rate
      const activityType = await query('SELECT hourly_rate FROM activity_types WHERE id = $1', [timesheetActivityTypeId]);
      if (activityType.rows.length > 0) {
        const cost = timesheetHours * parseFloat(activityType.rows[0].hourly_rate);
        await query(
          'UPDATE projects SET actual_cost = actual_cost + $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
          [cost, project_id]
        );
      }

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'create', 'timesheet', result.rows[0].id, JSON.stringify({ project_id, hours: timesheetHours, date: timesheetDate })]
      );

      res.status(201).json(result.rows[0]);
    } catch (error: any) {
      log.error('Create timesheet error', error, { 
        userId: req.user!.id, 
        project_id,
        errorMessage: error?.message,
        errorStack: error?.stack,
        errorCode: error?.code,
        body: req.body
      });
      
      // Provide more specific error messages
      let errorMessage = 'Failed to create timesheet';
      let statusCode = 500;
      
      if (error?.code === '23503') { // Foreign key violation
        errorMessage = 'Invalid project, activity type, or cost center';
        statusCode = 400;
      } else if (error?.code === '23505') { // Unique violation
        errorMessage = 'Timesheet already exists';
        statusCode = 409;
      } else if (error?.code === '23502') { // Not null violation
        errorMessage = 'Missing required field';
        statusCode = 400;
      } else if (error?.message) {
        errorMessage = error.message;
      }
      
      res.status(statusCode).json({ 
        error: errorMessage,
        details: process.env.NODE_ENV === 'development' ? {
          message: error?.message,
          code: error?.code,
          stack: error?.stack
        } : undefined
      });
    }
  }
);

// Update timesheet (handles both JSON and FormData with images)
router.put('/:id', authenticate, 
  (req, res, next) => {
    // Validate file count before multer processes
    if (req.headers['content-type']?.includes('multipart/form-data')) {
      // Let multer handle validation, but catch errors
      projectUpload.array('images', 5)(req, res, (err) => {
        if (err) {
          if (err instanceof multer.MulterError) {
            if (err.code === 'LIMIT_FILE_COUNT') {
              return res.status(400).json({ error: 'Maximum 5 images allowed' });
            }
            if (err.code === 'LIMIT_FILE_SIZE') {
              return res.status(400).json({ error: 'File size exceeds 10MB limit' });
            }
          }
          // Other multer errors (file type, etc.)
          return res.status(400).json({ error: err.message || 'File upload error' });
        }
        next();
      });
    } else {
      next();
    }
  },
  async (req: AuthRequest, res: Response) => {
    // Check if this is FormData (has files) or JSON
    const files = req.files as Express.Multer.File[];
    const isFormData = files && files.length > 0;
    
    // Extract fields from body (works for both JSON and FormData)
    const { sanitizeProjectId } = await import('../middleware/validateProject');
    let project_id: string;
    try {
      project_id = sanitizeProjectId(req.body.project_id);
    } catch (validationError: any) {
      return res.status(400).json({ 
        error: 'Invalid project_id',
        details: validationError.message
      });
    }
    const date = req.body.date;
    const hours = req.body.hours ? parseFloat(req.body.hours) : undefined;
    const activity_type_id = req.body.activity_type_id;
    const cost_center_id = req.body.cost_center_id;
    const notes = req.body.notes;
    const location = req.body.location;
    const synced = req.body.synced;
    const user_id = req.body.user_id;
    
    // Get image URLs from uploaded files or from body
    let imageUrls: string[] = [];
    
    if (isFormData && files.length > 0) {
      // Files were uploaded - upload to storage provider
      let storage;
      try {
        storage = await StorageFactory.getInstance();
      } catch (storageError: any) {
        log.error('Failed to initialize storage provider', storageError, { project_id, timesheetId: req.params.id });
        return res.status(500).json({ 
          error: 'Failed to initialize file storage',
          details: process.env.NODE_ENV === 'development' ? storageError.message : undefined
        });
      }
      const basePath = `projects/${project_id}`;
      
      // Upload each new file to storage provider
      for (const file of files) {
        let storagePath: string | undefined;
        try {
          // Generate partitioned path
          storagePath = generatePartitionedPath(file.originalname, basePath);
          
          // Stream file from memory buffer to storage provider
          const fileStream = bufferToStream(file.buffer);
          await storage.put(storagePath, fileStream, {
            contentType: file.mimetype,
          });
          
          // Get URL from storage provider
          const fileUrl = await storage.url(storagePath);
          imageUrls.push(fileUrl);
        } catch (uploadError: any) {
          log.error(`Failed to upload ${file.originalname} to storage`, uploadError, { 
            filename: file.originalname, 
            project_id,
            storagePath: storagePath || 'unknown',
            errorMessage: uploadError.message,
            errorStack: uploadError.stack
          });
          // Don't add to imageUrls if upload failed
        }
      }
      
      // Also include any existing image URLs from body
      if (req.body.image_urls) {
        try {
          const existingUrls = typeof req.body.image_urls === 'string' 
            ? JSON.parse(req.body.image_urls) 
            : req.body.image_urls;
          imageUrls = [...imageUrls, ...existingUrls];
        } catch (e) {
          // If parsing fails, just use the new files
        }
      }
    } else {
      // JSON request with pre-uploaded URLs or existing URLs
      imageUrls = req.body.image_urls || [];
    }

    try {
      // Check ownership or permission
      const existing = await query('SELECT user_id, hours, project_id, activity_type_id, COALESCE(billing_status, \'unbilled\') as billing_status FROM timesheets WHERE id = $1', [req.params.id]);
      if (existing.rows.length === 0) {
        return res.status(404).json({ error: 'Timesheet not found' });
      }

      const canEdit = req.user!.role === 'admin' || 
                      req.user!.role === 'manager' ||
                      existing.rows[0].user_id === req.user!.id;

      if (!canEdit) {
        return res.status(403).json({ error: 'Not authorized to edit this timesheet' });
      }

      // Check if timesheet is billed or paid - cannot edit
      const billingStatus = existing.rows[0].billing_status || 'unbilled';
      if (billingStatus === 'billed' || billingStatus === 'paid') {
        return res.status(400).json({ 
          error: 'Cannot edit timesheet that has been billed or paid',
          billing_status: billingStatus
        });
      }

      const updates: string[] = [];
      const values: any[] = [];
      let paramCount = 1;

      const fields: Record<string, any> = { 
        project_id, 
        date, 
        hours, 
        activity_type_id, 
        cost_center_id, 
        notes, 
        image_urls: imageUrls.length > 0 ? imageUrls : undefined,
        location, 
        synced 
      };
      
      // Add user_id if provided (for admin/manager updating timesheet for other users)
      if (user_id && user_id !== existing.rows[0].user_id) {
        const canManageOthers = req.user!.role === 'admin' || 
                                req.user!.role === 'manager' ||
                                (req.user!.permissions && req.user!.permissions.includes('can_view_all_timesheets'));
        if (canManageOthers) {
          fields.user_id = user_id;
        }
      }
      
      for (const [key, value] of Object.entries(fields)) {
        if (value !== undefined) {
          updates.push(`${key} = $${paramCount++}`);
          values.push(value);
        }
      }

      if (updates.length === 0) {
        return res.status(400).json({ error: 'No updates provided' });
      }

      updates.push('updated_at = CURRENT_TIMESTAMP');
      values.push(req.params.id);

      const result = await query(
        `UPDATE timesheets SET ${updates.join(', ')} WHERE id = $${paramCount} RETURNING *`,
        values
      );

      // Update project costs if hours changed
      if (hours !== undefined && hours !== existing.rows[0].hours) {
        const oldActivity = await query('SELECT hourly_rate FROM activity_types WHERE id = $1', [existing.rows[0].activity_type_id]);
        const newActivity = await query('SELECT hourly_rate FROM activity_types WHERE id = $1', [activity_type_id || existing.rows[0].activity_type_id]);
        
        if (oldActivity.rows.length > 0 && newActivity.rows.length > 0) {
          const oldCost = existing.rows[0].hours * parseFloat(oldActivity.rows[0].hourly_rate);
          const newCost = hours * parseFloat(newActivity.rows[0].hourly_rate);
          const costDiff = newCost - oldCost;
          
          await query(
            'UPDATE projects SET actual_cost = actual_cost + $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
            [costDiff, project_id || existing.rows[0].project_id]
          );
        }
      }

      res.json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to update timesheet' });
    }
  }
);

// Delete timesheet
router.delete('/:id', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const existing = await query(
      'SELECT user_id, hours, project_id, activity_type_id, COALESCE(billing_status, \'unbilled\') as billing_status FROM timesheets WHERE id = $1', 
      [req.params.id]
    );
    
    if (existing.rows.length === 0) {
      return res.status(404).json({ error: 'Timesheet not found' });
    }

    const canDelete = req.user!.role === 'admin' || 
                      req.user!.role === 'manager' ||
                      existing.rows[0].user_id === req.user!.id;

    if (!canDelete) {
      return res.status(403).json({ error: 'Not authorized to delete this timesheet' });
    }

    // Check if timesheet is billed or paid - cannot delete
    const billingStatus = existing.rows[0].billing_status || 'unbilled';
    if (billingStatus === 'billed' || billingStatus === 'paid') {
      return res.status(400).json({ 
        error: 'Cannot delete timesheet that has been billed or paid',
        billing_status: billingStatus
      });
    }

    // Get timesheet info for cleanup (including image_urls)
    const timesheetWithImages = await query(
      'SELECT image_urls, project_id FROM timesheets WHERE id = $1',
      [req.params.id]
    );
    
    const timesheetInfo = existing.rows[0];
    const imageUrls = timesheetWithImages.rows[0]?.image_urls || [];
    
    // Delete from database
    await query('DELETE FROM timesheets WHERE id = $1', [req.params.id]);

    // Delete associated image files using storage provider
    if (imageUrls.length > 0) {
      const storage = await StorageFactory.getInstance();
      const cleanupPromises: Promise<void>[] = [];

      for (const imageUrl of imageUrls) {
        // Skip HTTP URLs (S3 signed URLs - can't delete directly)
        if (!imageUrl || imageUrl.startsWith('http://') || imageUrl.startsWith('https://')) {
          continue;
        }

        // Extract storage path and delete
        const storagePath = resolveStoragePath(imageUrl);
        cleanupPromises.push(
          storage.delete(storagePath).catch((err) => {
            log.error('Failed to delete timesheet image', err, { timesheetId: req.params.id, path: storagePath });
          })
        );
      }

      // Run cleanup in background (don't block response)
      Promise.all(cleanupPromises).then(() => {
        log.info('Timesheet images cleanup completed', { timesheetId: req.params.id, imagesDeleted: cleanupPromises.length });
      }).catch((err) => {
        log.error('Error during timesheet cleanup', err, { timesheetId: req.params.id });
      });
    }

    // Update project costs
    const activity = await query('SELECT hourly_rate FROM activity_types WHERE id = $1', [existing.rows[0].activity_type_id]);
    if (activity.rows.length > 0 && existing.rows[0].project_id) {
      const cost = existing.rows[0].hours * parseFloat(activity.rows[0].hourly_rate);
      await query(
        'UPDATE projects SET actual_cost = actual_cost - $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
        [cost, existing.rows[0].project_id]
      );
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'delete', 'timesheet', req.params.id, JSON.stringify({ hours: existing.rows[0].hours })]
    );

    res.json({ message: 'Timesheet deleted' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to delete timesheet' });
  }
});

// Upload images for existing timesheet
router.post('/:id/images', authenticate,
  async (req: AuthRequest, res: Response, next) => {
    try {
      // Fetch project_id from timesheet BEFORE multer processes files
      const timesheet = await query('SELECT project_id FROM timesheets WHERE id = $1', [req.params.id]);
      if (timesheet.rows.length === 0) {
        return res.status(404).json({ error: 'Timesheet not found' });
      }

      const project_id = timesheet.rows[0].project_id;
      if (!project_id) {
        return res.status(400).json({ error: 'Timesheet does not have an associated project' });
      }

      // Add project_id to request body so multer can use it for destination
      req.body.project_id = project_id;

      // Now let multer process the files
      projectUpload.array('images', 5)(req, res, (err) => {
        if (err) {
          if (err instanceof multer.MulterError) {
            if (err.code === 'LIMIT_FILE_COUNT') {
              return res.status(400).json({ error: 'Maximum 5 images allowed per timesheet' });
            }
            if (err.code === 'LIMIT_FILE_SIZE') {
              return res.status(400).json({ error: 'File size exceeds 10MB limit. Please compress your images.' });
            }
          }
          return res.status(400).json({ error: err.message || 'File upload validation failed' });
        }
        next();
      });
    } catch (error) {
      log.error('Error fetching timesheet for image upload', error, { timesheetId: req.params.id });
      res.status(500).json({ error: 'Failed to process upload request' });
    }
  },
  async (req: AuthRequest, res: Response) => {
    try {
      const files = req.files as Express.Multer.File[];

      if (!files || files.length === 0) {
        return res.status(400).json({ error: 'No files uploaded' });
      }

      // Get project_id from request body (already set and sanitized in previous middleware)
      const project_id = req.body.project_id;
    
    // Upload files to storage provider
    let storage;
    try {
      storage = await StorageFactory.getInstance();
    } catch (storageError: any) {
      log.error('Failed to initialize storage provider', storageError, { project_id, timesheetId: req.params.id });
      return res.status(500).json({ 
        error: 'Failed to initialize file storage',
        details: process.env.NODE_ENV === 'development' ? storageError.message : undefined
      });
    }
    const basePath = `projects/${project_id}`;
    let imageUrls: string[] = [];
    
    for (const file of files) {
      let storagePath: string | undefined;
      try {
        // Generate partitioned path
        storagePath = generatePartitionedPath(file.originalname, basePath);
        
        // Stream file from memory buffer to storage provider
        const fileStream = bufferToStream(file.buffer);
        await storage.put(storagePath, fileStream, {
          contentType: file.mimetype,
        });
        
        // Get URL from storage provider
        const fileUrl = await storage.url(storagePath);
        imageUrls.push(fileUrl);
      } catch (uploadError: any) {
        log.error(`Failed to upload ${file.originalname} to storage`, uploadError, { 
          filename: file.originalname, 
          timesheetId: req.params.id,
          storagePath: storagePath || 'unknown',
          errorMessage: uploadError.message,
          errorStack: uploadError.stack
        });
        // Don't add to imageUrls if upload failed
      }
    }

    // Update image URLs
    const result = await query(
      `UPDATE timesheets 
       SET image_urls = array_cat(COALESCE(image_urls, '{}'), $1), 
           updated_at = CURRENT_TIMESTAMP
       WHERE id = $2
       RETURNING image_urls`,
      [imageUrls, req.params.id]
    );

    res.json({ 
      image_urls: result.rows[0].image_urls
    });
  } catch (error) {
    log.error('Upload images error', error, { timesheetId: req.params.id, userId: req.user!.id });
    res.status(500).json({ error: 'Failed to upload images' });
  }
});

// Delete individual image from timesheet
router.delete('/:id/images/:index', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    const timesheetId = req.params.id;
    const imageIndex = parseInt(req.params.index, 10);

    if (isNaN(imageIndex) || imageIndex < 0) {
      return res.status(400).json({ error: 'Invalid image index' });
    }

    // Get timesheet with images
    const timesheet = await query('SELECT image_urls, project_id FROM timesheets WHERE id = $1', [timesheetId]);
    if (timesheet.rows.length === 0) {
      return res.status(404).json({ error: 'Timesheet not found' });
    }

    const imageUrls = timesheet.rows[0].image_urls || [];
    if (imageIndex >= imageUrls.length) {
      return res.status(404).json({ error: 'Image not found' });
    }

    // Get image URL to delete file
    const imageUrl = imageUrls[imageIndex];
    const projectId = timesheet.rows[0].project_id;

    // Remove image from array
    const updatedUrls = [...imageUrls];
    updatedUrls.splice(imageIndex, 1);

    // Update database
    await query(
      `UPDATE timesheets 
       SET image_urls = $1, updated_at = CURRENT_TIMESTAMP
       WHERE id = $2`,
      [updatedUrls, timesheetId]
    );

    // Delete physical file
    try {
      // Delete file from storage
      const storage = await StorageFactory.getInstance();
      try {
        // Extract storage path from URL
        let storagePath: string;
        if (imageUrl.startsWith('http://') || imageUrl.startsWith('https://')) {
          // S3 signed URL - can't delete directly, would need S3 key
          log.warn('Cannot delete S3 file from signed URL', { imageUrl, timesheetId });
        } else {
          // Local path - extract relative path
          storagePath = resolveStoragePath(imageUrl);
          await storage.delete(storagePath);
        }
      } catch (deleteError: any) {
        log.error('Failed to delete image from storage', deleteError, { imageUrl, timesheetId });
        // Continue - file is already removed from array
      }
    } catch (fileError) {
      log.error('Failed to delete image file', fileError, { timesheetId: req.params.id, imageUrl });
      // Continue even if file deletion fails
    }

    res.json({ image_urls: updatedUrls, message: 'Image deleted' });
  } catch (error) {
    log.error('Delete image error', error, { timesheetId: req.params.id, userId: req.user!.id });
    res.status(500).json({ error: 'Failed to delete image' });
  }
});

export default router;
--- FILE: backend/src/routes/troubleshooter.ts ---
import { Router, Response } from 'express';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';
import { TestRunner } from '../lib/troubleshooter/testRunner';
import { scanRoutes } from '../lib/troubleshooter/routeScanner';

const router = Router();

// Import test suites
import * as authTests from '../lib/troubleshooter/testSuites/auth.test';
import * as clientsTests from '../lib/troubleshooter/testSuites/clients.test';
import * as projectsTests from '../lib/troubleshooter/testSuites/projects.test';
import * as timesheetsTests from '../lib/troubleshooter/testSuites/timesheets.test';
import * as usersTests from '../lib/troubleshooter/testSuites/users.test';
import * as permissionsTests from '../lib/troubleshooter/testSuites/permissions.test';
import * as settingsTests from '../lib/troubleshooter/testSuites/settings.test';
import * as xeroTests from '../lib/troubleshooter/testSuites/xero.test';
import * as emailTests from '../lib/troubleshooter/testSuites/email.test';
import * as dashboardTests from '../lib/troubleshooter/testSuites/dashboard.test';
import * as healthTests from '../lib/troubleshooter/testSuites/health.test';

// Create test runner instance
function createTestRunner(): TestRunner {
  const runner = new TestRunner();

  // Register all test suites
  runner.registerSuite({
    name: 'Authentication',
    category: 'Auth',
    runTests: authTests.runTests,
  });

  runner.registerSuite({
    name: 'Clients',
    category: 'CRUD',
    runTests: clientsTests.runTests,
  });

  runner.registerSuite({
    name: 'Projects',
    category: 'CRUD',
    runTests: projectsTests.runTests,
  });

  runner.registerSuite({
    name: 'Timesheets',
    category: 'CRUD',
    runTests: timesheetsTests.runTests,
  });

  runner.registerSuite({
    name: 'Users',
    category: 'CRUD',
    runTests: usersTests.runTests,
  });

  runner.registerSuite({
    name: 'Permissions',
    category: 'Security',
    runTests: permissionsTests.runTests,
  });

  runner.registerSuite({
    name: 'Settings',
    category: 'Configuration',
    runTests: settingsTests.runTests,
  });

  runner.registerSuite({
    name: 'Xero',
    category: 'Integration',
    runTests: xeroTests.runTests,
  });

  runner.registerSuite({
    name: 'Email',
    category: 'Integration',
    runTests: emailTests.runTests,
  });

  runner.registerSuite({
    name: 'Dashboard',
    category: 'Business Logic',
    runTests: dashboardTests.runTests,
  });

  runner.registerSuite({
    name: 'Health',
    category: 'System',
    runTests: healthTests.runTests,
  });

  return runner;
}

// Run all tests (Admin only)
router.post('/run', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const { category } = req.body;
    const runner = createTestRunner();

    const result = category
      ? await runner.runCategory(category)
      : await runner.runAll();

    res.json(result);
  } catch (error: any) {
    console.error('Troubleshooter error:', error);
    res.status(500).json({
      success: false,
      error: error.message || 'Failed to run troubleshooter',
    });
  }
});

// Get discovered routes (Admin only)
router.get('/routes', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const routes = await scanRoutes();
    res.json(routes);
  } catch (error: any) {
    console.error('Route scan error:', error);
    res.status(500).json({ error: 'Failed to scan routes' });
  }
});

// Get test suites info (Admin only)
router.get('/suites', authenticate, requirePermission('can_manage_users'), async (req: AuthRequest, res: Response) => {
  try {
    const runner = createTestRunner();
    const suites = runner.getTestSuites();
    res.json(suites);
  } catch (error: any) {
    console.error('Get suites error:', error);
    res.status(500).json({ error: 'Failed to get test suites' });
  }
});

export default router;

--- FILE: backend/src/routes/users.ts ---
import { Router, Response } from 'express';
import bcrypt from 'bcryptjs';
import { body, validationResult } from 'express-validator';
import { query } from '../db';
import { authenticate, requireRole, AuthRequest } from '../middleware/auth';
import { getDefaultPermissions } from '../lib/permissions';

const router = Router();

// Get all users (admin only)
router.get('/', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(`
      SELECT id, email, name, role, avatar, is_active, created_at, updated_at
      FROM users
      ORDER BY created_at DESC
    `);

    // Get permissions for each user
    const users = await Promise.all(result.rows.map(async (user) => {
      const permResult = await query(
        'SELECT permission, granted FROM user_permissions WHERE user_id = $1',
        [user.id]
      );
      return {
        ...user,
        permissions: permResult.rows
      };
    }));

    res.json(users);
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch users' });
  }
});

// Get single user
router.get('/:id', authenticate, requireRole('admin', 'manager'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      `SELECT id, email, name, role, avatar, is_active, created_at, updated_at
       FROM users WHERE id = $1`,
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'User not found' });
    }

    const permResult = await query(
      'SELECT permission, granted FROM user_permissions WHERE user_id = $1',
      [req.params.id]
    );

    res.json({
      ...result.rows[0],
      permissions: permResult.rows
    });
  } catch (error) {
    res.status(500).json({ error: 'Failed to fetch user' });
  }
});

// Create user (admin only)
router.post('/', authenticate, requireRole('admin'),
  body('email').isEmail().normalizeEmail(),
  body('password').isLength({ min: 8 }),
  body('name').trim().notEmpty(),
  body('role').isIn(['admin', 'manager', 'user']),
  async (req: AuthRequest, res: Response) => {
    const errors = validationResult(req);
    if (!errors.isEmpty()) {
      return res.status(400).json({ errors: errors.array() });
    }

    const { email, password, name, role } = req.body;

    try {
      const existing = await query('SELECT id FROM users WHERE email = $1', [email]);
      if (existing.rows.length > 0) {
        return res.status(400).json({ error: 'Email already exists' });
      }

      const passwordHash = await bcrypt.hash(password, 12);

      const result = await query(
        `INSERT INTO users (email, password_hash, name, role) 
         VALUES ($1, $2, $3, $4) 
         RETURNING id, email, name, role, created_at`,
        [email, passwordHash, name, role]
      );

      const newUser = result.rows[0];

      // Set default permissions based on role
      const defaultPermissions = getDefaultPermissions(role);
      for (const permission of defaultPermissions) {
        await query(
          'INSERT INTO user_permissions (user_id, permission, granted) VALUES ($1, $2, true)',
          [newUser.id, permission]
        );
      }

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'create_user', 'user', newUser.id, JSON.stringify({ email, role })]
      );

      res.status(201).json(newUser);
    } catch (error) {
      res.status(500).json({ error: 'Failed to create user' });
    }
  }
);

// Update user (admin only)
router.put('/:id', authenticate, requireRole('admin'),
  body('name').optional().trim().notEmpty(),
  body('role').optional().isIn(['admin', 'manager', 'user']),
  body('is_active').optional().isBoolean(),
  async (req: AuthRequest, res: Response) => {
    const { name, role, is_active } = req.body;

    try {
      const updates: string[] = [];
      const values: any[] = [];
      let paramCount = 1;

      if (name) {
        updates.push(`name = $${paramCount++}`);
        values.push(name);
      }
      if (role) {
        updates.push(`role = $${paramCount++}`);
        values.push(role);
      }
      if (is_active !== undefined) {
        updates.push(`is_active = $${paramCount++}`);
        values.push(is_active);
      }

      if (updates.length === 0) {
        return res.status(400).json({ error: 'No updates provided' });
      }

      updates.push('updated_at = CURRENT_TIMESTAMP');
      values.push(req.params.id);

      const result = await query(
        `UPDATE users SET ${updates.join(', ')} WHERE id = $${paramCount} 
         RETURNING id, email, name, role, is_active`,
        values
      );

      if (result.rows.length === 0) {
        return res.status(404).json({ error: 'User not found' });
      }

      // If role was updated, update permissions to match new role's defaults
      if (role) {
        // Get the updated user's role (in case it changed)
        const updatedUser = result.rows[0];
        
        // Delete existing permissions
        await query('DELETE FROM user_permissions WHERE user_id = $1', [req.params.id]);
        
        // Set default permissions for the new role
        const defaultPermissions = getDefaultPermissions(updatedUser.role);
        for (const permission of defaultPermissions) {
          await query(
            'INSERT INTO user_permissions (user_id, permission, granted) VALUES ($1, $2, true)',
            [req.params.id, permission]
          );
        }
      }

      res.json(result.rows[0]);
    } catch (error) {
      res.status(500).json({ error: 'Failed to update user' });
    }
  }
);

// Update user permissions (admin only)
router.put('/:id/permissions', authenticate, requireRole('admin'),
  body('permissions').isArray(),
  async (req: AuthRequest, res: Response) => {
    const { permissions } = req.body;

    try {
      // Delete existing permissions
      await query('DELETE FROM user_permissions WHERE user_id = $1', [req.params.id]);

      // Insert new permissions
      for (const perm of permissions) {
        await query(
          'INSERT INTO user_permissions (user_id, permission, granted) VALUES ($1, $2, $3)',
          [req.params.id, perm.permission, perm.granted]
        );
      }

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'update_permissions', 'user', req.params.id, JSON.stringify({ permissions })]
      );

      res.json({ message: 'Permissions updated' });
    } catch (error) {
      res.status(500).json({ error: 'Failed to update permissions' });
    }
  }
);

// Delete user (admin only)
router.delete('/:id', authenticate, requireRole('admin'), async (req: AuthRequest, res: Response) => {
  try {
    // Prevent self-deletion
    if (req.params.id === req.user!.id) {
      return res.status(400).json({ error: 'Cannot delete your own account' });
    }

    const result = await query(
      'DELETE FROM users WHERE id = $1 RETURNING id',
      [req.params.id]
    );

    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'User not found' });
    }

    res.json({ message: 'User deleted' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to delete user' });
  }
});

export default router;
--- FILE: backend/src/routes/xero.ts ---
import { Router, Response } from 'express';
import { query } from '../db';
import { authenticate, requirePermission, AuthRequest } from '../middleware/auth';
import { env } from '../config/env';
import { log } from '../lib/logger';
import { ensureXeroTables } from '../db/ensureXeroTables';
import { fetchWithRateLimit } from '../lib/xero/rateLimiter';
import { parseXeroError, getErrorMessage } from '../lib/xero/errorHandler';
import { createPaymentInXero, storePayment, getPayments, CreatePaymentData } from '../lib/xero/payments';
import { importBankTransactions, getBankTransactions, reconcileTransaction } from '../lib/xero/bankTransactions';
import { 
  createPurchaseOrderInXero, 
  storePurchaseOrder, 
  getPurchaseOrders, 
  getPurchaseOrderById, 
  updatePurchaseOrderStatus,
  CreatePurchaseOrderData 
} from '../lib/xero/purchaseOrders';
import { createBillInXero, storeBill, getBills, markBillAsPaid, CreateBillData } from '../lib/xero/bills';
import { createExpenseInXero, storeExpense, getExpenses, CreateExpenseData } from '../lib/xero/expenses';
import { 
  getProfitLossReport, 
  getBalanceSheetReport, 
  getCashFlowReport, 
  getAgedReceivablesReport, 
  getAgedPayablesReport 
} from '../lib/xero/reports';
import { syncItemsFromXero, getItems, getItemById, updateItemStock } from '../lib/xero/items';
import { 
  createCreditNoteInXero, 
  applyCreditNoteToInvoice, 
  storeCreditNote, 
  getCreditNotes, 
  CreateCreditNoteData 
} from '../lib/xero/creditNotes';
import { 
  getReminderSchedule, 
  updateReminderSchedule, 
  sendPaymentReminder, 
  processPaymentReminders, 
  getReminderHistory 
} from '../lib/xero/reminders';
import { 
  verifyWebhookSignature, 
  storeWebhookEvent, 
  processWebhookEvent, 
  getWebhookStatus, 
  getWebhookEvents 
} from '../lib/xero/webhooks';

const router = Router();

// Note: In production, use the xero-node package for actual Xero API integration
// This is a placeholder implementation showing the structure

// Helper to get Xero credentials from settings or env
async function getXeroCredentials() {
  // First try database settings
  const clientIdResult = await query(
    `SELECT value FROM settings WHERE key = 'xero_client_id' AND user_id IS NULL`
  );
  const clientSecretResult = await query(
    `SELECT value FROM settings WHERE key = 'xero_client_secret' AND user_id IS NULL`
  );
  const redirectUriResult = await query(
    `SELECT value FROM settings WHERE key = 'xero_redirect_uri' AND user_id IS NULL`
  );
  
  const clientIdFromDb = clientIdResult.rows[0]?.value;
  const clientSecretFromDb = clientSecretResult.rows[0]?.value;
  const clientId = clientIdFromDb || env.XERO_CLIENT_ID;
  const clientSecret = clientSecretFromDb || env.XERO_CLIENT_SECRET;
  
  // Construct redirect URI
  // Priority: Database setting -> XERO_REDIRECT_URI env -> FRONTEND_URL + /api/xero/callback -> BACKEND_URL + /api/xero/callback
  const savedRedirectUri = redirectUriResult.rows[0]?.value;
  let redirectUri = savedRedirectUri || env.XERO_REDIRECT_URI;
  
  // Log what we found with full details
  console.log('[Xero] Credential sources:', {
    clientId: {
      fromDatabase: clientIdFromDb ? `${String(clientIdFromDb).substring(0, 8)}... (${String(clientIdFromDb).length} chars)` : 'NOT SET',
      fromEnv: env.XERO_CLIENT_ID ? `${env.XERO_CLIENT_ID.substring(0, 8)}...` : 'NOT SET',
      final: clientId ? `${String(clientId).substring(0, 8)}... (${String(clientId).length} chars)` : 'NOT SET'
    },
    clientSecret: {
      fromDatabase: clientSecretFromDb ? `${String(clientSecretFromDb).length} chars` : 'NOT SET',
      fromEnv: env.XERO_CLIENT_SECRET ? `${env.XERO_CLIENT_SECRET.length} chars` : 'NOT SET',
      final: clientSecret ? `${String(clientSecret).length} chars` : 'NOT SET'
    },
    redirectUri: {
      fromDatabase: savedRedirectUri || 'NOT SET',
      fromEnv: env.XERO_REDIRECT_URI || 'NOT SET',
      frontendUrl: env.FRONTEND_URL || 'NOT SET',
      backendUrl: env.BACKEND_URL || 'NOT SET',
      final: redirectUri || 'NOT SET'
    }
  });
  
  // Validate Client ID format
  if (clientId) {
    const clientIdStr = String(clientId);
    if (clientIdStr.includes('@')) {
      log.error('[Xero] ERROR: Client ID appears to be an email address', null, { clientId: clientId?.substring(0, 8) + '...' });
      log.error('[Xero] Client ID should be a 32-character hexadecimal string, not an email!');
      log.error('[Xero] Please update the Client ID in Settings to your actual Xero Client ID from https://developer.xero.com/myapps');
    } else if (clientIdStr.length !== 32) {
      console.warn('[Xero] Client ID length unusual:', clientIdStr.length, 'Expected 32 characters');
    } else if (!/^[0-9A-Fa-f]{32}$/.test(clientIdStr)) {
      console.warn('[Xero] Client ID should contain only hexadecimal characters (0-9, A-F)');
    }
  }
  
  if (!redirectUri || redirectUri.trim() === '') {
    // If FRONTEND_URL is set (e.g., https://admin.ampedlogix.com), use that with /api prefix
    // This works for reverse proxy setups where frontend and API share the same domain
    const frontendUrl = env.FRONTEND_URL;
    if (frontendUrl && !frontendUrl.includes('localhost')) {
      redirectUri = `${frontendUrl}/api/xero/callback`;
      console.log('[Xero] Using redirect URI from FRONTEND_URL');
    } else {
      // Fallback to BACKEND_URL for direct backend access
      const backendUrl = env.BACKEND_URL || 'http://localhost:3001';
      redirectUri = `${backendUrl}/api/xero/callback`;
      console.log('[Xero] Using redirect URI from BACKEND_URL (fallback)');
    }
  } else {
    console.log('[Xero] Using redirect URI from database settings');
  }
  
  console.log('[Xero] Final redirect URI:', redirectUri);
  console.log('[Xero] Client ID:', clientId ? `${clientId.substring(0, 8)}...` : 'NOT SET');
  console.log('[Xero] Client Secret:', clientSecret ? 'SET' : 'NOT SET');
  
  return { clientId, clientSecret, redirectUri };
}

// Get Xero authorization URL
router.get('/auth/url', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { clientId, clientSecret, redirectUri } = await getXeroCredentials();
    
    if (!clientId || !clientSecret) {
      console.error('[Xero] Missing credentials:', { 
        hasClientId: !!clientId, 
        hasClientSecret: !!clientSecret 
      });
      return res.status(400).json({ 
        error: 'Xero credentials not configured. Please add your Client ID and Client Secret in Settings.',
        configured: false,
        details: {
          clientId: clientId ? 'Set' : 'Missing',
          clientSecret: clientSecret ? 'Set' : 'Missing'
        }
      });
    }
    
    // Validate Client ID is not an email address
    const clientIdStr = String(clientId);
    if (clientIdStr.includes('@')) {
      console.error('[Xero] Invalid Client ID: Email address detected:', clientIdStr);
      return res.status(400).json({
        error: 'Invalid Client ID: Email addresses cannot be used. Please enter your 32-character Xero Client ID from the Xero Developer Portal.',
        configured: false,
        details: {
          issue: 'Client ID appears to be an email address',
          expected: '32-character hexadecimal string',
          actual: clientIdStr.substring(0, 20) + '...',
          help: 'Get your Client ID from https://developer.xero.com/myapps'
        }
      });
    }
    
    // Validate Client ID format (Xero Client IDs are typically 32 characters)
    if (clientIdStr.length !== 32) {
      console.warn('[Xero] Client ID length incorrect:', clientIdStr.length, 'Expected 32');
      return res.status(400).json({
        error: `Invalid Client ID format. Xero Client IDs must be exactly 32 characters (you have ${clientIdStr.length}).`,
        configured: false,
        details: {
          expectedLength: 32,
          actualLength: clientIdStr.length,
          help: 'Get your Client ID from https://developer.xero.com/myapps'
        }
      });
    }
    
    // Validate it's hexadecimal
    if (!/^[0-9A-Fa-f]{32}$/.test(clientIdStr)) {
      console.warn('[Xero] Client ID should contain only hexadecimal characters');
    }

    // Validate redirect URI format
    try {
      const redirectUrl = new URL(redirectUri);
      if (redirectUrl.protocol !== 'https:' && !redirectUrl.hostname.includes('localhost')) {
        console.warn('[Xero] Redirect URI should use HTTPS for production:', redirectUri);
      }
    } catch (e) {
      console.error('[Xero] Invalid redirect URI format:', redirectUri);
      return res.status(400).json({
        error: 'Invalid redirect URI format',
        details: 'Redirect URI must be a valid URL'
      });
    }

    const scopes = [
      'openid',
      'profile',
      'email',
      'accounting.transactions',
      'accounting.contacts',
      'accounting.settings',
      'offline_access'
    ].join(' ');

    const authUrl = `https://login.xero.com/identity/connect/authorize?` +
      `response_type=code&` +
      `client_id=${clientId}&` +
      `redirect_uri=${encodeURIComponent(redirectUri)}&` +
      `scope=${encodeURIComponent(scopes)}&` +
      `state=${req.user!.id}`;

    console.log('[Xero] Generated auth URL with:', {
      clientId: `${clientId.substring(0, 8)}...`,
      clientIdFull: clientId, // Log full ID for debugging (remove in production)
      redirectUri,
      redirectUriEncoded: encodeURIComponent(redirectUri),
      scopes: scopes.split(' ').length + ' scopes',
      state: req.user!.id,
      authUrlPreview: authUrl.substring(0, 100) + '...'
    });

    // Return detailed info for debugging (including full client ID for verification)
    res.json({ 
      url: authUrl, 
      configured: true,
      redirectUri, // Return redirect URI so frontend can verify
      clientId: clientId, // Return full client ID for verification
      clientIdPrefix: clientId.substring(0, 8), // For display
      verification: {
        redirectUriMatch: 'Ensure this exact URI is in your Xero app: ' + redirectUri,
        clientIdMatch: 'Ensure this Client ID matches your Xero app: ' + clientId,
        xeroAppUrl: 'https://developer.xero.com/myapps'
      }
    });
  } catch (error: any) {
      log.error('[Xero] Failed to generate auth URL', error, {
        error: error.message,
        stack: error.stack
      });
    res.status(500).json({ 
      error: 'Failed to generate auth URL',
      details: process.env.NODE_ENV === 'development' ? error.message : undefined
    });
  }
});

// Handle Xero OAuth callback
// Helper function to send response that works in both popup and full-page redirect
function sendPopupOrRedirect(res: Response, frontendUrl: string, type: 'success' | 'error', message: string, errorParams?: string) {
  const html = `
    <!DOCTYPE html>
    <html>
      <head>
        <title>Xero Connection ${type === 'success' ? 'Successful' : 'Error'}</title>
        <style>
          body {
            font-family: system-ui, -apple-system, sans-serif;
            display: flex;
            align-items: center;
            justify-content: center;
            min-height: 100vh;
            margin: 0;
            background: #1a1d23;
            color: #e8eaed;
            text-align: center;
            padding: 20px;
          }
          .container {
            max-width: 400px;
          }
          .icon {
            font-size: 48px;
            margin-bottom: 16px;
          }
          .success { color: #39ff14; }
          .error { color: #ef4444; }
          h1 { margin: 0 0 8px; font-size: 24px; }
          p { color: #9ca3af; margin: 8px 0; }
          a { color: #60a5fa; text-decoration: none; }
          a:hover { text-decoration: underline; }
        </style>
      </head>
      <body>
        <div class="container">
          <div class="icon ${type}">
            ${type === 'success' ? '‚úì' : '‚úó'}
          </div>
          <h1>Connection ${type === 'success' ? 'Successful' : 'Failed'}</h1>
          <p>${message}</p>
          <p>This window should close automatically.</p>
        </div>
        <script>
          (function() {
            console.log('[Xero Callback] Window opener:', window.opener ? 'exists' : 'null');
            console.log('[Xero Callback] Window opener closed:', window.opener ? window.opener.closed : 'N/A');
            console.log('[Xero Callback] Origin:', window.location.origin);
            
            // Try to send message to parent window (popup mode)
            if (window.opener && !window.opener.closed) {
              try {
                const messageData = {
                  type: type === 'success' ? 'XERO_OAUTH_SUCCESS' : 'XERO_OAUTH_ERROR',
                  message: ${JSON.stringify(message)},
                  errorParams: ${JSON.stringify(errorParams || '')}
                };
                
                console.log('[Xero Callback] Sending postMessage:', messageData);
                
                // Send message with retry logic
                let retries = 0;
                const maxRetries = 3;
                const sendMessage = () => {
                  try {
                    window.opener.postMessage(messageData, window.location.origin);
                    console.log('[Xero Callback] postMessage sent successfully');
                    
                    // Close after a short delay to ensure message is received
                    setTimeout(function() {
                      console.log('[Xero Callback] Closing window...');
                      if (window.opener && !window.opener.closed) {
                        window.close();
                      }
                    }, 500);
                  } catch (e) {
                    console.error('[Xero Callback] Failed to postMessage, retry', retries + 1, ':', e);
                    if (retries < maxRetries) {
                      retries++;
                      setTimeout(sendMessage, 200);
                    } else {
                      // Fallback: try redirect after max retries
                      setTimeout(function() {
                        window.location.href = '${frontendUrl}/settings?xero_connected=${type === 'success' ? 'true' : 'false'}';
                      }, 1000);
                    }
                  }
                };
                
                sendMessage();
                return; // Exit early, don't redirect
              } catch (e) {
                console.error('[Xero Callback] Failed to postMessage:', e);
              }
            }
            
            // Fallback: redirect if not in popup (only if opener doesn't exist or is closed)
            console.log('[Xero Callback] No opener or opener closed, redirecting...');
            setTimeout(function() {
              ${type === 'success' 
                ? `window.location.href = '${frontendUrl}/settings?xero_connected=true';`
                : `window.location.href = '${frontendUrl}/settings${errorParams || ''}';`
              }
            }, 1000);
          })();
        </script>
      </body>
    </html>
  `;
  return res.send(html);
}

router.get('/callback', async (req, res) => {
  const { code, state, error, error_description } = req.query;
  
  // Get credentials first to determine the correct frontend URL
  // This ensures we use the same domain as the redirect URI
  let frontendUrl = env.FRONTEND_URL;
  
  try {
    const { redirectUri } = await getXeroCredentials();
    // Extract frontend URL from redirect URI (remove /api/xero/callback)
    if (redirectUri) {
      try {
        const redirectUrl = new URL(redirectUri);
        // If redirect URI is like https://admin.ampedlogix.com/api/xero/callback
        // Extract https://admin.ampedlogix.com
        frontendUrl = redirectUrl.origin;
        console.log('[Xero] Using frontend URL from redirect URI:', frontendUrl);
      } catch (e) {
        console.warn('[Xero] Could not parse redirect URI for frontend URL:', redirectUri);
      }
    }
  } catch (e) {
    console.warn('[Xero] Could not get credentials for frontend URL, using env:', e);
  }
  
  // Fallback to env or localhost
  if (!frontendUrl || frontendUrl.includes('localhost')) {
    frontendUrl = env.FRONTEND_URL || 'http://localhost:3000';
    console.log('[Xero] Using frontend URL from env or fallback:', frontendUrl);
  }

  try {
    // Check for OAuth errors from Xero
    if (error) {
      const errorStr: string = Array.isArray(error) 
        ? String(error[0]) 
        : typeof error === 'string' 
          ? error 
          : String(error);
      const errorDescStr: string | undefined = error_description 
        ? (Array.isArray(error_description) 
            ? String(error_description[0]) 
            : typeof error_description === 'string'
              ? error_description
              : String(error_description))
        : undefined;
      
      // Get credentials to include in error message
      const { clientId, redirectUri } = await getXeroCredentials();
      
      const errorDetails = {
        error: errorStr,
        error_description: errorDescStr,
        clientId: clientId || 'NOT SET',
        redirectUri: redirectUri || 'NOT SET',
        query: req.query
      };
      
      console.error('[Xero] OAuth error from Xero:', errorDetails);
      
      // Log to database error log if available
      try {
        await query(
          `INSERT INTO error_logs (type, message, details, created_at) 
           VALUES ($1, $2, $3, NOW())`,
          [
            'xero_oauth',
            `Xero OAuth Error: ${errorStr}`,
            JSON.stringify(errorDetails)
          ]
        );
      } catch (logError) {
        // Ignore if error_logs table doesn't exist
        console.warn('[Xero] Could not log to error_logs table:', logError);
      }
      
      let errorMessage = 'Authentication failed';
      if (errorStr === 'unauthorized_client') {
        errorMessage = `Client ID or Secret is incorrect, or redirect URI does not match Xero app settings.\n\n` +
          `Client ID being used: ${clientId || 'NOT SET'}\n` +
          `Redirect URI being used: ${redirectUri || 'NOT SET'}\n\n` +
          `Please verify these match your Xero app settings exactly.`;
      } else if (errorStr === 'access_denied') {
        errorMessage = 'Connection was cancelled by user';
      } else if (errorDescStr) {
        errorMessage = `${errorDescStr}\n\nClient ID: ${clientId || 'NOT SET'}\nRedirect URI: ${redirectUri || 'NOT SET'}`;
      }
      
      return res.redirect(`${frontendUrl}/settings?tab=integrations&xero_error=${encodeURIComponent(errorStr)}&xero_error_msg=${encodeURIComponent(errorMessage)}`);
    }

    // Ensure code is a string
    const codeStr: string | null = code 
      ? (Array.isArray(code) 
          ? String(code[0]) 
          : typeof code === 'string' 
            ? code 
            : String(code))
      : null;
    
    if (!codeStr) {
      console.error('[Xero] No authorization code received:', { query: req.query });
      return res.redirect(`${frontendUrl}/settings?tab=integrations&xero_error=no_code&xero_error_msg=${encodeURIComponent('No authorization code received from Xero')}`);
    }

    // Get credentials from database settings
    const { clientId, clientSecret, redirectUri } = await getXeroCredentials();

    if (!clientId || !clientSecret) {
      console.error('[Xero] Missing credentials in callback');
      return res.redirect(`${frontendUrl}/settings?tab=integrations&xero_error=credentials_missing&xero_error_msg=${encodeURIComponent('Xero credentials not found. Please configure them in Settings.')}`);
    }

    // Ensure credentials are trimmed and valid
    const trimmedClientId = String(clientId).trim();
    const trimmedClientSecret = String(clientSecret).trim();
    const trimmedRedirectUri = redirectUri.trim();
    
    // Validate Client ID format before token exchange
    if (trimmedClientId.includes('@')) {
      console.error('[Xero] ERROR: Client ID is an email address during token exchange:', trimmedClientId);
      return res.redirect(`${frontendUrl}/settings?tab=integrations&xero_error=invalid_client_id&xero_error_msg=${encodeURIComponent('Client ID appears to be an email address. Please enter your 32-character Xero Client ID from the Xero Developer Portal.')}`);
    }
    
    if (trimmedClientId.length !== 32) {
      console.error('[Xero] ERROR: Client ID length incorrect during token exchange:', {
        length: trimmedClientId.length,
        expected: 32,
        clientId: `${trimmedClientId.substring(0, 8)}...`
      });
      return res.redirect(`${frontendUrl}/settings?tab=integrations&xero_error=invalid_client_id&xero_error_msg=${encodeURIComponent(`Client ID must be exactly 32 characters (currently ${trimmedClientId.length}). Please verify your Client ID in Settings.`)}`);
    }

    // Log Client Secret info (first 4 and last 4 chars for debugging, but not full secret)
    const clientSecretPreview = trimmedClientSecret.length > 8 
      ? `${trimmedClientSecret.substring(0, 4)}...${trimmedClientSecret.substring(trimmedClientSecret.length - 4)}`
      : trimmedClientSecret.length > 0 
        ? `${trimmedClientSecret.substring(0, Math.min(4, trimmedClientSecret.length))}...`
        : 'EMPTY';
    
    console.log('[Xero] Exchanging code for tokens:', {
      hasCode: !!codeStr,
      codeLength: codeStr.length,
      redirectUri: trimmedRedirectUri,
      clientId: trimmedClientId, // Log full Client ID for debugging
      clientIdLength: trimmedClientId.length,
      clientSecretLength: trimmedClientSecret.length,
      clientSecretPreview: clientSecretPreview,
      clientSecretHasWhitespace: trimmedClientSecret !== String(clientSecret).trim(),
      clientSecretSet: !!trimmedClientSecret
    });

    // Prepare Basic Auth header
    const basicAuth = Buffer.from(`${trimmedClientId}:${trimmedClientSecret}`).toString('base64');
    
    console.log('[Xero] Token exchange request details:', {
      url: 'https://identity.xero.com/connect/token',
      clientIdLength: trimmedClientId.length,
      clientSecretLength: trimmedClientSecret.length,
      basicAuthLength: basicAuth.length,
      basicAuthPreview: `${basicAuth.substring(0, 10)}...`,
      redirectUri: trimmedRedirectUri,
      grantType: 'authorization_code',
      codeLength: codeStr.length
    });

    // Exchange code for tokens using actual Xero API
    const tokenResponse = await fetch('https://identity.xero.com/connect/token', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/x-www-form-urlencoded',
        'Authorization': `Basic ${basicAuth}`
      },
      body: new URLSearchParams({
        grant_type: 'authorization_code',
        code: codeStr,
        redirect_uri: trimmedRedirectUri
      })
    });

    if (!tokenResponse.ok) {
      const errorText = await tokenResponse.text();
      let errorData;
      try {
        errorData = JSON.parse(errorText);
      } catch {
        errorData = { error: errorText };
      }
      
      console.error('[Xero] Token exchange failed:', {
        status: tokenResponse.status,
        statusText: tokenResponse.statusText,
        error: errorData,
        redirectUri: trimmedRedirectUri,
        clientId: trimmedClientId, // Log full Client ID for debugging
        clientIdLength: trimmedClientId.length,
        clientSecretLength: trimmedClientSecret.length,
        clientSecretSet: !!trimmedClientSecret,
        redirectUriUsed: trimmedRedirectUri,
        requestDetails: {
          grant_type: 'authorization_code',
          codeLength: codeStr.length,
          redirect_uri: trimmedRedirectUri
        }
      });
      
      let errorMsg = 'Token exchange failed';
      let errorDetails = '';
      
      if (errorData.error === 'invalid_client') {
        errorMsg = 'Invalid Client ID or Client Secret.';
        errorDetails = `The credentials in your Settings don't match your Xero app.\n\n` +
          `Client ID used: ${trimmedClientId}\n` +
          `Client ID length: ${trimmedClientId.length} characters\n` +
          `Redirect URI used: ${trimmedRedirectUri}\n\n` +
          `Please verify:\n` +
          `1. Your Client ID in Settings matches the Client ID in your Xero app (https://developer.xero.com/myapps)\n` +
          `2. Your Client Secret in Settings matches the Client Secret in your Xero app\n` +
          `3. The Redirect URI "${trimmedRedirectUri}" is added to your Xero app's OAuth 2.0 redirect URIs`;
      } else if (errorData.error === 'invalid_grant') {
        errorMsg = 'Authorization code expired or invalid.';
        errorDetails = `The authorization code may have expired or the redirect URI doesn't match.\n\n` +
          `Redirect URI used: ${trimmedRedirectUri}\n\n` +
          `Please try connecting again.`;
      } else if (errorData.error_description) {
        errorMsg = errorData.error_description;
        errorDetails = `Xero error: ${errorData.error || 'Unknown error'}`;
      } else {
        errorDetails = `HTTP ${tokenResponse.status}: ${tokenResponse.statusText}`;
      }
      
      const fullErrorMessage = errorDetails ? `${errorMsg}\n\n${errorDetails}` : errorMsg;
      
      return res.redirect(`${frontendUrl}/settings?tab=integrations&xero_error=token_exchange_failed&xero_error_msg=${encodeURIComponent(fullErrorMessage)}&client_id=${encodeURIComponent(trimmedClientId)}&redirect_uri=${encodeURIComponent(trimmedRedirectUri)}`);
    }

    interface XeroTokenResponse {
      access_token: string;
      refresh_token: string;
      id_token?: string;
      token_type: string;
      expires_in: number;
    }
    
    interface XeroConnection {
      tenantId: string;
      tenantName: string;
    }

    const tokens = await tokenResponse.json() as XeroTokenResponse;
    const expiresAt = new Date(Date.now() + tokens.expires_in * 1000);

    console.log('[Xero] Token exchange successful:', {
      hasAccessToken: !!tokens.access_token,
      hasRefreshToken: !!tokens.refresh_token,
      expiresIn: tokens.expires_in,
      expiresAt: expiresAt.toISOString()
    });

    // Get tenant info (organization connected)
    let tenantId: string | null = null;
    let tenantName = 'Connected Organization';
    
    try {
      console.log('[Xero] Fetching Xero connections...');
      const connectionsResponse = await fetchWithRateLimit('https://api.xero.com/connections', {
        headers: {
          'Authorization': `Bearer ${tokens.access_token}`,
          'Content-Type': 'application/json'
        }
      });
      
      if (connectionsResponse.ok) {
        const connections = await connectionsResponse.json() as XeroConnection[];
        if (connections && connections.length > 0) {
          tenantId = connections[0].tenantId;
          tenantName = connections[0].tenantName;
          console.log('[Xero] Found connected organization:', { tenantId, tenantName });
        } else {
          console.warn('[Xero] No connections found in response');
        }
      } else {
        const errorText = await connectionsResponse.text();
        console.error('[Xero] Failed to get connections:', {
          status: connectionsResponse.status,
          statusText: connectionsResponse.statusText,
          error: errorText
        });
      }
    } catch (e) {
      console.error('[Xero] Error fetching connections:', e);
      // Don't fail the whole process if we can't get tenant info
    }

    // Store tokens (replace any existing)
    try {
      console.log('[Xero] Storing tokens in database...');
    await query('DELETE FROM xero_tokens');
    
    await query(
      `INSERT INTO xero_tokens (access_token, refresh_token, id_token, token_type, expires_at, tenant_id, tenant_name)
       VALUES ($1, $2, $3, $4, $5, $6, $7)`,
      [
        tokens.access_token,
        tokens.refresh_token,
        tokens.id_token || null,
        tokens.token_type,
        expiresAt,
        tenantId,
        tenantName
      ]
    );

      console.log('[Xero] Tokens stored successfully:', {
        tenantId,
        tenantName,
        expiresAt: expiresAt.toISOString()
      });
    } catch (dbError: any) {
      console.error('[Xero] Failed to store tokens in database:', {
        error: dbError.message,
        stack: dbError.stack,
        code: dbError.code
      });
      
      // Return error page but don't redirect to frontend with error
      // since Xero connection was successful
      return res.send(`
      <!DOCTYPE html>
      <html>
        <head>
            <title>AmpedFieldOps - Storage Error</title>
          <style>
            body { font-family: system-ui, sans-serif; background: #1a1d23; color: #e8eaed; display: flex; align-items: center; justify-content: center; min-height: 100vh; margin: 0; }
              .container { text-align: center; padding: 40px; max-width: 600px; }
              .warning { color: #fbbf24; font-size: 48px; margin-bottom: 16px; }
            h1 { margin: 0 0 8px; }
              p { color: #9ca3af; margin: 8px 0; }
              .error-details { background: #2a2d33; padding: 16px; border-radius: 8px; margin-top: 16px; text-align: left; font-size: 12px; }
          </style>
        </head>
        <body>
          <div class="container">
              <div class="warning">‚ö†Ô∏è</div>
              <h1>Connection Successful, But Storage Failed</h1>
              <p>Your Xero connection was successful, but we couldn't save it to the database.</p>
              <p>Please check the backend logs and try disconnecting and reconnecting.</p>
              <div class="error-details">
                <strong>Error:</strong> ${dbError.message || 'Database error'}
          </div>
          <script>
                setTimeout(() => {
                  window.location.href = '${frontendUrl}/settings?tab=integrations&xero_error=storage_failed&xero_error_msg=${encodeURIComponent('Connection successful but failed to save. Please try reconnecting.')}';
                }, 3000);
          </script>
            </div>
        </body>
      </html>
    `);
    }

    // Redirect to frontend with success
    return res.redirect(`${frontendUrl}/settings?tab=integrations&xero_connected=true`);
  } catch (error: any) {
    console.error('[Xero] Callback error:', {
      error: error.message,
      stack: error.stack,
      name: error.name
    });
    
    // Log to database error log if available
    try {
      await query(
        `INSERT INTO error_logs (type, message, details, created_at) 
         VALUES ($1, $2, $3, NOW())`,
        [
          'xero_callback',
          `Xero Callback Error: ${error.message}`,
          JSON.stringify({ stack: error.stack, name: error.name })
        ]
      );
    } catch (logError) {
      console.warn('[Xero] Could not log to error_logs table:', logError);
    }
    
    // Return HTML for error case too
    res.send(`
      <!DOCTYPE html>
      <html>
        <head>
          <title>AmpedFieldPro - Connection Failed</title>
          <style>
            body { font-family: system-ui, sans-serif; background: #1a1d23; color: #e8eaed; display: flex; align-items: center; justify-content: center; min-height: 100vh; margin: 0; }
            .container { text-align: center; padding: 40px; }
            .error { color: #ef4444; font-size: 48px; margin-bottom: 16px; }
            h1 { margin: 0 0 8px; }
            p { color: #9ca3af; }
          </style>
        </head>
        <body>
          <div class="container">
            <div class="error">‚úï</div>
            <h1>Connection Failed</h1>
            <p>This window will close automatically...</p>
          </div>
          <script>
              window.location.href = '${frontendUrl}/settings?tab=integrations&xero_error=callback_failed';
          </script>
        </body>
      </html>
    `);
  }
});

// Get Xero connection status
router.get('/status', authenticate, async (req: AuthRequest, res: Response) => {
  try {
    // Ensure tables exist before querying (don't fail if this errors)
    try {
      await ensureXeroTables();
    } catch (ensureError: any) {
      console.warn('[Xero] Failed to ensure tables exist:', ensureError.message);
      // Continue anyway - tables might already exist
    }
    
    const result = await query(
      `SELECT tenant_id, tenant_name, expires_at, updated_at FROM xero_tokens ORDER BY created_at DESC LIMIT 1`
    );

    // Check if credentials are configured
    const { clientId, clientSecret } = await getXeroCredentials();
    const isConfigured = !!(clientId && clientSecret);

    if (result.rows.length === 0) {
      return res.json({ 
        connected: false,
        configured: isConfigured
      });
    }

    const token = result.rows[0];
    const isExpired = new Date(token.expires_at) < new Date();

    res.json({
      connected: true,
      configured: isConfigured,
      tenant_name: token.tenant_name,
      expires_at: token.expires_at,
      last_sync: token.updated_at ? token.updated_at.toISOString() : null,
      needs_refresh: isExpired
    });
  } catch (error: any) {
    const errorMessage = error.message || 'Failed to get Xero status';
    const isTableError = errorMessage.includes('does not exist') || errorMessage.includes('relation') || error.code === '42P01';
    if (isTableError) {
      // Return default status object with 200 status instead of 500
      console.warn('[Xero] xero_tokens table not found. Returning default status. Run migrations to create tables.');
      try {
        const { clientId, clientSecret } = await getXeroCredentials();
        const isConfigured = !!(clientId && clientSecret);
        return res.json({ 
          connected: false,
          configured: isConfigured
        });
      } catch (credError) {
        // If credentials check also fails, return default
        return res.json({ 
          connected: false,
          configured: false
        });
      }
    }
    console.error('Failed to get Xero status:', error);
    // For non-table errors, return default status to prevent frontend errors
    res.json({ 
      connected: false,
      configured: false
    });
  }
});

// Disconnect Xero
router.delete('/disconnect', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    await query('DELETE FROM xero_tokens');
    
    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, details) 
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'disconnect', 'xero', JSON.stringify({ action: 'disconnected' })]
    );

    res.json({ message: 'Xero disconnected' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to disconnect Xero' });
  }
});

// Helper to get valid access token (refreshes if needed)
async function getValidAccessToken(): Promise<{ accessToken: string; tenantId: string } | null> {
  const tokenResult = await query('SELECT * FROM xero_tokens ORDER BY created_at DESC LIMIT 1');
  if (tokenResult.rows.length === 0) {
    return null;
  }

  const token = tokenResult.rows[0];
  const expiresAt = new Date(token.expires_at);
  
  // If token is expired, try to refresh
  if (expiresAt < new Date()) {
    const { clientId, clientSecret } = await getXeroCredentials();
    
    if (!clientId || !clientSecret || !token.refresh_token) {
      return null;
    }

    try {
      const refreshResponse = await fetch('https://identity.xero.com/connect/token', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/x-www-form-urlencoded',
          'Authorization': 'Basic ' + Buffer.from(`${clientId}:${clientSecret}`).toString('base64')
        },
        body: new URLSearchParams({
          grant_type: 'refresh_token',
          refresh_token: token.refresh_token
        })
      });

      if (!refreshResponse.ok) {
        const errorText = await refreshResponse.text();
        let errorData: any = {};
        try {
          errorData = JSON.parse(errorText);
        } catch {
          errorData = { error: errorText };
        }
        
        console.error('Token refresh failed:', {
          status: refreshResponse.status,
          error: errorData.error || errorData.error_description || 'Unknown error',
          details: errorData
        });
        
        // If refresh token is invalid/expired, clear tokens so user can reconnect
        if (errorData.error === 'invalid_grant' || refreshResponse.status === 401) {
          console.warn('[Xero] Refresh token expired or invalid. Clearing tokens.');
          await query('DELETE FROM xero_tokens WHERE id = $1', [token.id]);
        }
        
        return null;
      }

      interface RefreshTokenResponse {
        access_token: string;
        refresh_token: string; // Xero uses rotating refresh tokens - this is the NEW token
        expires_in: number;
      }

      const newTokens = await refreshResponse.json() as RefreshTokenResponse;
      const newExpiresAt = new Date(Date.now() + newTokens.expires_in * 1000);

      // IMPORTANT: Xero uses rotating refresh tokens
      // The refresh_token in the response is a NEW token that must be used for the next refresh
      // We MUST update the refresh_token in the database
      await query(
        `UPDATE xero_tokens SET access_token = $1, refresh_token = $2, expires_at = $3, updated_at = CURRENT_TIMESTAMP WHERE id = $4`,
        [newTokens.access_token, newTokens.refresh_token, newExpiresAt, token.id]
      );

      console.log('[Xero] Token refreshed successfully. New refresh token stored (rotating tokens).');
      return { accessToken: newTokens.access_token, tenantId: token.tenant_id };
    } catch (e) {
      console.error('Token refresh error:', e);
      return null;
    }
  }

  return { accessToken: token.access_token, tenantId: token.tenant_id };
}

// Helper function to find local records missing in Xero
function findMissingInXero<T extends Record<string, any>>(
  localRecords: T[],
  xeroRecords: Array<{ ID: string }>,
  idField: keyof T
): T[] {
  const xeroIds = new Set(xeroRecords.map(r => r.ID));
  return localRecords.filter(local => {
    const localXeroId = local[idField] as string | undefined | null;
    return !localXeroId || localXeroId.trim() === '' || !xeroIds.has(localXeroId);
  });
}

// Helper function to build Xero invoice payload from local invoice
async function buildXeroInvoicePayload(localInvoice: any): Promise<any> {
  // Get client's Xero contact ID
  let contactId: string | null = null;
  if (localInvoice.client_id) {
    const clientResult = await query('SELECT xero_contact_id FROM clients WHERE id = $1', [localInvoice.client_id]);
    if (clientResult.rows.length > 0 && clientResult.rows[0].xero_contact_id) {
      contactId = clientResult.rows[0].xero_contact_id;
    }
  }

  if (!contactId) {
    throw new Error('Client does not have a Xero contact ID. Please sync contacts first.');
  }

  // Parse line items
  let lineItems: any[] = [];
  if (localInvoice.line_items) {
    try {
      lineItems = typeof localInvoice.line_items === 'string' 
        ? JSON.parse(localInvoice.line_items) 
        : localInvoice.line_items;
    } catch (e) {
      console.error('Failed to parse line items:', e);
    }
  }

  // Build Xero line items format
  const xeroLineItems = lineItems.map((item: any) => ({
    Description: item.description || '',
    Quantity: item.quantity || 1,
    UnitAmount: item.unit_price || item.amount || 0,
    AccountCode: item.account_code || '200', // Default revenue account
    LineAmount: item.amount || (item.quantity || 1) * (item.unit_price || 0)
  }));

  return {
    Type: 'ACCREC', // Accounts Receivable
    Contact: { ContactID: contactId },
    Date: localInvoice.issue_date || new Date().toISOString().split('T')[0],
    DueDate: localInvoice.due_date || null,
    InvoiceNumber: localInvoice.invoice_number || null,
    Reference: localInvoice.reference || null, // Include client PO numbers
    LineItems: xeroLineItems,
    Status: localInvoice.status || 'DRAFT'
  };
}

// Helper function to build Xero quote payload from local quote
async function buildXeroQuotePayload(localQuote: any): Promise<any> {
  // Get client's Xero contact ID
  let contactId: string | null = null;
  if (localQuote.client_id) {
    const clientResult = await query('SELECT xero_contact_id FROM clients WHERE id = $1', [localQuote.client_id]);
    if (clientResult.rows.length > 0 && clientResult.rows[0].xero_contact_id) {
      contactId = clientResult.rows[0].xero_contact_id;
    }
  }

  if (!contactId) {
    throw new Error('Client does not have a Xero contact ID. Please sync contacts first.');
  }

  // Parse line items
  let lineItems: any[] = [];
  if (localQuote.line_items) {
    try {
      lineItems = typeof localQuote.line_items === 'string' 
        ? JSON.parse(localQuote.line_items) 
        : localQuote.line_items;
    } catch (e) {
      console.error('Failed to parse line items:', e);
    }
  }

  // Build Xero line items format
  const xeroLineItems = lineItems.map((item: any) => ({
    Description: item.description || '',
    Quantity: item.quantity || 1,
    UnitAmount: item.unit_price || item.amount || 0,
    AccountCode: item.account_code || '200',
    LineAmount: item.amount || (item.quantity || 1) * (item.unit_price || 0)
  }));

  return {
    Contact: { ContactID: contactId },
    Date: localQuote.issue_date || new Date().toISOString().split('T')[0],
    ExpiryDate: localQuote.expiry_date || null,
    LineItems: xeroLineItems,
    Status: localQuote.status || 'DRAFT'
  };
}

// Xero Contact interface
interface XeroContact {
  ContactID: string;
  Name: string;
  FirstName?: string;
  LastName?: string;
  EmailAddress?: string;
  Phones?: Array<{ PhoneType: string; PhoneNumber: string }>;
  Addresses?: Array<{
    AddressType: string;
    AddressLine1?: string;
    City?: string;
    Region?: string;
    PostalCode?: string;
    Country?: string;
  }>;
  IsCustomer?: boolean;
  IsSupplier?: boolean;
  ContactStatus?: string;
}

// Pull contacts from Xero and sync to local clients
router.post('/contacts/pull', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    // Fetch contacts from Xero
    const contactsResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Contacts?where=IsCustomer==true', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json'
      }
    });

    if (!contactsResponse.ok) {
      const error = await parseXeroError(contactsResponse);
      const errorMessage = getErrorMessage(error);
      console.error('Xero contacts fetch failed:', errorMessage, error);
      return res.status(400).json({ error: errorMessage });
    }

    interface XeroContactsResponse {
      Contacts: XeroContact[];
    }

    const data = await contactsResponse.json() as XeroContactsResponse;
    const xeroContacts = data.Contacts || [];

    let created = 0;
    let updated = 0;
    let skipped = 0;

    for (const contact of xeroContacts) {
      // Check if client exists by xero_contact_id
      const existingClient = await query(
        'SELECT id FROM clients WHERE xero_contact_id = $1',
        [contact.ContactID]
      );

      // Get phone number (prefer mobile, then default)
      const phone = contact.Phones?.find(p => p.PhoneType === 'MOBILE')?.PhoneNumber ||
                    contact.Phones?.find(p => p.PhoneType === 'DEFAULT')?.PhoneNumber || null;

      // Get address
      const streetAddress = contact.Addresses?.find(a => a.AddressType === 'STREET');
      const postalAddress = contact.Addresses?.find(a => a.AddressType === 'POBOX');
      
      const address = streetAddress ? 
        [streetAddress.AddressLine1, streetAddress.City, streetAddress.Region, streetAddress.PostalCode]
          .filter(Boolean).join(', ') : null;
      
      const billingAddress = postalAddress ?
        [postalAddress.AddressLine1, postalAddress.City, postalAddress.Region, postalAddress.PostalCode]
          .filter(Boolean).join(', ') : null;

      // Contact name from first/last or use company name
      const contactName = (contact.FirstName && contact.LastName) 
        ? `${contact.FirstName} ${contact.LastName}` 
        : null;

      if (existingClient.rows.length > 0) {
        // Update existing client
        await query(
          `UPDATE clients SET 
            name = COALESCE($1, name),
            contact_name = COALESCE($2, contact_name),
            email = COALESCE($3, email),
            phone = COALESCE($4, phone),
            address = COALESCE($5, address),
            billing_address = COALESCE($6, billing_address),
            updated_at = CURRENT_TIMESTAMP
          WHERE xero_contact_id = $7`,
          [contact.Name, contactName, contact.EmailAddress, phone, address, billingAddress, contact.ContactID]
        );
        updated++;
      } else {
        // Check if client exists by name (to avoid duplicates)
        const existingByName = await query(
          'SELECT id FROM clients WHERE LOWER(name) = LOWER($1)',
          [contact.Name]
        );

        if (existingByName.rows.length > 0) {
          // Link existing client to Xero contact
          await query(
            'UPDATE clients SET xero_contact_id = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
            [contact.ContactID, existingByName.rows[0].id]
          );
          updated++;
        } else {
          // Create new client from Xero contact
          await query(
            `INSERT INTO clients (name, contact_name, email, phone, address, billing_address, xero_contact_id, status)
             VALUES ($1, $2, $3, $4, $5, $6, $7, 'active')`,
            [contact.Name, contactName, contact.EmailAddress, phone, address, billingAddress, contact.ContactID]
          );
          created++;
        }
      }
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, details) 
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'sync', 'xero_contacts_pull', JSON.stringify({ created, updated, skipped, total: xeroContacts.length })]
    );

    res.json({
      success: true,
      synced_at: new Date(),
      results: {
        total: xeroContacts.length,
        created,
        updated,
        skipped
      }
    });
  } catch (error) {
    console.error('Xero contacts pull error:', error);
    res.status(500).json({ error: 'Failed to pull contacts from Xero' });
  }
});

// Push a local client to Xero as a contact
router.post('/contacts/push/:clientId', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { clientId } = req.params;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    // Get client from database
    const clientResult = await query('SELECT * FROM clients WHERE id = $1', [clientId]);
    if (clientResult.rows.length === 0) {
      return res.status(404).json({ error: 'Client not found' });
    }

    const client = clientResult.rows[0];

    // Build Xero contact payload
    const xeroContact: {
      Name: string;
      FirstName?: string;
      LastName?: string;
      EmailAddress?: string;
      Phones?: Array<{ PhoneType: string; PhoneNumber: string }>;
      Addresses?: Array<{
        AddressType: string;
        AddressLine1: string;
      }>;
      IsCustomer: boolean;
    } = {
      Name: client.name,
      IsCustomer: true
    };

    if (client.contact_name) {
      const nameParts = client.contact_name.split(' ');
      xeroContact.FirstName = nameParts[0];
      xeroContact.LastName = nameParts.slice(1).join(' ') || undefined;
    }

    if (client.email) {
      xeroContact.EmailAddress = client.email;
    }

    if (client.phone) {
      xeroContact.Phones = [{ PhoneType: 'DEFAULT', PhoneNumber: client.phone }];
    }

    if (client.address || client.billing_address) {
      xeroContact.Addresses = [];
      if (client.address) {
        xeroContact.Addresses.push({ AddressType: 'STREET', AddressLine1: client.address });
      }
      if (client.billing_address) {
        xeroContact.Addresses.push({ AddressType: 'POBOX', AddressLine1: client.billing_address });
      }
    }

    // If client already has xero_contact_id, update existing contact
    if (client.xero_contact_id) {
      const updateResponse = await fetchWithRateLimit(`https://api.xero.com/api.xro/2.0/Contacts/${client.xero_contact_id}`, {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${tokenData.accessToken}`,
          'Xero-Tenant-Id': tokenData.tenantId,
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify({ Contacts: [xeroContact] })
      });

      if (!updateResponse.ok) {
        const error = await parseXeroError(updateResponse);
        const errorMessage = getErrorMessage(error);
        console.error('Xero contact update failed:', errorMessage, error);
        return res.status(400).json({ error: errorMessage });
      }

      res.json({
        success: true,
        action: 'updated',
        xero_contact_id: client.xero_contact_id
      });
    } else {
      // Create new contact in Xero
      const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Contacts', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${tokenData.accessToken}`,
          'Xero-Tenant-Id': tokenData.tenantId,
          'Content-Type': 'application/json',
          'Accept': 'application/json'
        },
        body: JSON.stringify({ Contacts: [xeroContact] })
      });

      if (!createResponse.ok) {
        const errorText = await createResponse.text();
        console.error('Xero contact create failed:', errorText);
        return res.status(400).json({ error: 'Failed to create contact in Xero' });
      }

      interface XeroCreateContactResponse {
        Contacts: XeroContact[];
      }

      const result = await createResponse.json() as XeroCreateContactResponse;
      const newXeroContactId = result.Contacts?.[0]?.ContactID;

      if (newXeroContactId) {
        // Update local client with Xero contact ID
        await query(
          'UPDATE clients SET xero_contact_id = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
          [newXeroContactId, clientId]
        );
      }

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
         VALUES ($1, $2, $3, $4, $5)`,
        [req.user!.id, 'push_to_xero', 'client', clientId, JSON.stringify({ xero_contact_id: newXeroContactId })]
      );

      res.json({
        success: true,
        action: 'created',
        xero_contact_id: newXeroContactId
      });
    }
  } catch (error) {
    console.error('Xero contact push error:', error);
    res.status(500).json({ error: 'Failed to push client to Xero' });
  }
});

// Push all local clients without xero_contact_id to Xero
router.post('/contacts/push-all', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    // Get all clients without xero_contact_id
    const clientsResult = await query(
      'SELECT * FROM clients WHERE xero_contact_id IS NULL AND status = $1',
      ['active']
    );

    const clients = clientsResult.rows;
    let created = 0;
    let failed = 0;

    for (const client of clients) {
      const xeroContact: {
        Name: string;
        FirstName?: string;
        LastName?: string;
        EmailAddress?: string;
        Phones?: Array<{ PhoneType: string; PhoneNumber: string }>;
        Addresses?: Array<{ AddressType: string; AddressLine1: string }>;
        IsCustomer: boolean;
      } = {
        Name: client.name,
        IsCustomer: true
      };

      if (client.contact_name) {
        const nameParts = client.contact_name.split(' ');
        xeroContact.FirstName = nameParts[0];
        xeroContact.LastName = nameParts.slice(1).join(' ') || undefined;
      }

      if (client.email) {
        xeroContact.EmailAddress = client.email;
      }

      if (client.phone) {
        xeroContact.Phones = [{ PhoneType: 'DEFAULT', PhoneNumber: client.phone }];
      }

      if (client.address) {
        xeroContact.Addresses = [{ AddressType: 'STREET', AddressLine1: client.address }];
      }

      try {
        const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Contacts', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${tokenData.accessToken}`,
            'Xero-Tenant-Id': tokenData.tenantId,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
          },
          body: JSON.stringify({ Contacts: [xeroContact] })
        });

        if (createResponse.ok) {
          interface XeroCreateContactResponse {
            Contacts: XeroContact[];
          }
          const result = await createResponse.json() as XeroCreateContactResponse;
          const newXeroContactId = result.Contacts?.[0]?.ContactID;

          if (newXeroContactId) {
            await query(
              'UPDATE clients SET xero_contact_id = $1, updated_at = CURRENT_TIMESTAMP WHERE id = $2',
              [newXeroContactId, client.id]
            );
            created++;
          }
        } else {
          const error = await parseXeroError(createResponse);
          console.error('Failed to push contact to Xero:', getErrorMessage(error), error);
          failed++;
        }
      } catch (e) {
        failed++;
      }
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, details) 
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'sync', 'xero_contacts_push', JSON.stringify({ created, failed, total: clients.length })]
    );

    res.json({
      success: true,
      synced_at: new Date(),
      results: {
        total: clients.length,
        created,
        failed
      }
    });
  } catch (error) {
    console.error('Xero contacts push-all error:', error);
    res.status(500).json({ error: 'Failed to push clients to Xero' });
  }
});

// Sync result type
interface SyncResult {
  pulled: { created: number; updated: number };
  pushed: { created: number; failed: number };
}

// Bidirectional sync functions for each data type

// Sync Contacts bidirectionally
async function syncContactsBidirectional(
  tokenData: { accessToken: string; tenantId: string },
  makeInternalRequest: <T = any>(method: string, path: string, body?: any) => Promise<T>
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    // Pull contacts from Xero
    const pullResult = await makeInternalRequest<{ created?: number; updated?: number; skipped?: number }>('POST', '/api/xero/contacts/pull');
    result.pulled.created = pullResult.created || 0;
    result.pulled.updated = pullResult.updated || 0;

    // Push local clients to Xero
    const pushResult = await makeInternalRequest<{ results?: { total?: number; created?: number; failed?: number } }>('POST', '/api/xero/contacts/push-all');
    if (pushResult.results) {
      result.pushed.created = pushResult.results.created || 0;
      result.pushed.failed = pushResult.results.failed || 0;
    }
  } catch (error: any) {
    console.error('Contacts sync error:', error);
    result.pushed.failed = 1;
  }

  return result;
}

// Sync Invoices bidirectionally
// Helper function to safely parse dates from Xero API
function parseXeroDate(dateString: string | null | undefined): Date | null {
  if (!dateString || dateString === '' || dateString === 'null') {
    return null;
  }
  const date = new Date(dateString);
  return isNaN(date.getTime()) ? null : date;
}

// Helper function to parse date with fallback (for required date fields)
function parseXeroDateWithFallback(dateString: string | null | undefined, fallback: Date = new Date()): Date {
  const parsed = parseXeroDate(dateString);
  return parsed || fallback;
}

async function syncInvoicesBidirectional(
  tokenData: { accessToken: string; tenantId: string },
  userId: string
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    // Fetch invoices from Xero
    const invoicesResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Invoices', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json'
      }
    });

    if (invoicesResponse.ok) {
      const invoicesData = await invoicesResponse.json() as { Invoices?: any[] };
      const invoices = invoicesData.Invoices || [];

      // Pull: Import/update invoices from Xero
      for (const invoice of invoices) {
        const existing = await query(
          'SELECT id FROM xero_invoices WHERE xero_invoice_id = $1',
          [invoice.InvoiceID]
        );

        // Get client ID from Xero contact
        let clientId: string | null = null;
        if (invoice.Contact?.ContactID) {
          const clientResult = await query(
            'SELECT id FROM clients WHERE xero_contact_id = $1',
            [invoice.Contact.ContactID]
          );
          if (clientResult.rows.length > 0) {
            clientId = clientResult.rows[0].id;
          }
        }

        // Parse line items
        const lineItems = invoice.LineItems ? JSON.stringify(invoice.LineItems) : null;

        if (existing.rows.length > 0) {
          await query(
            `UPDATE xero_invoices SET 
              invoice_number = $1, status = $2, total = $3, amount_due = $4,
              due_date = $5, issue_date = $6, client_id = $7, line_items = $8,
              synced_at = CURRENT_TIMESTAMP
              WHERE xero_invoice_id = $9`,
            [
              invoice.InvoiceNumber,
              invoice.Status,
              invoice.Total || 0,
              invoice.AmountDue || 0,
              parseXeroDate(invoice.DueDate),
              parseXeroDate(invoice.Date),
              clientId,
              lineItems,
              invoice.InvoiceID
            ]
          );
          result.pulled.updated++;
        } else {
          await query(
            `INSERT INTO xero_invoices (xero_invoice_id, invoice_number, status, total, amount_due, due_date, issue_date, client_id, line_items, synced_at)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, CURRENT_TIMESTAMP)`,
            [
              invoice.InvoiceID,
              invoice.InvoiceNumber,
              invoice.Status,
              invoice.Total || 0,
              invoice.AmountDue || 0,
              parseXeroDate(invoice.DueDate),
              parseXeroDate(invoice.Date),
              clientId,
              lineItems
            ]
          );
          result.pulled.created++;
        }
      }

      // Push: Send local invoices missing in Xero
      const localInvoicesResult = await query(
        `SELECT * FROM xero_invoices 
         WHERE xero_invoice_id IS NULL OR xero_invoice_id = ''`
      );
      const localInvoices = localInvoicesResult.rows;
      const missingInvoices = findMissingInXero(localInvoices, invoices, 'xero_invoice_id');

      for (const localInvoice of missingInvoices) {
        try {
          const invoicePayload = await buildXeroInvoicePayload(localInvoice);
          const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Invoices', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${tokenData.accessToken}`,
              'Xero-Tenant-Id': tokenData.tenantId,
              'Content-Type': 'application/json',
              'Accept': 'application/json'
            },
            body: JSON.stringify({ Invoices: [invoicePayload] })
          });

          if (createResponse.ok) {
            const createResult = await createResponse.json() as { Invoices?: Array<{ InvoiceID: string }> };
            const xeroInvoiceId = createResult.Invoices?.[0]?.InvoiceID;
            if (xeroInvoiceId) {
              await query(
                `UPDATE xero_invoices SET xero_invoice_id = $1, synced_at = CURRENT_TIMESTAMP WHERE id = $2`,
                [xeroInvoiceId, localInvoice.id]
              );
              result.pushed.created++;
            } else {
              result.pushed.failed++;
            }
          } else {
            const errorText = await createResponse.text();
            console.error('Failed to push invoice to Xero:', errorText);
            try {
              await query(
                `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
                 VALUES ($1, $2, $3, $4, $5)`,
                [userId, 'xero_sync_error', 'invoice', localInvoice.id, JSON.stringify({ 
                  invoice_number: localInvoice.invoice_number,
                  error: errorText.substring(0, 500)
                })]
              );
            } catch (logError) {
              console.debug('Failed to log sync error:', logError);
            }
            result.pushed.failed++;
          }
        } catch (pushError: any) {
          console.error('Error pushing invoice to Xero:', pushError);
          try {
            await query(
              `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
               VALUES ($1, $2, $3, $4, $5)`,
              [userId, 'xero_sync_error', 'invoice', localInvoice.id, JSON.stringify({ 
                error: pushError.message?.substring(0, 500) || 'Unknown error'
              })]
            );
          } catch (logError) {
            console.debug('Failed to log sync error:', logError);
          }
          result.pushed.failed++;
        }
      }
    }
  } catch (error: any) {
    console.error('Invoices sync error:', error);
  }

  return result;
}

// Sync Quotes bidirectionally
async function syncQuotesBidirectional(
  tokenData: { accessToken: string; tenantId: string },
  userId: string
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    const quotesResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Quotes', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json'
      }
    });

    if (quotesResponse.ok) {
      const quotesData = await quotesResponse.json() as { Quotes?: any[] };
      const quotes = quotesData.Quotes || [];

      // Pull: Import/update quotes from Xero
      for (const quote of quotes) {
        const existing = await query(
          'SELECT id FROM xero_quotes WHERE xero_quote_id = $1',
          [quote.QuoteID]
        );

        // Get client ID from Xero contact
        let clientId: string | null = null;
        if (quote.Contact?.ContactID) {
          const clientResult = await query(
            'SELECT id FROM clients WHERE xero_contact_id = $1',
            [quote.Contact.ContactID]
          );
          if (clientResult.rows.length > 0) {
            clientId = clientResult.rows[0].id;
          }
        }

        // Parse line items
        const lineItems = quote.LineItems ? JSON.stringify(quote.LineItems) : null;

        if (existing.rows.length > 0) {
          await query(
            `UPDATE xero_quotes SET 
              quote_number = $1, status = $2, total = $3,
              expiry_date = $4, client_id = $5, line_items = $6, issue_date = $7,
              synced_at = CURRENT_TIMESTAMP
              WHERE xero_quote_id = $8`,
            [
              quote.QuoteNumber,
              quote.Status,
              quote.Total || 0,
              quote.ExpiryDate ? new Date(quote.ExpiryDate) : null,
              clientId,
              lineItems,
              quote.Date ? new Date(quote.Date) : null,
              quote.QuoteID
            ]
          );
          result.pulled.updated++;
        } else {
          await query(
            `INSERT INTO xero_quotes (xero_quote_id, quote_number, status, total, expiry_date, client_id, line_items, issue_date, synced_at)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, CURRENT_TIMESTAMP)`,
            [
              quote.QuoteID,
              quote.QuoteNumber,
              quote.Status,
              quote.Total || 0,
              quote.ExpiryDate ? new Date(quote.ExpiryDate) : null,
              clientId,
              lineItems,
              quote.Date ? new Date(quote.Date) : null
            ]
          );
          result.pulled.created++;
        }
      }

      // Push: Send local quotes missing in Xero
      const localQuotesResult = await query(
        `SELECT * FROM xero_quotes 
         WHERE xero_quote_id IS NULL OR xero_quote_id = ''`
      );
      const localQuotes = localQuotesResult.rows;
      const missingQuotes = findMissingInXero(localQuotes, quotes, 'xero_quote_id');

      for (const localQuote of missingQuotes) {
        try {
          const quotePayload = await buildXeroQuotePayload(localQuote);
          const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Quotes', {
            method: 'POST',
            headers: {
              'Authorization': `Bearer ${tokenData.accessToken}`,
              'Xero-Tenant-Id': tokenData.tenantId,
              'Content-Type': 'application/json',
              'Accept': 'application/json'
            },
            body: JSON.stringify({ Quotes: [quotePayload] })
          });

          if (createResponse.ok) {
            const createResult = await createResponse.json() as { Quotes?: Array<{ QuoteID: string }> };
            const xeroQuoteId = createResult.Quotes?.[0]?.QuoteID;
            if (xeroQuoteId) {
              await query(
                `UPDATE xero_quotes SET xero_quote_id = $1, synced_at = CURRENT_TIMESTAMP WHERE id = $2`,
                [xeroQuoteId, localQuote.id]
              );
              result.pushed.created++;
            } else {
              result.pushed.failed++;
            }
          } else {
            const errorText = await createResponse.text();
            console.error('Failed to push quote to Xero:', errorText);
            result.pushed.failed++;
          }
        } catch (pushError: any) {
          console.error('Error pushing quote to Xero:', pushError);
          result.pushed.failed++;
        }
      }
    }
  } catch (error: any) {
    console.error('Quotes sync error:', error);
  }

  return result;
}

// Sync Items bidirectionally
async function syncItemsBidirectional(
  tokenData: { accessToken: string; tenantId: string }
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    // Pull items from Xero using existing function
    const syncedCount = await syncItemsFromXero(tokenData);
    result.pulled.created = syncedCount;

    // Push local items missing in Xero
    const localItemsResult = await query(
      `SELECT * FROM xero_items 
       WHERE xero_item_id IS NULL OR xero_item_id = ''`
    );
    const localItems = localItemsResult.rows;

    // Get items from Xero to check which are missing
    const itemsResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Items', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json'
      }
    });

    let xeroItems: any[] = [];
    if (itemsResponse.ok) {
      const itemsData = await itemsResponse.json() as { Items?: any[] };
      xeroItems = itemsData.Items || [];
    }

    const missingItems = findMissingInXero(localItems, xeroItems, 'xero_item_id');

    for (const localItem of missingItems) {
      try {
        const itemPayload = {
          Code: localItem.code || localItem.name?.substring(0, 30).toUpperCase().replace(/\s+/g, '_'),
          Name: localItem.name,
          Description: localItem.description || '',
          IsTrackedAsInventory: localItem.is_tracked || false
        };

        const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Items', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${tokenData.accessToken}`,
            'Xero-Tenant-Id': tokenData.tenantId,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
          },
          body: JSON.stringify({ Items: [itemPayload] })
        });

        if (createResponse.ok) {
          const createResult = await createResponse.json() as { Items?: Array<{ ItemID: string }> };
          const xeroItemId = createResult.Items?.[0]?.ItemID;
          if (xeroItemId) {
            await query(
              `UPDATE xero_items SET xero_item_id = $1, synced_at = CURRENT_TIMESTAMP WHERE id = $2`,
              [xeroItemId, localItem.id]
            );
            result.pushed.created++;
          } else {
            result.pushed.failed++;
          }
        } else {
          const errorText = await createResponse.text();
          console.error('Failed to push item to Xero:', errorText);
          result.pushed.failed++;
        }
      } catch (pushError: any) {
        console.error('Error pushing item to Xero:', pushError);
        result.pushed.failed++;
      }
    }
  } catch (error: any) {
    console.error('Items sync error:', error);
  }

  return result;
}

// Sync Purchase Orders bidirectionally
async function syncPurchaseOrdersBidirectional(
  tokenData: { accessToken: string; tenantId: string }
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    // Pull purchase orders from Xero
    const poResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/PurchaseOrders', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json'
      }
    });

    let purchaseOrders: any[] = [];

    if (poResponse.ok) {
      const poData = await poResponse.json() as { PurchaseOrders?: any[] };
      purchaseOrders = poData.PurchaseOrders || [];

      // Pull: Import/update purchase orders from Xero
      for (const po of purchaseOrders) {
        const existing = await query(
          'SELECT id FROM xero_purchase_orders WHERE xero_po_id = $1',
          [po.PurchaseOrderID]
        );

        if (existing.rows.length > 0) {
          await query(
            `UPDATE xero_purchase_orders SET 
              po_number = $1, status = $2, total_amount = $3, date = $4, 
              delivery_date = $5, synced_at = CURRENT_TIMESTAMP
              WHERE xero_po_id = $6`,
            [
              po.PurchaseOrderNumber,
              po.Status,
              po.Total || 0,
              parseXeroDateWithFallback(po.Date), // date is required, use today if missing
              parseXeroDate(po.DeliveryDate), // delivery_date can be null
              po.PurchaseOrderID
            ]
          );
          result.pulled.updated++;
        } else {
          // Get supplier contact ID
          let supplierId: string | null = null;
          if (po.Contact?.ContactID) {
            const supplierResult = await query(
              'SELECT id FROM clients WHERE xero_contact_id = $1',
              [po.Contact.ContactID]
            );
            if (supplierResult.rows.length > 0) {
              supplierId = supplierResult.rows[0].id;
            }
          }

          // Try to find a project for this supplier
          // First, try to find an active project with this supplier as client
          let projectId: string | null = null;
          if (supplierId) {
            const projectResult = await query(
              `SELECT id FROM projects 
               WHERE client_id = $1 AND status IN ('quoted', 'in-progress') 
               ORDER BY created_at DESC LIMIT 1`,
              [supplierId]
            );
            if (projectResult.rows.length > 0) {
              projectId = projectResult.rows[0].id;
            }
          }

          // If no project found, purchase order will be imported without project_id
          // User can link it manually later
          if (!projectId) {
            console.log(`[Xero] Importing purchase order ${po.PurchaseOrderNumber} without project - can be linked manually later`);
          }

          await query(
            `INSERT INTO xero_purchase_orders 
             (xero_po_id, po_number, supplier_id, project_id, status, total_amount, date, delivery_date, synced_at)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, CURRENT_TIMESTAMP)`,
            [
              po.PurchaseOrderID,
              po.PurchaseOrderNumber,
              supplierId,
              projectId,
              po.Status,
              po.Total || 0,
              parseXeroDateWithFallback(po.Date), // date is required, use today if missing
              parseXeroDate(po.DeliveryDate) // delivery_date can be null
            ]
          );
          result.pulled.created++;
        }
      }
    }

    // Push: Send local purchase orders missing in Xero
    const localPOResult = await query(
      `SELECT * FROM xero_purchase_orders 
       WHERE xero_po_id IS NULL OR xero_po_id = ''`
    );
    const localPOs = localPOResult.rows;
    const missingPOs = findMissingInXero(localPOs, purchaseOrders, 'xero_po_id');

    for (const localPO of missingPOs) {
      try {
        // Get supplier's Xero contact ID
        let supplierXeroId: string | null = null;
        if (localPO.supplier_id) {
          const supplierResult = await query(
            'SELECT xero_contact_id FROM clients WHERE id = $1',
            [localPO.supplier_id]
          );
          if (supplierResult.rows.length > 0 && supplierResult.rows[0].xero_contact_id) {
            supplierXeroId = supplierResult.rows[0].xero_contact_id;
          }
        }

        if (!supplierXeroId) {
          console.error('Purchase order supplier does not have Xero contact ID');
          result.pushed.failed++;
          continue;
        }

        // Get line items
        const lineItemsResult = await query(
          'SELECT * FROM xero_purchase_order_line_items WHERE po_id = $1',
          [localPO.id]
        );
        const lineItems = lineItemsResult.rows;

        const poPayload = {
          Contact: { ContactID: supplierXeroId },
          Date: localPO.date || new Date().toISOString().split('T')[0],
          DeliveryDate: localPO.delivery_date || null,
          LineItems: lineItems.map((item: any) => ({
            Description: item.description || '',
            Quantity: item.quantity || 1,
            UnitAmount: item.unit_amount || 0,
            AccountCode: item.account_code || '200'
          })),
          Reference: localPO.notes || null
        };

        const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/PurchaseOrders', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${tokenData.accessToken}`,
            'Xero-Tenant-Id': tokenData.tenantId,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
          },
          body: JSON.stringify({ PurchaseOrders: [poPayload] })
        });

        if (createResponse.ok) {
          const createResult = await createResponse.json() as { PurchaseOrders?: Array<{ PurchaseOrderID: string }> };
          const xeroPOId = createResult.PurchaseOrders?.[0]?.PurchaseOrderID;
          if (xeroPOId) {
            await query(
              `UPDATE xero_purchase_orders SET xero_po_id = $1, synced_at = CURRENT_TIMESTAMP WHERE id = $2`,
              [xeroPOId, localPO.id]
            );
            result.pushed.created++;
          } else {
            result.pushed.failed++;
          }
        } else {
          const errorText = await createResponse.text();
          console.error('Failed to push purchase order to Xero:', errorText);
          result.pushed.failed++;
        }
      } catch (pushError: any) {
        console.error('Error pushing purchase order to Xero:', pushError);
        result.pushed.failed++;
      }
    }
  } catch (error: any) {
    console.error('Purchase orders sync error:', error);
  }

  return result;
}

// Sync Bills bidirectionally
async function syncBillsBidirectional(
  tokenData: { accessToken: string; tenantId: string }
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    // Pull bills from Xero
    // Note: Xero doesn't have a dedicated /Bills endpoint
    // Bills are Invoices with Type='ACCPAY' (Accounts Payable)
    // We'll fetch all invoices and filter for ACCPAY type
    const billsResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Invoices?where=Type=="ACCPAY"', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json'
      }
    });

    let bills: any[] = [];

    if (billsResponse.ok) {
      const billsData = await billsResponse.json() as { Invoices?: any[] };
      // Map invoices to bills format for consistency
      bills = (billsData.Invoices || []).map(inv => ({
        BillID: inv.InvoiceID,
        BillNumber: inv.InvoiceNumber,
        Contact: inv.Contact,
        Status: inv.Status,
        Total: inv.Total,
        AmountDue: inv.AmountDue,
        Date: inv.Date,
        DueDate: inv.DueDate,
        LineItems: inv.LineItems
      }));

      // Pull: Import/update bills from Xero
      for (const bill of bills) {
        const existing = await query(
          'SELECT id FROM xero_bills WHERE xero_bill_id = $1',
          [bill.BillID]
        );

        if (existing.rows.length > 0) {
          await query(
            `UPDATE xero_bills SET 
              bill_number = $1, status = $2, amount = $3, amount_due = $4,
              date = $5, due_date = $6, synced_at = CURRENT_TIMESTAMP
              WHERE xero_bill_id = $7`,
            [
              bill.BillNumber,
              bill.Status,
              bill.Total || 0,
              bill.AmountDue || 0,
              bill.Date ? new Date(bill.Date) : null,
              bill.DueDate ? new Date(bill.DueDate) : null,
              bill.BillID
            ]
          );
          result.pulled.updated++;
        } else {
          // Get supplier contact ID
          let supplierId: string | null = null;
          if (bill.Contact?.ContactID) {
            const supplierResult = await query(
              'SELECT id FROM clients WHERE xero_contact_id = $1',
              [bill.Contact.ContactID]
            );
            if (supplierResult.rows.length > 0) {
              supplierId = supplierResult.rows[0].id;
            }
          }

          await query(
            `INSERT INTO xero_bills 
             (xero_bill_id, bill_number, supplier_id, status, amount, amount_due, date, due_date, synced_at)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, CURRENT_TIMESTAMP)`,
            [
              bill.BillID || bill.InvoiceID, // Handle both formats
              bill.BillNumber || bill.InvoiceNumber, // Handle both formats
              supplierId,
              bill.Status,
              bill.Total || 0,
              bill.AmountDue || 0,
              bill.Date ? new Date(bill.Date) : null,
              bill.DueDate ? new Date(bill.DueDate) : null
            ]
          );
          result.pulled.created++;
        }
      }
    }

    // Push: Send local bills missing in Xero
    const localBillsResult = await query(
      `SELECT * FROM xero_bills 
       WHERE xero_bill_id IS NULL OR xero_bill_id = ''`
    );
    const localBills = localBillsResult.rows;
    const missingBills = findMissingInXero(localBills, bills, 'xero_bill_id');

    for (const localBill of missingBills) {
      try {
        // Get supplier's Xero contact ID
        let supplierXeroId: string | null = null;
        if (localBill.supplier_id) {
          const supplierResult = await query(
            'SELECT xero_contact_id FROM clients WHERE id = $1',
            [localBill.supplier_id]
          );
          if (supplierResult.rows.length > 0 && supplierResult.rows[0].xero_contact_id) {
            supplierXeroId = supplierResult.rows[0].xero_contact_id;
          }
        }

        if (!supplierXeroId) {
          console.error('Bill supplier does not have Xero contact ID');
          result.pushed.failed++;
          continue;
        }

        // Parse line items
        let lineItems: any[] = [];
        if (localBill.line_items) {
          try {
            lineItems = typeof localBill.line_items === 'string' 
              ? JSON.parse(localBill.line_items) 
              : localBill.line_items;
          } catch (e) {
            console.error('Failed to parse line items:', e);
          }
        }

        // Xero Bills are created using the Invoices endpoint with Type: 'ACCPAY'
        const billPayload = {
          Type: 'ACCPAY', // Accounts Payable (Bill)
          Contact: { ContactID: supplierXeroId },
          Date: localBill.date || new Date().toISOString().split('T')[0],
          DueDate: localBill.due_date || null,
          LineItems: lineItems.map((item: any) => ({
            Description: item.description || '',
            Quantity: item.quantity || 1,
            UnitAmount: item.unit_amount || item.amount || 0,
            AccountCode: item.account_code || '200'
          })),
          Status: localBill.status || 'AUTHORISED'
        };

        const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Invoices', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${tokenData.accessToken}`,
            'Xero-Tenant-Id': tokenData.tenantId,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
          },
          body: JSON.stringify({ Invoices: [billPayload] })
        });

        if (createResponse.ok) {
          const createResult = await createResponse.json() as { Invoices?: Array<{ InvoiceID: string; Type: string }> };
          const xeroInvoice = createResult.Invoices?.[0];
          // Verify it's a bill (ACCPAY type)
          if (xeroInvoice && xeroInvoice.Type === 'ACCPAY') {
            await query(
              `UPDATE xero_bills SET xero_bill_id = $1, synced_at = CURRENT_TIMESTAMP WHERE id = $2`,
              [xeroInvoice.InvoiceID, localBill.id]
            );
            result.pushed.created++;
          } else {
            console.error('Created invoice is not a bill (Type is not ACCPAY)');
            result.pushed.failed++;
          }
        } else {
          const error = await parseXeroError(createResponse);
          const errorMessage = getErrorMessage(error);
          console.error('Failed to push bill to Xero:', errorMessage, error);
          result.pushed.failed++;
        }
      } catch (pushError: any) {
        console.error('Error pushing bill to Xero:', pushError);
        result.pushed.failed++;
      }
    }
  } catch (error: any) {
    console.error('Bills sync error:', error);
  }

  return result;
}

// Sync Expenses bidirectionally
async function syncExpensesBidirectional(
  tokenData: { accessToken: string; tenantId: string }
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    // Pull receipts/expenses from Xero
    // Note: Xero uses /ExpenseClaims for expense claims, not /Receipts
    // Receipts are different - they're for recording cash transactions
    // We should use /ExpenseClaims for expense management
    const receiptsResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/ExpenseClaims', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json'
      }
    });

    let receipts: any[] = [];

    if (receiptsResponse.ok) {
      const receiptsData = await receiptsResponse.json() as { ExpenseClaims?: any[] };
      // Map ExpenseClaims to receipts format for consistency
      receipts = (receiptsData.ExpenseClaims || []).map(ec => ({
        ReceiptID: ec.ExpenseClaimID,
        ReceiptNumber: ec.ExpenseClaimNumber,
        Date: ec.Date,
        Total: ec.Total,
        Status: ec.Status,
        LineItems: ec.LineItems
      }));

      // Pull: Import/update expenses from Xero
      for (const receipt of receipts) {
        const existing = await query(
          'SELECT id FROM xero_expenses WHERE xero_expense_id = $1',
          [receipt.ReceiptID]
        );

        if (existing.rows.length > 0) {
          await query(
            `UPDATE xero_expenses SET 
              amount = $1, date = $2, description = $3, status = $4,
              synced_at = CURRENT_TIMESTAMP
              WHERE xero_expense_id = $5`,
            [
              receipt.Total || 0,
              receipt.Date ? new Date(receipt.Date) : null,
              receipt.LineItems?.[0]?.Description || '',
              receipt.Status || 'DRAFT',
              receipt.ReceiptID
            ]
          );
          result.pulled.updated++;
        } else {
          await query(
            `INSERT INTO xero_expenses 
             (xero_expense_id, amount, date, description, status, synced_at)
             VALUES ($1, $2, $3, $4, $5, CURRENT_TIMESTAMP)`,
            [
              receipt.ReceiptID,
              receipt.Total || 0,
              receipt.Date ? new Date(receipt.Date) : null,
              receipt.LineItems?.[0]?.Description || '',
              receipt.Status || 'DRAFT'
            ]
          );
          result.pulled.created++;
        }
      }
    }

    // Push: Send local expenses missing in Xero
    const localExpensesResult = await query(
      `SELECT * FROM xero_expenses 
       WHERE xero_expense_id IS NULL OR xero_expense_id = ''`
    );
    const localExpenses = localExpensesResult.rows;
    const missingExpenses = findMissingInXero(localExpenses, receipts, 'xero_expense_id');

    for (const localExpense of missingExpenses) {
      try {
        const receiptPayload = {
          Date: localExpense.date || new Date().toISOString().split('T')[0],
          Contact: {}, // Optional for receipts
          LineItems: [{
            Description: localExpense.description || 'Expense',
            Quantity: 1,
            UnitAmount: localExpense.amount || 0,
            AccountCode: '200' // Default expense account
          }],
          Status: localExpense.status || 'DRAFT',
          Reference: localExpense.description || null
        };

        const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/ExpenseClaims', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${tokenData.accessToken}`,
            'Xero-Tenant-Id': tokenData.tenantId,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
          },
          body: JSON.stringify({ ExpenseClaims: [receiptPayload] })
        });

        if (createResponse.ok) {
          const createResult = await createResponse.json() as { ExpenseClaims?: Array<{ ExpenseClaimID: string }> };
          const xeroExpenseId = createResult.ExpenseClaims?.[0]?.ExpenseClaimID;
          if (xeroExpenseId) {
            await query(
              `UPDATE xero_expenses SET xero_expense_id = $1, synced_at = CURRENT_TIMESTAMP WHERE id = $2`,
              [xeroExpenseId, localExpense.id]
            );
            result.pushed.created++;
          } else {
            result.pushed.failed++;
          }
        } else {
          const error = await parseXeroError(createResponse);
          const errorMessage = getErrorMessage(error);
          console.error('Failed to push expense to Xero:', errorMessage, error);
          result.pushed.failed++;
        }
      } catch (pushError: any) {
        console.error('Error pushing expense to Xero:', pushError);
        result.pushed.failed++;
      }
    }
  } catch (error: any) {
    console.error('Expenses sync error:', error);
  }

  return result;
}

// Sync Payments bidirectionally
async function syncPaymentsBidirectional(
  tokenData: { accessToken: string; tenantId: string }
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    // Pull payments from Xero
    const paymentsResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Payments', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json'
      }
    });

    let payments: any[] = [];

    if (paymentsResponse.ok) {
      const paymentsData = await paymentsResponse.json() as { Payments?: any[] };
      payments = paymentsData.Payments || [];

      // Pull: Import/update payments from Xero
      for (const payment of payments) {
        const existing = await query(
          'SELECT id FROM xero_payments WHERE xero_payment_id = $1',
          [payment.PaymentID]
        );

        if (existing.rows.length > 0) {
          await query(
            `UPDATE xero_payments SET 
              amount = $1, payment_date = $2, payment_method = $3, reference = $4,
              synced_at = CURRENT_TIMESTAMP
              WHERE xero_payment_id = $5`,
            [
              payment.Amount || 0,
              payment.Date ? new Date(payment.Date) : null,
              payment.PaymentType || 'ACCRECPAYMENT',
              payment.Reference || null,
              payment.PaymentID
            ]
          );
          result.pulled.updated++;
        } else {
          // Get invoice ID
          let invoiceId: string | null = null;
          if (payment.Invoice?.InvoiceID) {
            const invoiceResult = await query(
              'SELECT id FROM xero_invoices WHERE xero_invoice_id = $1',
              [payment.Invoice.InvoiceID]
            );
            if (invoiceResult.rows.length > 0) {
              invoiceId = invoiceResult.rows[0].id;
            }
          }

          await query(
            `INSERT INTO xero_payments 
             (xero_payment_id, invoice_id, amount, payment_date, payment_method, reference, synced_at)
             VALUES ($1, $2, $3, $4, $5, $6, CURRENT_TIMESTAMP)`,
            [
              payment.PaymentID,
              invoiceId,
              payment.Amount || 0,
              payment.Date ? new Date(payment.Date) : null,
              payment.PaymentType || 'ACCRECPAYMENT',
              payment.Reference || null
            ]
          );
          result.pulled.created++;
        }
      }
    }

    // Push: Send local payments missing in Xero
    const localPaymentsResult = await query(
      `SELECT * FROM xero_payments 
       WHERE xero_payment_id IS NULL OR xero_payment_id = ''`
    );
    const localPayments = localPaymentsResult.rows;
    const missingPayments = findMissingInXero(localPayments, payments, 'xero_payment_id');

    for (const localPayment of missingPayments) {
      try {
        // Get invoice's Xero invoice ID
        let invoiceXeroId: string | null = null;
        if (localPayment.invoice_id) {
          const invoiceResult = await query(
            'SELECT xero_invoice_id FROM xero_invoices WHERE id = $1',
            [localPayment.invoice_id]
          );
          if (invoiceResult.rows.length > 0 && invoiceResult.rows[0].xero_invoice_id) {
            invoiceXeroId = invoiceResult.rows[0].xero_invoice_id;
          }
        }

        if (!invoiceXeroId) {
          console.error('Payment invoice does not have Xero invoice ID');
          result.pushed.failed++;
          continue;
        }

        const paymentPayload = {
          Invoice: { InvoiceID: invoiceXeroId },
          Account: { Code: localPayment.account_code || '090' }, // Default bank account
          Date: localPayment.payment_date || new Date().toISOString().split('T')[0],
          Amount: localPayment.amount || 0,
          Reference: localPayment.reference || null
        };

        const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Payments', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${tokenData.accessToken}`,
            'Xero-Tenant-Id': tokenData.tenantId,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
          },
          body: JSON.stringify({ Payments: [paymentPayload] })
        });

        if (createResponse.ok) {
          const createResult = await createResponse.json() as { Payments?: Array<{ PaymentID: string }> };
          const xeroPaymentId = createResult.Payments?.[0]?.PaymentID;
          if (xeroPaymentId) {
            await query(
              `UPDATE xero_payments SET xero_payment_id = $1, synced_at = CURRENT_TIMESTAMP WHERE id = $2`,
              [xeroPaymentId, localPayment.id]
            );
            result.pushed.created++;
          } else {
            result.pushed.failed++;
          }
        } else {
          const errorText = await createResponse.text();
          console.error('Failed to push payment to Xero:', errorText);
          result.pushed.failed++;
        }
      } catch (pushError: any) {
        console.error('Error pushing payment to Xero:', pushError);
        result.pushed.failed++;
      }
    }
  } catch (error: any) {
    console.error('Payments sync error:', error);
  }

  return result;
}

// Sync Credit Notes bidirectionally
async function syncCreditNotesBidirectional(
  tokenData: { accessToken: string; tenantId: string }
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    // Pull credit notes from Xero
    const creditNotesResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/CreditNotes', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json'
      }
    });

    let creditNotes: any[] = [];

    if (creditNotesResponse.ok) {
      const creditNotesData = await creditNotesResponse.json() as { CreditNotes?: any[] };
      creditNotes = creditNotesData.CreditNotes || [];

      // Pull: Import/update credit notes from Xero
      for (const creditNote of creditNotes) {
        const existing = await query(
          'SELECT id FROM xero_credit_notes WHERE xero_credit_note_id = $1',
          [creditNote.CreditNoteID]
        );

        if (existing.rows.length > 0) {
          await query(
            `UPDATE xero_credit_notes SET 
              credit_note_number = $1, status = $2, amount = $3, date = $4,
              synced_at = CURRENT_TIMESTAMP
              WHERE xero_credit_note_id = $5`,
            [
              creditNote.CreditNoteNumber,
              creditNote.Status,
              creditNote.Total || 0,
              creditNote.Date ? new Date(creditNote.Date) : null,
              creditNote.CreditNoteID
            ]
          );
          result.pulled.updated++;
        } else {
          // Get invoice ID
          let invoiceId: string | null = null;
          if (creditNote.AppliedAmount && creditNote.AppliedAmount > 0) {
            // Try to find related invoice
            const invoiceResult = await query(
              'SELECT id FROM xero_invoices WHERE xero_invoice_id = $1 LIMIT 1',
              [creditNote.InvoiceID || '']
            );
            if (invoiceResult.rows.length > 0) {
              invoiceId = invoiceResult.rows[0].id;
            }
          }

          await query(
            `INSERT INTO xero_credit_notes 
             (xero_credit_note_id, credit_note_number, invoice_id, amount, date, status, synced_at)
             VALUES ($1, $2, $3, $4, $5, $6, CURRENT_TIMESTAMP)`,
            [
              creditNote.CreditNoteID,
              creditNote.CreditNoteNumber,
              invoiceId,
              creditNote.Total || 0,
              creditNote.Date ? new Date(creditNote.Date) : null,
              creditNote.Status || 'AUTHORISED'
            ]
          );
          result.pulled.created++;
        }
      }
    }

    // Push: Send local credit notes missing in Xero
    const localCreditNotesResult = await query(
      `SELECT * FROM xero_credit_notes 
       WHERE xero_credit_note_id IS NULL OR xero_credit_note_id = ''`
    );
    const localCreditNotes = localCreditNotesResult.rows;
    const missingCreditNotes = findMissingInXero(localCreditNotes, creditNotes, 'xero_credit_note_id');

    for (const localCreditNote of missingCreditNotes) {
      try {
        // Get invoice's Xero invoice ID
        let invoiceXeroId: string | null = null;
        if (localCreditNote.invoice_id) {
          const invoiceResult = await query(
            'SELECT xero_invoice_id FROM xero_invoices WHERE id = $1',
            [localCreditNote.invoice_id]
          );
          if (invoiceResult.rows.length > 0 && invoiceResult.rows[0].xero_invoice_id) {
            invoiceXeroId = invoiceResult.rows[0].xero_invoice_id;
          }
        }

        if (!invoiceXeroId) {
          console.error('Credit note invoice does not have Xero invoice ID');
          result.pushed.failed++;
          continue;
        }

        const creditNotePayload = {
          Type: 'ACCRECCREDIT', // Accounts Receivable Credit
          Contact: {}, // Will be populated from invoice
          Date: localCreditNote.date || new Date().toISOString().split('T')[0],
          CreditNoteNumber: localCreditNote.credit_note_number || null,
          Status: localCreditNote.status || 'AUTHORISED',
          LineAmountTypes: 'Exclusive',
          LineItems: [{
            Description: localCreditNote.reason || 'Credit note',
            Quantity: 1,
            UnitAmount: localCreditNote.amount || 0,
            AccountCode: '200'
          }]
        };

        const createResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/CreditNotes', {
          method: 'POST',
          headers: {
            'Authorization': `Bearer ${tokenData.accessToken}`,
            'Xero-Tenant-Id': tokenData.tenantId,
            'Content-Type': 'application/json',
            'Accept': 'application/json'
          },
          body: JSON.stringify({ CreditNotes: [creditNotePayload] })
        });

        if (createResponse.ok) {
          const createResult = await createResponse.json() as { CreditNotes?: Array<{ CreditNoteID: string }> };
          const xeroCreditNoteId = createResult.CreditNotes?.[0]?.CreditNoteID;
          if (xeroCreditNoteId) {
            await query(
              `UPDATE xero_credit_notes SET xero_credit_note_id = $1, synced_at = CURRENT_TIMESTAMP WHERE id = $2`,
              [xeroCreditNoteId, localCreditNote.id]
            );
            result.pushed.created++;
          } else {
            result.pushed.failed++;
          }
        } else {
          const errorText = await createResponse.text();
          console.error('Failed to push credit note to Xero:', errorText);
          result.pushed.failed++;
        }
      } catch (pushError: any) {
        console.error('Error pushing credit note to Xero:', pushError);
        result.pushed.failed++;
      }
    }
  } catch (error: any) {
    console.error('Credit notes sync error:', error);
  }

  return result;
}

// Sync Bank Transactions (pull only)
async function syncBankTransactions(
  tokenData: { accessToken: string; tenantId: string }
): Promise<SyncResult> {
  const result: SyncResult = { pulled: { created: 0, updated: 0 }, pushed: { created: 0, failed: 0 } };

  try {
    // Pull bank transactions from Xero
    const bankTransactionsResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/BankTransactions', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Accept': 'application/json'
      }
    });

    if (bankTransactionsResponse.ok) {
      const bankTransactionsData = await bankTransactionsResponse.json() as { BankTransactions?: any[] };
      const bankTransactions = bankTransactionsData.BankTransactions || [];

      // Pull: Import/update bank transactions from Xero
      for (const transaction of bankTransactions) {
        const existing = await query(
          'SELECT id FROM bank_transactions WHERE xero_bank_transaction_id = $1',
          [transaction.BankTransactionID]
        );

        if (existing.rows.length > 0) {
          await query(
            `UPDATE bank_transactions SET 
              date = $1, amount = $2, type = $3, description = $4, reference = $5,
              reconciled = $6, synced_at = CURRENT_TIMESTAMP
              WHERE xero_bank_transaction_id = $7`,
            [
              transaction.Date ? new Date(transaction.Date) : null,
              transaction.Total || 0,
              transaction.Type || 'SPEND',
              transaction.LineItems?.[0]?.Description || '',
              transaction.Reference || null,
              transaction.Status === 'RECONCILED',
              transaction.BankTransactionID
            ]
          );
          result.pulled.updated++;
        } else {
          // Get contact ID
          let contactId: string | null = null;
          if (transaction.Contact?.ContactID) {
            const contactResult = await query(
              'SELECT id FROM clients WHERE xero_contact_id = $1',
              [transaction.Contact.ContactID]
            );
            if (contactResult.rows.length > 0) {
              contactId = contactResult.rows[0].id;
            }
          }

          await query(
            `INSERT INTO bank_transactions 
             (xero_bank_transaction_id, bank_account_code, bank_account_name, date, amount, type, 
              description, reference, contact_id, reconciled, synced_at)
             VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, $10, CURRENT_TIMESTAMP)`,
            [
              transaction.BankTransactionID,
              transaction.BankAccount?.Code || null,
              transaction.BankAccount?.Name || null,
              transaction.Date ? new Date(transaction.Date) : null,
              transaction.Total || 0,
              transaction.Type || 'SPEND',
              transaction.LineItems?.[0]?.Description || '',
              transaction.Reference || null,
              contactId,
              transaction.Status === 'RECONCILED'
            ]
          );
          result.pulled.created++;
        }
      }
    }
  } catch (error: any) {
    console.error('Bank transactions sync error:', error);
  }

  return result;
}

// Sync Tracking Categories (pull only)
async function syncTrackingCategories(
  tokenData: { accessToken: string; tenantId: string }
): Promise<{ mapped: number }> {
  let mapped = 0;

  try {
    const trackingResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/TrackingCategories', {
      headers: {
        'Authorization': `Bearer ${tokenData.accessToken}`,
        'Xero-Tenant-Id': tokenData.tenantId,
        'Content-Type': 'application/json',
        'Accept': 'application/json'
      }
    });

    if (trackingResponse.ok) {
      const trackingData = await trackingResponse.json() as { TrackingCategories?: any[] };
      const categories = trackingData.TrackingCategories || [];

      for (const category of categories) {
        // Map tracking categories to cost centers
        const existing = await query(
          'SELECT id FROM cost_centers WHERE xero_tracking_category_id = $1',
          [category.TrackingCategoryID]
        );

        if (existing.rows.length === 0 && category.Options && category.Options.length > 0) {
          // Create cost centers for tracking category options
          for (const option of category.Options) {
            await query(
              `INSERT INTO cost_centers (code, name, xero_tracking_category_id, is_active)
               VALUES ($1, $2, $3, true)
               ON CONFLICT (code) DO UPDATE SET xero_tracking_category_id = $3`,
              [
                option.Name.toUpperCase().replace(/\s+/g, '_').substring(0, 20),
                option.Name,
                category.TrackingCategoryID
              ]
            );
            mapped++;
          }
        }
      }
    }
  } catch (error: any) {
    console.error('Tracking categories sync error:', error);
  }

  return { mapped };
}

// Sync data with Xero - performs bidirectional sync
router.post('/sync', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { type } = req.body; // 'contacts', 'invoices', 'tracking_categories', 'all'

    // Check if connected
    const tokenResult = await query('SELECT * FROM xero_tokens ORDER BY created_at DESC LIMIT 1');
    if (tokenResult.rows.length === 0) {
      return res.status(400).json({ error: 'Xero not connected' });
    }

    const tokenId = tokenResult.rows[0].id;
    const syncResults: {
      success: boolean;
      synced_at: Date;
      last_sync: string;
      results: Record<string, { 
        synced?: number; 
        created?: number; 
        updated?: number; 
        mapped?: number; 
        total?: number; 
        failed?: number;
        pulled_created?: number;
        pulled_updated?: number;
        pushed_created?: number;
        pushed_failed?: number;
      }>;
    } = {
      success: true,
      synced_at: new Date(),
      last_sync: new Date().toISOString(),
      results: {}
    };

    // Get token data for sync operations
    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    // Helper to make internal API calls
    const makeInternalRequest = async <T = any>(method: string, path: string, body?: any): Promise<T> => {
      const baseUrl = process.env.BACKEND_URL || `http://localhost:${process.env.PORT || 3001}`;
      const url = `${baseUrl}${path}`;
      const options: RequestInit = {
        method,
        headers: {
          'Content-Type': 'application/json',
          'Authorization': `Bearer ${req.headers.authorization?.replace('Bearer ', '') || ''}`
        }
      };
      if (body) {
        options.body = JSON.stringify(body);
      }
      const response = await fetch(url, options);
      if (!response.ok) {
        const errorText = await response.text();
        throw new Error(`Sync operation failed: ${errorText}`);
      }
      return response.json() as T;
    };

    try {
      // Sync Contacts (Pull from Xero and Push local to Xero)
    if (type === 'contacts' || type === 'all') {
        try {
          const result = await syncContactsBidirectional(tokenData, makeInternalRequest);
          syncResults.results.contacts = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created + result.pushed.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated,
            pushed_created: result.pushed.created,
            pushed_failed: result.pushed.failed
          };
        } catch (error: any) {
          console.error('Contacts sync error:', error);
          syncResults.results.contacts = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0, pushed_created: 0, pushed_failed: 0 };
        }
      }

      // Sync Invoices bidirectionally
    if (type === 'invoices' || type === 'all') {
        try {
          const result = await syncInvoicesBidirectional(tokenData, req.user!.id);
          syncResults.results.invoices = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created + result.pushed.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated,
            pushed_created: result.pushed.created,
            pushed_failed: result.pushed.failed
          };
        } catch (error: any) {
          console.error('Invoices sync error:', error);
          syncResults.results.invoices = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0, pushed_created: 0, pushed_failed: 0 };
        }
      }

      // Sync Quotes bidirectionally
      if (type === 'quotes' || type === 'all') {
        try {
          const result = await syncQuotesBidirectional(tokenData, req.user!.id);
          syncResults.results.quotes = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created + result.pushed.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated,
            pushed_created: result.pushed.created,
            pushed_failed: result.pushed.failed
          };
        } catch (error: any) {
          console.error('Quotes sync error:', error);
          syncResults.results.quotes = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0, pushed_created: 0, pushed_failed: 0 };
        }
      }

      // Sync Tracking Categories (pull only)
    if (type === 'tracking_categories' || type === 'all') {
        try {
          const result = await syncTrackingCategories(tokenData);
          syncResults.results.tracking_categories = { mapped: result.mapped };
        } catch (error: any) {
          console.error('Tracking categories sync error:', error);
          syncResults.results.tracking_categories = { mapped: 0 };
        }
      }

      // Sync Items bidirectionally
      if (type === 'items' || type === 'all') {
        try {
          const result = await syncItemsBidirectional(tokenData);
          syncResults.results.items = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created + result.pushed.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated,
            pushed_created: result.pushed.created,
            pushed_failed: result.pushed.failed
          };
        } catch (error: any) {
          console.error('Items sync error:', error);
          syncResults.results.items = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0, pushed_created: 0, pushed_failed: 0 };
        }
      }

      // Sync Purchase Orders bidirectionally
      if (type === 'purchase_orders' || type === 'all') {
        try {
          const result = await syncPurchaseOrdersBidirectional(tokenData);
          syncResults.results.purchase_orders = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created + result.pushed.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated,
            pushed_created: result.pushed.created,
            pushed_failed: result.pushed.failed
          };
        } catch (error: any) {
          console.error('Purchase orders sync error:', error);
          syncResults.results.purchase_orders = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0, pushed_created: 0, pushed_failed: 0 };
        }
      }

      // Sync Bills bidirectionally
      if (type === 'bills' || type === 'all') {
        try {
          const result = await syncBillsBidirectional(tokenData);
          syncResults.results.bills = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created + result.pushed.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated,
            pushed_created: result.pushed.created,
            pushed_failed: result.pushed.failed
          };
        } catch (error: any) {
          console.error('Bills sync error:', error);
          syncResults.results.bills = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0, pushed_created: 0, pushed_failed: 0 };
        }
      }

      // Sync Expenses bidirectionally
      if (type === 'expenses' || type === 'all') {
        try {
          const result = await syncExpensesBidirectional(tokenData);
          syncResults.results.expenses = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created + result.pushed.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated,
            pushed_created: result.pushed.created,
            pushed_failed: result.pushed.failed
          };
        } catch (error: any) {
          console.error('Expenses sync error:', error);
          syncResults.results.expenses = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0, pushed_created: 0, pushed_failed: 0 };
        }
      }

      // Sync Payments bidirectionally
      if (type === 'payments' || type === 'all') {
        try {
          const result = await syncPaymentsBidirectional(tokenData);
          syncResults.results.payments = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created + result.pushed.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated,
            pushed_created: result.pushed.created,
            pushed_failed: result.pushed.failed
          };
        } catch (error: any) {
          console.error('Payments sync error:', error);
          syncResults.results.payments = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0, pushed_created: 0, pushed_failed: 0 };
        }
      }

      // Sync Credit Notes bidirectionally
      if (type === 'credit_notes' || type === 'all') {
        try {
          const result = await syncCreditNotesBidirectional(tokenData);
          syncResults.results.credit_notes = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created + result.pushed.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated,
            pushed_created: result.pushed.created,
            pushed_failed: result.pushed.failed
          };
        } catch (error: any) {
          console.error('Credit notes sync error:', error);
          syncResults.results.credit_notes = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0, pushed_created: 0, pushed_failed: 0 };
        }
      }

      // Sync Bank Transactions (pull only)
      if (type === 'bank_transactions' || type === 'all') {
        try {
          const result = await syncBankTransactions(tokenData);
          syncResults.results.bank_transactions = {
            synced: result.pulled.created + result.pulled.updated,
            created: result.pulled.created,
            updated: result.pulled.updated,
            pulled_created: result.pulled.created,
            pulled_updated: result.pulled.updated
          };
        } catch (error: any) {
          console.error('Bank transactions sync error:', error);
          syncResults.results.bank_transactions = { synced: 0, created: 0, updated: 0, pulled_created: 0, pulled_updated: 0 };
        }
      }

      // All sync operations complete

      // Update token last sync time after all sync operations complete
    await query(
      'UPDATE xero_tokens SET updated_at = CURRENT_TIMESTAMP WHERE id = $1',
        [tokenId]
      );

      // Get updated timestamp for response
      const updatedToken = await query(
        'SELECT updated_at FROM xero_tokens WHERE id = $1',
        [tokenId]
      );
      if (updatedToken.rows.length > 0) {
        syncResults.last_sync = updatedToken.rows[0].updated_at.toISOString();
      }

      // Log activity
      await query(
        `INSERT INTO activity_logs (user_id, action, entity_type, details) 
         VALUES ($1, $2, $3, $4)`,
        [req.user!.id, 'sync', 'xero', JSON.stringify(syncResults)]
      );

      res.json(syncResults);
    } catch (error: any) {
    console.error('Xero sync error:', error);
      // Still update timestamp even on partial failure
      await query(
        'UPDATE xero_tokens SET updated_at = CURRENT_TIMESTAMP WHERE id = $1',
        [tokenId]
      );
      res.status(500).json({ 
        error: 'Sync failed', 
        details: error.message,
        partial_results: syncResults.results
      });
    }
  } catch (error: any) {
    console.error('Xero sync error:', error);
    res.status(500).json({ error: 'Sync failed', details: error.message });
  }
});

// Get invoices from Xero (cached)
router.get('/invoices', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    // Ensure tables exist before querying (don't fail if this errors)
    try {
      await ensureXeroTables();
    } catch (ensureError: any) {
      console.warn('[Xero] Failed to ensure tables exist:', ensureError.message);
      // Continue anyway - tables might already exist
    }
    
    const { status, client_id, date_from, date_to, include_deleted } = req.query;

    let sql = `
      SELECT xi.*, c.name as client_name
      FROM xero_invoices xi
      LEFT JOIN clients c ON xi.client_id = c.id
      WHERE 1=1
    `;
    const params: any[] = [];
    let paramCount = 1;

    // Filter deleted invoices unless explicitly requested
    if (include_deleted !== 'true') {
      sql += ` AND xi.deleted_at IS NULL`;
    }

    if (status) {
      sql += ` AND xi.status = $${paramCount++}`;
      params.push(status);
    }

    if (client_id) {
      sql += ` AND xi.client_id = $${paramCount++}`;
      params.push(client_id);
    }

    if (date_from) {
      sql += ` AND xi.issue_date >= $${paramCount++}`;
      params.push(date_from);
    }

    if (date_to) {
      sql += ` AND xi.issue_date <= $${paramCount++}`;
      params.push(date_to);
    }

    sql += ' ORDER BY xi.issue_date DESC';

    const result = await query(sql, params);
    res.json(result.rows);
  } catch (error: any) {
    const errorMessage = error.message || 'Failed to fetch invoices';
    const isTableError = errorMessage.includes('does not exist') || errorMessage.includes('relation') || error.code === '42P01';
    if (isTableError) {
      // Return empty array with 200 status instead of 500
      console.warn('[Xero] xero_invoices table not found. Returning empty array. Run migrations to create tables.');
      return res.json([]);
    }
    console.error('Failed to fetch invoices:', error);
    // For non-table errors, still return empty array to prevent frontend errors
    res.json([]);
  }
});

// Create invoice in Xero
router.post('/invoices', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { client_id, project_id, line_items, due_date } = req.body;

    if (!client_id) {
      return res.status(400).json({ error: 'Client is required' });
    }

    // Calculate total from line items
    const total = Array.isArray(line_items) 
      ? line_items.reduce((sum: number, item: any) => sum + (item.amount || 0), 0)
      : 0;

    // Generate invoice number
    const countResult = await query('SELECT COUNT(*) as count FROM xero_invoices');
    const invoiceNumber = `INV-${String(parseInt(countResult.rows[0].count) + 1).padStart(5, '0')}`;

    // In production, create invoice via Xero API and get xero_invoice_id
    // This is a placeholder that stores locally first

    const result = await query(
      `INSERT INTO xero_invoices (xero_invoice_id, invoice_number, client_id, project_id, status, line_items, total, amount_due, due_date, issue_date, synced_at)
       VALUES ($1, $2, $3, $4, 'DRAFT', $5, $6, $6, $7, CURRENT_DATE, CURRENT_TIMESTAMP)
       RETURNING *`,
      [invoiceNumber, invoiceNumber, client_id, project_id || null, JSON.stringify(line_items), total, due_date || null]
    );

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'create', 'invoice', result.rows[0].id, JSON.stringify({ invoice_number: invoiceNumber, total })]
    );

    res.status(201).json(result.rows[0]);
  } catch (error) {
    console.error('Failed to create invoice:', error);
    res.status(500).json({ error: 'Failed to create invoice' });
  }
});

// Preview invoice from timesheets (without creating)
router.post('/invoices/from-timesheets/preview', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { client_id, project_id, date_from, date_to, period } = req.body;

    if (!client_id) {
      return res.status(400).json({ error: 'Client is required' });
    }

    // Build query for unbilled timesheets (same as create endpoint)
    let sql = `
      SELECT t.*, 
        at.name as activity_type_name,
        at.hourly_rate,
        (t.hours * COALESCE(at.hourly_rate, 0)) as line_total,
        cc.client_po_number
      FROM timesheets t
      LEFT JOIN activity_types at ON t.activity_type_id = at.id
      LEFT JOIN cost_centers cc ON t.cost_center_id = cc.id
      WHERE t.client_id = $1 
        AND COALESCE(t.billing_status, 'unbilled') = 'unbilled'
        AND t.deleted_at IS NULL
    `;
    const params: any[] = [client_id];
    let paramCount = 2;

    if (project_id) {
      sql += ` AND t.project_id = $${paramCount++}`;
      params.push(project_id);
    }

    if (date_from) {
      sql += ` AND t.date >= $${paramCount++}`;
      params.push(date_from);
    }

    if (date_to) {
      sql += ` AND t.date <= $${paramCount++}`;
      params.push(date_to);
    } else if (period === 'week') {
      sql += ` AND t.date >= CURRENT_DATE - INTERVAL '7 days'`;
    } else if (period === 'month') {
      sql += ` AND t.date >= DATE_TRUNC('month', CURRENT_DATE)`;
    }

    sql += ' ORDER BY t.date, t.created_at';

    const timesheetsResult = await query(sql, params);

    if (timesheetsResult.rows.length === 0) {
      return res.status(400).json({ error: 'No unbilled timesheets found for the selected criteria' });
    }

    // Collect unique client PO numbers
    const clientPONumbers = new Set<string>();
    for (const ts of timesheetsResult.rows) {
      if (ts.client_po_number && ts.client_po_number.trim()) {
        clientPONumbers.add(ts.client_po_number.trim());
      }
    }
    const clientPOString = Array.from(clientPONumbers).join(', ');

    // Group by activity type
    const lineItemsMap = new Map<string, { hours: number; rate: number; description: string }>();
    
    for (const ts of timesheetsResult.rows) {
      const key = ts.activity_type_id || 'other';
      const rate = parseFloat(ts.hourly_rate || '0');
      const hours = parseFloat(ts.hours);
      
      if (!lineItemsMap.has(key)) {
        lineItemsMap.set(key, {
          hours: 0,
          rate,
          description: ts.activity_type_name || 'Other'
        });
      }
      
      const item = lineItemsMap.get(key)!;
      item.hours += hours;
    }

    // Convert to line items array
    const lineItems = Array.from(lineItemsMap.values()).map(item => ({
      description: `${item.description} - ${item.hours.toFixed(2)} hours`,
      quantity: item.hours,
      unit_price: item.rate,
      amount: item.hours * item.rate
    }));

    const total = lineItems.reduce((sum, item) => sum + item.amount, 0);

    // Generate proposed invoice number
    const countResult = await query('SELECT COUNT(*) as count FROM xero_invoices WHERE deleted_at IS NULL');
    const proposedInvoiceNumber = `INV-${String(parseInt(countResult.rows[0].count) + 1).padStart(5, '0')}`;

    // Check Xero for existing invoice numbers
    let existingInvoiceNumbers: string[] = [];
    try {
      const tokenData = await getValidAccessToken();
      if (tokenData) {
        const invoicesResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Invoices?where=Type=="ACCREC"', {
          headers: {
            'Authorization': `Bearer ${tokenData.accessToken}`,
            'Xero-Tenant-Id': tokenData.tenantId,
            'Accept': 'application/json'
          }
        });

        if (invoicesResponse.ok) {
          const xeroData = await invoicesResponse.json() as any;
          if (xeroData.Invoices) {
            existingInvoiceNumbers = xeroData.Invoices.map((inv: any) => inv.InvoiceNumber).filter((num: string) => num);
          }
        }
      }
    } catch (error) {
      console.warn('Could not check Xero for existing invoice numbers:', error);
    }

    // Also check local database
    const localInvoicesResult = await query('SELECT invoice_number FROM xero_invoices WHERE invoice_number IS NOT NULL AND deleted_at IS NULL');
    const localInvoiceNumbers = localInvoicesResult.rows.map(row => row.invoice_number);
    const allExistingNumbers = [...new Set([...existingInvoiceNumbers, ...localInvoiceNumbers])];

    // Find next available invoice number
    let invoiceNumber = proposedInvoiceNumber;
    let counter = 1;
    while (allExistingNumbers.includes(invoiceNumber)) {
      const baseNumber = parseInt(countResult.rows[0].count) + counter;
      invoiceNumber = `INV-${String(baseNumber).padStart(5, '0')}`;
      counter++;
    }

    // Get client name
    const clientResult = await query('SELECT name FROM clients WHERE id = $1', [client_id]);
    const clientName = clientResult.rows[0]?.name || 'Unknown Client';

    res.json({
      client_id,
      client_name: clientName,
      project_id: project_id || null,
      invoice_number: invoiceNumber,
      line_items: lineItems,
      total,
      reference: clientPOString || null,
      timesheets_count: timesheetsResult.rows.length,
      date_range: {
        from: date_from || (period === 'week' ? new Date(Date.now() - 7 * 24 * 60 * 60 * 1000).toISOString().split('T')[0] : 
                             period === 'month' ? new Date(new Date().getFullYear(), new Date().getMonth(), 1).toISOString().split('T')[0] : null),
        to: date_to || new Date().toISOString().split('T')[0]
      }
    });
  } catch (error) {
    console.error('Failed to preview invoice from timesheets:', error);
    res.status(500).json({ error: 'Failed to preview invoice from timesheets' });
  }
});

// Create invoice from timesheets
router.post('/invoices/from-timesheets', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { client_id, project_id, date_from, date_to, period, due_date, invoice_number } = req.body;

    if (!client_id) {
      return res.status(400).json({ error: 'Client is required' });
    }

    // Build query for unbilled timesheets
    let sql = `
      SELECT t.*, 
        at.name as activity_type_name,
        at.hourly_rate,
        (t.hours * COALESCE(at.hourly_rate, 0)) as line_total,
        cc.client_po_number
      FROM timesheets t
      LEFT JOIN activity_types at ON t.activity_type_id = at.id
      LEFT JOIN cost_centers cc ON t.cost_center_id = cc.id
      WHERE t.client_id = $1 
        AND COALESCE(t.billing_status, 'unbilled') = 'unbilled'
        AND t.deleted_at IS NULL
    `;
    const params: any[] = [client_id];
    let paramCount = 2;

    if (project_id) {
      sql += ` AND t.project_id = $${paramCount++}`;
      params.push(project_id);
    }

    if (date_from) {
      sql += ` AND t.date >= $${paramCount++}`;
      params.push(date_from);
    }

    if (date_to) {
      sql += ` AND t.date <= $${paramCount++}`;
      params.push(date_to);
    } else if (period === 'week') {
      // Last 7 days
      sql += ` AND t.date >= CURRENT_DATE - INTERVAL '7 days'`;
    } else if (period === 'month') {
      // Current month
      sql += ` AND t.date >= DATE_TRUNC('month', CURRENT_DATE)`;
    }

    sql += ' ORDER BY t.date, t.created_at';

    const timesheetsResult = await query(sql, params);

    if (timesheetsResult.rows.length === 0) {
      return res.status(400).json({ error: 'No unbilled timesheets found for the selected criteria' });
    }

    // Collect unique client PO numbers from cost centers
    const clientPONumbers = new Set<string>();
    for (const ts of timesheetsResult.rows) {
      if (ts.client_po_number && ts.client_po_number.trim()) {
        clientPONumbers.add(ts.client_po_number.trim());
      }
    }
    const clientPOString = Array.from(clientPONumbers).join(', ');

    // Group by activity type and create line items
    const lineItemsMap = new Map<string, { hours: number; rate: number; description: string }>();
    
    for (const ts of timesheetsResult.rows) {
      const key = ts.activity_type_id || 'other';
      const rate = parseFloat(ts.hourly_rate || '0');
      const hours = parseFloat(ts.hours);
      
      if (!lineItemsMap.has(key)) {
        lineItemsMap.set(key, {
          hours: 0,
          rate,
          description: ts.activity_type_name || 'Other'
        });
      }
      
      const item = lineItemsMap.get(key)!;
      item.hours += hours;
    }

    // Convert to line items array
    const lineItems = Array.from(lineItemsMap.values()).map(item => ({
      description: `${item.description} - ${item.hours.toFixed(2)} hours`,
      quantity: item.hours,
      unit_price: item.rate,
      amount: item.hours * item.rate
    }));

    const total = lineItems.reduce((sum, item) => sum + item.amount, 0);

    // Generate invoice number and check for duplicates
    const countResult = await query('SELECT COUNT(*) as count FROM xero_invoices WHERE deleted_at IS NULL');
    let proposedInvoiceNumber = `INV-${String(parseInt(countResult.rows[0].count) + 1).padStart(5, '0')}`;
    
    // Check Xero for existing invoice numbers
    let existingInvoiceNumbers: string[] = [];
    try {
      const tokenData = await getValidAccessToken();
      if (tokenData) {
        const invoicesResponse = await fetchWithRateLimit('https://api.xero.com/api.xro/2.0/Invoices?where=Type=="ACCREC"', {
          headers: {
            'Authorization': `Bearer ${tokenData.accessToken}`,
            'Xero-Tenant-Id': tokenData.tenantId,
            'Accept': 'application/json'
          }
        });

        if (invoicesResponse.ok) {
          const xeroData = await invoicesResponse.json() as any;
          if (xeroData.Invoices) {
            existingInvoiceNumbers = xeroData.Invoices.map((inv: any) => inv.InvoiceNumber).filter((num: string) => num);
          }
        }
      }
    } catch (error) {
      console.warn('Could not check Xero for existing invoice numbers:', error);
    }

    // Also check local database
    const localInvoicesResult = await query('SELECT invoice_number FROM xero_invoices WHERE invoice_number IS NOT NULL AND deleted_at IS NULL');
    const localInvoiceNumbers = localInvoicesResult.rows.map(row => row.invoice_number);
    const allExistingNumbers = [...new Set([...existingInvoiceNumbers, ...localInvoiceNumbers])];

    // Use provided invoice number from preview, or find next available
    let invoiceNumber = invoice_number || proposedInvoiceNumber;
    if (!invoice_number) {
      let counter = 1;
      while (allExistingNumbers.includes(invoiceNumber)) {
        const baseNumber = parseInt(countResult.rows[0].count) + counter;
        invoiceNumber = `INV-${String(baseNumber).padStart(5, '0')}`;
        counter++;
      }
    }

    // Create invoice locally with pending sync status
    // Include client PO numbers in the invoice reference if available
    const invoiceReference = clientPOString || null;
    
    const invoiceResult = await query(
      `INSERT INTO xero_invoices (xero_invoice_id, invoice_number, client_id, project_id, status, line_items, total, amount_due, due_date, issue_date, sync_status, synced_at, reference)
       VALUES ($1, $2, $3, $4, 'DRAFT', $5, $6, $6, $7, CURRENT_DATE, 'pending', CURRENT_TIMESTAMP, $8)
       RETURNING *`,
      [invoiceNumber, invoiceNumber, client_id, project_id || null, JSON.stringify(lineItems), total, due_date || null, invoiceReference]
    );

    const invoiceId = invoiceResult.rows[0].id;

    // Update timesheets billing status
    const timesheetIds = timesheetsResult.rows.map(ts => ts.id);
    await query(
      `UPDATE timesheets 
       SET billing_status = 'billed', invoice_id = $1, updated_at = CURRENT_TIMESTAMP 
       WHERE id = ANY($2)`,
      [invoiceId, timesheetIds]
    );

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'create', 'invoice', invoiceId, JSON.stringify({ 
        invoice_number: invoiceNumber, 
        total, 
        timesheets_count: timesheetIds.length,
        from_timesheets: true,
        sync_status: 'pending'
      })]
    );

    // Queue the Xero sync job (async, non-blocking)
    // Use invoice ID as job ID to prevent duplicate jobs for the same invoice
    try {
      const { addXeroSyncJob, xeroSyncQueue } = await import('../lib/queue');
      
      // Check if a job for this invoice already exists
      if (xeroSyncQueue) {
        const existingJobs = await xeroSyncQueue.getJobs(['waiting', 'active', 'delayed'], 0, -1);
        const duplicateJob = existingJobs.find(
          (job) => job.data.type === 'sync_invoice_from_timesheets' && job.data.data.invoiceId === invoiceId
        );

        if (duplicateJob) {
          console.log(`[Xero Sync] Job already exists for invoice ${invoiceId}, skipping duplicate job creation`);
        } else {
          await addXeroSyncJob('sync_invoice_from_timesheets', {
            invoiceId,
            clientId: client_id,
            projectId: project_id || null,
            lineItems,
            total,
            dueDate: due_date || null,
            timesheetIds,
            reference: invoiceReference, // Include client PO numbers
          }, `invoice-${invoiceId}`); // Use invoiceId as jobId for idempotency
        }
      } else {
        // Fallback if queue not available
        await addXeroSyncJob('sync_invoice_from_timesheets', {
          invoiceId,
          clientId: client_id,
          projectId: project_id || null,
          lineItems,
          total,
          dueDate: due_date || null,
          timesheetIds,
          reference: invoiceReference, // Include client PO numbers
        }, `invoice-${invoiceId}`);
      }
    } catch (queueError: any) {
      console.error('Failed to queue Xero sync job:', queueError);
      // Update invoice sync status to indicate queue failure
      await query(
        `UPDATE xero_invoices 
         SET sync_status = 'failed', updated_at = CURRENT_TIMESTAMP
         WHERE id = $1`,
        [invoiceId]
      );
      // Log the error
      await query(
        `INSERT INTO sync_logs (entity_type, entity_id, request_payload, response_payload, status_code, error_message, created_at)
         VALUES ($1, $2, $3, $4, $5, $6, CURRENT_TIMESTAMP)`,
        ['invoice', invoiceId, null, null, null, `Queue initialization failed: ${queueError.message}`]
      );
      // Don't fail the request - invoice is created, user can retry sync later
    }

    // Return 202 Accepted - invoice created, sync in progress
    res.status(202).json({
      ...invoiceResult.rows[0],
      timesheets_count: timesheetIds.length,
      sync_status: 'pending',
      message: 'Invoice created. Syncing to Xero in the background...'
    });
  } catch (error) {
    console.error('Failed to create invoice from timesheets:', error);
    res.status(500).json({ error: 'Failed to create invoice from timesheets' });
  }
});

// Get quotes from Xero (cached)
router.get('/quotes', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    // Ensure tables exist before querying (don't fail if this errors)
    try {
      await ensureXeroTables();
    } catch (ensureError: any) {
      console.warn('[Xero] Failed to ensure tables exist:', ensureError.message);
      // Continue anyway - tables might already exist
    }
    
    const result = await query(`
      SELECT xq.*, c.name as client_name
      FROM xero_quotes xq
      LEFT JOIN clients c ON xq.client_id = c.id
      ORDER BY xq.issue_date DESC
    `);

    res.json(result.rows);
  } catch (error: any) {
    // Catch all errors and return empty array - don't fail the request
    console.error('Failed to fetch quotes:', error);
    const errorMessage = error.message || 'Unknown error';
    // Log the actual error for debugging
    console.error('[Xero Quotes] Error details:', {
      message: errorMessage,
      code: error.code,
      stack: error.stack
    });
    // Always return empty array with 200 status
    res.status(200).json([]);
  }
});

// Create quote in Xero
router.post('/quotes', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { client_id, project_id, line_items, expiry_date } = req.body;

    const result = await query(
      `INSERT INTO xero_quotes (xero_quote_id, client_id, project_id, status, line_items, expiry_date, synced_at)
       VALUES ($1, $2, $3, 'PENDING', $4, $5, CURRENT_TIMESTAMP)
       RETURNING *`,
      [`QTE-${Date.now()}`, client_id, project_id, JSON.stringify(line_items), expiry_date]
    );

    res.status(201).json(result.rows[0]);
  } catch (error) {
    res.status(500).json({ error: 'Failed to create quote' });
  }
});

// Convert quote to invoice
router.post('/quotes/:id/convert', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const quote = await query('SELECT * FROM xero_quotes WHERE id = $1', [req.params.id]);
    
    if (quote.rows.length === 0) {
      return res.status(404).json({ error: 'Quote not found' });
    }

    const q = quote.rows[0];

    // Create invoice from quote
    const invoice = await query(
      `INSERT INTO xero_invoices (xero_invoice_id, client_id, project_id, status, line_items, total, synced_at)
       VALUES ($1, $2, $3, 'DRAFT', $4, $5, CURRENT_TIMESTAMP)
       RETURNING *`,
      [`INV-${Date.now()}`, q.client_id, q.project_id, q.line_items, q.total]
    );

    // Update quote status
    await query(
      `UPDATE xero_quotes SET status = 'CONVERTED', updated_at = CURRENT_TIMESTAMP WHERE id = $1`,
      [req.params.id]
    );

    res.json(invoice.rows[0]);
  } catch (error) {
    res.status(500).json({ error: 'Failed to convert quote' });
  }
});

// Create payment in Xero
router.post('/payments', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { invoice_id, amount, payment_date, payment_method, reference, account_code, currency } = req.body;

    if (!invoice_id || !amount || !payment_date || !payment_method) {
      return res.status(400).json({ error: 'Missing required fields: invoice_id, amount, payment_date, payment_method' });
    }

    // Get invoice details
    const invoiceResult = await query('SELECT id, xero_invoice_id, total, amount_due FROM xero_invoices WHERE id = $1', [invoice_id]);
    if (invoiceResult.rows.length === 0) {
      return res.status(404).json({ error: 'Invoice not found' });
    }

    const invoice = invoiceResult.rows[0];
    const paymentAmount = parseFloat(amount);

    // Validate payment amount
    if (paymentAmount <= 0) {
      return res.status(400).json({ error: 'Payment amount must be greater than 0' });
    }

    if (paymentAmount > parseFloat(invoice.amount_due || invoice.total)) {
      return res.status(400).json({ error: 'Payment amount exceeds invoice amount due' });
    }

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    // Create payment in Xero (only if invoice has xero_invoice_id)
    let xeroPaymentId: string | undefined;
    if (invoice.xero_invoice_id) {
      const xeroPayment = await createPaymentInXero(
        tokenData,
        {
          invoice_id,
          amount: paymentAmount,
          payment_date,
          payment_method,
          reference,
          account_code,
          currency,
        },
        invoice.xero_invoice_id
      );

      if (xeroPayment) {
        xeroPaymentId = xeroPayment.PaymentID;
      }
    }

    // Store payment in local database
    const paymentId = await storePayment({
      invoice_id,
      amount: paymentAmount,
      payment_date,
      payment_method,
      reference,
      account_code,
      currency: currency || 'USD',
      xero_payment_id: xeroPaymentId,
      user_id: req.user!.id,
    });

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'create_payment', 'payment', paymentId, JSON.stringify({ invoice_id, amount: paymentAmount, payment_method })]
    );

    // Get updated payment with invoice details
    const paymentResult = await query(
      `SELECT p.*, xi.invoice_number, c.name as client_name 
       FROM xero_payments p
       LEFT JOIN xero_invoices xi ON p.invoice_id = xi.id
       LEFT JOIN clients c ON xi.client_id = c.id
       WHERE p.id = $1`,
      [paymentId]
    );

    res.status(201).json(paymentResult.rows[0]);
  } catch (error: any) {
    console.error('Failed to create payment:', error);
    res.status(500).json({ error: 'Failed to create payment: ' + (error.message || 'Unknown error') });
  }
});

// Get payments
router.get('/payments', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    // Ensure tables exist before querying (don't fail if this errors)
    try {
      await ensureXeroTables();
    } catch (ensureError: any) {
      console.warn('[Xero] Failed to ensure tables exist:', ensureError.message);
      // Continue anyway - tables might already exist
    }
    
    const { invoice_id, date_from, date_to, payment_method } = req.query;

    const payments = await getPayments({
      invoice_id: invoice_id as string,
      date_from: date_from as string,
      date_to: date_to as string,
      payment_method: payment_method as string,
    });

    res.json(payments);
  } catch (error: any) {
    // Catch all errors and return empty array - don't fail the request
    console.error('Failed to fetch payments:', error);
    const errorMessage = error.message || 'Unknown error';
    // Log the actual error for debugging
    console.error('[Xero Payments] Error details:', {
      message: errorMessage,
      code: error.code,
      stack: error.stack
    });
    // Always return empty array with 200 status
    res.status(200).json([]);
  }
});

// Mark invoice as paid
router.put('/invoices/:id/mark-paid', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { amount, payment_date, payment_method, reference, account_code } = req.body;

    // Get invoice
    const invoiceResult = await query('SELECT * FROM xero_invoices WHERE id = $1', [req.params.id]);
    if (invoiceResult.rows.length === 0) {
      return res.status(404).json({ error: 'Invoice not found' });
    }

    const invoice = invoiceResult.rows[0];
    const paymentAmount = amount || parseFloat(invoice.amount_due || invoice.total);
    const paymentDate = payment_date || new Date().toISOString().split('T')[0];
    const paymentMethod = payment_method || 'BANK_TRANSFER';

    // Create payment
    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    let xeroPaymentId: string | undefined;
    if (invoice.xero_invoice_id) {
      const xeroPayment = await createPaymentInXero(
        tokenData,
        {
          invoice_id: invoice.id,
          amount: paymentAmount,
          payment_date: paymentDate,
          payment_method: paymentMethod as any,
          reference,
          account_code,
        },
        invoice.xero_invoice_id
      );

      if (xeroPayment) {
        xeroPaymentId = xeroPayment.PaymentID;
      }
    }

    // Store payment
    const paymentId = await storePayment({
      invoice_id: invoice.id,
      amount: paymentAmount,
      payment_date: paymentDate,
      payment_method: paymentMethod as any,
      reference,
      account_code,
      xero_payment_id: xeroPaymentId,
      user_id: req.user!.id,
    });

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'mark_paid', 'invoice', invoice.id, JSON.stringify({ payment_id: paymentId, amount: paymentAmount })]
    );

    // Get updated invoice
    const updatedInvoice = await query('SELECT * FROM xero_invoices WHERE id = $1', [req.params.id]);

    res.json(updatedInvoice.rows[0]);
  } catch (error: any) {
    console.error('Failed to mark invoice as paid:', error);
    res.status(500).json({ error: 'Failed to mark invoice as paid: ' + (error.message || 'Unknown error') });
  }
});

// Import bank transactions from Xero
router.post('/bank-transactions', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { date_from, date_to } = req.body;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    const imported = await importBankTransactions(tokenData, date_from, date_to);

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, details) 
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'import', 'bank_transactions', JSON.stringify({ imported, date_from, date_to })]
    );

    res.json({
      success: true,
      imported,
      message: `Imported ${imported} bank transaction(s)`,
    });
  } catch (error: any) {
    console.error('Failed to import bank transactions:', error);
    res.status(500).json({ error: 'Failed to import bank transactions: ' + (error.message || 'Unknown error') });
  }
});

// Get bank transactions
router.get('/bank-transactions', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    await ensureXeroTables(); // Ensure tables exist
    const { date_from, date_to, reconciled, payment_id } = req.query;

    const transactions = await getBankTransactions({
      date_from: date_from as string,
      date_to: date_to as string,
      reconciled: reconciled === 'true' ? true : reconciled === 'false' ? false : undefined,
      payment_id: payment_id as string,
    });

    res.status(200).json(transactions);
  } catch (error: any) {
    console.error('Failed to fetch bank transactions:', error);
    res.status(200).json([]); // Return empty array with 200 status on any error
  }
});

// Reconcile bank transaction with payment
router.post('/reconcile', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { transaction_id, payment_id } = req.body;

    if (!transaction_id || !payment_id) {
      return res.status(400).json({ error: 'Missing required fields: transaction_id, payment_id' });
    }

    await reconcileTransaction(transaction_id, payment_id);

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, details) 
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'reconcile', 'bank_transaction', JSON.stringify({ transaction_id, payment_id })]
    );

    res.json({ success: true, message: 'Transaction reconciled successfully' });
  } catch (error: any) {
    console.error('Failed to reconcile transaction:', error);
    res.status(500).json({ error: 'Failed to reconcile transaction: ' + (error.message || 'Unknown error') });
  }
});

// Purchase Orders endpoints
router.post('/purchase-orders', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { supplier_id, project_id, date, delivery_date, line_items, notes, currency } = req.body;

    if (!supplier_id || !project_id || !date || !line_items || line_items.length === 0) {
      return res.status(400).json({ error: 'Missing required fields: supplier_id, project_id, date, line_items' });
    }

    // Verify project exists (and not soft-deleted)
    const projectResult = await query('SELECT id FROM projects WHERE id = $1 AND deleted_at IS NULL', [project_id]);
    if (projectResult.rows.length === 0) {
      return res.status(404).json({ error: 'Project not found' });
    }

    // Get supplier Xero contact ID (and not soft-deleted)
    const supplierResult = await query('SELECT xero_contact_id FROM clients WHERE id = $1 AND deleted_at IS NULL', [supplier_id]);
    if (supplierResult.rows.length === 0) {
      return res.status(404).json({ error: 'Supplier not found' });
    }

    const supplierXeroId = supplierResult.rows[0].xero_contact_id;

    // Generate PO number
    const countResult = await query('SELECT COUNT(*) as count FROM xero_purchase_orders WHERE deleted_at IS NULL');
    const poNumber = `PO-${String(parseInt(countResult.rows[0].count) + 1).padStart(5, '0')}`;

    // Store PO in local database with pending sync status
    const poId = await storePurchaseOrder({
      supplier_id,
      project_id,
      date,
      delivery_date,
      line_items,
      notes,
      currency,
      xero_po_id: undefined, // Will be set after sync
      po_number: poNumber,
    });

    // Update sync status to pending
    await query(
      `UPDATE xero_purchase_orders 
       SET sync_status = 'pending', updated_at = CURRENT_TIMESTAMP 
       WHERE id = $1`,
      [poId]
    );

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'create', 'purchase_order', poId, JSON.stringify({ 
        po_number: poNumber, 
        project_id, 
        supplier_id,
        sync_status: 'pending'
      })]
    );

    // Queue the Xero sync job (async, non-blocking)
    try {
      const { addXeroSyncJob } = await import('../lib/queue');
      await addXeroSyncJob('sync_purchase_order', {
        poId,
        supplierId: supplier_id,
        projectId: project_id,
        date,
        deliveryDate: delivery_date || null,
        lineItems: line_items,
        notes: notes || null,
        currency: currency || 'USD',
        poNumber,
      });
    } catch (queueError: any) {
      console.error('Failed to queue Xero sync job:', queueError);
      // Update PO sync status to indicate queue failure
      await query(
        `UPDATE xero_purchase_orders 
         SET sync_status = 'failed', updated_at = CURRENT_TIMESTAMP
         WHERE id = $1`,
        [poId]
      );
      // Log the error
      await query(
        `INSERT INTO sync_logs (entity_type, entity_id, request_payload, response_payload, status_code, error_message, created_at)
         VALUES ($1, $2, $3, $4, $5, $6, CURRENT_TIMESTAMP)`,
        ['purchase_order', poId, null, null, null, `Queue initialization failed: ${queueError.message}`]
      );
      // Don't fail the request - PO is created, user can retry sync later
    }

    // Get created PO with details
    const po = await getPurchaseOrderById(poId);
    
    // Return 202 Accepted - PO created, sync in progress
    res.status(202).json({
      ...po,
      sync_status: 'pending',
      message: 'Purchase order created. Syncing to Xero in the background...'
    });
  } catch (error: any) {
    console.error('Failed to create purchase order:', error);
    res.status(500).json({ error: 'Failed to create purchase order: ' + (error.message || 'Unknown error') });
  }
});

router.get('/purchase-orders', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    // Ensure tables exist before querying (don't fail if this errors)
    try {
      await ensureXeroTables();
    } catch (ensureError: any) {
      console.warn('[Xero] Failed to ensure tables exist:', ensureError.message);
      // Continue anyway - tables might already exist
    }
    
    const { project_id, supplier_id, status, date_from, date_to, cost_center_id } = req.query;

    const pos = await getPurchaseOrders({
      project_id: project_id as string,
      supplier_id: supplier_id as string,
      status: status as string,
      date_from: date_from as string,
      date_to: date_to as string,
      cost_center_id: cost_center_id as string,
    });

    res.json(pos);
  } catch (error: any) {
    // Catch all errors and return empty array - don't fail the request
    console.error('Failed to fetch purchase orders:', error);
    const errorMessage = error.message || 'Unknown error';
    // Log the actual error for debugging
    console.error('[Xero Purchase Orders] Error details:', {
      message: errorMessage,
      code: error.code,
      stack: error.stack
    });
    // Always return empty array with 200 status
    res.status(200).json([]);
  }
});

router.get('/purchase-orders/project/:project_id', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const pos = await getPurchaseOrders({ project_id: req.params.project_id });
    res.json(pos);
  } catch (error) {
    console.error('Failed to fetch purchase orders:', error);
    res.status(500).json({ error: 'Failed to fetch purchase orders' });
  }
});

router.get('/purchase-orders/cost-center/:cost_center_id', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    // Ensure tables exist before querying
    try {
      await ensureXeroTables();
    } catch (ensureError: any) {
      console.warn('[Xero] Failed to ensure tables exist:', ensureError.message);
    }

    const pos = await getPurchaseOrders({ cost_center_id: req.params.cost_center_id });
    
    // For each PO, get the line items that match this cost center
    const posWithLineItems = await Promise.all(pos.map(async (po) => {
      const lineItemsResult = await query(
        `SELECT li.*, cc.code as cost_center_code, cc.name as cost_center_name
         FROM xero_purchase_order_line_items li
         LEFT JOIN cost_centers cc ON li.cost_center_id = cc.id
         WHERE li.po_id = $1 AND li.cost_center_id = $2
         ORDER BY li.created_at`,
        [po.id, req.params.cost_center_id]
      );
      
      // Calculate total amount for this cost center's line items
      const costCenterTotal = lineItemsResult.rows.reduce((sum, item) => sum + parseFloat(item.line_amount || 0), 0);
      
      return {
        ...po,
        cost_center_line_items: lineItemsResult.rows,
        cost_center_total: costCenterTotal,
      };
    }));

    res.json(posWithLineItems);
  } catch (error: any) {
    console.error('Failed to fetch purchase orders by cost center:', error);
    res.status(500).json({ error: 'Failed to fetch purchase orders' });
  }
});

// Get sync status for invoice
router.get('/invoices/:id/sync-status', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      'SELECT sync_status, xero_sync_id FROM xero_invoices WHERE id = $1 AND deleted_at IS NULL',
      [req.params.id]
    );
    
    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Invoice not found' });
    }
    
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Failed to get invoice sync status:', error);
    res.status(500).json({ error: 'Failed to get sync status' });
  }
});

// Get sync status for purchase order
router.get('/purchase-orders/:id/sync-status', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await query(
      'SELECT sync_status, xero_sync_id FROM xero_purchase_orders WHERE id = $1 AND deleted_at IS NULL',
      [req.params.id]
    );
    
    if (result.rows.length === 0) {
      return res.status(404).json({ error: 'Purchase order not found' });
    }
    
    res.json(result.rows[0]);
  } catch (error) {
    console.error('Failed to get PO sync status:', error);
    res.status(500).json({ error: 'Failed to get sync status' });
  }
});

// Get sync logs for an entity
router.get('/sync-logs', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { entity_type, entity_id } = req.query;
    
    if (!entity_type || !entity_id) {
      return res.status(400).json({ error: 'entity_type and entity_id are required' });
    }
    
    const result = await query(
      `SELECT * FROM sync_logs 
       WHERE entity_type = $1 AND entity_id = $2 
       ORDER BY created_at DESC 
       LIMIT 10`,
      [entity_type, entity_id]
    );
    
    res.json(result.rows);
  } catch (error) {
    console.error('Failed to get sync logs:', error);
    res.status(500).json({ error: 'Failed to get sync logs' });
  }
});

router.get('/purchase-orders/:id', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const po = await getPurchaseOrderById(req.params.id);
    if (!po) {
      return res.status(404).json({ error: 'Purchase order not found' });
    }
    res.json(po);
  } catch (error) {
    console.error('Failed to fetch purchase order:', error);
    res.status(500).json({ error: 'Failed to fetch purchase order' });
  }
});

router.put('/purchase-orders/:id', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { status, project_id } = req.body;

    const updates: string[] = [];
    const values: any[] = [];
    let paramCount = 1;

    if (status) {
      updates.push(`status = $${paramCount++}`);
      values.push(status);
    }

    if (project_id !== undefined) {
      // Allow setting project_id to null to unlink
      if (project_id === null || project_id === '') {
        updates.push(`project_id = NULL`);
      } else {
        // Verify project exists
        const projectResult = await query('SELECT id FROM projects WHERE id = $1', [project_id]);
        if (projectResult.rows.length === 0) {
          return res.status(404).json({ error: 'Project not found' });
        }
        updates.push(`project_id = $${paramCount++}`);
        values.push(project_id);
      }
    }

    if (updates.length === 0) {
      return res.status(400).json({ error: 'No updates provided. Provide status and/or project_id' });
    }

    updates.push('updated_at = CURRENT_TIMESTAMP');
    values.push(req.params.id);

    await query(
      `UPDATE xero_purchase_orders SET ${updates.join(', ')} WHERE id = $${paramCount}`,
      values
    );

    // Log activity
    const logDetails: any = {};
    if (status) logDetails.status = status;
    if (project_id !== undefined) logDetails.project_id = project_id;

    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'update', 'purchase_order', req.params.id, JSON.stringify(logDetails)]
    );

    const po = await getPurchaseOrderById(req.params.id);
    res.json(po);
  } catch (error: any) {
    console.error('Failed to update purchase order:', error);
    res.status(500).json({ error: 'Failed to update purchase order: ' + (error.message || 'Unknown error') });
  }
});

router.post('/purchase-orders/:id/convert-to-bill', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const po = await getPurchaseOrderById(req.params.id);
    if (!po) {
      return res.status(404).json({ error: 'Purchase order not found' });
    }

    if (po.status === 'BILLED') {
      return res.status(400).json({ error: 'Purchase order already converted to bill' });
    }

    // Get supplier Xero contact ID
    const supplierResult = await query('SELECT xero_contact_id FROM clients WHERE id = $1', [po.supplier_id]);
    if (supplierResult.rows.length === 0) {
      return res.status(404).json({ error: 'Supplier not found' });
    }

    const supplierXeroId = supplierResult.rows[0].xero_contact_id;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    // Convert line items to bill line items
    const lineItems = po.line_items_detail || JSON.parse(po.line_items || '[]');
    const billLineItems = lineItems.map((item: any) => ({
      description: item.description,
      quantity: item.quantity || 1,
      unit_amount: item.unit_amount || item.line_amount,
      account_code: item.account_code,
    }));

    // Create bill in Xero if supplier has Xero ID
    let xeroBillId: string | undefined;
    if (supplierXeroId) {
      const xeroBill = await createBillInXero(
        tokenData,
        {
          supplier_id: po.supplier_id,
          purchase_order_id: po.id,
          project_id: po.project_id,
          date: new Date().toISOString().split('T')[0],
          line_items: billLineItems,
        },
        supplierXeroId
      );

      if (xeroBill) {
        xeroBillId = xeroBill.InvoiceID;
      }
    }

    // Generate bill number
    const countResult = await query('SELECT COUNT(*) as count FROM xero_bills');
    const billNumber = `BILL-${String(parseInt(countResult.rows[0].count) + 1).padStart(5, '0')}`;

    // Store bill
    const billId = await storeBill({
      supplier_id: po.supplier_id,
      purchase_order_id: po.id,
      project_id: po.project_id,
      date: new Date().toISOString().split('T')[0],
      line_items: billLineItems,
      xero_bill_id: xeroBillId,
      bill_number: billNumber,
    });

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'convert', 'purchase_order', po.id, JSON.stringify({ bill_id: billId, po_id: po.id })]
    );

    const bill = await query(
      `SELECT b.*, c.name as supplier_name, p.code as project_code, p.name as project_name
       FROM xero_bills b
       LEFT JOIN clients c ON b.supplier_id = c.id
       LEFT JOIN projects p ON b.project_id = p.id
       WHERE b.id = $1`,
      [billId]
    );

    res.status(201).json(bill.rows[0]);
  } catch (error: any) {
    console.error('Failed to convert purchase order to bill:', error);
    res.status(500).json({ error: 'Failed to convert purchase order to bill: ' + (error.message || 'Unknown error') });
  }
});

// Bills endpoints
router.post('/bills', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { supplier_id, purchase_order_id, project_id, date, due_date, line_items, reference, currency } = req.body;

    if (!supplier_id || !date || !line_items || line_items.length === 0) {
      return res.status(400).json({ error: 'Missing required fields: supplier_id, date, line_items' });
    }

    // Get supplier Xero contact ID
    const supplierResult = await query('SELECT xero_contact_id FROM clients WHERE id = $1', [supplier_id]);
    if (supplierResult.rows.length === 0) {
      return res.status(404).json({ error: 'Supplier not found' });
    }

    const supplierXeroId = supplierResult.rows[0].xero_contact_id;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    // Create bill in Xero if supplier has Xero ID
    let xeroBillId: string | undefined;
    if (supplierXeroId) {
      const xeroBill = await createBillInXero(
        tokenData,
        { supplier_id, purchase_order_id, project_id, date, due_date, line_items, reference, currency },
        supplierXeroId
      );

      if (xeroBill) {
        xeroBillId = xeroBill.InvoiceID;
      }
    }

    // Generate bill number
    const countResult = await query('SELECT COUNT(*) as count FROM xero_bills');
    const billNumber = `BILL-${String(parseInt(countResult.rows[0].count) + 1).padStart(5, '0')}`;

    // Store bill
    const billId = await storeBill({
      supplier_id,
      purchase_order_id,
      project_id,
      date,
      due_date,
      line_items,
      reference,
      currency,
      xero_bill_id: xeroBillId,
      bill_number: billNumber,
    });

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'create', 'bill', billId, JSON.stringify({ bill_number: billNumber, supplier_id })]
    );

    const bill = await query(
      `SELECT b.*, c.name as supplier_name, p.code as project_code, p.name as project_name
       FROM xero_bills b
       LEFT JOIN clients c ON b.supplier_id = c.id
       LEFT JOIN projects p ON b.project_id = p.id
       WHERE b.id = $1`,
      [billId]
    );

    res.status(201).json(bill.rows[0]);
  } catch (error: any) {
    console.error('Failed to create bill:', error);
    res.status(500).json({ error: 'Failed to create bill: ' + (error.message || 'Unknown error') });
  }
});

router.get('/bills', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    // Ensure tables exist before querying (don't fail if this errors)
    try {
      await ensureXeroTables();
    } catch (ensureError: any) {
      console.warn('[Xero] Failed to ensure tables exist:', ensureError.message);
      // Continue anyway - tables might already exist
    }
    
    const { supplier_id, project_id, purchase_order_id, status, date_from, date_to } = req.query;

    const bills = await getBills({
      supplier_id: supplier_id as string,
      project_id: project_id as string,
      purchase_order_id: purchase_order_id as string,
      status: status as string,
      date_from: date_from as string,
      date_to: date_to as string,
    });

    res.json(bills);
  } catch (error: any) {
    // Catch all errors and return empty array - don't fail the request
    console.error('Failed to fetch bills:', error);
    const errorMessage = error.message || 'Unknown error';
    // Log the actual error for debugging
    console.error('[Xero Bills] Error details:', {
      message: errorMessage,
      code: error.code,
      stack: error.stack
    });
    // Always return empty array with 200 status
    res.status(200).json([]);
  }
});

router.post('/bills/:id/pay', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { amount } = req.body;

    await markBillAsPaid(req.params.id, amount);

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'pay', 'bill', req.params.id, JSON.stringify({ amount })]
    );

    const bill = await query(
      `SELECT b.*, c.name as supplier_name, p.code as project_code, p.name as project_name
       FROM xero_bills b
       LEFT JOIN clients c ON b.supplier_id = c.id
       LEFT JOIN projects p ON b.project_id = p.id
       WHERE b.id = $1`,
      [req.params.id]
    );

    res.json(bill.rows[0]);
  } catch (error: any) {
    console.error('Failed to mark bill as paid:', error);
    res.status(500).json({ error: 'Failed to mark bill as paid: ' + (error.message || 'Unknown error') });
  }
});

// Expenses endpoints
router.post('/expenses', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { project_id, cost_center_id, amount, date, description, receipt_url, currency } = req.body;

    if (!amount || !date || !description) {
      return res.status(400).json({ error: 'Missing required fields: amount, date, description' });
    }

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    // Get tracking categories if cost center is provided
    let trackingCategories: Array<{ name: string; option: string }> | undefined;
    if (cost_center_id) {
      const costCenterResult = await query(
        'SELECT xero_tracking_category_id, code FROM cost_centers WHERE id = $1',
        [cost_center_id]
      );
      if (costCenterResult.rows.length > 0 && costCenterResult.rows[0].xero_tracking_category_id) {
        // This would need to be expanded based on Xero tracking category structure
      }
    }

    // Create expense in Xero
    const xeroExpense = await createExpenseInXero(
      tokenData,
      { project_id, cost_center_id, amount, date, description, receipt_url, currency },
      trackingCategories
    );

    const xeroExpenseId = xeroExpense?.ExpenseClaimID;

    // Store expense
    const expenseId = await storeExpense({
      project_id,
      cost_center_id,
      amount,
      date,
      description,
      receipt_url,
      xero_expense_id: xeroExpenseId,
    });

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'create', 'expense', expenseId, JSON.stringify({ amount, project_id, cost_center_id })]
    );

    const expense = await query(
      `SELECT e.*, p.code as project_code, p.name as project_name, cc.code as cost_center_code, cc.name as cost_center_name
       FROM xero_expenses e
       LEFT JOIN projects p ON e.project_id = p.id
       LEFT JOIN cost_centers cc ON e.cost_center_id = cc.id
       WHERE e.id = $1`,
      [expenseId]
    );

    res.status(201).json(expense.rows[0]);
  } catch (error: any) {
    console.error('Failed to create expense:', error);
    res.status(500).json({ error: 'Failed to create expense: ' + (error.message || 'Unknown error') });
  }
});

router.get('/expenses', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    // Ensure tables exist before querying (don't fail if this errors)
    try {
      await ensureXeroTables();
    } catch (ensureError: any) {
      console.warn('[Xero] Failed to ensure tables exist:', ensureError.message);
      // Continue anyway - tables might already exist
    }
    
    const { project_id, cost_center_id, status, date_from, date_to } = req.query;

    const expenses = await getExpenses({
      project_id: project_id as string,
      cost_center_id: cost_center_id as string,
      status: status as string,
      date_from: date_from as string,
      date_to: date_to as string,
    });

    res.json(expenses);
  } catch (error: any) {
    // Catch all errors and return empty array - don't fail the request
    console.error('Failed to fetch expenses:', error);
    const errorMessage = error.message || 'Unknown error';
    // Log the actual error for debugging
    console.error('[Xero Expenses] Error details:', {
      message: errorMessage,
      code: error.code,
      stack: error.stack
    });
    // Always return empty array with 200 status
    res.status(200).json([]);
  }
});

// Financial Reports endpoints
router.get('/reports/profit-loss', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { date_from, date_to } = req.query;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(200).json({ error: 'Xero not connected or token expired', report: null });
    }

    const report = await getProfitLossReport(tokenData, date_from as string, date_to as string);
    if (!report) {
      return res.status(200).json({ error: 'Failed to fetch Profit & Loss report', report: null });
    }

    res.status(200).json(report);
  } catch (error: any) {
    console.error('Failed to fetch P&L report:', error);
    res.status(200).json({ error: 'Failed to fetch Profit & Loss report', report: null });
  }
});

router.get('/reports/balance-sheet', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { date } = req.query;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(200).json({ error: 'Xero not connected or token expired', report: null });
    }

    const report = await getBalanceSheetReport(tokenData, date as string);
    if (!report) {
      return res.status(200).json({ error: 'Failed to fetch Balance Sheet report', report: null });
    }

    res.status(200).json(report);
  } catch (error: any) {
    console.error('Failed to fetch Balance Sheet report:', error);
    res.status(200).json({ error: 'Failed to fetch Balance Sheet report', report: null });
  }
});

router.get('/reports/cash-flow', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { date_from, date_to } = req.query;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(200).json({ error: 'Xero not connected or token expired', report: null });
    }

    const report = await getCashFlowReport(tokenData, date_from as string, date_to as string);
    if (!report) {
      return res.status(200).json({ error: 'Failed to fetch Cash Flow report', report: null });
    }

    res.status(200).json(report);
  } catch (error: any) {
    console.error('Failed to fetch Cash Flow report:', error);
    res.status(200).json({ error: 'Failed to fetch Cash Flow report', report: null });
  }
});

router.get('/reports/aged-receivables', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { date } = req.query;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(200).json({ error: 'Xero not connected or token expired', report: null });
    }

    const report = await getAgedReceivablesReport(tokenData, date as string);
    if (!report) {
      return res.status(200).json({ error: 'Failed to fetch Aged Receivables report', report: null });
    }

    res.status(200).json(report);
  } catch (error: any) {
    console.error('Failed to fetch Aged Receivables report:', error);
    res.status(200).json({ error: 'Failed to fetch Aged Receivables report', report: null });
  }
});

router.get('/reports/aged-payables', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { date } = req.query;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(200).json({ error: 'Xero not connected or token expired', report: null });
    }

    const report = await getAgedPayablesReport(tokenData, date as string);
    if (!report) {
      return res.status(200).json({ error: 'Failed to fetch Aged Payables report', report: null });
    }

    res.status(200).json(report);
  } catch (error: any) {
    console.error('Failed to fetch Aged Payables report:', error);
    res.status(200).json({ error: 'Failed to fetch Aged Payables report', report: null });
  }
});

// Items/Inventory endpoints
router.post('/items/sync', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    const synced = await syncItemsFromXero(tokenData);

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, details) 
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'sync', 'xero_items', JSON.stringify({ synced })]
    );

    res.json({ success: true, synced, message: `Synced ${synced} item(s)` });
  } catch (error: any) {
    console.error('Failed to sync items:', error);
    res.status(500).json({ error: 'Failed to sync items: ' + (error.message || 'Unknown error') });
  }
});

router.get('/items', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { search, is_tracked } = req.query;

    const items = await getItems({
      search: search as string,
      is_tracked: is_tracked === 'true' ? true : is_tracked === 'false' ? false : undefined,
    });

    res.json(items);
  } catch (error) {
    console.error('Failed to fetch items:', error);
    res.status(500).json({ error: 'Failed to fetch items' });
  }
});

router.get('/items/:id', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const item = await getItemById(req.params.id);
    if (!item) {
      return res.status(404).json({ error: 'Item not found' });
    }
    res.json(item);
  } catch (error) {
    console.error('Failed to fetch item:', error);
    res.status(500).json({ error: 'Failed to fetch item' });
  }
});

router.put('/items/:id/stock', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { stock_level } = req.body;

    if (stock_level === undefined || stock_level < 0) {
      return res.status(400).json({ error: 'Valid stock_level is required' });
    }

    await updateItemStock(req.params.id, parseFloat(stock_level));

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'update_stock', 'item', req.params.id, JSON.stringify({ stock_level })]
    );

    const item = await getItemById(req.params.id);
    res.json(item);
  } catch (error: any) {
    console.error('Failed to update item stock:', error);
    res.status(500).json({ error: 'Failed to update item stock: ' + (error.message || 'Unknown error') });
  }
});

// Credit Notes endpoints
router.post('/credit-notes', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { invoice_id, amount, date, reason, description, currency } = req.body;

    if (!invoice_id || !amount || !date) {
      return res.status(400).json({ error: 'Missing required fields: invoice_id, amount, date' });
    }

    // Get invoice details
    const invoiceResult = await query('SELECT id, xero_invoice_id, client_id, total FROM xero_invoices WHERE id = $1', [invoice_id]);
    if (invoiceResult.rows.length === 0) {
      return res.status(404).json({ error: 'Invoice not found' });
    }

    const invoice = invoiceResult.rows[0];

    // Get client Xero contact ID
    const clientResult = await query('SELECT xero_contact_id FROM clients WHERE id = $1', [invoice.client_id]);
    if (clientResult.rows.length === 0 || !clientResult.rows[0].xero_contact_id) {
      return res.status(404).json({ error: 'Client Xero contact ID not found' });
    }

    const contactXeroId = clientResult.rows[0].xero_contact_id;

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    // Create credit note in Xero
    let xeroCreditNoteId: string | undefined;
    if (invoice.xero_invoice_id && contactXeroId) {
      const xeroCreditNote = await createCreditNoteInXero(
        tokenData,
        { invoice_id, amount, date, reason, description, currency },
        invoice.xero_invoice_id,
        contactXeroId
      );

      if (xeroCreditNote) {
        xeroCreditNoteId = xeroCreditNote.CreditNoteID;

        // Apply credit note to invoice
        await applyCreditNoteToInvoice(tokenData, xeroCreditNoteId, invoice.xero_invoice_id);
      }
    }

    // Generate credit note number
    const countResult = await query('SELECT COUNT(*) as count FROM xero_credit_notes');
    const creditNoteNumber = `CN-${String(parseInt(countResult.rows[0].count) + 1).padStart(5, '0')}`;

    // Store credit note
    const creditNoteId = await storeCreditNote({
      invoice_id,
      amount: parseFloat(amount),
      date,
      reason,
      description,
      currency,
      xero_credit_note_id: xeroCreditNoteId,
      credit_note_number: creditNoteNumber,
    });

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'create', 'credit_note', creditNoteId, JSON.stringify({ invoice_id, amount, reason })]
    );

    const creditNote = await query(
      `SELECT cn.*, xi.invoice_number, c.name as client_name
       FROM xero_credit_notes cn
       LEFT JOIN xero_invoices xi ON cn.invoice_id = xi.id
       LEFT JOIN clients c ON xi.client_id = c.id
       WHERE cn.id = $1`,
      [creditNoteId]
    );

    res.status(201).json(creditNote.rows[0]);
  } catch (error: any) {
    console.error('Failed to create credit note:', error);
    res.status(500).json({ error: 'Failed to create credit note: ' + (error.message || 'Unknown error') });
  }
});

router.get('/credit-notes', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { invoice_id, date_from, date_to, status } = req.query;

    const creditNotes = await getCreditNotes({
      invoice_id: invoice_id as string,
      date_from: date_from as string,
      date_to: date_to as string,
      status: status as string,
    });

    res.json(creditNotes);
  } catch (error) {
    console.error('Failed to fetch credit notes:', error);
    res.status(500).json({ error: 'Failed to fetch credit notes' });
  }
});

router.post('/credit-notes/:id/apply', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const creditNoteResult = await query('SELECT xero_credit_note_id, invoice_id FROM xero_credit_notes WHERE id = $1', [req.params.id]);
    if (creditNoteResult.rows.length === 0) {
      return res.status(404).json({ error: 'Credit note not found' });
    }

    const creditNote = creditNoteResult.rows[0];
    const invoiceResult = await query('SELECT xero_invoice_id FROM xero_invoices WHERE id = $1', [creditNote.invoice_id]);
    
    if (invoiceResult.rows.length === 0 || !invoiceResult.rows[0].xero_invoice_id) {
      return res.status(404).json({ error: 'Invoice not found or not synced to Xero' });
    }

    const tokenData = await getValidAccessToken();
    if (!tokenData) {
      return res.status(400).json({ error: 'Xero not connected or token expired' });
    }

    const applied = await applyCreditNoteToInvoice(
      tokenData,
      creditNote.xero_credit_note_id,
      invoiceResult.rows[0].xero_invoice_id
    );

    if (!applied) {
      return res.status(500).json({ error: 'Failed to apply credit note to invoice' });
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'apply', 'credit_note', req.params.id, JSON.stringify({ invoice_id: creditNote.invoice_id })]
    );

    res.json({ success: true, message: 'Credit note applied to invoice successfully' });
  } catch (error: any) {
    console.error('Failed to apply credit note:', error);
    res.status(500).json({ error: 'Failed to apply credit note: ' + (error.message || 'Unknown error') });
  }
});

// Payment Reminders endpoints
router.get('/reminders/schedule', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const schedule = await getReminderSchedule();
    res.json(schedule);
  } catch (error: any) {
    console.error('Failed to get reminder schedule:', error);
    res.status(500).json({ error: 'Failed to get reminder schedule: ' + (error.message || 'Unknown error') });
  }
});

router.put('/reminders/schedule', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const schedule = req.body;

    await updateReminderSchedule(schedule);

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, details) 
       VALUES ($1, $2, $3, $4)`,
      [req.user!.id, 'update', 'reminder_schedule', JSON.stringify(schedule)]
    );

    res.json({ success: true, schedule });
  } catch (error: any) {
    console.error('Failed to update reminder schedule:', error);
    res.status(500).json({ error: 'Failed to update reminder schedule: ' + (error.message || 'Unknown error') });
  }
});

router.post('/reminders/send', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const { invoice_id, reminder_type } = req.body;

    if (!invoice_id) {
      return res.status(400).json({ error: 'invoice_id is required' });
    }

    const success = await sendPaymentReminder(invoice_id, reminder_type || 'manual');

    if (!success) {
      return res.status(500).json({ error: 'Failed to send payment reminder' });
    }

    // Log activity
    await query(
      `INSERT INTO activity_logs (user_id, action, entity_type, entity_id, details) 
       VALUES ($1, $2, $3, $4, $5)`,
      [req.user!.id, 'send_reminder', 'invoice', invoice_id, JSON.stringify({ reminder_type: reminder_type || 'manual' })]
    );

    res.json({ success: true, message: 'Payment reminder sent successfully' });
  } catch (error: any) {
    console.error('Failed to send payment reminder:', error);
    res.status(500).json({ error: 'Failed to send payment reminder: ' + (error.message || 'Unknown error') });
  }
});

router.post('/reminders/process', authenticate, requirePermission('can_sync_xero'), async (req: AuthRequest, res: Response) => {
  try {
    const result = await processPaymentReminders();
    res.json({ success: true, ...result });
  } catch (error: any) {
    console.error('Failed to process payment reminders:', error);
    res.status(500).json({ error: 'Failed to process payment reminders: ' + (error.message || 'Unknown error') });
  }
});

router.get('/reminders/history', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { invoice_id, date_from, date_to } = req.query;

    const history = await getReminderHistory({
      invoice_id: invoice_id as string,
      date_from: date_from as string,
      date_to: date_to as string,
    });

    res.json(history);
  } catch (error) {
    console.error('Failed to fetch reminder history:', error);
    res.status(500).json({ error: 'Failed to fetch reminder history' });
  }
});

// Webhooks endpoints
router.post('/webhooks', async (req: AuthRequest, res: Response) => {
  try {
    const signature = req.headers['x-xero-signature'] as string;
    const webhookKey = process.env.XERO_WEBHOOK_KEY || '';

    if (!signature || !webhookKey) {
      return res.status(401).json({ error: 'Missing webhook signature or key' });
    }

    const payload = JSON.stringify(req.body);
    
    // Verify signature
    if (!verifyWebhookSignature(payload, signature, webhookKey)) {
      return res.status(401).json({ error: 'Invalid webhook signature' });
    }

    // Process webhook events
    const events = req.body.events || [];
    const eventIds: string[] = [];

    for (const event of events) {
      const eventId = await storeWebhookEvent(
        event.eventType,
        event.resourceId,
        event
      );
      eventIds.push(eventId);

      // Process event asynchronously
      processWebhookEvent(eventId).catch(error => {
        console.error('Error processing webhook event:', error);
      });
    }

    res.status(200).json({ success: true, events_processed: eventIds.length });
  } catch (error: any) {
    console.error('Webhook processing error:', error);
    res.status(500).json({ error: 'Webhook processing error: ' + (error.message || 'Unknown error') });
  }
});

router.get('/webhooks/status', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const status = await getWebhookStatus();
    res.json(status);
  } catch (error: any) {
    console.error('Failed to get webhook status:', error);
    res.status(500).json({ error: 'Failed to get webhook status: ' + (error.message || 'Unknown error') });
  }
});

router.get('/webhooks/events', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    const { event_type, processed, date_from, date_to } = req.query;

    const events = await getWebhookEvents({
      event_type: event_type as string,
      processed: processed === 'true' ? true : processed === 'false' ? false : undefined,
      date_from: date_from as string,
      date_to: date_to as string,
    });

    res.json(events);
  } catch (error) {
    console.error('Failed to fetch webhook events:', error);
    res.status(500).json({ error: 'Failed to fetch webhook events' });
  }
});

// Get financial summary
router.get('/summary', authenticate, requirePermission('can_view_financials'), async (req: AuthRequest, res: Response) => {
  try {
    // Ensure tables exist before querying (don't fail if this errors)
    try {
      await ensureXeroTables();
    } catch (ensureError: any) {
      console.warn('[Xero] Failed to ensure tables exist:', ensureError.message);
      // Continue anyway - tables might already exist
    }
    
    // Helper function to safely query and return default on ANY error
    const safeQuery = async (sql: string, defaultValue: any) => {
      try {
        const result = await query(sql);
        return result;
      } catch (error: any) {
        // Catch ALL errors and return default - don't throw
        console.warn('[Xero Summary] Query failed, using default value:', error.message);
        return { rows: Array.isArray(defaultValue) ? defaultValue : [defaultValue] };
      }
    };

    // Outstanding invoices
    const outstanding = await safeQuery(`
      SELECT COALESCE(SUM(amount_due), 0) as total
      FROM xero_invoices
      WHERE status IN ('AUTHORISED', 'SUBMITTED')
    `, { total: '0' });

    // Paid this month
    const paidThisMonth = await safeQuery(`
      SELECT COALESCE(SUM(amount_paid), 0) as total
      FROM xero_invoices
      WHERE status = 'PAID'
      AND updated_at >= date_trunc('month', CURRENT_DATE)
    `, { total: '0' });

    // Pending quotes
    const pendingQuotes = await safeQuery(`
      SELECT COALESCE(SUM(total), 0) as total, COUNT(*) as count
      FROM xero_quotes
      WHERE status = 'PENDING'
    `, { total: '0', count: '0' });

    // Revenue last 6 months
    const revenueByMonth = await safeQuery(`
      SELECT 
        date_trunc('month', issue_date) as month,
        COALESCE(SUM(total), 0) as total
      FROM xero_invoices
      WHERE status = 'PAID'
      AND issue_date >= CURRENT_DATE - INTERVAL '6 months'
      GROUP BY date_trunc('month', issue_date)
      ORDER BY month ASC
    `, []);

    // Top clients by revenue
    const topClients = await safeQuery(`
      SELECT 
        c.id, c.name,
        COALESCE(SUM(xi.total), 0) as total_revenue
      FROM clients c
      LEFT JOIN xero_invoices xi ON c.id = xi.client_id AND xi.status = 'PAID'
      GROUP BY c.id, c.name
      ORDER BY total_revenue DESC
      LIMIT 5
    `, []);

    res.json({
      outstanding_invoices: parseFloat(outstanding.rows[0].total) || 0,
      paid_this_month: parseFloat(paidThisMonth.rows[0].total) || 0,
      pending_quotes: {
        total: parseFloat(pendingQuotes.rows[0].total) || 0,
        count: parseInt(pendingQuotes.rows[0].count) || 0
      },
      revenue_by_month: revenueByMonth.rows,
      top_clients: topClients.rows
    });
  } catch (error: any) {
    console.error('Failed to fetch financial summary:', error);
    const errorMessage = error.message || 'Failed to fetch financial summary';
    // Return empty summary instead of error
    res.json({
      outstanding_invoices: 0,
      paid_this_month: 0,
      pending_quotes: { total: 0, count: 0 },
      revenue_by_month: [],
      top_clients: []
    });
  }
});

export default router;
--- FILE: backend/src/scripts/migrate-files-to-storage.ts ---
#!/usr/bin/env tsx
/**
 * File Migration Script
 * 
 * Migrates existing files from old filesystem paths to the new storage abstraction layer.
 * This script is idempotent and can be run multiple times safely.
 * 
 * Usage:
 *   npm run migrate:files
 *   or
 *   tsx src/scripts/migrate-files-to-storage.ts
 */

import { query } from '../db';
import { StorageFactory } from '../lib/storage/StorageFactory';
import { generatePartitionedPath, resolveStoragePath } from '../lib/storage/pathUtils';
import { createReadStream } from 'fs';
import { createHash } from 'crypto';
import fs from 'fs';
import path from 'path';
import { log } from '../lib/logger';
import { isGoogleDriveConnected } from '../lib/googleDrive';

interface MigrationRecord {
  id: string;
  file_id?: string;
  entity_type: string;
  entity_id?: string;
  source_path: string;
  destination_path: string;
  status: 'pending' | 'in_progress' | 'completed' | 'failed';
  error_message?: string;
  file_size?: number;
  checksum?: string;
}

/**
 * Calculate SHA-256 checksum of a file
 */
async function calculateChecksum(filePath: string): Promise<string> {
  return new Promise((resolve, reject) => {
    const hash = createHash('sha256');
    const stream = fs.createReadStream(filePath);
    
    stream.on('data', (data) => hash.update(data));
    stream.on('end', () => resolve(hash.digest('hex')));
    stream.on('error', reject);
  });
}

/**
 * Check if a file has already been migrated
 */
async function isAlreadyMigrated(
  entityType: string,
  entityId: string | undefined,
  sourcePath: string
): Promise<boolean> {
  const result = await query(
    `SELECT id FROM file_migrations 
     WHERE entity_type = $1 
     AND (entity_id = $2 OR ($2 IS NULL AND entity_id IS NULL))
     AND source_path = $3 
     AND status = 'completed'`,
    [entityType, entityId || null, sourcePath]
  );
  
  return result.rows.length > 0;
}

/**
 * Check if destination path already exists in storage
 */
async function destinationExists(destinationPath: string): Promise<boolean> {
  try {
    const storage = await StorageFactory.getInstance();
    return await storage.exists(destinationPath);
  } catch (error) {
    log.error('Error checking if destination exists', error);
    return false;
  }
}

/**
 * Create or update migration record
 */
async function createMigrationRecord(
  fileId: string | undefined,
  entityType: string,
  entityId: string | undefined,
  sourcePath: string,
  destinationPath: string,
  status: MigrationRecord['status'],
  fileSize?: number,
  checksum?: string,
  errorMessage?: string
): Promise<string> {
  // Check if migration record already exists
  const existing = await query(
    `SELECT id FROM file_migrations 
     WHERE entity_type = $1 
     AND (entity_id = $2 OR ($2 IS NULL AND entity_id IS NULL))
     AND source_path = $3`,
    [entityType, entityId || null, sourcePath]
  );

  if (existing.rows.length > 0) {
    // Update existing record
    await query(
      `UPDATE file_migrations 
       SET status = $1, 
           destination_path = $2,
           file_size = $3,
           checksum = $4,
           error_message = $5,
           updated_at = CURRENT_TIMESTAMP,
           migrated_at = CASE WHEN $1 = 'completed' THEN CURRENT_TIMESTAMP ELSE migrated_at END
       WHERE id = $6`,
      [status, destinationPath, fileSize || null, checksum || null, errorMessage || null, existing.rows[0].id]
    );
    return existing.rows[0].id;
  } else {
    // Create new record
    const result = await query(
      `INSERT INTO file_migrations (
        file_id, entity_type, entity_id, source_path, destination_path, 
        status, file_size, checksum, error_message, migrated_at
      ) VALUES ($1, $2, $3, $4, $5, $6, $7, $8, $9, CASE WHEN $6 = 'completed' THEN CURRENT_TIMESTAMP ELSE NULL END)
      RETURNING id`,
      [fileId || null, entityType, entityId || null, sourcePath, destinationPath, status, fileSize || null, checksum || null, errorMessage || null]
    );
    return result.rows[0].id;
  }
}

/**
 * Migrate a single file
 */
async function migrateFile(
  fileId: string | undefined,
  entityType: string,
  entityId: string | undefined,
  sourcePath: string,
  basePath: string,
  filename: string
): Promise<{ success: boolean; destinationPath?: string; error?: string }> {
  try {
    // Check if already migrated
    if (await isAlreadyMigrated(entityType, entityId, sourcePath)) {
      log.info(`File already migrated: ${sourcePath}`);
      return { success: true };
    }

    // Resolve absolute path if relative
    const absoluteSourcePath = sourcePath.startsWith('/') 
      ? sourcePath 
      : path.join(process.cwd(), 'uploads', sourcePath.replace(/^\/?uploads\//, ''));

    // Check if source file exists
    if (!fs.existsSync(absoluteSourcePath)) {
      const errorMsg = `Source file not found: ${absoluteSourcePath}`;
      log.warn(errorMsg);
      await createMigrationRecord(fileId, entityType, entityId, sourcePath, '', 'failed', undefined, undefined, errorMsg);
      return { success: false, error: errorMsg };
    }

    // Generate destination path
    const destinationPath = generatePartitionedPath(filename, basePath);

    // Check if destination already exists (from previous partial migration)
    if (await destinationExists(destinationPath)) {
      log.info(`Destination already exists, skipping copy: ${destinationPath}`);
      // Update database reference and mark as completed
      await updateDatabaseReference(entityType, entityId, fileId, sourcePath, destinationPath);
      await createMigrationRecord(fileId, entityType, entityId, sourcePath, destinationPath, 'completed');
      return { success: true, destinationPath };
    }

    // Get file stats
    const stats = fs.statSync(absoluteSourcePath);
    const fileSize = stats.size;

    // Calculate checksum (skip for very large files to save time)
    let checksum: string | undefined;
    const storage = await StorageFactory.getInstance();
    const driver = storage.getDriver();
    
    // For Google Drive, skip checksum calculation for files > 10MB to speed up migration
    // For other drivers, calculate checksum for all files
    if (driver !== 'google-drive' || fileSize < 10 * 1024 * 1024) {
      log.info(`Calculating checksum for: ${absoluteSourcePath} (${(fileSize / 1024 / 1024).toFixed(2)} MB)`);
      checksum = await calculateChecksum(absoluteSourcePath);
    } else {
      log.info(`Skipping checksum for large file: ${absoluteSourcePath} (${(fileSize / 1024 / 1024).toFixed(2)} MB)`);
    }

    // Create migration record as 'in_progress'
    await createMigrationRecord(fileId, entityType, entityId, sourcePath, destinationPath, 'in_progress', fileSize, checksum);

    // Copy file to storage
    if (driver === 'google-drive') {
      log.info(`Uploading to Google Drive: ${sourcePath} -> ${destinationPath} (${(fileSize / 1024 / 1024).toFixed(2)} MB)`);
    } else {
      log.info(`Migrating file: ${sourcePath} -> ${destinationPath}`);
    }
    
    const fileStream = createReadStream(absoluteSourcePath);
    await storage.put(destinationPath, fileStream, {
      contentType: getContentType(filename),
    });

    // Update database reference
    await updateDatabaseReference(entityType, entityId, fileId, sourcePath, destinationPath);

    // Mark migration as completed
    await createMigrationRecord(fileId, entityType, entityId, sourcePath, destinationPath, 'completed', fileSize, checksum);

    if (driver === 'google-drive') {
      log.info(`‚úì Successfully uploaded to Google Drive: ${destinationPath}`);
    } else {
      log.info(`Successfully migrated: ${sourcePath} -> ${destinationPath}`);
    }
    return { success: true, destinationPath };
  } catch (error: any) {
    const errorMsg = error?.message || 'Unknown error';
    
    // Provide more helpful error messages for Google Drive
    if (errorMsg.includes('Google Drive') || errorMsg.includes('gdrive')) {
      log.error(`Failed to upload to Google Drive: ${sourcePath}`, error);
      log.error('  This may be due to:');
      log.error('  - Google Drive API rate limits (wait and retry)');
      log.error('  - Insufficient permissions');
      log.error('  - Network connectivity issues');
    } else {
      log.error(`Failed to migrate file: ${sourcePath}`, error);
    }
    
    await createMigrationRecord(fileId, entityType, entityId, sourcePath, '', 'failed', undefined, undefined, errorMsg);
    return { success: false, error: errorMsg };
  }
}

/**
 * Get content type from filename
 */
function getContentType(filename: string): string {
  const ext = path.extname(filename).toLowerCase();
  const mimeTypes: Record<string, string> = {
    '.jpg': 'image/jpeg',
    '.jpeg': 'image/jpeg',
    '.png': 'image/png',
    '.gif': 'image/gif',
    '.webp': 'image/webp',
    '.pdf': 'application/pdf',
    '.doc': 'application/msword',
    '.docx': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
    '.xls': 'application/vnd.ms-excel',
    '.xlsx': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
    '.txt': 'text/plain',
    '.csv': 'text/csv',
  };
  return mimeTypes[ext] || 'application/octet-stream';
}

/**
 * Update database reference to point to new storage path
 */
async function updateDatabaseReference(
  entityType: string,
  entityId: string | undefined,
  fileId: string | undefined,
  oldPath: string,
  newPath: string
): Promise<void> {
  const storage = await StorageFactory.getInstance();
  const newUrl = await storage.url(newPath);

  switch (entityType) {
    case 'project_file':
      if (fileId) {
        await query(
          `UPDATE project_files SET file_path = $1 WHERE id = $2`,
          [newUrl, fileId]
        );
      }
      break;

    case 'timesheet_image':
      if (entityId) {
        // Update timesheet image_urls array
        const timesheet = await query(
          `SELECT image_urls FROM timesheets WHERE id = $1`,
          [entityId]
        );
        if (timesheet.rows.length > 0) {
          const imageUrls = timesheet.rows[0].image_urls || [];
          const updatedUrls = imageUrls.map((url: string) => 
            url === oldPath ? newUrl : url
          );
          await query(
            `UPDATE timesheets SET image_urls = $1 WHERE id = $2`,
            [updatedUrls, entityId]
          );
        }
      }
      break;

    case 'safety_document':
      if (entityId) {
        await query(
          `UPDATE safety_documents SET file_path = $1 WHERE id = $2`,
          [newUrl, entityId]
        );
      }
      break;

    case 'logo':
    case 'favicon':
      // Settings table - update the value JSON
      const settingKey = entityType === 'logo' ? 'company_logo' : 'company_favicon';
      const settings = await query(
        `SELECT id, value FROM settings WHERE key = $1 AND user_id IS NULL`,
        [settingKey]
      );
      for (const setting of settings.rows) {
        const value = typeof setting.value === 'string' ? JSON.parse(setting.value) : setting.value;
        if (value && (value.url === oldPath || value.path === oldPath)) {
          value.url = newUrl;
          value.path = newPath;
          await query(
            `UPDATE settings SET value = $1 WHERE id = $2`,
            [JSON.stringify(value), setting.id]
          );
        }
      }
      break;
  }
}

/**
 * Migrate project files
 */
async function migrateProjectFiles(): Promise<{ success: number; failed: number }> {
  log.info('Starting migration of project files...');
  const files = await query(
    `SELECT id, project_id, file_path, file_name 
     FROM project_files 
     WHERE file_path IS NOT NULL 
     AND file_path != ''
     AND NOT (file_path LIKE 'http://%' OR file_path LIKE 'https://%')
     AND NOT (file_path LIKE 'gdrive://%')`
  );

  log.info(`Found ${files.rows.length} project files to migrate`);
  let success = 0;
  let failed = 0;
  let processed = 0;

  for (const file of files.rows) {
    processed++;
    if (processed % 10 === 0) {
      log.info(`Progress: ${processed}/${files.rows.length} files processed (${success} succeeded, ${failed} failed)`);
    }
    const basePath = `projects/${file.project_id}/files`;
    const result = await migrateFile(
      file.id,
      'project_file',
      file.id,
      file.file_path,
      basePath,
      file.file_name
    );
    if (result.success) {
      success++;
    } else {
      failed++;
    }
  }

  log.info(`Project files migration complete: ${success} succeeded, ${failed} failed`);
  return { success, failed };
}

/**
 * Migrate timesheet images
 */
async function migrateTimesheetImages(): Promise<{ success: number; failed: number }> {
  log.info('Starting migration of timesheet images...');
  const timesheets = await query(
    `SELECT id, project_id, image_urls 
     FROM timesheets 
     WHERE image_urls IS NOT NULL 
     AND array_length(image_urls, 1) > 0`
  );

  // Count total images to migrate
  let totalImages = 0;
  for (const timesheet of timesheets.rows) {
    const imageUrls = timesheet.image_urls || [];
    for (const imageUrl of imageUrls) {
      if (!imageUrl.startsWith('http://') && !imageUrl.startsWith('https://') && !imageUrl.startsWith('gdrive://')) {
        totalImages++;
      }
    }
  }
  
  log.info(`Found ${totalImages} timesheet images to migrate`);
  let success = 0;
  let failed = 0;
  let processed = 0;

  for (const timesheet of timesheets.rows) {
    const imageUrls = timesheet.image_urls || [];
    for (let i = 0; i < imageUrls.length; i++) {
      const imageUrl = imageUrls[i];
      // Skip HTTP URLs (already in cloud storage)
      if (imageUrl.startsWith('http://') || imageUrl.startsWith('https://')) {
        continue;
      }

      const basePath = `projects/${timesheet.project_id}/timesheets`;
      const filename = path.basename(imageUrl) || `image_${i}.jpg`;
      const result = await migrateFile(
        undefined,
        'timesheet_image',
        timesheet.id,
        imageUrl,
        basePath,
        filename
      );
      processed++;
      if (processed % 10 === 0) {
        log.info(`Progress: ${processed}/${totalImages} images processed (${success} succeeded, ${failed} failed)`);
      }
      if (result.success) {
        success++;
      } else {
        failed++;
      }
    }
  }

  log.info(`Timesheet images migration complete: ${success} succeeded, ${failed} failed`);
  return { success, failed };
}

/**
 * Migrate safety documents
 */
async function migrateSafetyDocuments(): Promise<{ success: number; failed: number }> {
  log.info('Starting migration of safety documents...');
  const documents = await query(
    `SELECT id, project_id, file_path, title, document_type 
     FROM safety_documents 
     WHERE file_path IS NOT NULL 
     AND file_path != ''
     AND NOT (file_path LIKE 'http://%' OR file_path LIKE 'https://%')
     AND NOT (file_path LIKE 'gdrive://%')`
  );

  log.info(`Found ${documents.rows.length} safety documents to migrate`);
  let success = 0;
  let failed = 0;

  for (const doc of documents.rows) {
    const basePath = `projects/${doc.project_id}/safety-documents`;
    const filename = path.basename(doc.file_path) || `${doc.document_type}_${doc.id}.pdf`;
    const result = await migrateFile(
      undefined,
      'safety_document',
      doc.id,
      doc.file_path,
      basePath,
      filename
    );
    if (result.success) {
      success++;
    } else {
      failed++;
    }
  }

  log.info(`Safety documents migration complete: ${success} succeeded, ${failed} failed`);
  return { success, failed };
}

/**
 * Migrate logo and favicon
 */
async function migrateLogosAndFavicons(): Promise<{ success: number; failed: number }> {
  log.info('Starting migration of logos and favicons...');
  const settings = await query(
    `SELECT key, value FROM settings 
     WHERE key IN ('company_logo', 'company_favicon') 
     AND user_id IS NULL`
  );

  let success = 0;
  let failed = 0;

  for (const setting of settings.rows) {
    try {
      const value = typeof setting.value === 'string' ? JSON.parse(setting.value) : setting.value;
      if (!value || (!value.url && !value.path)) {
        continue;
      }

      const filePath = value.path || value.url;
      // Skip HTTP URLs and Google Drive URLs (already migrated)
      if (filePath.startsWith('http://') || filePath.startsWith('https://') || filePath.startsWith('gdrive://')) {
        continue;
      }

      const entityType = setting.key === 'company_logo' ? 'logo' : 'favicon';
      const basePath = 'settings';
      const filename = path.basename(filePath) || (entityType === 'logo' ? 'logo.png' : 'favicon.ico');
      
      const result = await migrateFile(
        undefined,
        entityType,
        undefined,
        filePath,
        basePath,
        filename
      );
      if (result.success) {
        success++;
      } else {
        failed++;
      }
    } catch (error) {
      log.error(`Failed to process ${setting.key}`, error);
      failed++;
    }
  }

  log.info(`Logos and favicons migration complete: ${success} succeeded, ${failed} failed`);
  return { success, failed };
}

/**
 * Verify storage connection before migration
 */
async function verifyStorageConnection(): Promise<void> {
  try {
    const storage = await StorageFactory.getInstance();
    const driver = storage.getDriver();
    
    log.info(`Storage driver: ${driver}`);
    
    if (driver === 'google-drive') {
      log.info('Verifying Google Drive connection...');
      const connected = await isGoogleDriveConnected();
      if (!connected) {
        throw new Error('Google Drive is not connected. Please connect Google Drive in the Settings > Integrations tab before running migration.');
      }
      
      // Test connection by calling testConnection
      try {
        await storage.testConnection();
        log.info('‚úì Google Drive connection verified');
      } catch (error: any) {
        throw new Error(`Google Drive connection test failed: ${error.message || 'Unknown error'}`);
      }
    } else if (driver === 's3') {
      log.info('Verifying S3 connection...');
      try {
        await storage.testConnection();
        log.info('‚úì S3 connection verified');
      } catch (error: any) {
        throw new Error(`S3 connection test failed: ${error.message || 'Unknown error'}`);
      }
    } else {
      log.info('‚úì Local storage ready');
    }
  } catch (error: any) {
    log.error('Storage connection verification failed', error);
    throw error;
  }
}

/**
 * Main migration function
 */
async function migrateFiles(): Promise<void> {
  log.info('=== Starting File Migration ===');
  
  try {
    // Ensure file_migrations table exists
    const migrationTableCheck = await query(
      `SELECT EXISTS (
        SELECT FROM information_schema.tables 
        WHERE table_schema = 'public' 
        AND table_name = 'file_migrations'
      )`
    );

    if (!migrationTableCheck.rows[0].exists) {
      log.error('file_migrations table does not exist. Please run the migration SQL first.');
      process.exit(1);
    }

    // Verify storage connection before starting migration
    await verifyStorageConnection();

    // Get storage driver for progress reporting
    const storage = await StorageFactory.getInstance();
    const driver = storage.getDriver();
    if (driver === 'google-drive') {
      log.info('‚ö†Ô∏è  Note: Google Drive migrations may be slower due to API rate limits.');
      log.info('   Large migrations may take significant time. Progress will be logged.');
    }

    // Run migrations
    const projectFilesResult = await migrateProjectFiles();
    const timesheetImagesResult = await migrateTimesheetImages();
    const safetyDocumentsResult = await migrateSafetyDocuments();
    const logosResult = await migrateLogosAndFavicons();

    // Summary
    const totalSuccess = projectFilesResult.success + timesheetImagesResult.success + 
                         safetyDocumentsResult.success + logosResult.success;
    const totalFailed = projectFilesResult.failed + timesheetImagesResult.failed + 
                       safetyDocumentsResult.failed + logosResult.failed;

    log.info('=== Migration Summary ===');
    log.info(`Project Files: ${projectFilesResult.success} succeeded, ${projectFilesResult.failed} failed`);
    log.info(`Timesheet Images: ${timesheetImagesResult.success} succeeded, ${timesheetImagesResult.failed} failed`);
    log.info(`Safety Documents: ${safetyDocumentsResult.success} succeeded, ${safetyDocumentsResult.failed} failed`);
    log.info(`Logos/Favicons: ${logosResult.success} succeeded, ${logosResult.failed} failed`);
    log.info(`Total: ${totalSuccess} succeeded, ${totalFailed} failed`);

    if (totalFailed > 0) {
      log.warn('Some files failed to migrate. Check the file_migrations table for details.');
      process.exit(1);
    } else {
      log.info('All files migrated successfully!');
      process.exit(0);
    }
  } catch (error) {
    log.error('Migration failed', error);
    process.exit(1);
  }
}

// Run migration if executed directly
if (require.main === module) {
  migrateFiles();
}

export { migrateFiles };
--- FILE: backend/src/server.ts ---
import express from 'express';
import cors from 'cors';
import helmet from 'helmet';
import path from 'path';
import rateLimit from 'express-rate-limit';
import { env } from './config/env';
import { createDynamicCorsOrigin, initializeCorsCache } from './config/cors';
import { logger, log } from './lib/logger';
import { RATE_LIMIT_CONSTANTS } from './lib/constants';
import { requestIdMiddleware, requestLogger } from './middleware/requestLogger';
import { errorHandler } from './middleware/errorHandler';
import { StorageFactory } from './lib/storage/StorageFactory';
import { resolveStoragePath } from './lib/storage/pathUtils';
import { authenticate } from './middleware/auth';

// Import routes
import authRoutes from './routes/auth';
import usersRoutes from './routes/users';
import clientsRoutes from './routes/clients';
import projectsRoutes from './routes/projects';
import timesheetsRoutes from './routes/timesheets';
import costCentersRoutes from './routes/costCenters';
import activityTypesRoutes from './routes/activityTypes';
import searchRoutes from './routes/search';
import setupRoutes from './routes/setup';
import xeroRoutes from './routes/xero';
import settingsRoutes from './routes/settings';
import permissionsRoutes from './routes/permissions';
import rolePermissionsRoutes from './routes/role-permissions';
import dashboardRoutes from './routes/dashboard';
import healthRoutes from './routes/health';
import troubleshooterRoutes from './routes/troubleshooter';
import filesRoutes from './routes/files';
import safetyDocumentsRoutes from './routes/safetyDocuments';
import backupsRoutes from './routes/backups';
import documentScanRoutes from './routes/documentScan';

const app = express();

// Request ID middleware (must be first)
app.use(requestIdMiddleware);

// Security headers with enhanced configuration
// CSP will be set dynamically based on storage configuration
app.use(async (req, res, next) => {
  try {
    const { generateCSPDirective } = await import('./lib/csp');
    const csp = await generateCSPDirective();
    
    helmet({
      contentSecurityPolicy: false, // Disable default CSP, we'll set it manually
      crossOriginEmbedderPolicy: false, // Disable for API server
      referrerPolicy: { policy: 'strict-origin-when-cross-origin' },
    })(req, res, () => {
      // Override CSP header with dynamic value
      res.setHeader('Content-Security-Policy', csp);
      next();
    });
  } catch (error) {
    // Fallback to default helmet config if CSP generation fails
    helmet({
      contentSecurityPolicy: {
        directives: {
          defaultSrc: ["'self'"],
          styleSrc: ["'self'", "'unsafe-inline'"],
          scriptSrc: ["'self'"],
          imgSrc: ["'self'", "data:", "https:"],
          connectSrc: ["'self'"],
          fontSrc: ["'self'"],
          objectSrc: ["'none'"],
          mediaSrc: ["'self'"],
          frameSrc: ["'none'"],
        },
      },
      crossOriginEmbedderPolicy: false,
      referrerPolicy: { policy: 'strict-origin-when-cross-origin' },
    })(req, res, next);
  }
});

// CORS configuration
app.use(cors({
  origin: createDynamicCorsOrigin(),
  credentials: true
}));

// Request size limits to prevent DoS attacks
app.use(express.json({ limit: '1mb' }));
app.use(express.urlencoded({ extended: true, limit: '1mb' }));

// Request logging middleware
app.use(requestLogger);

// Global API rate limiting - applies to all API endpoints
// More lenient than auth endpoints to allow normal usage
// Note: React apps make multiple simultaneous requests on page load
const globalApiRateLimit = rateLimit({
  windowMs: RATE_LIMIT_CONSTANTS.GLOBAL_API_WINDOW_MS,
  max: RATE_LIMIT_CONSTANTS.GLOBAL_API_MAX_REQUESTS,
  message: 'Too many requests, please try again later.',
  standardHeaders: true,
  legacyHeaders: false,
  skipSuccessfulRequests: true, // Don't count successful requests to be more lenient
  skip: (req) => {
    // Skip rate limiting for health check endpoint
    return req.path === '/api/health';
  },
  // Use IP-based rate limiting only
  // Note: We removed unsafe JWT parsing here for security
  // If user-specific rate limiting is needed, it should be done after authentication
  keyGenerator: (req) => {
    return req.ip || 'unknown';
  },
});

// Rate limiting for uploads
const uploadRateLimit = rateLimit({
  windowMs: RATE_LIMIT_CONSTANTS.UPLOAD_WINDOW_MS,
  max: RATE_LIMIT_CONSTANTS.UPLOAD_MAX_REQUESTS,
  message: 'Too many upload requests, please try again later.',
  standardHeaders: true,
  legacyHeaders: false,
});

// File serving via storage provider (replaces express.static)
// This route handles both local and S3 storage with S3 short-circuit for performance
app.get('/uploads/:path*', authenticate, async (req, res, next) => {
  try {
    const filePath = req.params.path + (req.params[0] || '');
    const storage = await StorageFactory.getInstance();
    
    // S3 short-circuit: return signed URL directly (offloads bandwidth to S3)
    if (storage.getDriver() === 's3') {
      const storagePath = resolveStoragePath(filePath);
      const signedUrl = await storage.signedUrl(storagePath, 3600); // 1 hour expiry
      return res.redirect(signedUrl);
    }
    
    // Local storage: stream file
    const storagePath = resolveStoragePath(filePath);
    const exists = await storage.exists(storagePath);
    
    if (!exists) {
      return res.status(404).json({ error: 'File not found' });
    }
    
    const stream = await storage.getStream(storagePath);
    const metadata = await storage.getMetadata(storagePath);
    
    res.setHeader('Content-Type', metadata.mimeType || 'application/octet-stream');
    res.setHeader('Content-Disposition', `inline; filename="${metadata.name}"`);
    res.setHeader('Cache-Control', 'public, max-age=3600');
    
    stream.pipe(res);
  } catch (error: any) {
    log.error('File serving error', error, { path: req.params.path });
    res.status(500).json({ error: 'Failed to serve file' });
  }
});

// Apply global rate limiting to all API routes
app.use('/api', globalApiRateLimit);

// API Routes
app.use('/api/auth', authRoutes);
app.use('/api/users', usersRoutes);
app.use('/api/clients', clientsRoutes);
app.use('/api/projects', projectsRoutes);
app.use('/api/timesheets', timesheetsRoutes);
app.use('/api/cost-centers', costCentersRoutes);
app.use('/api/activity-types', activityTypesRoutes);
app.use('/api/search', searchRoutes);
app.use('/api/setup', setupRoutes);
app.use('/api/xero', xeroRoutes);
app.use('/api/settings', settingsRoutes);
app.use('/api/permissions', permissionsRoutes);
app.use('/api/role-permissions', rolePermissionsRoutes);
app.use('/api/dashboard', dashboardRoutes);
app.use('/api/health', healthRoutes);
app.use('/api/troubleshooter', troubleshooterRoutes);
app.use('/api/files', filesRoutes);
app.use('/api/safety-documents', safetyDocumentsRoutes);
app.use('/api/backups', backupsRoutes);
app.use('/api/document-scan', documentScanRoutes);

// Error handling middleware (must be last)
app.use(errorHandler);

app.listen(env.PORT, async () => {
  logger.info('üöÄ AmpedFieldOps API server starting', {
    port: env.PORT,
    environment: env.NODE_ENV,
    frontendUrl: env.FRONTEND_URL,
  });
  
  // Initialize CORS cache (extracts frontend URL from Xero redirect URI)
  try {
    await initializeCorsCache();
    logger.info('üîí CORS configuration initialized');
  } catch (error) {
    log.error('‚ùå Failed to initialize CORS cache', error);
    // Don't fail startup - CORS will use fallback values
  }
  
  // Verify email configuration on startup
  try {
    const { verifyEmailConfig } = await import('./lib/email');
    await verifyEmailConfig();
  } catch (error) {
    // Email verification is optional, don't fail startup
    logger.debug('üìß Email configuration check skipped');
  }

  // Start backup scheduler
  try {
    const { startBackupScheduler } = await import('./jobs/backupScheduler');
    startBackupScheduler();
    logger.info('üíæ Backup scheduler initialized');
  } catch (error) {
    log.error('‚ùå Failed to start backup scheduler', error);
  }

  // Initialize Xero sync queue worker
  try {
    const { xeroSyncWorker } = await import('./lib/queue');
    logger.info('üîÑ Xero sync queue worker initialized');
  } catch (error) {
    log.error('‚ùå Failed to initialize Xero sync queue worker', error);
    // Don't fail startup if Redis is not available - queue will retry
  }
});

export default app;
--- FILE: postcss.config.js ---
export default {
  plugins: {
    tailwindcss: {},
    autoprefixer: {},
  },
}
--- FILE: src/lib/api.ts ---
// Use empty string as API_URL since endpoints already include /api prefix
// Nginx will proxy /api requests to backend
const API_URL = '';

import type { DocumentScan, DocumentMatch } from '@/types';

interface ApiOptions {
  method?: 'GET' | 'POST' | 'PUT' | 'DELETE';
  body?: any;
  headers?: Record<string, string>;
}

// Error logging callback type
type ErrorLogCallback = (error: {
  type: 'api' | 'client' | 'auth' | 'network' | 'unknown';
  message: string;
  details?: string;
  stack?: string;
  endpoint?: string;
  user_id?: string;
  user_name?: string;
}) => void;

// Global error logger reference (set by NotificationContext)
let errorLogCallback: ErrorLogCallback | null = null;

export function setErrorLogCallback(callback: ErrorLogCallback | null) {
  errorLogCallback = callback;
}

class ApiClient {
  private token: string | null = null;

  constructor() {
    this.token = localStorage.getItem('auth_token');
  }

  private logApiError(endpoint: string, error: Error, type: 'api' | 'auth' | 'network' = 'api') {
    if (errorLogCallback) {
      const user = this.getCurrentUserFromStorage();
      errorLogCallback({
        type,
        message: error.message,
        details: `Endpoint: ${endpoint}`,
        stack: error.stack,
        endpoint,
        user_id: user?.id,
        user_name: user?.name,
      });
    }
  }

  private getCurrentUserFromStorage() {
    try {
      const stored = localStorage.getItem('current_user');
      return stored ? JSON.parse(stored) : null;
    } catch {
      return null;
    }
  }

  setToken(token: string | null) {
    this.token = token;
    if (token) {
      localStorage.setItem('auth_token', token);
    } else {
      localStorage.removeItem('auth_token');
    }
  }

  getToken() {
    return this.token;
  }

  async request<T>(endpoint: string, options: ApiOptions = {}): Promise<T> {
    const { method = 'GET', body, headers = {} } = options;

    const config: RequestInit = {
      method,
      headers: {
        'Content-Type': 'application/json',
        ...headers,
      },
    };

    if (this.token) {
      (config.headers as Record<string, string>)['Authorization'] = `Bearer ${this.token}`;
    }

    if (body) {
      config.body = JSON.stringify(body);
    }

    try {
      const response = await fetch(`${API_URL}${endpoint}`, config);

      if (response.status === 401) {
        this.setToken(null);
        const error = new Error('Unauthorized - session expired');
        this.logApiError(endpoint, error, 'auth');
        window.location.href = '/login';
        throw error;
      }

      if (!response.ok) {
        // Try to parse JSON error response
        let errorData: any;
        let errorMessage = 'Request failed';
        
        try {
          const contentType = response.headers.get('content-type');
          if (contentType && contentType.includes('application/json')) {
            errorData = await response.json();
            errorMessage = errorData.error || errorData.message || `Request failed (${response.status})`;
          } else {
            // Non-JSON response (could be HTML error page, CORS error, etc.)
            const text = await response.text();
            errorMessage = `Request failed (${response.status} ${response.statusText})`;
            if (text && text.length < 500) {
              errorMessage += `: ${text.substring(0, 200)}`;
            }
            errorData = { error: errorMessage, status: response.status, statusText: response.statusText };
          }
        } catch (e) {
          // Failed to parse response
          errorMessage = `Request failed (${response.status} ${response.statusText})`;
          errorData = { error: errorMessage, status: response.status };
        }
        
        const error = new Error(errorMessage);
        // Don't log "User not found" on auth/me endpoint - expected when session expires
        const isExpectedAuthError = endpoint.includes('/auth/me') && error.message.includes('not found');
        if (!isExpectedAuthError) {
          this.logApiError(endpoint, error, 'api');
        }
        throw error;
      }

      return response.json();
    } catch (error: any) {
      // Network errors (fetch throws) - could be CORS, connection refused, etc.
      if (error.name === 'TypeError' && error.message.includes('fetch')) {
        // Check if it's a CORS error
        if (error.message.includes('CORS') || error.message.includes('cross-origin')) {
          const corsError = new Error('CORS error - backend may not be configured for this domain');
          this.logApiError(endpoint, corsError, 'network');
          throw corsError;
        }
        const networkError = new Error(`Network error: ${error.message}`);
        this.logApiError(endpoint, networkError, 'network');
        throw networkError;
      }
      // Re-throw already handled errors
      throw error;
    }
  }

  async uploadFile(endpoint: string, file: File, fieldName = 'file'): Promise<any> {
    const formData = new FormData();
    formData.append(fieldName, file);

    try {
      const response = await fetch(`${API_URL}${endpoint}`, {
        method: 'POST',
        headers: this.token ? { Authorization: `Bearer ${this.token}` } : {},
        body: formData,
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Upload failed' }));
        const error = new Error(errorData.error || 'Upload failed');
        this.logApiError(endpoint, error, 'api');
        throw error;
      }

      return response.json();
    } catch (error: any) {
      if (error.name === 'TypeError' && error.message.includes('fetch')) {
        const networkError = new Error('Network error during file upload');
        this.logApiError(endpoint, networkError, 'network');
        throw networkError;
      }
      throw error;
    }
  }

  // Auth
  async login(email: string, password: string) {
    const result = await this.request<{ user: any; token: string }>('/api/auth/login', {
      method: 'POST',
      body: { email, password },
    });
    this.setToken(result.token);
    return result;
  }

  async register(email: string, password: string, name: string) {
    const result = await this.request<{ user: any; token: string }>('/api/auth/register', {
      method: 'POST',
      body: { email, password, name },
    });
    this.setToken(result.token);
    return result;
  }

  async logout() {
    this.setToken(null);
  }

  async getCurrentUser() {
    return this.request<any>('/api/auth/me');
  }

  async refreshToken() {
    const result = await this.request<{ token: string }>('/api/auth/refresh', { method: 'POST' });
    this.setToken(result.token);
    return result;
  }

  async forgotPassword(email: string) {
    return this.request('/api/auth/forgot-password', { method: 'POST', body: { email } });
  }

  async resetPassword(token: string, password: string) {
    return this.request('/api/auth/reset-password', { method: 'POST', body: { token, password } });
  }

  async updateProfile(data: { name?: string; email?: string; avatar?: string }) {
    return this.request('/api/auth/profile', { method: 'PUT', body: data });
  }

  async changePassword(currentPassword: string, newPassword: string) {
    return this.request('/api/auth/change-password', { 
      method: 'PUT', 
      body: { currentPassword, newPassword } 
    });
  }

  // Setup
  async getSetupStatus() {
    return this.request<{ completed: boolean; step: number | null }>('/api/setup/status');
  }

  async setupAdmin(data: { email: string; password: string; name: string; company_name?: string; timezone?: string }) {
    const result = await this.request<{ user: any; token: string; step: number }>('/api/setup/admin', {
      method: 'POST',
      body: data,
    });
    this.setToken(result.token);
    return result;
  }

  async deleteDefaultAdmin() {
    return this.request<{ message: string }>('/api/setup/default-admin', {
      method: 'DELETE'
    });
  }

  async checkDefaultAdminExists(): Promise<boolean> {
    try {
      const status = await this.request<{ hasDefaultAdmin: boolean }>('/api/setup/default-admin-status');
      return status.hasDefaultAdmin || false;
    } catch {
      return false;
    }
  }

  async uploadLogo(file: File) {
    return this.uploadFile('/api/setup/logo', file, 'logo');
  }

  async setupCompany(data: { company_name: string; timezone?: string }) {
    return this.request('/api/setup/company', { method: 'POST', body: data });
  }

  async completeSetup() {
    return this.request('/api/setup/complete', { method: 'POST' });
  }

  async getBranding() {
    return this.request<{ company_name: string; company_logo: string | null; company_favicon?: string | null }>('/api/setup/branding');
  }

  // Dashboard
  async getDashboardMetrics() {
    return this.request<any>('/api/dashboard/metrics');
  }

  async getRecentTimesheets(limit = 5) {
    return this.request<any[]>(`/api/dashboard/recent-timesheets?limit=${limit}`);
  }

  async getActiveProjects(limit = 5) {
    return this.request<any[]>(`/api/dashboard/active-projects?limit=${limit}`);
  }

  async getQuickStats() {
    return this.request<any>('/api/dashboard/quick-stats');
  }

  // Clients
  async getClients(params?: { 
    status?: string; 
    search?: string;
    page?: number;
    limit?: number;
    sort?: string;
    order?: 'asc' | 'desc';
  }) {
    const searchParams = new URLSearchParams();
    if (params) {
      Object.entries(params).forEach(([key, value]) => {
        if (value !== undefined && value !== null && value !== '') {
          searchParams.append(key, String(value));
        }
      });
    }
    return this.request<{
      data: any[];
      pagination: {
        page: number;
        limit: number;
        total: number;
        totalPages: number;
        hasNext: boolean;
        hasPrev: boolean;
      };
    }>(`/api/clients?${searchParams}`);
  }

  async getClient(id: string) {
    return this.request<any>(`/api/clients/${id}`);
  }

  async createClient(data: any) {
    return this.request('/api/clients', { method: 'POST', body: data });
  }

  async updateClient(id: string, data: any) {
    return this.request(`/api/clients/${id}`, { method: 'PUT', body: data });
  }

  async deleteClient(id: string) {
    return this.request(`/api/clients/${id}`, { method: 'DELETE' });
  }

  // Projects
  async getProjects(params?: { 
    status?: string; 
    client_id?: string; 
    search?: string;
    page?: number;
    limit?: number;
    sort?: string;
    order?: 'asc' | 'desc';
  }) {
    const searchParams = new URLSearchParams();
    if (params) {
      Object.entries(params).forEach(([key, value]) => {
        if (value !== undefined && value !== null && value !== '') {
          searchParams.append(key, String(value));
        }
      });
    }
    return this.request<{
      data: any[];
      pagination: {
        page: number;
        limit: number;
        total: number;
        totalPages: number;
        hasNext: boolean;
        hasPrev: boolean;
      };
    }>(`/api/projects?${searchParams}`);
  }

  async getProject(id: string) {
    return this.request<any>(`/api/projects/${id}`);
  }

  async createProject(data: any) {
    return this.request('/api/projects', { method: 'POST', body: data });
  }

  async updateProject(id: string, data: any) {
    return this.request(`/api/projects/${id}`, { method: 'PUT', body: data });
  }

  async deleteProject(id: string) {
    return this.request(`/api/projects/${id}`, { method: 'DELETE' });
  }

  // Timesheets
  async getTimesheets(params?: { 
    user_id?: string; 
    project_id?: string; 
    client_id?: string;
    date_from?: string; 
    date_to?: string;
    cost_center_id?: string;
    billing_status?: string;
    page?: number;
    limit?: number;
  }) {
    const searchParams = new URLSearchParams();
    if (params) {
      Object.entries(params).forEach(([key, value]) => {
        if (value !== undefined && value !== null && value !== '') {
          searchParams.append(key, String(value));
        }
      });
    }
    return this.request<{
      data: any[];
      pagination: {
        page: number;
        limit: number;
        total: number;
        totalPages: number;
        hasNext: boolean;
        hasPrev: boolean;
      };
    }>(`/api/timesheets?${searchParams}`);
  }

  async getTimesheet(id: string) {
    return this.request<any>(`/api/timesheets/${id}`);
  }

  async createTimesheet(data: any) {
    // If there are image files, use FormData
    if (data.image_files && data.image_files.length > 0) {
      const formData = new FormData();
      formData.append('project_id', data.project_id);
      formData.append('activity_type_id', data.activity_type_id);
      formData.append('cost_center_id', data.cost_center_id);
      if (data.user_id) {
        formData.append('user_id', data.user_id);
      }
      formData.append('date', data.date);
      formData.append('hours', data.hours.toString());
      if (data.notes) formData.append('notes', data.notes);
      if (data.location) formData.append('location', data.location);
      
      data.image_files.forEach((file: File, index: number) => {
        formData.append(`images`, file);
      });

      return this.requestFormData('/api/timesheets', formData);
    }
    
    const { image_files, ...jsonData } = data;
    return this.request('/api/timesheets', { method: 'POST', body: jsonData });
  }

  async requestFormData<T>(endpoint: string, formData: FormData): Promise<T> {
    const config: RequestInit = {
      method: 'POST',
      body: formData,
    };

    if (this.token) {
      config.headers = {
        'Authorization': `Bearer ${this.token}`,
      };
    }

    const response = await fetch(`${API_URL}${endpoint}`, config);

    if (response.status === 401) {
      this.setToken(null);
      window.location.href = '/login';
      throw new Error('Unauthorized');
    }

    if (!response.ok) {
      const error = await response.json().catch(() => ({ error: 'Request failed' }));
      throw new Error(error.error || error.message || 'Request failed');
    }

    return response.json();
  }

  async updateTimesheet(id: string, data: any) {
    // If data is FormData, use requestFormData
    if (data instanceof FormData) {
      const config: RequestInit = {
        method: 'PUT',
        body: data,
      };

      if (this.token) {
        config.headers = {
          'Authorization': `Bearer ${this.token}`,
        };
      }

      const response = await fetch(`${API_URL}/api/timesheets/${id}`, config);

      if (response.status === 401) {
        this.setToken(null);
        window.location.href = '/login';
        throw new Error('Unauthorized');
      }

      if (!response.ok) {
        const error = await response.json().catch(() => ({ error: 'Request failed' }));
        throw new Error(error.error || error.message || 'Request failed');
      }

      return response.json();
    }
    
    // Otherwise, use regular JSON request
    return this.request(`/api/timesheets/${id}`, { method: 'PUT', body: data });
  }

  async deleteTimesheet(id: string) {
    return this.request(`/api/timesheets/${id}`, { method: 'DELETE' });
  }

  async uploadTimesheetImages(id: string, files: File[]) {
    const formData = new FormData();
    files.forEach(file => formData.append('images', file));

    const response = await fetch(`${API_URL}/api/timesheets/${id}/images`, {
      method: 'POST',
      headers: this.token ? { Authorization: `Bearer ${this.token}` } : {},
      body: formData,
    });

    if (!response.ok) throw new Error('Upload failed');
    return response.json();
  }

  async deleteTimesheetImage(timesheetId: string, imageIndex: number) {
    return this.request(`/api/timesheets/${timesheetId}/images/${imageIndex}`, { method: 'DELETE' });
  }

  // Timesheet Images
  async getTimesheetImages(projectId?: string) {
    if (projectId) {
      return this.request<Array<{
        url: string;
        filename: string;
        timesheet_id: string;
        timesheet_date: string;
        upload_date: string;
        user_name: string;
        project_code: string;
        project_name: string;
        image_index: number;
      }>>(`/api/files/timesheet-images/${projectId}`);
    }
    return this.request<Array<{
      project_id: string;
      project_code: string;
      project_name: string;
      client_name: string;
      timesheets_with_images: number;
      total_images: number;
    }>>('/api/files/timesheet-images');
  }

  // Logos
  async getLogos() {
    return this.request<Array<{
      url: string;
      filename: string;
      upload_date: string;
      file_size: number;
    }>>('/api/files/logos');
  }

  async deleteLogo(filename: string) {
    return this.request<{ message: string }>(`/api/files/logos/${encodeURIComponent(filename)}`, { method: 'DELETE' });
  }

  // Cost Centers
  async getCostCenters(activeOnly = false, projectId?: string) {
    const params = new URLSearchParams();
    if (activeOnly) params.append('active_only', 'true');
    if (projectId) params.append('project_id', projectId);
    return this.request<any[]>(`/api/cost-centers?${params}`);
  }

  async getCostCenter(id: string) {
    return this.request<any>(`/api/cost-centers/${id}`);
  }

  async createCostCenter(data: any) {
    return this.request('/api/cost-centers', { method: 'POST', body: data });
  }

  async updateCostCenter(id: string, data: any) {
    return this.request(`/api/cost-centers/${id}`, { method: 'PUT', body: data });
  }

  async deleteCostCenter(id: string) {
    return this.request(`/api/cost-centers/${id}`, { method: 'DELETE' });
  }

  // Activity Types
  async getActivityTypes(activeOnly = false) {
    return this.request<any[]>(`/api/activity-types?active_only=${activeOnly}`);
  }

  async getActivityType(id: string) {
    return this.request<any>(`/api/activity-types/${id}`);
  }

  async createActivityType(data: any) {
    return this.request('/api/activity-types', { method: 'POST', body: data });
  }

  async updateActivityType(id: string, data: any) {
    return this.request(`/api/activity-types/${id}`, { method: 'PUT', body: data });
  }

  async deleteActivityType(id: string) {
    return this.request(`/api/activity-types/${id}`, { method: 'DELETE' });
  }

  // Users
  async getUsers() {
    return this.request<any[]>('/api/users');
  }

  async getUser(id: string) {
    return this.request<any>(`/api/users/${id}`);
  }

  async createUser(data: any) {
    return this.request('/api/users', { method: 'POST', body: data });
  }

  async updateUser(id: string, data: any) {
    return this.request(`/api/users/${id}`, { method: 'PUT', body: data });
  }

  async updateUserPermissions(id: string, permissions: { permission: string; granted: boolean }[]) {
    return this.request(`/api/users/${id}/permissions`, { method: 'PUT', body: { permissions } });
  }

  async deleteUser(id: string) {
    return this.request(`/api/users/${id}`, { method: 'DELETE' });
  }

  // Search
  async search(query: string, type?: string) {
    return this.request<{ clients: any[]; projects: any[]; timesheets: any[] }>(
      `/api/search?q=${encodeURIComponent(query)}${type ? `&type=${type}` : ''}`
    );
  }

  async getRecentSearches() {
    return this.request<any[]>('/api/search/recent');
  }

  async clearRecentSearches() {
    return this.request('/api/search/recent', { method: 'DELETE' });
  }

  // Settings
  async getSettings() {
    return this.request<Record<string, any>>('/api/settings');
  }

  async getSetting(key: string) {
    return this.request<{ key: string; value: any }>(`/api/settings/${key}`);
  }

  async updateSetting(key: string, value: any, global = false) {
    return this.request(`/api/settings/${key}`, { method: 'PUT', body: { value, global } });
  }

  async updateSettings(settings: { key: string; value: any }[], global = false) {
    return this.request('/api/settings', { method: 'PUT', body: { settings, global } });
  }

  async uploadCompanyLogo(file: File) {
    return this.uploadFile('/api/settings/logo', file, 'logo');
  }

  async uploadFavicon(file: File) {
    return this.uploadFile('/api/settings/favicon', file, 'favicon');
  }

  async sendTestEmail(email: string) {
    return this.request<{ message: string }>('/api/settings/email/test', {
      method: 'POST',
      body: { email },
    });
  }

  async getActivityLogs(params?: { user_id?: string; action?: string; limit?: number; offset?: number }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<{ logs: any[]; total: number }>(`/api/settings/logs/activity?${searchParams}`);
  }

  // Permissions
  async getPermissions() {
    return this.request<any[]>('/api/permissions');
  }

  async getPermission(id: string) {
    return this.request<any>(`/api/permissions/${id}`);
  }

  async createPermission(data: { key: string; label: string; description?: string }) {
    return this.request<any>('/api/permissions', { method: 'POST', body: data });
  }

  async updatePermission(id: string, data: { label?: string; description?: string; is_active?: boolean }) {
    return this.request<any>(`/api/permissions/${id}`, { method: 'PUT', body: data });
  }

  async deletePermission(id: string) {
    return this.request(`/api/permissions/${id}`, { method: 'DELETE' });
  }

  // Role Permissions
  async getRolePermissions() {
    return this.request<{ permissions: Array<{ key: string; label: string; description: string }>; rolePermissions: Record<string, Record<string, boolean>> }>('/api/role-permissions');
  }

  async updateRolePermissions(rolePermissions: Record<string, Record<string, boolean>>) {
    return this.request('/api/role-permissions', {
      method: 'PUT',
      body: { rolePermissions }
    });
  }

  // Xero
  async getXeroAuthUrl() {
    return this.request<{ 
      url: string; 
      configured: boolean;
      redirectUri?: string;
      clientId?: string;
      clientIdPrefix?: string;
      verification?: {
        redirectUriMatch?: string;
        clientIdMatch?: string;
        xeroAppUrl?: string;
      };
    }>('/api/xero/auth/url');
  }

  async getHealthStatus() {
    return this.request('/api/health', { method: 'GET' });
  }

  async getXeroStatus() {
    return this.request<{
      connected: boolean;
      configured: boolean;
      tenant_name?: string;
      last_sync?: string;
    }>('/api/xero/status');
  }

  async disconnectXero() {
    return this.request('/api/xero/disconnect', { method: 'DELETE' });
  }

  async syncXero(type: 'contacts' | 'invoices' | 'tracking_categories' | 'all') {
    return this.request('/api/xero/sync', { method: 'POST', body: { type } });
  }

  // Pull contacts from Xero to local clients
  async pullXeroContacts() {
    return this.request<{
      success: boolean;
      synced_at: string;
      results: { total: number; created: number; updated: number; skipped: number };
    }>('/api/xero/contacts/pull', { method: 'POST' });
  }

  // Push a single client to Xero
  async pushClientToXero(clientId: string) {
    return this.request<{
      success: boolean;
      action: 'created' | 'updated';
      xero_contact_id: string;
    }>(`/api/xero/contacts/push/${clientId}`, { method: 'POST' });
  }

  // Push all local clients without xero_contact_id to Xero
  async pushAllClientsToXero() {
    return this.request<{
      success: boolean;
      synced_at: string;
      results: { total: number; created: number; failed: number };
    }>('/api/xero/contacts/push-all', { method: 'POST' });
  }

  async getXeroInvoices(params?: { status?: string; client_id?: string; date_from?: string; date_to?: string; include_deleted?: boolean }) {
    const searchParams = new URLSearchParams();
    if (params) {
      Object.entries(params).forEach(([key, value]) => {
        if (value !== undefined && value !== null) {
          searchParams.append(key, String(value));
        }
      });
    }
    return this.request<any[]>(`/api/xero/invoices?${searchParams}`);
  }

  async createXeroInvoice(data: any) {
    return this.request('/api/xero/invoices', { method: 'POST', body: data });
  }

  async previewInvoiceFromTimesheets(data: { client_id: string; project_id?: string; date_from?: string; date_to?: string; period?: 'week' | 'month' }) {
    const response = await fetch(`${API_URL}/api/xero/invoices/from-timesheets/preview`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(this.token ? { Authorization: `Bearer ${this.token}` } : {}),
      },
      body: JSON.stringify(data),
    });
    if (!response.ok) {
      const error = await response.json();
      throw new Error(error.error || 'Failed to preview invoice');
    }
    return response.json();
  }

  async createInvoiceFromTimesheets(data: { client_id: string; project_id?: string; date_from?: string; date_to?: string; period?: 'week' | 'month'; due_date?: string; invoice_number?: string }) {
    const response = await fetch(`${API_URL}/api/xero/invoices/from-timesheets`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(this.token ? { Authorization: `Bearer ${this.token}` } : {}),
      },
      body: JSON.stringify(data),
    });

    const result = await response.json();
    
    // Handle 202 Accepted (async sync)
    if (response.status === 202) {
      return { ...result, sync_status: 'pending', async: true };
    }
    
    if (!response.ok) {
      throw new Error(result.error || 'Failed to create invoice from timesheets');
    }
    
    return result;
  }

  async getSyncLogs(entityType: string, entityId: string) {
    return this.request<any[]>(`/api/xero/sync-logs?entity_type=${entityType}&entity_id=${entityId}`);
  }

  async getInvoiceSyncStatus(invoiceId: string) {
    return this.request<{ sync_status: string; xero_sync_id?: string }>(`/api/xero/invoices/${invoiceId}/sync-status`);
  }

  async getPOSyncStatus(poId: string) {
    return this.request<{ sync_status: string; xero_sync_id?: string }>(`/api/xero/purchase-orders/${poId}/sync-status`);
  }

  async markInvoiceAsPaid(invoiceId: string) {
    return this.request(`/api/xero/invoices/${invoiceId}/paid`, { method: 'PUT' });
  }

  async getXeroQuotes() {
    return this.request<any[]>('/api/xero/quotes');
  }

  async createXeroQuote(data: any) {
    return this.request('/api/xero/quotes', { method: 'POST', body: data });
  }

  async convertQuoteToInvoice(quoteId: string) {
    return this.request(`/api/xero/quotes/${quoteId}/convert`, { method: 'POST' });
  }

  async getXeroFinancialSummary() {
    return this.request<any>('/api/xero/summary');
  }

  // Payments
  async getPayments(params?: { invoice_id?: string; date_from?: string; date_to?: string; payment_method?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any[]>(`/api/xero/payments?${searchParams}`);
  }

  async createPayment(data: { invoice_id: string; amount: number; payment_date: string; payment_method: string; reference?: string; account_code?: string; currency?: string }) {
    return this.request<any>('/api/xero/payments', { method: 'POST', body: data });
  }

  async markInvoiceAsPaidXero(invoiceId: string, data?: { amount?: number; payment_date?: string; payment_method?: string; reference?: string; account_code?: string }) {
    return this.request<any>(`/api/xero/invoices/${invoiceId}/mark-paid`, { method: 'PUT', body: data || {} });
  }

  // Bank Transactions
  async getBankTransactions(params?: { date_from?: string; date_to?: string; reconciled?: boolean; payment_id?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any[]>(`/api/xero/bank-transactions?${searchParams}`);
  }

  async importBankTransactions(data?: { date_from?: string; date_to?: string }) {
    return this.request<{ success: boolean; imported: number; message: string }>('/api/xero/bank-transactions', { method: 'POST', body: data || {} });
  }

  async reconcileTransaction(data: { transaction_id: string; payment_id: string }) {
    return this.request<{ success: boolean; message: string }>('/api/xero/reconcile', { method: 'POST', body: data });
  }

  // Purchase Orders
  async getPurchaseOrders(params?: { project_id?: string; supplier_id?: string; status?: string; date_from?: string; date_to?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any[]>(`/api/xero/purchase-orders?${searchParams}`);
  }

  async getPurchaseOrder(id: string) {
    return this.request<any>(`/api/xero/purchase-orders/${id}`);
  }

  async getPurchaseOrdersByProject(projectId: string) {
    return this.request<any[]>(`/api/xero/purchase-orders/project/${projectId}`);
  }

  async getPurchaseOrdersByCostCenter(costCenterId: string) {
    return this.request<any[]>(`/api/xero/purchase-orders/cost-center/${costCenterId}`);
  }

  async createPurchaseOrder(data: { supplier_id: string; project_id: string; date: string; delivery_date?: string; line_items: Array<{ description: string; quantity: number; unit_amount: number; account_code?: string; cost_center_id?: string; item_id?: string }>; notes?: string; currency?: string }) {
    const response = await fetch(`${API_URL}/api/xero/purchase-orders`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        ...(this.token ? { Authorization: `Bearer ${this.token}` } : {}),
      },
      body: JSON.stringify(data),
    });

    const result = await response.json();
    
    // Handle 202 Accepted (async sync)
    if (response.status === 202) {
      return { ...result, sync_status: 'pending', async: true };
    }
    
    if (!response.ok) {
      throw new Error(result.error || 'Failed to create purchase order');
    }
    
    return result;
  }

  async updatePurchaseOrder(id: string, data: { status?: string }) {
    return this.request<any>(`/api/xero/purchase-orders/${id}`, { method: 'PUT', body: data });
  }

  async convertPurchaseOrderToBill(poId: string) {
    return this.request<any>(`/api/xero/purchase-orders/${poId}/convert-to-bill`, { method: 'POST' });
  }

  // Bills
  async getBills(params?: { supplier_id?: string; project_id?: string; purchase_order_id?: string; status?: string; date_from?: string; date_to?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any[]>(`/api/xero/bills?${searchParams}`);
  }

  async createBill(data: { supplier_id: string; purchase_order_id?: string; project_id?: string; date: string; due_date?: string; line_items: Array<{ description: string; quantity: number; unit_amount: number; account_code?: string }>; reference?: string; currency?: string }) {
    return this.request<any>('/api/xero/bills', { method: 'POST', body: data });
  }

  async markBillAsPaid(billId: string, data?: { amount?: number }) {
    return this.request<any>(`/api/xero/bills/${billId}/pay`, { method: 'POST', body: data || {} });
  }

  // Expenses
  async getExpenses(params?: { project_id?: string; cost_center_id?: string; status?: string; date_from?: string; date_to?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any[]>(`/api/xero/expenses?${searchParams}`);
  }

  async createExpense(data: { project_id?: string; cost_center_id?: string; amount: number; date: string; description: string; receipt_url?: string; currency?: string }) {
    return this.request<any>('/api/xero/expenses', { method: 'POST', body: data });
  }

  // Credit Notes
  async getCreditNotes(params?: { invoice_id?: string; date_from?: string; date_to?: string; status?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any[]>(`/api/xero/credit-notes?${searchParams}`);
  }

  async createCreditNote(data: { invoice_id: string; amount: number; date: string; reason?: string; description?: string; currency?: string }) {
    return this.request<any>('/api/xero/credit-notes', { method: 'POST', body: data });
  }

  async applyCreditNote(creditNoteId: string) {
    return this.request<{ success: boolean; message: string }>(`/api/xero/credit-notes/${creditNoteId}/apply`, { method: 'POST' });
  }

  // Items/Inventory
  async getItems(params?: { search?: string; is_tracked?: boolean }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any[]>(`/api/xero/items?${searchParams}`);
  }

  async getItem(id: string) {
    return this.request<any>(`/api/xero/items/${id}`);
  }

  async syncItems() {
    return this.request<{ success: boolean; synced: number; message: string }>('/api/xero/items/sync', { method: 'POST' });
  }

  async updateItemStock(itemId: string, stockLevel: number) {
    return this.request<any>(`/api/xero/items/${itemId}/stock`, { method: 'PUT', body: { stock_level: stockLevel } });
  }

  // Payment Reminders
  async getReminderSchedule() {
    return this.request<any>('/api/xero/reminders/schedule');
  }

  async updateReminderSchedule(schedule: { days_after_due: number[]; email_template?: string; enabled: boolean }) {
    return this.request<any>('/api/xero/reminders/schedule', { method: 'PUT', body: schedule });
  }

  async sendPaymentReminder(data: { invoice_id: string; reminder_type?: string }) {
    return this.request<{ success: boolean; message: string }>('/api/xero/reminders/send', { method: 'POST', body: data });
  }

  async processPaymentReminders() {
    return this.request<{ success: boolean; sent: number; failed: number }>('/api/xero/reminders/process', { method: 'POST' });
  }

  async getReminderHistory(params?: { invoice_id?: string; date_from?: string; date_to?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any[]>(`/api/xero/reminders/history?${searchParams}`);
  }

  // Financial Reports
  async getProfitLossReport(params?: { date_from?: string; date_to?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any>(`/api/xero/reports/profit-loss?${searchParams}`);
  }

  async getBalanceSheetReport(params?: { date?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any>(`/api/xero/reports/balance-sheet?${searchParams}`);
  }

  async getCashFlowReport(params?: { date_from?: string; date_to?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any>(`/api/xero/reports/cash-flow?${searchParams}`);
  }

  async getAgedReceivablesReport(params?: { date?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any>(`/api/xero/reports/aged-receivables?${searchParams}`);
  }

  async getAgedPayablesReport(params?: { date?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any>(`/api/xero/reports/aged-payables?${searchParams}`);
  }

  // Webhooks
  async getWebhookStatus() {
    return this.request<any>('/api/xero/webhooks/status');
  }

  async getWebhookEvents(params?: { event_type?: string; processed?: boolean; date_from?: string; date_to?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<any[]>(`/api/xero/webhooks/events?${searchParams}`);
  }

  // Project Financials
  async getProjectFinancials(projectId: string) {
    return this.request<any>(`/api/projects/${projectId}/financials`);
  }

  // Troubleshooter
  async runTroubleshooter(category?: string) {
    return this.request<{
      success: boolean;
      totalTests: number;
      passed: number;
      failed: number;
      skipped: number;
      duration: number;
      results: Array<{
        id: string;
        name: string;
        category: string;
        status: 'passed' | 'failed' | 'skipped';
        duration: number;
        message: string;
        error?: {
          message: string;
          stack?: string;
          details?: any;
        };
        timestamp: string;
      }>;
      timestamp: string;
    }>('/api/troubleshooter/run', {
      method: 'POST',
      body: category ? { category } : {},
    });
  }

  async getTroubleshooterRoutes() {
    return this.request<Array<{
      method: string;
      path: string;
      file: string;
      middleware: string[];
    }>>('/api/troubleshooter/routes');
  }

  async getTroubleshooterSuites() {
    return this.request<Array<{
      name: string;
      category: string;
    }>>('/api/troubleshooter/suites');
  }

  // File Management
  async getFiles(params?: { project_id?: string; cost_center_id?: string; file_type?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<import('../types').ProjectFile[]>(`/api/files?${searchParams}`);
  }

  async getFile(id: string) {
    return this.request<import('../types').ProjectFile>(`/api/files/${id}`);
  }


  async uploadProjectFile(file: File, projectId: string, costCenterId?: string): Promise<import('../types').ProjectFile> {
    // Create FormData manually to include additional fields
    const formData = new FormData();
    formData.append('file', file);
    formData.append('project_id', projectId);
    if (costCenterId) {
      formData.append('cost_center_id', costCenterId);
    }

    const headers: Record<string, string> = {};
    if (this.token) {
      headers['Authorization'] = `Bearer ${this.token}`;
    }

    try {
      const response = await fetch(`${API_URL}/api/files`, {
        method: 'POST',
        headers,
        body: formData,
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Upload failed' }));
        const error = new Error(errorData.error || 'Upload failed');
        this.logApiError('/api/files', error, 'api');
        throw error;
      }

      return response.json();
    } catch (error: any) {
      if (error.name === 'TypeError' && error.message.includes('fetch')) {
        const networkError = new Error('Network error during file upload');
        this.logApiError('/api/files', networkError, 'network');
        throw networkError;
      }
      throw error;
    }
  }

  async deleteFile(id: string) {
    return this.request<{ message: string }>(`/api/files/${id}`, { method: 'DELETE' });
  }

  async downloadFile(id: string): Promise<Blob> {
    const response = await fetch(`/api/files/${id}/download`, {
      headers: {
        'Authorization': `Bearer ${this.getToken()}`,
      },
    });
    if (!response.ok) {
      throw new Error('Failed to download file');
    }
    return response.blob();
  }

  async getProjectFiles(projectId: string) {
    return this.request<import('../types').ProjectFile[]>(`/api/files/projects/${projectId}`);
  }

  async getCostCenterFiles(costCenterId: string) {
    return this.request<import('../types').ProjectFile[]>(`/api/files/cost-centers/${costCenterId}`);
  }

  // Safety Documents
  async getSafetyDocuments(params?: { project_id?: string; cost_center_id?: string; document_type?: string; status?: string }) {
    const searchParams = new URLSearchParams(params as Record<string, string>);
    return this.request<import('../types').SafetyDocument[]>(`/api/safety-documents?${searchParams}`);
  }

  async getSafetyDocument(id: string) {
    return this.request<import('../types').SafetyDocument>(`/api/safety-documents/${id}`);
  }

  async createSafetyDocument(data: {
    project_id: string;
    cost_center_id?: string;
    document_type: 'jsa' | 'electrical_compliance' | 'electrical_safety_certificate';
    title: string;
    data: import('../types').JSAData | import('../types').ComplianceData | import('../types').SafetyCertificateData;
    status?: 'draft' | 'completed' | 'approved';
  }) {
    return this.request<import('../types').SafetyDocument>('/api/safety-documents', { method: 'POST', body: data });
  }

  async updateSafetyDocument(id: string, data: {
    title?: string;
    data?: import('../types').JSAData | import('../types').ComplianceData | import('../types').SafetyCertificateData;
    status?: 'draft' | 'completed' | 'approved';
  }) {
    return this.request<import('../types').SafetyDocument>(`/api/safety-documents/${id}`, { method: 'PUT', body: data });
  }

  async deleteSafetyDocument(id: string) {
    return this.request<{ message: string }>(`/api/safety-documents/${id}`, { method: 'DELETE' });
  }

  async generateSafetyDocumentPDF(id: string) {
    return this.request<{ message: string; file_path: string }>(`/api/safety-documents/${id}/generate-pdf`, { method: 'POST' });
  }

  async downloadSafetyDocumentPDF(id: string): Promise<Blob> {
    const response = await fetch(`/api/safety-documents/${id}/pdf`, {
      headers: {
        'Authorization': `Bearer ${this.getToken()}`,
      },
    });
    if (!response.ok) {
      throw new Error('Failed to download PDF');
    }
    return response.blob();
  }

  // Backups
  async getBackups() {
    return this.request<any[]>('/api/backups');
  }

  async getBackup(id: string) {
    return this.request<any>(`/api/backups/${id}`);
  }

  // Storage Settings
  async getStorageSettings() {
    return this.request<{
      driver: 'local' | 's3' | 'google-drive';
      basePath?: string;
      s3Bucket?: string;
      s3Region?: string;
      s3AccessKeyId?: string;
      s3SecretAccessKey?: string;
      s3Endpoint?: string;
      googleDriveFolderId?: string;
      googleDriveConnected?: boolean;
    }>('/api/settings/storage');
  }

  async updateStorageSettings(data: {
    driver: 'local' | 's3' | 'google-drive';
    basePath?: string;
    s3Bucket?: string;
    s3Region?: string;
    s3AccessKeyId?: string;
    s3SecretAccessKey?: string;
    s3Endpoint?: string;
    googleDriveFolderId?: string;
  }) {
    return this.request('/api/settings/storage', { method: 'PUT', body: data });
  }

  async testStorageConnection(data: {
    driver: 'local' | 's3' | 'google-drive';
    basePath?: string;
    s3Bucket?: string;
    s3Region?: string;
    s3AccessKeyId?: string;
    s3SecretAccessKey?: string;
    s3Endpoint?: string;
    googleDriveFolderId?: string;
  }) {
    return this.request<{ success: boolean; message: string }>('/api/settings/storage/test', { method: 'POST', body: data });
  }

  async createBackup(data: { type: 'full' | 'database' | 'files'; storage_type?: 'local' | 'google_drive' }) {
    return this.request<any>('/api/backups', { method: 'POST', body: data });
  }

  async downloadBackup(id: string): Promise<Blob> {
    const response = await fetch(`/api/backups/${id}/download`, {
      headers: {
        'Authorization': `Bearer ${this.getToken()}`,
      },
    });
    if (!response.ok) {
      throw new Error('Failed to download backup');
    }
    return response.blob();
  }

  async deleteBackup(id: string) {
    return this.request<{ message: string }>(`/api/backups/${id}`, { method: 'DELETE' });
  }

  async restoreBackup(id: string, confirm: boolean = true) {
    return this.request<{ message: string }>(`/api/backups/${id}/restore`, { 
      method: 'POST', 
      body: { confirm } 
    });
  }

  async getGoogleDriveAuthUrl() {
    return this.request<{ url: string }>('/api/backups/google-drive/auth');
  }

  async getGoogleDriveStatus() {
    return this.request<{ connected: boolean }>('/api/backups/google-drive/status');
  }

  async getBackupSchedule() {
    return this.request<{
      enabled: boolean;
      frequency: string;
      retention_days: number;
      backup_type: 'full' | 'database' | 'files';
      storage_type: 'local' | 'google_drive';
    }>('/api/backups/schedule');
  }

  async updateBackupSchedule(schedule: {
    enabled: boolean;
    frequency: string;
    retention_days: number;
    backup_type: 'full' | 'database' | 'files';
    storage_type: 'local' | 'google_drive';
  }) {
    return this.request<{ message: string; schedule: any }>('/api/backups/schedule', {
      method: 'POST',
      body: schedule
    });
  }

  async cleanupBackups(retention_days: number = 30) {
    return this.request<{ message: string }>('/api/backups/cleanup', {
      method: 'POST',
      body: { retention_days }
    });
  }

  async testS3Connection(config: { accessKeyId: string; secretAccessKey: string; region: string; bucket: string }) {
    return this.request<{ message: string }>('/api/settings/test-s3', {
      method: 'POST',
      body: config
    });
  }

  // Document Scanning API methods
  async uploadDocumentForScan(file: File, projectId: string, costCenterId?: string, processOCR: boolean = true) {
    const formData = new FormData();
    formData.append('file', file);
    formData.append('project_id', projectId);
    if (costCenterId) {
      formData.append('cost_center_id', costCenterId);
    }
    formData.append('process_ocr', String(processOCR));

    try {
      const response = await fetch(`${API_URL}/api/document-scan/upload`, {
        method: 'POST',
        headers: this.token ? { Authorization: `Bearer ${this.token}` } : {},
        body: formData,
      });

      if (!response.ok) {
        const errorData = await response.json().catch(() => ({ error: 'Upload failed' }));
        const error = new Error(errorData.error || 'Upload failed');
        this.logApiError('/api/document-scan/upload', error, 'api');
        throw error;
      }

      return response.json();
    } catch (error: any) {
      if (error.name === 'TypeError' && error.message.includes('fetch')) {
        const networkError = new Error('Network error during file upload');
        this.logApiError('/api/document-scan/upload', networkError, 'network');
        throw networkError;
      }
      throw error;
    }
  }

  async getDocumentScan(scanId: string) {
    return this.request<DocumentScan>(`/api/document-scan/${scanId}`);
  }

  async getDocumentScans(params?: { project_id?: string; status?: string; document_type?: string }) {
    const queryParams = new URLSearchParams();
    if (params?.project_id) queryParams.append('project_id', params.project_id);
    if (params?.status) queryParams.append('status', params.status);
    if (params?.document_type) queryParams.append('document_type', params.document_type);
    
    const query = queryParams.toString();
    return this.request<DocumentScan[]>(`/api/document-scan${query ? `?${query}` : ''}`);
  }

  async getDocumentMatches(scanId: string) {
    return this.request<DocumentMatch[]>(`/api/document-scan/${scanId}/matches`);
  }

  async confirmDocumentMatch(scanId: string, matchId: string) {
    return this.request<{ success: boolean; message: string; match: DocumentMatch }>(
      `/api/document-scan/${scanId}/match/${matchId}/confirm`,
      { method: 'POST' }
    );
  }

  async rejectDocumentMatches(scanId: string) {
    return this.request<{ success: boolean; message: string }>(
      `/api/document-scan/${scanId}/match/reject`,
      { method: 'POST' }
    );
  }

  async retryDocumentScan(scanId: string) {
    return this.request<{ success: boolean; message: string; scan: { id: string; status: string } }>(
      `/api/document-scan/${scanId}/retry`,
      { method: 'POST' }
    );
  }
}

export const api = new ApiClient();
export default api;
--- FILE: src/lib/favicon.ts ---
/**
 * Utility functions for managing the favicon
 */

/**
 * Updates the favicon in the document head
 * @param faviconUrl - URL to the favicon file
 */
export function updateFavicon(faviconUrl: string | null | undefined) {
  if (!faviconUrl) return;
  
  // Remove existing favicon links
  const existingLinks = document.querySelectorAll("link[rel*='icon']");
  existingLinks.forEach(link => link.remove());
  
  // Add new favicon link
  const link = document.createElement('link');
  link.rel = 'icon';
  link.type = faviconUrl.endsWith('.svg') ? 'image/svg+xml' : 
              faviconUrl.endsWith('.ico') ? 'image/x-icon' : 
              'image/png';
  link.href = faviconUrl;
  document.head.appendChild(link);
}

/**
 * Loads favicon from settings API
 */
export async function loadFaviconFromSettings(api: any) {
  try {
    const settings = await api.getSettings();
    if (settings.company_favicon) {
      updateFavicon(settings.company_favicon);
    }
  } catch (error) {
    // Silently fail - favicon is not critical
    console.debug('Failed to load favicon from settings:', error);
  }
}

--- FILE: src/lib/utils.ts ---
import { type ClassValue, clsx } from "clsx"
import { twMerge } from "tailwind-merge"

export function cn(...inputs: ClassValue[]) {
  return twMerge(clsx(inputs))
}
--- FILE: src/types/index.ts ---
export type ProjectStatus = 'quoted' | 'in-progress' | 'completed' | 'invoiced' | 'paid';
export type UserRole = 'admin' | 'manager' | 'user';

export interface Client {
  id: string;
  name: string;
  contact_name: string;
  email: string;
  phone: string;
  address: string;
  location: string;
  billing_address?: string;
  billing_email?: string;
  xero_contact_id?: string;
  client_type?: 'customer' | 'supplier' | 'both';
  status: 'active' | 'inactive';
  notes?: string;
  created_at: string;
  updated_at: string;
  // Computed fields
  active_projects?: number;
  total_hours?: number;
  last_contact?: string;
  last_activity?: string;
  // Supplier-specific computed fields
  total_purchase_orders?: number;
  total_bills?: number;
  total_spent?: number;
}

export interface CostCenter {
  id: string;
  code: string;
  name: string;
  description: string;
  budget: number;
  project_id?: string; // Job-specific cost center
  project_name?: string;
  xero_tracking_category_id?: string;
  client_po_number?: string; // Client-supplied purchase order number
  is_active: boolean;
  created_at: string;
  updated_at: string;
  // Computed fields
  project_count?: number;
  total_hours?: number;
  total_cost?: number;
  actual_cost?: number;
  remaining_budget?: number;
}

export interface ActivityType {
  id: string;
  name: string;
  icon: string;
  color: string;
  hourly_rate: number;
  is_active: boolean;
  created_at: string;
  updated_at: string;
  usage_count?: number;
}

export interface Project {
  id: string;
  code: string;
  name: string;
  client_id: string;
  client_name?: string;
  status: ProjectStatus;
  budget: number;
  actual_cost: number;
  description: string;
  start_date: string;
  end_date?: string;
  xero_project_id?: string;
  files: string[];
  created_at: string;
  updated_at: string;
  // Computed and related fields
  hours_logged?: number;
  cost_centers?: CostCenter[];
  cost_center_ids?: string[];
  cost_center_codes?: string[];
}

export interface TimesheetEntry {
  id: string;
  user_id: string;
  project_id: string;
  client_id: string;
  activity_type_id: string;
  cost_center_id: string;
  date: string;
  hours: number;
  notes: string;
  image_urls: string[];
  cloud_image_urls?: string[]; // Cloud storage URLs for images
  location?: string;
  synced: boolean;
  xero_timesheet_id?: string;
  billing_status?: 'unbilled' | 'billed' | 'paid';
  invoice_id?: string;
  created_at: string;
  updated_at: string;
  // Joined fields
  user_name?: string;
  project_name?: string;
  project_code?: string;
  client_name?: string;
  activity_type_name?: string;
  activity_type_icon?: string;
  activity_type_color?: string;
  cost_center_code?: string;
  cost_center_name?: string;
}

export interface User {
  id: string;
  name: string;
  email: string;
  role: UserRole;
  avatar?: string;
  is_active: boolean;
  permissions: string[];
  created_at: string;
  updated_at: string;
}

export interface Permission {
  permission: string;
  granted: boolean;
}

export interface DashboardMetrics {
  totalProjects: number;
  activeProjects: number;
  totalHours: number;
  totalRevenue: number;
  projectsTrend: number;
  hoursTrend: number;
  revenueTrend: number;
  activeTeam: number;
  recentActivity: Array<{
    date: string;
    hours: number;
  }>;
}

export interface QuickStats {
  budgetUtilization: number;
  projectsOnTrack: number;
  overdueProjects: number;
}

export interface DocumentScan {
  id: string;
  file_id: string;
  user_id: string;
  status: 'pending' | 'processing' | 'completed' | 'failed';
  document_type?: 'receipt' | 'invoice' | 'purchase_order' | 'bill' | 'expense' | 'unknown';
  extracted_data?: {
    document_number?: string;
    date?: string;
    amount?: number;
    total_amount?: number;
    tax_amount?: number;
    vendor_name?: string;
    vendor_address?: string;
    line_items?: any[];
    raw_text?: string;
  };
  confidence?: number;
  error_message?: string;
  xero_attachment_id?: string;
  processed_at?: string;
  created_at: string;
  updated_at: string;
  file_name?: string;
  file_path?: string;
  mime_type?: string;
  user_name?: string;
  project_code?: string;
  project_name?: string;
}

export interface DocumentMatch {
  id: string;
  scan_id: string;
  entity_type: 'purchase_order' | 'invoice' | 'bill' | 'expense';
  entity_id: string;
  confidence_score: number;
  match_reasons: string[];
  confirmed: boolean;
  confirmed_by?: string;
  confirmed_at?: string;
  created_at: string;
  entity_name?: string;
  entity_amount?: number;
}

export interface XeroInvoice {
  id: string;
  xero_invoice_id: string;
  invoice_number: string;
  client_id: string;
  client_name?: string;
  project_id?: string;
  status: string;
  amount_due: number;
  amount_paid: number;
  total: number;
  currency: string;
  issue_date: string;
  due_date: string;
  line_items: any[];
  synced_at: string;
}

export interface XeroQuote {
  id: string;
  xero_quote_id: string;
  quote_number: string;
  client_id: string;
  client_name?: string;
  project_id?: string;
  status: string;
  total: number;
  currency: string;
  issue_date: string;
  expiry_date: string;
  line_items: any[];
  synced_at: string;
}

export interface XeroPayment {
  id: string;
  xero_payment_id?: string;
  invoice_id: string;
  invoice_number?: string;
  client_name?: string;
  amount: number;
  payment_date: string;
  payment_method: 'CASH' | 'CHECK' | 'BANK_TRANSFER' | 'CREDIT_CARD' | 'ONLINE';
  reference?: string;
  account_code?: string;
  currency: string;
  created_at: string;
}

export interface BankTransaction {
  id: string;
  xero_bank_transaction_id?: string;
  bank_account_code?: string;
  bank_account_name?: string;
  date: string;
  amount: number;
  type: 'RECEIVE' | 'SPEND';
  description?: string;
  reference?: string;
  contact_name?: string;
  reconciled: boolean;
  payment_id?: string;
  reconciled_date?: string;
  created_at: string;
}

export interface PurchaseOrder {
  id: string;
  xero_po_id?: string;
  po_number: string;
  supplier_id: string;
  supplier_name?: string;
  project_id: string;
  project_code?: string;
  project_name?: string;
  status: 'DRAFT' | 'SUBMITTED' | 'AUTHORISED' | 'BILLED' | 'CANCELLED';
  date: string;
  delivery_date?: string;
  total_amount: number;
  currency: string;
  line_items: any[];
  line_items_detail?: PurchaseOrderLineItem[];
  bill_id?: string;
  notes?: string;
  created_at: string;
  updated_at: string;
}

export interface PurchaseOrderLineItem {
  id: string;
  po_id: string;
  description: string;
  quantity: number;
  unit_amount: number;
  account_code?: string;
  cost_center_id?: string;
  cost_center_code?: string;
  cost_center_name?: string;
  item_id?: string;
  line_amount: number;
}

export interface Bill {
  id: string;
  xero_bill_id?: string;
  bill_number: string;
  supplier_id: string;
  supplier_name?: string;
  purchase_order_id?: string;
  po_number?: string;
  project_id?: string;
  project_code?: string;
  project_name?: string;
  amount: number;
  amount_paid: number;
  amount_due: number;
  currency: string;
  date: string;
  due_date?: string;
  status: 'DRAFT' | 'SUBMITTED' | 'AUTHORISED' | 'PAID' | 'VOIDED';
  paid_date?: string;
  line_items: any[];
  created_at: string;
  updated_at: string;
}

export interface Expense {
  id: string;
  xero_expense_id?: string;
  project_id?: string;
  project_code?: string;
  project_name?: string;
  cost_center_id?: string;
  cost_center_code?: string;
  cost_center_name?: string;
  amount: number;
  date: string;
  description: string;
  receipt_url?: string;
  status: 'DRAFT' | 'SUBMITTED' | 'APPROVED' | 'PAID';
  created_at: string;
  updated_at: string;
}

export interface CreditNote {
  id: string;
  xero_credit_note_id?: string;
  credit_note_number: string;
  invoice_id: string;
  invoice_number?: string;
  client_name?: string;
  amount: number;
  date: string;
  reason?: string;
  status: 'DRAFT' | 'SUBMITTED' | 'AUTHORISED' | 'VOIDED';
  created_at: string;
  updated_at: string;
}

export interface XeroItem {
  id: string;
  xero_item_id: string;
  code?: string;
  name: string;
  description?: string;
  purchase_price: number;
  sale_price: number;
  stock_level: number;
  is_tracked: boolean;
  synced_at?: string;
}

export interface PaymentReminder {
  id: string;
  invoice_id: string;
  invoice_number?: string;
  client_name?: string;
  sent_date: string;
  reminder_type: string;
  sent_to: string;
  created_at: string;
}

export interface ProjectFinancials {
  project: {
    id: string;
    code: string;
    name: string;
  };
  financials: {
    budget: number;
    po_commitments: number;
    actual_cost: number;
    available_budget: number;
  };
  purchase_orders: {
    total_count: number;
    total_committed: number;
    draft_count: number;
    authorised_count: number;
    billed_count: number;
  };
  bills: {
    total_count: number;
    total_amount: number;
    total_paid: number;
    total_due: number;
  };
  expenses: {
    total_count: number;
    total_amount: number;
  };
}

export interface Setting {
  key: string;
  value: any;
  user_id?: string;
}

export interface ActivityLog {
  id: string;
  user_id: string;
  user_name?: string;
  user_email?: string;
  action: string;
  entity_type: string;
  entity_id?: string;
  details: any;
  ip_address?: string;
  created_at: string;
}

export type NotificationType = 'info' | 'success' | 'warning' | 'error';

export interface AppNotification {
  id: string;
  type: NotificationType;
  title: string;
  message: string;
  action?: {
    label: string;
    href?: string;
    onClick?: () => void;
  };
  read: boolean;
  created_at: string;
}

export interface ErrorLogEntry {
  id: string;
  type: 'api' | 'client' | 'auth' | 'network' | 'unknown';
  message: string;
  details?: string;
  stack?: string;
  endpoint?: string;
  user_id?: string;
  user_name?: string;
  created_at: string;
}

export interface ProjectFile {
  id: string;
  project_id: string;
  cost_center_id?: string;
  file_name: string;
  file_path: string;
  file_type: 'image' | 'pdf' | 'document';
  file_size: number;
  mime_type?: string;
  uploaded_by?: string;
  uploaded_by_name?: string;
  project_code?: string;
  project_name?: string;
  client_name?: string;
  cost_center_code?: string;
  cost_center_name?: string;
  created_at: string;
  updated_at: string;
}

export interface SafetyDocument {
  id: string;
  project_id: string;
  cost_center_id?: string;
  document_type: 'jsa' | 'electrical_compliance' | 'electrical_safety_certificate';
  title: string;
  data: JSAData | ComplianceData | SafetyCertificateData;
  file_path?: string;
  status: 'draft' | 'completed' | 'approved';
  created_by?: string;
  created_by_name?: string;
  approved_by?: string;
  approved_by_name?: string;
  approved_at?: string;
  project_code?: string;
  project_name?: string;
  client_name?: string;
  cost_center_code?: string;
  cost_center_name?: string;
  created_at: string;
  updated_at: string;
}

export interface JSAData {
  job_description: string;
  location: string;
  date: string;
  prepared_by?: string;
  prepared_by_name?: string;
  prepared_by_date?: string;
  approved_by_name?: string;
  approved_by_date?: string;
  hazards?: Array<{
    description: string;
    risk_level: string;
    control_measures: string;
  }>;
  notes?: string;
}

export interface ComplianceData {
  certificate_number: string;
  issue_date: string;
  location: string;
  description: string;
  installation_date?: string;
  testing_results?: string | Array<{
    test: string;
    result: string;
  }>;
  compliance_standards?: string[];
  inspector_name?: string;
  inspector_license?: string;
  inspection_date?: string;
  inspector_signature_date?: string;
}

export interface SafetyCertificateData {
  certificate_number: string;
  issue_date: string;
  expiry_date?: string;
  location: string;
  description: string;
  safety_checks?: Array<{
    check: string;
    status: string;
    notes?: string;
  }>;
  inspector_name?: string;
  inspector_license?: string;
  inspection_date?: string;
  inspector_signature_date?: string;
}

export interface Backup {
  id: string;
  backup_type: 'full' | 'database' | 'files';
  storage_type: 'local' | 'google_drive';
  file_path?: string;
  file_size?: number;
  google_drive_file_id?: string;
  status: 'pending' | 'completed' | 'failed';
  error_message?: string;
  created_by?: string;
  created_by_name?: string;
  created_at: string;
  expires_at?: string;
}
--- FILE: src/vite-env.d.ts ---
/// <reference types="vite/client" />
--- FILE: tailwind.config.js ---
/** @type {import('tailwindcss').Config} */
module.exports = {
  darkMode: ["class"],
  content: [
    './pages/**/*.{ts,tsx}',
    './components/**/*.{ts,tsx}',
    './app/**/*.{ts,tsx}',
    './src/**/*.{ts,tsx}',
  ],
  prefix: "",
  theme: {
  	container: {
  		center: true,
  		padding: '2rem',
  		screens: {
  			'2xl': '1400px'
  		}
  	},
  	extend: {
  		colors: {
  			border: 'hsl(var(--border))',
  			input: 'hsl(var(--input))',
  			ring: 'hsl(var(--ring))',
  			background: 'hsl(var(--background))',
  			foreground: 'hsl(var(--foreground))',
  			primary: {
  				DEFAULT: 'hsl(var(--primary))',
  				foreground: 'hsl(var(--primary-foreground))'
  			},
  			secondary: {
  				DEFAULT: 'hsl(var(--secondary))',
  				foreground: 'hsl(var(--secondary-foreground))'
  			},
  			destructive: {
  				DEFAULT: 'hsl(var(--destructive))',
  				foreground: 'hsl(var(--destructive-foreground))'
  			},
  			muted: {
  				DEFAULT: 'hsl(var(--muted))',
  				foreground: 'hsl(var(--muted-foreground))'
  			},
  			accent: {
  				DEFAULT: 'hsl(var(--accent))',
  				foreground: 'hsl(var(--accent-foreground))'
  			},
  			popover: {
  				DEFAULT: 'hsl(var(--popover))',
  				foreground: 'hsl(var(--popover-foreground))'
  			},
  			card: {
  				DEFAULT: 'hsl(var(--card))',
  				foreground: 'hsl(var(--card-foreground))'
  			},
  			sidebar: {
  				DEFAULT: 'hsl(var(--sidebar-background))',
  				foreground: 'hsl(var(--sidebar-foreground))',
  				primary: 'hsl(var(--sidebar-primary))',
  				'primary-foreground': 'hsl(var(--sidebar-primary-foreground))',
  				accent: 'hsl(var(--sidebar-accent))',
  				'accent-foreground': 'hsl(var(--sidebar-accent-foreground))',
  				border: 'hsl(var(--sidebar-border))',
  				ring: 'hsl(var(--sidebar-ring))'
  			}
  		},
  		borderRadius: {
  			lg: 'var(--radius)',
  			md: 'calc(var(--radius) - 2px)',
  			sm: 'calc(var(--radius) - 4px)'
  		},
  		keyframes: {
  			'accordion-down': {
  				from: {
  					height: '0'
  				},
  				to: {
  					height: 'var(--radix-accordion-content-height)'
  				}
  			},
  			'accordion-up': {
  				from: {
  					height: 'var(--radix-accordion-content-height)'
  				},
  				to: {
  					height: '0'
  				}
  			}
  		},
  		animation: {
  			'accordion-down': 'accordion-down 0.2s ease-out',
  			'accordion-up': 'accordion-up 0.2s ease-out'
  		}
  	}
  },
  plugins: [require("tailwindcss-animate")],
}--- FILE: vite.config.ts ---
import path from "path";
import { defineConfig } from "vite";
import react from "@vitejs/plugin-react-swc";

// https://vitejs.dev/config/
export default defineConfig({
  base: process.env.NODE_ENV === "development" ? "/" : process.env.VITE_BASE_PATH || "/",
  optimizeDeps: {
    entries: ["src/main.tsx"],
  },
  plugins: [
    react(),
  ],
  resolve: {
    preserveSymlinks: true,
    alias: {
      "@": path.resolve(__dirname, "./src"),
    },
  },
  server: {
    // @ts-ignore
    allowedHosts: true,
  },
  build: {
    rollupOptions: {
      output: {
        manualChunks: {
          // Vendor chunks - separate large libraries
          'react-vendor': ['react', 'react-dom', 'react-router', 'react-router-dom'],
          'ui-vendor': [
            '@radix-ui/react-dialog',
            '@radix-ui/react-dropdown-menu',
            '@radix-ui/react-select',
            '@radix-ui/react-tabs',
            '@radix-ui/react-toast',
            '@radix-ui/react-popover',
            '@radix-ui/react-checkbox',
            '@radix-ui/react-label',
          ],
          'chart-vendor': ['recharts'],
          'form-vendor': ['react-hook-form', '@hookform/resolvers', 'zod'],
          'utils-vendor': ['date-fns', 'lucide-react', 'sonner'],
        },
        // Optimize chunk file names
        chunkFileNames: 'assets/[name]-[hash].js',
        entryFileNames: 'assets/[name]-[hash].js',
        assetFileNames: 'assets/[name]-[hash].[ext]',
      },
    },
    // Increase chunk size warning limit (optional, but we're splitting so this is fine)
    chunkSizeWarningLimit: 600,
  },
});
